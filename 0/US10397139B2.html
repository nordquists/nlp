
    <html>
        <body>
            <search-app>
                <article class="result" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
    <h1 itemprop="pageTitle">US10397139B2 - Storage device in which forwarding-function-equipped memory nodes are mutually connected and data processing method 
        - Google Patents</h1><section itemprop="abstract" itemscope="">
<h2>Abstract</h2>
<div html="" itemprop="content"><abstract lang="EN" load-source="patent-office" mxw-id="PA307951769">
<div class="abstract" id="p-0001" num="0000">According to one embodiment, a storage device includes a plurality of memory nodes. Each of memory nodes includes a plurality of input ports, a plurality of output ports, a selector, a packet controller and a memory. The selector outputs a packet input to the input port to one of the output ports. The packet controller controls the selector. The memory stores data. The memory nodes are mutually connected at the input ports and the output ports. The memory node has an address that is determined by its physical position. The packet controller switches the output port that outputs the packet based on information including at least a destination address of the packet and an address of the memory node having the packet controller when receiving a packet that is not addressed to the memory node having the packet controller.</div>
</abstract>
</div>
</section><section itemprop="description" itemscope="">
<h2>Description</h2>
<div html="" itemprop="content"><div class="description" lang="EN" load-source="patent-office" mxw-id="PDES200776737">
<heading id="h-0001">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<div class="description-paragraph" id="p-0002" num="0001">This application is a continuation of U.S. application Ser. No. 14/974,245, filed on Dec. 18, 2015, which is a continuation of U.S. application Ser. No. 13/293,399, filed Nov. 10, 2011, now U.S. Pat. No. 9,246,709, which claims priority to Japanese Patent Application No. 2010-252336, filed on Nov. 10, 2010, the entire contents of each of which are incorporated herein by reference.</div>
<heading id="h-0002">FIELD</heading>
<div class="description-paragraph" id="p-0003" num="0002">Embodiments described herein relate generally to a storage device in which forwarding-function-equipped memory nodes are mutually connected and a data processing method, for example, to a data packet forwarding control method in the storage device.</div>
<heading id="h-0003">BACKGROUND</heading>
<div class="description-paragraph" id="p-0004" num="0003">A storage device in which forwarding-function-equipped memory nodes are mutually connected is conceivable as a storage device in which a capacity can easily be expanded. Each memory node performs given processing such as read and write in the case that the memory node receives a data packet addressed thereto. On the other hand, in the case that the memory node receives the data packet that is not addressed thereto, the memory node properly forwards the received data packet to another memory node. Each memory node properly performs the forwarding, which allows the data packet to reach the destination memory node.</div>
<div class="description-paragraph" id="p-0005" num="0004">Each memory node includes a memory, a controller equipped with the forwarding function, and ports. Each memory node maintains and manages a routing table indicating a forwarding destination of the packet, and forwards the packet according to the routing table. When the routing table is managed, any logical packet forwarding network can foe constructed irrespective of the physical position of each memory node.</div>
<div class="description-paragraph" id="p-0006" num="0005">However, in the case that a new memory node is added in order to expand the capacity, or in the case that the existing memory node is removed due to a malfunction and the like, it is necessary to update the routing table of each memory node, and a procedure to update the routing table becomes troublesome. In the case that the number of memory nodes is significantly increased, a huge amount of computing cost is necessary to maintain and manage the routing table, which sets a restriction to expandability of the capacity.</div>
<div class="description-paragraph" id="p-0007" num="0006">In the storage device in which the forwarding-function-equipped memory nodes are mutually connected, when a plurality of pieces of data are written or read to/from the memory nodes, generally it is difficult to simultaneously conduct communication of the data through the same line, which easily generates forwarding waiting of the data. The forwarding waiting of the data leads to increase a time necessary to write and read the data.</div>
<description-of-drawings>
<heading id="h-0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<div class="description-paragraph" id="p-0008" num="0007"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a view illustrating a configuration of a storage device according to a first embodiment;</div>
<div class="description-paragraph" id="p-0009" num="0008"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a view illustrating a configuration of a memory node in the first embodiment;</div>
<div class="description-paragraph" id="p-0010" num="0009"> <figref idrefs="DRAWINGS">FIGS. 3A, 3B, 3C, 3D, and 3B</figref> are views illustrating disposition examples of the memory nodes in the first embodiment;</div>
<div class="description-paragraph" id="p-0011" num="0010"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a view illustrating a forwarding algorithm 1 in the storage device of the first embodiment;</div>
<div class="description-paragraph" id="p-0012" num="0011"> <figref idrefs="DRAWINGS">FIGS. 5A and 5B</figref> are views illustrating a packet forwarding procedure by the forwarding algorithm 1 in the first embodiment;</div>
<div class="description-paragraph" id="p-0013" num="0012"> <figref idrefs="DRAWINGS">FIG. 5C</figref> is a flowchart of the packet forwarding procedure by the forwarding algorithm 1 in the first embodiment;</div>
<div class="description-paragraph" id="p-0014" num="0013"> <figref idrefs="DRAWINGS">FIG. 5D</figref> is a view illustrating an example of the packet forwarding procedure by the forwarding algorithm 1 in the first embodiment;</div>
<div class="description-paragraph" id="p-0015" num="0014"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a view illustrating a configuration of a storage system including a storage device of the first embodiment;</div>
<div class="description-paragraph" id="p-0016" num="0015"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a view illustrating a write operation in the storage system of the first embodiment;</div>
<div class="description-paragraph" id="p-0017" num="0016"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a view illustrating a read operation in the storage system of the first embodiment;</div>
<div class="description-paragraph" id="p-0018" num="0017"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a view illustrating an automatic address acquiring method in the storage device of the first embodiment;</div>
<div class="description-paragraph" id="p-0019" num="0018"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a view illustrating a forwarding algorithm 2 in a storage device according to a second embodiment;</div>
<div class="description-paragraph" id="p-0020" num="0019"> <figref idrefs="DRAWINGS">FIGS. 11A and 11B</figref> are views illustrating a packet forwarding procedure by the forwarding algorithm 2 in the second embodiment;</div>
<div class="description-paragraph" id="p-0021" num="0020"> <figref idrefs="DRAWINGS">FIG. 11C</figref> is a flowchart of the packet forwarding procedure by the forwarding algorithm 2 in the second embodiment;</div>
<div class="description-paragraph" id="p-0022" num="0021"> <figref idrefs="DRAWINGS">FIG. 11D</figref> is a view illustrating an example of the packet forwarding procedure by the forwarding algorithm 2 in the second embodiment;</div>
<div class="description-paragraph" id="p-0023" num="0022"> <figref idrefs="DRAWINGS">FIG. 12A</figref> is a view illustrating an example of the packet forwarding procedure by the forwarding algorithm 1;</div>
<div class="description-paragraph" id="p-0024" num="0023"> <figref idrefs="DRAWINGS">FIG. 12B</figref> is a view illustrating an example of the packet forwarding procedure by the forwarding algorithm 2;</div>
<div class="description-paragraph" id="p-0025" num="0024"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a view illustrating a forwarding algorithm 3 in a storage device according to a third embodiment;</div>
<div class="description-paragraph" id="p-0026" num="0025"> <figref idrefs="DRAWINGS">FIGS. 14A and 14B</figref> are views illustrating a packet forwarding procedure by the forwarding algorithm 3 in the third embodiment;</div>
<div class="description-paragraph" id="p-0027" num="0026"> <figref idrefs="DRAWINGS">FIG. 14C</figref> is a flowchart of the packet forwarding procedure by the forwarding algorithm 3 in the third embodiment;</div>
<div class="description-paragraph" id="p-0028" num="0027"> <figref idrefs="DRAWINGS">FIG. 14D</figref> is a view illustrating an example of the packet forwarding procedure by the forwarding algorithm 3 in the third embodiment;</div>
<div class="description-paragraph" id="p-0029" num="0028"> <figref idrefs="DRAWINGS">FIG. 15</figref> is a view illustrating a forwarding algorithm 4 in the storage device of the third embodiment;</div>
<div class="description-paragraph" id="p-0030" num="0029"> <figref idrefs="DRAWINGS">FIG. 16</figref> is a view illustrating a forwarding algorithm 5 in the storage device of the third embodiment;</div>
<div class="description-paragraph" id="p-0031" num="0030"> <figref idrefs="DRAWINGS">FIG. 17</figref> is a view illustrating a configuration of a storage system according to a fourth embodiment;</div>
<div class="description-paragraph" id="p-0032" num="0031"> <figref idrefs="DRAWINGS">FIG. 18</figref> is a view illustrating a bypass transfer occurrence rate and jam occurrence rate in the storage system of the fourth embodiment;</div>
<div class="description-paragraph" id="p-0033" num="0032"> <figref idrefs="DRAWINGS">FIG. 19</figref> is a view illustrating a configuration of a storage device according to a fifth embodiment;</div>
<div class="description-paragraph" id="p-0034" num="0033"> <figref idrefs="DRAWINGS">FIG. 20</figref> is a view illustrating a configuration of a storage system according to a sixth embodiment;</div>
<div class="description-paragraph" id="p-0035" num="0034"> <figref idrefs="DRAWINGS">FIG. 21</figref> is a view illustrating another configuration of the storage system of the sixth embodiment;</div>
<div class="description-paragraph" id="p-0036" num="0035"> <figref idrefs="DRAWINGS">FIG. 22</figref> is a view illustrating a configuration of a storage system according to a seventh embodiment;</div>
<div class="description-paragraph" id="p-0037" num="0036"> <figref idrefs="DRAWINGS">FIG. 23</figref> is a view illustrating a comparative example of the storage system of the seventh embodiment;</div>
<div class="description-paragraph" id="p-0038" num="0037"> <figref idrefs="DRAWINGS">FIG. 24</figref> is a view illustrating address information recorded in a header portion of the packet in the seventh embodiment;</div>
<div class="description-paragraph" id="p-0039" num="0038"> <figref idrefs="DRAWINGS">FIG. 25</figref> is a view illustrating a write operation in the storage system of the seventh embodiment;</div>
<div class="description-paragraph" id="p-0040" num="0039"> <figref idrefs="DRAWINGS">FIG. 26</figref> is a view illustrating another configuration of the storage system of the seventh embodiment;</div>
<div class="description-paragraph" id="p-0041" num="0040"> <figref idrefs="DRAWINGS">FIG. 27</figref> is a view illustrating a configuration of a storage system according to an eighth embodiment;</div>
<div class="description-paragraph" id="p-0042" num="0041"> <figref idrefs="DRAWINGS">FIG. 28</figref> is a view illustrating a comparative example of the storage system of the eighth embodiment;</div>
<div class="description-paragraph" id="p-0043" num="0042"> <figref idrefs="DRAWINGS">FIG. 29</figref> is a view illustrating address information recorded in the header portion of the packet in the eighth embodiment;</div>
<div class="description-paragraph" id="p-0044" num="0043"> <figref idrefs="DRAWINGS">FIG. 30</figref> is a view illustrating a write operation in the storage system of the eighth embodiment;</div>
<div class="description-paragraph" id="p-0045" num="0044"> <figref idrefs="DRAWINGS">FIGS. 31 and 32</figref> are views illustrating other configuration examples of the storage system of the eighth embodiment;</div>
<div class="description-paragraph" id="p-0046" num="0045"> <figref idrefs="DRAWINGS">FIG. 33A</figref> is a view illustrating a configuration of a storage system according to a ninth embodiment;</div>
<div class="description-paragraph" id="p-0047" num="0046"> <figref idrefs="DRAWINGS">FIGS. 33B, 33C, and 33D</figref> are views illustrating a read operation in which forwarding waiting is generated in the storage system;</div>
<div class="description-paragraph" id="p-0048" num="0047"> <figref idrefs="DRAWINGS">FIGS. 34A, 34B, 34C, 34D and 34E</figref> are views illustrating a read operation in which generation of the forwarding waiting is avoided in the storage system of the ninth embodiment;</div>
<div class="description-paragraph" id="p-0049" num="0048"> <figref idrefs="DRAWINGS">FIGS. 35A and 35B</figref> are views illustrating another example of the read operation in which the generation of the forwarding waiting is avoided in the storage system of the ninth embodiment;</div>
<div class="description-paragraph" id="p-0050" num="0049"> <figref idrefs="DRAWINGS">FIGS. 36A, 368, 36C, 36D, 36E and 36F</figref> are views illustrating other examples of the read operation in which the generation of the forwarding waiting is avoided in the storage system of the ninth embodiment;</div>
<div class="description-paragraph" id="p-0051" num="0050"> <figref idrefs="DRAWINGS">FIG. 37A</figref> is a view illustrating a configuration of a storage system according to a tenth embodiment;</div>
<div class="description-paragraph" id="p-0052" num="0051"> <figref idrefs="DRAWINGS">FIGS. 37B, 37C, 37D, 37E, 37F and 37G</figref> are views illustrating a write operation in which the forwarding waiting is generated in the storage system; and</div>
<div class="description-paragraph" id="p-0053" num="0052"> <figref idrefs="DRAWINGS">FIGS. 38A, 38B, 38C, 38D and 38E</figref> are views illustrating other examples of the write operation in which the generation of the forwarding waiting is avoided in the storage system of the tenth embodiment.</div>
</description-of-drawings>
<heading id="h-0005">DETAILED DESCRIPTION</heading>
<div class="description-paragraph" id="p-0054" num="0053">Hereinafter, embodiments will be described with reference to the drawings. In the following description, a component having the same function and configuration is designated by the same numeral, and the overlapping description is made only when required.</div>
<div class="description-paragraph" id="p-0055" num="0054">In general, according to one embodiment, a storage device includes a plurality of memory nodes. Each of memory nodes includes a plurality of input ports, a plurality of output ports, a selector, a packet controller and a memory. The selector outputs a packet input to the input port to one of the output ports. The packet controller controls the selector. The memory stores data. The memory nodes are mutually connected at the input ports and the output ports. The memory node has an address that is determined by its physical position. The packet controller switches the output port that outputs the packet based on information including at least a destination address of the packet and an address of the memory node having the packet controller when receiving a packet that is not addressed to the memory node having the packet controller.</div>
<div class="description-paragraph" id="h-0006" num="0000">[First Embodiment]</div>
<div class="description-paragraph" id="p-0056" num="0055">According to a first embodiment, a storage device in which, forwarding-function-equipped memory nodes are mutually connected has a forwarding method in which each memory node efficiently forwards a data packet.</div>
<div class="description-paragraph" id="p-0057" num="0056">[1] Configuration of Storage Device</div>
<div class="description-paragraph" id="p-0058" num="0057"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a view illustrating a configuration of the storage device of the first embodiment, and <figref idrefs="DRAWINGS">FIG. 1</figref> illustrates a method for physically disposing the memory nodes and an example of a corresponding address allocating method.</div>
<div class="description-paragraph" id="p-0059" num="0058">As illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>, a storage device <b>10</b> includes memory nodes <b>11</b> equipped with data forwarding functions. Each memory node <b>11</b> is disposed at a lattice point of a square lattice. It is assumed that a logical address of the memory node located at a lattice coordinate (x,y) is (x,y) that is matched with a position coordinate. That is, the logical address of the memory node <b>11</b> is matched with a physical address (lattice coordinate (x,y)).</div>
<div class="description-paragraph" id="p-0060" num="0059">Each memory node <b>11</b> includes four input ports <b>12</b> and four output ports <b>13</b>. Each memory node <b>11</b> is mutually connected to four adjacent memory nodes <b>11</b> through the input ports <b>12</b> and the output ports <b>13</b>. Specifically, the input port <b>12</b> and the output port <b>13</b> of the two adjacent memory nodes that are opposite each other are connected to each other.</div>
<div class="description-paragraph" id="p-0061" num="0060"> <figref idrefs="DRAWINGS">FIG. 2</figref> illustrates a configuration of each memory node <b>11</b>. The memory node <b>11</b> includes the input port <b>12</b>, an input port buffer <b>12</b>A, the output port <b>13</b>, an output port buffer <b>13</b>A, a selector <b>14</b>, a packet controller <b>15</b>, a memory <b>16</b>, a memory controller <b>17</b>, an MPU <b>18</b>, and a local bus <b>19</b>.</div>
<div class="description-paragraph" id="p-0062" num="0061">A packet input to the input port <b>12</b> is temporarily stored in the input port buffer <b>12</b>A. The packet is input to the selector <b>14</b> from the input port buffer <b>12</b>A, and a control signal is input to the selector <b>14</b> from the packet controller <b>15</b>. The selector <b>14</b> selects one of the input packets and outputs the selected packet to the output port buffer <b>13</b>A in response to the control signal. The output port buffer <b>13</b>A temporarily stores the packet output from the selector <b>14</b>, and outputs the packet to the output port <b>13</b>. The packet controller <b>15</b> controls the output of the selector <b>14</b>. As used herein, the packet means a formatted unit of transferring data that includes a header portion including at least a destination address and a source address and a data portion.</div>
<div class="description-paragraph" id="p-0063" num="0062">The memory <b>16</b> includes memory cells in which pieces of data are stored. For example, the memory <b>16</b> includes a NAND flash memory. The memory controller <b>17</b> controls write, read, and erase operations with respect to the memory <b>16</b>. The MPU <b>18</b> performs arithmetic processing necessary in the memory node. The local bus <b>19</b> mutually connects the input port buffer <b>12</b>A, the packet controller <b>15</b>, the memory controller <b>17</b>, and the MPU <b>18</b> to perform signal transmission.</div>
<div class="description-paragraph" id="p-0064" num="0063">The packet received by the memory node <b>11</b> is stored in the input port, buffer <b>12</b>A through the input port <b>12</b>. The packet controller <b>15</b> determines whether the received packet is addressed to the memory node (hereinafter referred to as a self-node) of the packet controller <b>15</b> based on two pieces of information on the destination (target) address included in the packet and the address of the self-node.</div>
<div class="description-paragraph" id="p-0065" num="0064">When the received packet is addressed to the self-node, the packet controller <b>15</b> performs the write or read operation or given processing with respect to the memory <b>16</b> of the self-node. When the received packet is not addressed to the self-node, the packet controller <b>15</b> determines the adjacent memory node to which the packet is forwarded based on the two pieces of information on the destination address and the address of the self-node, and the selector <b>14</b> outputs the packet to the corresponding output port buffer <b>13</b>A.</div>
<div class="description-paragraph" id="p-0066" num="0065">In the storage device illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>, the memory node is disposed at the lattice point of the square lattice. However the first embodiment is not limited to the storage device illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>. Examples will be described below with reference to <figref idrefs="DRAWINGS">FIGS. 3A to 3E</figref>.</div>
<div class="description-paragraph" id="p-0067" num="0066">A configuration illustrated in <figref idrefs="DRAWINGS">FIG. 3A</figref> corresponds to the example illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>. More generally, in the first embodiment, each memory node is disposed at the lattice point. Here, the lattice points are sets of regularly placed points in a plane. Both the x-coordinate and the y-coordinate of each lattice point are integers. The lattice points also include the case in which the length of the unit vector in the x-direction (e<sub>x</sub>) differs from that of the unit vector in the y-direction (e<sub>y</sub>), that is, the case in which the repetition period in the x-direction differs from that in the y-direction. <figref idrefs="DRAWINGS">FIG. 3B</figref> illustrates this example.</div>
<div class="description-paragraph" id="p-0068" num="0067">The lattice also includes the case in which the unit vectors in the x-direction and the y-direction are not orthogonal to each other, namely, the case in which an x-axis and a y-axis are not orthogonal to each other. <figref idrefs="DRAWINGS">FIG. 3C</figref> illustrates this example. The number of mutual connection ports of the memory node is not limited to 4. <figref idrefs="DRAWINGS">FIG. 3D</figref> illustrates an example in which the number of mutual connection ports is 6.</div>
<div class="description-paragraph" id="p-0069" num="0068">In the first embodiment, in each case, it is assumed that the logical address of the memory node located at the lattice coordinate (x,y) is (x,y) that is matched with the position coordinate irrespective of the definition of the lattice. That is, the logical address of the memory node is matched with the physical address (lattice coordinate (x,y)).</div>
<div class="description-paragraph" id="p-0070" num="0069">More generally, in the first embodiment, included is the case in which a set of two or more memory nodes is disposed at each lattice point. <figref idrefs="DRAWINGS">FIG. 3E</figref> illustrates an example in which the two memory nodes are disposed at each lattice point. In the example of <figref idrefs="DRAWINGS">FIG. 3E</figref>, for example, the two memory nodes are disposed at a lattice point (1,0). It is assumed that the two memory nodes disposed at the lattice point (1,0) are (1,0,0) and (1,0,1). That is, the coordinate of one memory node is expressed by a set of three integers of (x,y,z). In this case, it is also assumed that the logical address of the memory node located at the node coordinate (x,y,z) is (x,y,z) that is matched with the position coordinate. That is, the logical address of the memory node is matched with the physical address (lattice coordinate (x,y,z)). In addition, in the first embodiment, also included is the case in which the plane in which the lattice points are disposed is three-dimensionally bent or folded.</div>
<div class="description-paragraph" id="p-0071" num="0070">The adjacent memory node means a memory node having the following positional relationship in <figref idrefs="DRAWINGS">FIGS. 3A to 3E</figref>. In <figref idrefs="DRAWINGS">FIGS. 3A to 3C</figref>, for example, in the case that the self-node exists at the coordinate (1,1), the memory node adjacent to the self-node means the four memory nodes that exist at the coordinates (0,1), (1,2), (2,1), and (1,0). In <figref idrefs="DRAWINGS">FIG. 3D</figref>, for example, in the case that the self-node exists at the coordinate (<b>1</b>,<b>1</b>), the memory node adjacent to the self-node means the six memory nodes that exist at the coordinates (0,1), (0,2), (1,2), (2,1), (2,0), and (1,0). In <figref idrefs="DRAWINGS">FIG. 3E</figref>, for example, in the case that the self-node exists at the coordinate (1,0,1), the memory node adjacent to the self-nods means the three memory nodes that exist at the coordinates (0,1,0), (1,1,0), and (1,0,0).</div>
<div class="description-paragraph" id="p-0072" num="0071">[2] Forwarding Algorithm 1 of Storage Device</div>
<div class="description-paragraph" id="p-0073" num="0072">In a forwarding algorithm 1, the memory node of the forwarding destination is determined based on two pieces of information on the destination address included in the packet and the address of the self-node.</div>
<div class="description-paragraph" id="p-0074" num="0073"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a view illustrating the forwarding algorithm 1 in the storage device of the first embodiment. An example of a method for determining the adjacent node of the forwarding destination based on the two pieces of information on the destination address included in the packet and the address of the self-node will be described with reference to <figref idrefs="DRAWINGS">FIG. 4</figref>. This method is referred to as the forwarding algorithm 1.</div>
<div class="description-paragraph" id="p-0075" num="0074">The memory node that receives the packet forwards the packet to the adjacent memory node in which a distance between the destination node (to) of the packet and the self-node (PP: Present position) is minimized.</div>
<div class="description-paragraph" id="p-0076" num="0075">A specific example of a packet forwarding process based on the forwarding algorithm 1 will be described with reference to <figref idrefs="DRAWINGS">FIGS. 5A to 5D</figref>.</div>
<div class="description-paragraph" id="p-0077" num="0076">As illustrated in <figref idrefs="DRAWINGS">FIG. 5A</figref>, it is assumed that (X<sub>to</sub>, Y<sub>to</sub>) is an address of the destination node (to), it is assumed that (X<sub>pp</sub>, y<sub>pp</sub>) is an address of the self-node (PP), and it is assumed that dx= x<sub>to</sub>−X<sub>pp </sub>and dy=y<sub>to</sub>−y<sub>pp</sub>. As illustrated in <figref idrefs="DRAWINGS">FIG. 5B</figref>, as to a direction indicating the forwarding destination, it is assumed that N (North) is a direction in which y is increased, it is assumed that E (East) is a direction in which x is increased, it is assumed that S (South) is a direction in which y is decreased, and it is assumed that W (West) is a direction in which x is decreased.</div>
<div class="description-paragraph" id="p-0078" num="0077">Assuming that |a| is a sign indicating an absolute value of a, the packet proceeds in the x-direction in the case of |dx|&gt;|dy|, and the packet proceeds in the y-direction in the case of |dx|&lt;|dy|. In the case that the packet proceeds in the x-direction, the packet is forwarded to E in the case of dx &gt;0, and the packet is forwarded to W in the case of dx &lt;0. Similarly, in the case that the packet proceeds in the Y-direction, the packet is forwarded to N in the case of dy &gt; 0, and the packet is forwarded to S in the case of dy &lt; 0.</div>
<div class="description-paragraph" id="p-0079" num="0078"> <figref idrefs="DRAWINGS">FIG. 5C</figref> illustrates a flowchart of the forwarding algorithm 1 in the storage device. The forwarding algorithm 1 is stored in the packet controller <b>15</b> and executed by the packet controller <b>15</b>.</div>
<div class="description-paragraph" id="p-0080" num="0079">The packet controller <b>15</b> calculates dx=x<sub>to</sub>−x<sub>pp </sub>and dy=y<sub>to</sub>−y<sub>pp </sub>(Step S<b>1</b>). Then the packet controller <b>15</b> determines whether dx is 0 (Step S<b>2</b>). When dx is 0, the packet controller <b>15</b> determines whether y<sub>to</sub>&gt;y<sub>pp </sub>holds (Step S<b>3</b>). When y<sub>to</sub>&gt;y<sub>pp </sub>holds, the packet controller <b>15</b> forwards the packet to N (Step S<b>4</b>). On the other hand, when y<sub>to</sub>&gt;y<sub>pp </sub>does not hold, the packet controller <b>15</b> forwards the packet to S (Step S<b>5</b>).</div>
<div class="description-paragraph" id="p-0081" num="0080">When dx is not 0 in Step S<b>2</b>, the packet controller <b>15</b> determines whether dy is 0 (Step S<b>6</b>). When dy is 0, the packet controller <b>15</b> determines whether x<sub>to</sub>&gt; x<sub>pp </sub>holds (Step S<b>7</b>). When x<sub>to</sub>&gt;x<sub>pp </sub>holds, the packet controller <b>15</b> forwards the packet to E (Step S<b>8</b>). On the other hand, when x<sub>to</sub>&gt;x<sub>pp </sub>does not hold, the packet controller <b>15</b> forwards the packet to W (Step S<b>9</b>).</div>
<div class="description-paragraph" id="p-0082" num="0081">When dy is not 0 in Step S<b>6</b>, namely, when dx and dy are not 0, the packet controller <b>15</b> determines whether dx &gt;0 and dy &gt;0 hold (Step S<b>10</b>). When dx &gt;0 and dy &gt;0 hold, the packet controller <b>15</b> determines whether dx &gt;dy holds (Step S<b>11</b>). When dx&gt;dy holds, the packet controller <b>15</b> forwards the packet to E (Step S<b>12</b>). On the other hand, when dx&gt;dy does not hold, the packet controller <b>15</b> forwards the packet to N (Step S<b>13</b>).</div>
<div class="description-paragraph" id="p-0083" num="0082">When dx &gt;0 and dy &gt;0 do not hold in Step S<b>10</b>, the packet controller <b>15</b> determines whether dx &lt;0 and dy &gt;0 hold (Step S<b>14</b>). When dx &lt;0 and dy &gt;0 hold, the packet controller <b>15</b> determines whether (−1)·dx&gt;dy holds (Step S<b>15</b>). When (−1)·dx&gt;dy holds, the packet controller <b>15</b> forwards the packet to W (Step S<b>16</b>). On the other hand, when (−1)·dx &gt;dy does not hold, the packet controller <b>15</b> forwards the packet to N (Step S<b>17</b>).</div>
<div class="description-paragraph" id="p-0084" num="0083">When dx&lt;0 and dy&gt;0 do not hold in Step S<b>14</b>, the packet controller <b>15</b> determines whether dx&lt;0 and dy&lt;0 hold (Step S<b>18</b>). When dx&lt;0 and dy&lt;0 hold, the packet controller <b>15</b> determines whether dx&gt;dy holds (Step S<b>19</b>). When dx&gt;dy holds, the packet controller <b>15</b> forwards the packet to S (Step S<b>20</b>). On the other hand, when dx&gt;dy does not hold, the packet controller <b>15</b> forwards the packet to W (Step S<b>21</b>).</div>
<div class="description-paragraph" id="p-0085" num="0084">When dx&lt;0 and dy&lt;0do not hold in Step S<b>18</b>, the packet controller <b>15</b> determines whether dx&gt;(−1)·dy holds (Step S<b>22</b>). When dx&gt;(−1)·dy holds, the packet controller <b>15</b> forwards the packet to E (Step S<b>23</b>). On the other hand, when dx&gt;(−1)·dy does not hold, the packet controller <b>15</b> forwards the packet to S (Step S<b>24</b>).</div>
<div class="description-paragraph" id="p-0086" num="0085">Through the above processing, the packet input to the memory node is forwarded to the adjacent memory node in which the distance between the destination node (to) and the self-node (PP) is minimized,</div>
<div class="description-paragraph" id="p-0087" num="0086"> <figref idrefs="DRAWINGS">FIG. 5D</figref> illustrates a specific example of the packet forwarding process. In the forwarding algorithm 1, the packet proceeds in the x-direction until |dx|=|dy| in the case of |dx|&gt;|dy|, and the packet proceeds continuously in the y-direction in the case of |dx|&lt;|dy|, and the packet proceeds mutually in the x-direction and the y-direction after |dx|=|dy|.</div>
<div class="description-paragraph" id="p-0088" num="0087">For example, in the case <b>1</b>, because of dx=0 and dy&gt;0, the packet proceeds to N until reaching the destination node (to). In the case <b>4</b>, because of dx&gt;0 and dy&gt;0 and dx&lt;dy, the packet proceeds continuously to N until dx=dy, and the packet proceeds mutually to E and N after dx=dy.</div>
<div class="description-paragraph" id="p-0089" num="0088">[3] Storage System including Storage Device</div>
<div class="description-paragraph" id="p-0090" num="0089"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a view illustrating a configuration of a storage system including the storage device of the first embodiment.</div>
<div class="description-paragraph" id="p-0091" num="0090">A storage system <b>20</b> is one in which a client uses the storage device, and the storage system <b>20</b> includes the following configuration.</div>
<div class="description-paragraph" id="p-0092" num="0091">The storage device <b>10</b> is connected to the client through a gateway server. In the case that the communication protocol in the storage device <b>10</b> differs from the communication protocols of gateway servers <b>21</b>A and <b>21</b>B, adapters <b>22</b>A and <b>22</b>B may be placed therebetween.</div>
<div class="description-paragraph" id="p-0093" num="0092">Particularly, the memory node (1,4) disposed in an outer peripheral portion of the storage device <b>10</b> is connected to a client <b>31</b>A through the adapter <b>22</b>A and the gateway server <b>21</b>A. Similarly, the memory node (1,1) is connected to clients <b>31</b>B<b>1</b> and <b>31</b>B<b>2</b> through the adapter <b>22</b>B and the gateway server <b>21</b>B. The “memory node (x,y)” expresses the memory node having the address (x,y). The same holds true for the following description.</div>
<div class="description-paragraph" id="p-0094" num="0093">For example, each of the gateway servers <b>21</b>A and <b>21</b>B includes a computer, and has an address based on the same protocol as the memory node <b>11</b> of the storage device <b>10</b>. In <figref idrefs="DRAWINGS">FIG. 6</figref>, the gateway server <b>21</b>A has the address (0,4), and the gateway server <b>21</b>B has the address (0,1).</div>
<div class="description-paragraph" id="p-0095" num="0094">A write operation in the storage system will be described below.</div>
<div class="description-paragraph" id="p-0096" num="0095"> <figref idrefs="DRAWINGS">FIG. 7</figref> illustrates a procedure in which the client writes a file in the storage device <b>10</b>. Here the client <b>31</b>A writes the file in the storage device <b>10</b>.</div>
<div class="description-paragraph" id="p-0097" num="0096">The client <b>31</b>A transmits the file and a file ID to the gateway server <b>21</b>A (see (<b>1</b>) of <figref idrefs="DRAWINGS">FIG. 7</figref>). The file ID is an identifier that can uniquely identify the file. For example, a full path file name of ¥¥strage_system ¥home ¥cliantA ¥file1.txt in a given file system can be used as the file ID.</div>
<div class="description-paragraph" id="p-0098" num="0097">The gateway server <b>21</b>A divides the file into data packets having a defined size and allocates a packet ID to each packet. The gateway server <b>21</b>A writes the file ID and the packet IDs of the divided packets in a file table (see (<b>2</b>) of <figref idrefs="DRAWINGS">FIG. 7</figref>). The packet ID is an identifier that can uniquely identify the packet. For example, “file ID+continuous number” of . . . \file1. text_ 1 and . . . \file1.txt<sup>−</sup>2 can be allocated as the packet ID.</div>
<div class="description-paragraph" id="p-0099" num="0098">The gateway server <b>21</b>A determines the address (hereinafter referred to as a write node address) of the memory node in which the packet is written based on the information on the packet ID (see (<b>3</b>) of <figref idrefs="DRAWINGS">FIG. 7</figref>). At this point, a node de termini rig technique called a consistent hashing (see Document 1) used in a large-scale distributed file system may be used. The consistent hashing has an advantage that the write nods address is determined using both a hash value of the node address and a hash value of the packet ID.</div>
<div class="description-paragraph" id="p-0100" num="0099">[Document 1]: “Cloud technology seizing far side of cloud world” edited by Fujio Maruyama and Kazuyuki Shuto, ASCII MEDIA WORKS, Nov. 6, 2009, p.88, ISBN978-4-04-868064-6</div>
<div class="description-paragraph" id="p-0101" num="0100">Then the gateway server <b>21</b>A sets the write node address to the destination address while setting the address of the gateway server <b>21</b>A to the source address, and transmits the write packet to the storage device <b>10</b> (see (<b>4</b>) and (<b>5</b>) of <figref idrefs="DRAWINGS">FIG. 7</figref>).</div>
<div class="description-paragraph" id="p-0102" num="0101">The forwarding is properly repeated in the storage device <b>10</b> according to the forwarding algorithm 1, whereby the packet transmitted to the memory node (1,4) from the gateway server <b>21</b>A reaches the memory node of the destination address (see (<b>6</b>) of <figref idrefs="DRAWINGS">FIG. 7</figref>). In the target memory node, the received packet is written in the memory <b>16</b> of the self-node (see (<b>7</b>) of <figref idrefs="DRAWINGS">FIG. 7</figref>). Then a write completion packet is sent back to the gateway server <b>21</b>A (see (<b>8</b>) of <figref idrefs="DRAWINGS">FIG. 7</figref>).</div>
<div class="description-paragraph" id="p-0103" num="0102">A read operation in the storage system will be described below.</div>
<div class="description-paragraph" id="p-0104" num="0103"> <figref idrefs="DRAWINGS">FIG. 8</figref> illustrates a procedure in which the client reads the file from the storage device <b>10</b>. Here, the client <b>31</b>A reads the file from the storage device <b>10</b>.</div>
<div class="description-paragraph" id="p-0105" num="0104">The client <b>31</b>A transmits a read request (file ID) to the gateway server <b>21</b>A (see (<b>1</b>) of <figref idrefs="DRAWINGS">FIG. 8</figref>).</div>
<div class="description-paragraph" id="p-0106" num="0105">The gateway server <b>21</b>A acquires the packet ID corresponding to the file ID from the file table (see (<b>2</b>) of <figref idrefs="DRAWINGS">FIG. 8</figref>). The gateway server <b>21</b>A determines the address (hereinafter referred to as a read node address) of the memory node from which the data is read based on the information on the packet ID (see (<b>3</b>) of <figref idrefs="DRAWINGS">FIG. 8</figref>). At this point, the node determining technique called the consistent hashing used in the large-scale distributed file system may be used.</div>
<div class="description-paragraph" id="p-0107" num="0106">The gateway server <b>21</b>A sets the read node address to the destination address while setting the address of the gateway server <b>21</b>A to the source address, and transmits the read packet to the storage device <b>10</b> (see (<b>4</b>) and (<b>5</b>) of <figref idrefs="DRAWINGS">FIG. 8</figref>).</div>
<div class="description-paragraph" id="p-0108" num="0107">The forwarding is properly repeated in the storage device <b>10</b> according to the forwarding algorithm 1, whereby the packet transmitted to the memory node (<b>1</b>,<b>4</b>) reaches the memory node of the destination address (see (<b>6</b>) of <figref idrefs="DRAWINGS">FIG. 8</figref>). In the target memory node, the target data is read from the memory <b>16</b> of the self-node according to the read packet (see (<b>7</b>) of <figref idrefs="DRAWINGS">FIG. 8</figref>). Then the read data is sent back as the data packet to the gateway server <b>21</b>A (see (<b>8</b>) of <figref idrefs="DRAWINGS">FIG. 8</figref>).</div>
<div class="description-paragraph" id="p-0109" num="0108">In the system illustrated in <figref idrefs="DRAWINGS">FIG. 6</figref>, the gateway server may perform write data randomizing processing (Rand processing), providing an Error-Correcting Code (ECC) to the write data, and a function (ECC function) of detecting and correcting an error of the read data using the ECC. In this case, it is not necessary for the memory controller of each memory node to have the write data randomizing processing function and the ECC function. Additionally, it is not necessary to perform the ECC processing during communication between the memory nodes. Therefore, cost per memory node can be reduced.</div>
<div class="description-paragraph" id="p-0110" num="0109">[4] Expandability of Storage Device</div>
<div class="description-paragraph" id="p-0111" num="0110">A method for adding a new memory node to the storage device will be described.</div>
<div class="description-paragraph" id="p-0112" num="0111"> <figref idrefs="DRAWINGS">FIG. 9</figref> illustrates an automatic address acquiring method when the new memory node is added to the storage device.</div>
<div class="description-paragraph" id="p-0113" num="0112">In the storage device <b>10</b> of the first embodiment, because the logical address of the memory node located at the lattice coordinate (x,y) is (x,y) that is matched with the position coordinate, the additional memory node makes an inquiry of the address to the adjacent node to be able to easily determine the address of the self-node.</div>
<div class="description-paragraph" id="p-0114" num="0113">For example, when the additional memory node makes the inquiry of the address to the adjacent node located in the W-direction, assuming that (x,y) is the address of the adjacent node, the address of the additional node becomes (x+1,y). Similarly, when the additional memory node makes the inquiry of the address to the adjacent nodes (x,y) located in the N-, E-, and S-direction, the address of the self-node becomes (x, y−1), (x−1, y), and (x, y+1), respectively.</div>
<div class="description-paragraph" id="p-0115" num="0114"> <figref idrefs="DRAWINGS">FIG. 9</figref> illustrates the case in which the new memory node is added in the E-direction of the memory node (4,4). The additional memory node transmits an address request packet in which “to” and “from” are none to the adjacent node (4,4) located in the W-direction. The memory node (4,4) that receives the address_ request packet sets an address_ answer packet, in which “from” is set to the self-node address while “to” is set to (5,4), to an output port buffer of the memory node located in the E-direction. The additional node receives the address_ answer packet to determine that the address of the self-node is (5,4).</div>
<div class="description-paragraph" id="p-0116" num="0115">A manual address setting method is also conceivable as another method. In the manual address setting method, an operator of the storage device <b>10</b> previously determines the address of the additional memory node, and the operator adds the new memory node after the new memory node is preset.</div>
<div class="description-paragraph" id="p-0117" num="0116">In the automatic address acquiring method, it is necessary for the packet controller of each memory node to have a function of replying the Address_request packet. Therefore, the cost per packet controller tends to be increased. On the other hand, it is not necessary to preset the address of the additional memory node, so that the procedure for adding the memory node can be simplified, leading to reduction of operational cost.</div>
<div class="description-paragraph" id="p-0118" num="0117">As described above, according to the first embodiment, the logical address and the physical position (physical address) of the memory node are matched with each other, so that the data forwarding method can efficiently be performed while each memory node needs not to manage the routing table. Therefore, the storage device has the excellent expandability, namely, the memory node can easily be added to the storage de vice.</div>
<div class="description-paragraph" id="h-0007" num="0000">[Second Embodiment]</div>
<div class="description-paragraph" id="p-0119" num="0118">A storage device according to a second embodiment will be described. The storage device of the second embodiment includes a forwarding algorithm 2 that is different from the forwarding algorithm 1 included in the storage device of the first embodiment. In the forwarding algorithm 2, the memory node of the forwarding destination is determined based on three pieces of information, namely, the destination address and the source address, which are included in the packet, and the address of the self-node. Because the storage device of the second embodiment has the same configuration as those of <figref idrefs="DRAWINGS">FIGS. 1 and 2</figref>, the description is omitted.</div>
<div class="description-paragraph" id="p-0120" num="0119">[1] Forwarding Algorithm 2 of Storage Device</div>
<div class="description-paragraph" id="p-0121" num="0120"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a view illustrating the forwarding algorithm 2 in the storage device of the second embodiment. An example of a method for determining the adjacent node of the forwarding destination based on the three pieces of information, namely, the destination address and the source address of the packet and the address of the self-node will be described with reference to <figref idrefs="DRAWINGS">FIG. 10</figref>. This method is referred to as the forwarding algorithm 2.</div>
<div class="description-paragraph" id="p-0122" num="0121">As illustrated in <figref idrefs="DRAWINGS">FIG. 10</figref>, a determination, which one of two areas separated by a straight line connecting the destination node (to) and the source node (from) the self-node (PP) exists in is made, and the packet is forwarded to the adjacent memory node in the direction allocated to the area.</div>
<div class="description-paragraph" id="p-0123" num="0122">A specific example of the packet forwarding process based on the forwarding algorithm 2 will be described with reference to <figref idrefs="DRAWINGS">FIGS. 11A to 11D</figref>.</div>
<div class="description-paragraph" id="p-0124" num="0123">As illustrated in <figref idrefs="DRAWINGS">FIG. 11A</figref>, it is assumed that (x<sub>to</sub>, y<sub>to</sub>) is an address of the destination node (to), it is assumed that (x<sub>from</sub>, y<sub>from</sub>) is an address of the source node (from), it is assumed that (x<sub>pp</sub>, y<sub>pp</sub>) is an address of the self-node (PP), and it is assumed that dx=x<sub>to</sub>−x<sub>from</sub>, dy=y<sub>to</sub>−y<sub>from</sub>, Dx=x<sub>pp</sub>−x<sub>from</sub>, and Dy=y<sub>pp</sub>−y<sub>from</sub>. As to the direction indicating the forwarding destination, as illustrated in <figref idrefs="DRAWINGS">FIG. 11B</figref>, it is assumed that N is a direction in which y is increased, it is assumed that E is a direction in which x is increased, it is assumed that S is a direction in which y is decreased, and it is assumed that W is a direction in which x is decreased.</div>
<div class="description-paragraph" id="p-0125" num="0124">Based on an equation of y=(dx/dy)·x that is the straight line connecting the destination node (to) and the source node (from), Dy and (dy/dx)·Dx are compared to determine which one of the two areas separated by the straight, line the self-node (PP) exists in.</div>
<div class="description-paragraph" id="p-0126" num="0125">The method for allocating the forwarding direction will be described by taking the case of dx&gt;0 and dy&gt;0 as an example. In the case that Dy and (dy/dx)·Dx are compared, it is assumed that an A area is one in which Dy is larger than (dy/dx)·Dx, and it is assumed that a B area is the other. In the forwarding, E is allocated to a first preferential direction of the A area, and N is allocated to a first preferential direction of the B area. In the forwarding algorithm 2, the forwarding is performed such that the packet proceeds along the straight line connecting the destination node (to) and the source node (from).</div>
<div class="description-paragraph" id="p-0127" num="0126"> <figref idrefs="DRAWINGS">FIG. 11C</figref> illustrates a flowchart of the forwarding algorithm 2 in the storage device. The forwarding algorithm 2 is stored in a packet controller <b>15</b> and executed by the packet controller <b>15</b>.</div>
<div class="description-paragraph" id="p-0128" num="0127">The packet controller <b>15</b> calculates dx=x<sub>to</sub>−x<sub>from</sub>, dy=y<sub>to</sub>−y<sub>from</sub>, Dx=x<sub>pp</sub>−x<sub>from</sub>, and Dy=y<sub>pp</sub>−y<sub>from </sub>(Step S<b>31</b>). Then the packet controller <b>15</b> determines whether dx is 0 (Step S<b>32</b>). When dx is 0, the packet controller <b>15</b> determines whether y<sub>to</sub>&gt;y<sub>pp </sub>holds (Step S<b>33</b>). When y<sub>to</sub>&gt;y<sub>pp </sub>holds, the packet controller <b>15</b> forwards the packet to N (Step S<b>34</b>). On the other hand, when y<sub>to</sub>&gt;y<sub>pp </sub>does not hold, the packet controller <b>15</b> forwards the packet to S (Step S<b>35</b>).</div>
<div class="description-paragraph" id="p-0129" num="0128">When dx is not 0 in Step S<b>32</b>, the packet controller <b>15</b> determines whether dy is 0 (Step S<b>36</b>). When dy is 0, the packet controller <b>15</b> determines whether x<sub>to</sub>&gt;x<sub>pp </sub>holds (Step S<b>37</b>). When x<sub>to</sub>&gt;x<sub>pp </sub>holds, the packet controller <b>15</b> forwards the packet to E (Step S<b>38</b>). On the other hand, when x<sub>to</sub>&gt;x<sub>pp </sub>does not hold, the packet controller <b>15</b> forwards the packet to W (Step S<b>39</b>).</div>
<div class="description-paragraph" id="p-0130" num="0129">When dy is not 0 in Step S<b>36</b>, namely, when dx and dy are not 0, the packet controller <b>15</b> determines whether Dy·dx&gt;dy-Dx holds (Step S<b>40</b>). When Dy·dx&gt;dy·Dx holds, the packet controller <b>15</b> determines whether dx&gt;0 and dy&gt;0 hold (Step S<b>41</b>). When dx&gt;0 and dy&gt;0 hold, the packet controller <b>15</b> forwards the packet to E (Step S<b>42</b>). On the other hand, when dx&gt;0 and dy&gt;0 do not hold, the packet controller <b>15</b> determines whether dx&lt;0 and dy&gt;0 hold (Step <b>343</b>). When dx&lt;0 and dy&gt;0 hold, the packet controller forwards the packet to N (Step <b>344</b>).</div>
<div class="description-paragraph" id="p-0131" num="0130">When dx&lt;0 and dy&gt;0 do not hold in Step S<b>43</b>, the packet controller <b>15</b> determines whether dx&lt;0 and dy&lt;0 hold (Step S<b>45</b>). When dx&lt;0 and dy&lt;0 hold, the packet controller <b>15</b> forwards the packet to W (Step S<b>46</b>). When dx&lt;0 and dy&lt;0 do not hold, the packet controller <b>15</b> forwards the packet to S (Step S<b>47</b>).</div>
<div class="description-paragraph" id="p-0132" num="0131">When Dy·dx&gt;dy·Dx does not hold in Step S<b>40</b>, the packet controller <b>1</b>.<b>5</b> determines whether dx&gt;0 and dy&gt;0 hold (Step S<b>48</b>). When dx&gt;0 and dy&gt;0 hold, the packet controller <b>15</b> forwards the packet to N (Step S<b>49</b>). When dx&gt;0 and dy&gt;0 do not hold, the packet controller <b>15</b> determines whether dx&lt;0 and dy&gt;0 hold (Step S<b>50</b>). When dx&lt;0 and dy&gt;0 hold, the packet controller <b>15</b> forwards the packet to W (Step S<b>51</b>). When dx&lt;0 and dy&gt;0 do not hold, the packet controller <b>15</b> determines whether dx&lt;0 and dy&lt;0 hold (Step S<b>52</b>). When dx&lt;0 and dy&lt;0 hold, the packet controller <b>15</b> forwards the packet to S (Step S<b>53</b>). When dx&lt;0 and dy&lt;0 do not hold, the packet controller <b>15</b> forwards the packet to E (Step S<b>54</b>).</div>
<div class="description-paragraph" id="p-0133" num="0132">Through the above processing, the packet input to the memory node is forwarded to the adjacent memory node such that the packet proceeds along the straight line connecting the destination node (to) and the source node (from).</div>
<div class="description-paragraph" id="p-0134" num="0133"> <figref idrefs="DRAWINGS">FIG. 11D</figref> illustrates a specific example of the packet forwarding process. In the forwarding algorithm 2, the forwarding is performed such that the packet proceeds along the straight line connecting the destination node (to) and the source node (from). For example, in the case <b>3</b>, because of dx&lt;0 and dy&gt;0, the packet proceeds to W or N so as to stay close to the straight line connecting the destination node (to) and the source node (from) as much as possible. In the case <b>4</b>, because of dx&gt;0 and dy&gt;0, the packet proceeds to N or E so as to stay close to the straight line connecting the destination node (to) and the source node (from) as much as possible.</div>
<div class="description-paragraph" id="p-0135" num="0134">An advantage of the forwarding algorithm 2 over the forwarding algorithm 1 will be described with reference to <figref idrefs="DRAWINGS">FIGS. 12A and 12B</figref>.</div>
<div class="description-paragraph" id="p-0136" num="0135"> <figref idrefs="DRAWINGS">FIGS. 12A and 12B</figref> illustrate the packet forwarding processes in the case that the packets addressed to the destination node (to) are transmitted from the two source nodes (from<b>1</b>) and (from<b>2</b>). <figref idrefs="DRAWINGS">FIG. 12A</figref> illustrates the packet forwarding process by the forwarding algorithm 1, and the <figref idrefs="DRAWINGS">FIG. 12B</figref> illustrates the packet forwarding process by the forwarding algorithm 2.</div>
<div class="description-paragraph" id="p-0137" num="0136">In the forwarding algorithm 1 illustrated in <figref idrefs="DRAWINGS">FIG. 12A</figref>, a merging waiting jam is generated at a point where the two packets merge. On the other hand, in the forwarding algorithm 2 illustrated in <figref idrefs="DRAWINGS">FIG. 12B</figref>, the jam is not generated. Accordingly, in the forwarding algorithm 2, a probability that the jam is generated can be decreased compared with the forwarding algorithm 1.</div>
<div class="description-paragraph" id="p-0138" num="0137">As described above, according to the second embodiment, the probability that the jam is generated can be decreased compared with the first embodiment, and the storage device in which a response speed is maintained even if many clients are simultaneously connected can be provided.</div>
<div class="description-paragraph" id="p-0139" num="0138">The logical address and the physical address of the memory node are matched similarly to the first embodiment, so that the data forwarding method can efficiently be performed while each memory node needs not to manage the routing table. Therefore, the storage device has the excellent expandability, namely, the memory node can easily be added to the storage device. Other configurations and effects of the embodiment are similar to those of the first embodiment.</div>
<div class="description-paragraph" id="h-0008" num="0000">[Third Embodiment]</div>
<div class="description-paragraph" id="p-0140" num="0139">A storage device according to a third embodiment, will be described. The storage device of the third embodiment includes a forwarding algorithm 3 that is different from the forwarding algorithms 1 and 2 included in the storage devices of the first and second embodiments. In the forwarding algorithm 3, the memory node of the forwarding destination is determined based on four pieces of information, namely, the destination address and the source address, which are included in the packet, the address of the self-node, and output port, occupancy information on the self-node. Because the storage device of the third embodiment has the same configuration as those of <figref idrefs="DRAWINGS">FIGS. 1 and 2</figref>, the description is omitted.</div>
<div class="description-paragraph" id="p-0141" num="0140">[1] Forwarding Algorithm 3 of Storage Device</div>
<div class="description-paragraph" id="p-0142" num="0141"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a view illustrating the forwarding algorithm 3 in the storage device of the third embodiment. An example of a method for determining the adjacent node of the forwarding destination based on the four pieces of information, namely, the destination address and the source address of the packet, the address of the self-node, and the output port occupancy information on the self-node will be described with reference to <figref idrefs="DRAWINGS">FIG. 13</figref>. This method is referred to as the forwarding algorithm 3.</div>
<div class="description-paragraph" id="p-0143" num="0142">As illustrated in <figref idrefs="DRAWINGS">FIG. 13</figref>, the determination which one of two areas separated by the straight line connecting the destination node (to) and the source node (from) the self-node (PP) exists in is made, and the packet is forwarded to the adjacent node in the direction that is determined by the output port occupancy information on the self-node in the two directions allocated to the area. A first preferential direction and a second preferential direction are allocated to each area. The second preferential direction is selected in the case that an output port buffer in the first preferential direction is occupied by another packet.</div>
<div class="description-paragraph" id="p-0144" num="0143">A specific example of the packet forwarding process based on the forwarding algorithm 3 will be described with reference to <figref idrefs="DRAWINGS">FIG. 13</figref> and <figref idrefs="DRAWINGS">FIGS. 14A to 14D</figref>.</div>
<div class="description-paragraph" id="p-0145" num="0144">As illustrated in <figref idrefs="DRAWINGS">FIG. 14A</figref>, it is assumed that (x<sub>to</sub>, y<sub>to</sub>) is an address of the destination node (to), it is assumed that (x<sub>from</sub>, y<sub>from</sub>) is an address of the scarce node (from), it is assumed that (x<sub>pp</sub>, y<sub>pp</sub>) is an address of the self-node (PP), and it is assumed that dx=x<sub>to</sub>−x<sub>from</sub>, dy=y<sub>to</sub>−y<sub>from</sub>, Dx=x<sub>pp</sub>−x<sub>from</sub>, and Dy=y<sub>pp</sub>−y<sub>from</sub>.</div>
<div class="description-paragraph" id="p-0146" num="0145"> <figref idrefs="DRAWINGS">FIG. 13</figref> illustrates the case of dx&gt;0 and dy&gt;0. In the case that Dy and (dy/dx)·Dx are compared, it is assumed that an A area is one in which Dy Is larger than (dy/dx)·Dx, and it is assumed that a B area is the other. In the forwarding, E is allocated to the first preferential direction of the A area, and N is allocated to the first preferential direction of the B area. N is allocated to the second preferential direction (bypass direction) of the A area, and S is allocated to the second preferential direction of the B area. For example, in the case that the memory node that forwards the packet belongs to the B area as illustrated in the drawing, when the output port buffer in the N-direction that is the first preferential direction is occupied by another packet, the memory node forwards the packet in the E-direction that is the second preferential direction.</div>
<div class="description-paragraph" id="p-0147" num="0146"> <figref idrefs="DRAWINGS">FIG. 14C</figref> illustrates a flowchart of the forwarding algorithm 3 in the storage device. The forwarding algorithm 3 is stored in a packet controller <b>15</b> and executed by the packet controller <b>15</b>. As illustrated in <figref idrefs="DRAWINGS">FIG. 14B</figref>, it is assumed that OFBN is an output port buffer that outputs the packet to N, it is assumed that OPBE is an output port buffer that outputs the packet to E, it is assumed that OPBW is an output port buffer that outputs the packet to W, and it is assumed that OPBS is an output port buffer that outputs the packet to S.</div>
<div class="description-paragraph" id="p-0148" num="0147">Information (the output port occupancy information) on whether the output port buffers OPBN, OPBE, OPBW, and OPBS are vacant (the packet can be stored) or occupied by the packet is stored in the packet controller <b>15</b> as follows. The packet controller <b>15</b> has buffer occupancy flag bits corresponding to the total number of output port buffers and input port buffers. In the case that the packet is stored in the output port buffer, the packet controller <b>15</b> sets the buffer occupancy flag bit corresponding to the output, port buffer to “1”. In the case that the packet is output from the output port buffer, the packet controller <b>15</b> sets the buffer occupancy flag bit corresponding to the output port buffer to “0”. The packet controller <b>15</b> can determine whether the corresponding output port buffer is vacant (or occupied by the packet) by evaluating the buffer occupancy flag bit.</div>
<div class="description-paragraph" id="p-0149" num="0148">The packet controller <b>15</b> calculates dx=x<sub>to</sub>−x<sub>from</sub>, dy=y<sub>to</sub>−y<sub>from</sub>, Dx=x<sub>pp</sub>−x<sub>from</sub>, and Dy=y<sub>pp</sub>−y<sub>from </sub>(Step S<b>61</b>). Then the packet controller <b>15</b> determines whether dx is 0 (Step S<b>62</b>). When dx is 0, the packet controller <b>15</b> determines whether y<sub>to</sub>&gt;y<sub>pp </sub>holds (Step S<b>63</b>). When y<sub>to</sub>&gt;y<sub>pp </sub>holds, the packet controller <b>15</b> forwards the packet to N (Step S<b>64</b>). On the other hand, when y<sub>to</sub>&gt;y<sub>pp </sub>does not hold, the packet controller <b>15</b> forwards the packet to S (Step S<b>65</b>).</div>
<div class="description-paragraph" id="p-0150" num="0149">When dx is not 0 in Step S<b>62</b>, the packet controller <b>15</b> determines whether dy is 0 (Step S<b>66</b>). When dy is 0, the packet controller <b>15</b> determines whether x<sub>to</sub>&gt;x<sub>pp </sub>holds (Step S<b>67</b>). When x<sub>to</sub>&gt;x<sub>pp </sub>holds, the packet controller <b>15</b> forwards the packet to E (Step S<b>68</b>). On the other hand, when x<sub>to</sub>&gt;x<sub>pp </sub>does not hold, the packet controller <b>15</b> forwards the packet to W (Step S<b>69</b>).</div>
<div class="description-paragraph" id="p-0151" num="0150">When dy is not 0 in Step S<b>66</b>, namely, when dx and dy are not 0, the packet controller <b>15</b> determines whether Dy·dx&gt;dy·Dx holds (Step S<b>70</b>). When Dy·dx&gt;dy·Dx holds, the packet controller <b>15</b> determines whether dx&gt;0 and dy&gt;0 hold (Step S<b>71</b>). When dx&gt;0 and dy&gt;0 hold, the packet controller <b>15</b> determines whether the output port buffer OPBE that outputs the packet to E is vacant, namely, whether the output port buffer OPBE is not occupied by another packet (Step S<b>72</b>). When the output port buffer OPBE is vacant, the packet controller <b>15</b> forwards the packet to E (Step S<b>73</b>). On the other hand, when the output port buffer OPBE is not vacant, the packet controller <b>15</b> forwards the packet to N (Step S<b>74</b>).</div>
<div class="description-paragraph" id="p-0152" num="0151">When dx&gt;0 and dy&gt;0 do not hold in Step S<b>71</b>, the packet controller <b>15</b> determines whether dx&lt;0 and dy&gt;0 hold (Step S<b>75</b>). When dx&lt;0 and dy&gt;0 hold, the packet controller <b>15</b> determines whether the output port buffer OPBN that outputs the packet to N is vacant (Step S<b>76</b>). When the output port buffer OPBN is vacant, the packet controller <b>15</b> forwards the packet to N (Step S<b>77</b>). On the other hand, when the output port buffer OFBN is not vacant, the packet controller <b>15</b> forwards the packet to W (Step S<b>78</b>).</div>
<div class="description-paragraph" id="p-0153" num="0152">When dx&lt;0 and dy&gt;0 do not hold in Step S<b>75</b>, the packet controller <b>15</b> determines whether dx&lt;0 and dy&lt;0 hold (Step S<b>79</b>). When dx&lt;0 and dy&lt;0 hold, the packet controller <b>15</b> determines whether the output port buffer OPBW that outputs the packet to W is vacant (Step S<b>80</b>). When the output port buffer OPBW is vacant, the packet controller <b>15</b> forwards the packet to W (Step S<b>81</b>). On the other hand, when the output port buffer OPBW is not vacant, the packet controller <b>15</b> forwards the packet to S (Step S<b>82</b>).</div>
<div class="description-paragraph" id="p-0154" num="0153">When dx&lt;0 and dy&lt;0 do not hold in Step S<b>79</b>, the packet controller <b>15</b> determines whether the output port buffer OPBS that outputs the packet to S is vacant (Step S<b>83</b>). When the output port buffer OPBS is vacant, the packet controller <b>15</b> forwards the packet to S (Step S<b>84</b>). On the other hand, when the output port buffer OPBS is not vacant, the packet controller <b>15</b> forwards the packet to E (Step S<b>85</b>).</div>
<div class="description-paragraph" id="p-0155" num="0154">When Dy·dx&gt;dy·Dx does not hold in Step S<b>70</b>, the packet controller <b>15</b> determines whether dx&gt;0 and dy&gt;0 hold (Step S<b>86</b>). When dx&gt;0 and dy&gt;0 hold, the packet controller <b>15</b> determines whether the output port buffer OPEN that outputs the packet to N is vacant (Step S<b>87</b>). When the output port buffer OPEN is vacant, the packet controller <b>15</b> forwards the packet to N (Step S<b>88</b>). On the other hand, when the output port buffer OPBN is not vacant, the packet controller <b>15</b> forwards the packet to E (Step S<b>89</b>).</div>
<div class="description-paragraph" id="p-0156" num="0155">When dx&gt;0 and dy&gt;0 do not hold in Step S<b>86</b>, the packet controller <b>15</b> determines whether dx&lt;0 and dy&gt;0 hold (Step S<b>90</b>). When dx&lt;0 and dy&gt;0 hold, the packet controller <b>15</b> determines whether the output port buffer OPBW that outputs the packet to W is vacant (Step S<b>91</b>). When the output port buffer OPBW is vacant, the packet controller <b>15</b> forwards the packet to W (Step S<b>92</b>). On the other hand, when the output port buffer OPBW is not vacant, the packet controller <b>15</b> forwards the packet to N (Step S<b>93</b>).</div>
<div class="description-paragraph" id="p-0157" num="0156">When dx&lt;0 and dy&gt;0 do not hold in Step S<b>90</b>, the packet controller <b>15</b> determines whether dx&lt;0 and dy&lt;0 hold (Step S<b>94</b>). When dx&lt;0 and dy&lt;0 hold, the packet controller <b>15</b> determines whether the output port buffer OPBS that outputs the packet to S is vacant (Step S<b>95</b>). When the output port buffer OPBS is vacant, the packet controller <b>15</b> forwards the packet to S (Step S<b>96</b>). On the other hand, when the output port buffer OPBS is not vacant, the packet controller <b>15</b> forwards the packet to W (Step S<b>97</b>).</div>
<div class="description-paragraph" id="p-0158" num="0157">When dx&lt;0 and dy&lt;0 do not hold in Step S<b>94</b>, the packet controller <b>15</b> determines whether the output port buffer OPBE that outputs the packet to E is vacant (Step S<b>98</b>). When the output port buffer OPBE is vacant, the packet controller <b>15</b> forwards the packet to E (Step S<b>99</b>). On the other hand, when the output port buffer OPBE is not vacant, the packet controller <b>15</b> forwards the packet to S (Step S<b>100</b>).</div>
<div class="description-paragraph" id="p-0159" num="0158">Through the above processing, in the case that the jam is generated in the first preferential direction, the packet is forwarded in the second preferential direction, whereby the packet is forwarded to the adjacent memory node along the straight line connecting the destination node (to) and the source node (from) while the jam is avoided.</div>
<div class="description-paragraph" id="p-0160" num="0159"> <figref idrefs="DRAWINGS">FIG. 14D</figref> illustrates a specific example of the packet forwarding process. The case <b>1</b> is an example in which the jam is not generated. In the case <b>1</b>, the packet is forwarded along the straight line connecting the destination node (to) and the source node (from). The cases <b>2</b> and <b>3</b> are examples in which the jam is avoided. In the case <b>2</b>, the jam is generated in the N-direction when the packet is forwarded to N. Therefore, as illustrated in the case <b>3</b>, the packet is forwarded to E to avoid the jam. The cases <b>4</b> and <b>5</b> are other examples in which the jam is avoided. In the case <b>4</b>, the jam is generated in the E-direction when the packet is forwarded to E. Therefore, as illustrated in the case <b>5</b>, the packet is forwarded to N to avoid the jam.</div>
<div class="description-paragraph" id="p-0161" num="0160">In the forwarding algorithm 3, in the case that the jam is generated in the first preferential direction, the jam can be avoided by forwarding the packet in the second preferential direction. At this point, the number of forwarding steps until the packet reaches the destination node is not changed compared with the case in which the jam is not generated.</div>
<div class="description-paragraph" id="p-0162" num="0161">[2] Forwarding Algorithm 4 of Storage Devices</div>
<div class="description-paragraph" id="p-0163" num="0162"> <figref idrefs="DRAWINGS">FIG. 15</figref> is a view illustrating a forwarding algorithm 4 in the storage device. A first example of another method for determining the adjacent node of the forwarding destination based on the four pieces of information, namely, the destination address and the source address of the packet, the address of the self-node, and the output port occupancy information on the self-node will be described with reference to <figref idrefs="DRAWINGS">FIG. 15</figref>. This method is referred to as the forwarding algorithm 4.</div>
<div class="description-paragraph" id="p-0164" num="0163">As illustrated in <figref idrefs="DRAWINGS">FIG. 15</figref>, four areas that are separated by the first straight line connecting the destination node (to) and the source node (from) and a second straight line orthogonal to the first straight line at the position of the destination node (to) are defined. A determination which one of the four areas the self-node (PP) exists in is made, and the packet is forwarded to the adjacent node in the direction that is determined by the output port occupancy information on the self-node (PP) in the two directions of the first preferential direction and the second preferential direction, which are allocated to the area in which the self-node (PP) exists.</div>
<div class="description-paragraph" id="p-0165" num="0164">The advantage of the forwarding algorithm 4 over the forwarding algorithm 3 is as follows. In the forwarding algorithm 3, it is necessary to provide a restriction that the packet Is prohibited from being forwarded to the outside of the area defined by a rectangle in which the straight line connecting the destination node (to) and the source node (from) is used as a diagonal line. On the other hand, in the forwarding algorithm 4, it is not necessary to provide the restriction.</div>
<div class="description-paragraph" id="p-0166" num="0165">[3] Forwarding Algorithm 5 of Storage Device</div>
<div class="description-paragraph" id="p-0167" num="0166"> <figref idrefs="DRAWINGS">FIG. 16</figref> is a view illustrating a forwarding algorithm 5 in the storage device. A second example of another method for determining the adjacent node of the forwarding destination based on the four pieces of information, namely, the destination address and the source address of the packet, the address of the self-node, and the output port occupancy information on the self-node will be described with reference to <figref idrefs="DRAWINGS">FIG. 16</figref>. This method is referred to as the forwarding algorithm 5.</div>
<div class="description-paragraph" id="p-0168" num="0167">As illustrated in <figref idrefs="DRAWINGS">FIG. 16</figref>, eight areas that are separated by four straight, lines, namely, the first straight line connecting the destination node (to) and the source node (from), the second straight line orthogonal to the fist straight line at the position of the destination node (to), and the third and fourth straight lines extending in the x-direction and the y-direction at the position of the destination node (to) are defined. A determination which one of the eight areas the self-node (PP) exists in is made, and the packet is forwarded to the adjacent node in the direction that is determined by the output port occupancy information on the self-node (PP) in the two directions of the first preferential direction and the second preferential direction, which, are allocated to the area in which the self-node (PP) exists. For example, the third and fourth straight lines extending in the x-direction and the y-direction at the position of the destination node (to) include two straight lines that pass through the destination node (to) and extend along two directions in which, the memory nodes are arrayed.</div>
<div class="description-paragraph" id="p-0169" num="0168">The advantage of the forwarding algorithm 5 over the forwarding algorithm 4 is as follows. In the algorithm 4, in the case that the packet is forwarded in the second preferential direction (bypass direction) outside of the area defined by the rectangle in which the straight line connecting the destination node (to) and the source node (from) is used as a diagonal line, the number of forwarding steps is increased by at least, one until the packet reaches the destination node (to). On the other hand, in the forwarding algorithm 5, the number of forwarding steps is not increased.</div>
<div class="description-paragraph" id="p-0170" num="0169">As described above, according to the third embodiment, the probability that the jam is generated can be decreased compared with the first and second embodiments, and the storage device in which the response speed is maintained even if many clients are simultaneously connected can be provided.</div>
<div class="description-paragraph" id="p-0171" num="0170">The logical address and the physical address of the memory node are matched similarly to the first embodiment, so that the data forwarding method can efficiently be performed while each memory node needs not to manage the routing table. Therefore, the storage device has the excellent expandability, namely, the memory node can easily be added to the storage device. Other configurations and effects of the embodiment are similar to those of the first embodiment.</div>
<div class="description-paragraph" id="h-0009" num="0000">[Fourth Embodiment]</div>
<div class="description-paragraph" id="p-0172" num="0171">In a storage system according to a fourth embodiment that includes a storage device including forwarding-function-equipped memory nodes and a control computer connected to the storage device, an operational condition of the storage system in which the jam is not generated in forwarding the packet, namely, the operational condition that becomes jam free will be described.</div>
<div class="description-paragraph" id="p-0173" num="0172">[1] Configuration of Storage System</div>
<div class="description-paragraph" id="p-0174" num="0173"> <figref idrefs="DRAWINGS">FIG. 17</figref> is a view illustrating a configuration of the storage system of the fourth embodiment.</div>
<div class="description-paragraph" id="p-0175" num="0174">As illustrated in <figref idrefs="DRAWINGS">FIG. 17</figref>, the storage system includes a storage device <b>10</b> that includes memory nodes <b>11</b> and control computers <b>41</b> that are connected to the storage device <b>10</b>. As illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>, the storage device <b>10</b> has the configuration in which the memory nodes having the data forwarding functions are mutually connected. The control computer <b>41</b> is connected to the memory node <b>11</b> that is disposed in the outer peripheral portion of the storage device <b>10</b>.</div>
<div class="description-paragraph" id="p-0176" num="0175">[2] Jam-Free Operational Condition of Storage System</div>
<div class="description-paragraph" id="p-0177" num="0176">A framework of a packet forwarding simulation in the storage system will be described with reference to <figref idrefs="DRAWINGS">FIG. 17</figref>. A process in which a request packet transmitted from the control computer <b>41</b> connected to the storage device <b>10</b> reaches the memory node of the destination address and a process in which a data packet sent back from the target memory node reaches the original control computer <b>41</b> are simulated. The bypass-function-equipped routing algorithm (forwarding algorithm 3) described with reference to <figref idrefs="DRAWINGS">FIG. 13</figref> is used as the packet forwarding algorithm.</div>
<div class="description-paragraph" id="p-0178" num="0177">It is assumed that N<sub>node</sub>=Nx×Ny is the number of memory nodes of the storage device <b>10</b>, and it is assumed that Nc is the number of control computers connected to the storage device <b>10</b>. It is assumed that a unit step time is a time for which the packet is forwarded once between the memory nodes. It is assumed that Rr is a probability that the control computer <b>41</b> transmits the request packet per unit step time. Rr is increased up to 1. It is assumed that R<sub>bypass </sub>a bypass transfer occurrence rate, and it is assumed that R<sub>jam </sub>is a jam occurrence rate.</div>
<div class="description-paragraph" id="p-0179" num="0178">The bypass transfer occurrence rate R<sub>bypass </sub>indicates a probability that the jam is avoided by the bypass forwarding when the memory node tries to forward one packet. On the other hand, the jam occurrence rate R<sub>jam </sub>indicates a probability that, because not only the output port buffer in the first preferential direction but also the output port buffer in the second preferential direction are occupied by other packets when the memory node tries to forward one packet, the packet cannot be forwarded, the jam is generated, and the packet remains. It is assumed that R<sub>load </sub>is a load factor. The load factor R<sub>load </sub>is an average of the number of packets existing in one memory node.</div>
<div class="description-paragraph" id="p-0180" num="0179"> <figref idrefs="DRAWINGS">FIG. 18</figref> illustrates a relationship between the bypass transfer occurrence rate R<sub>bypass </sub>the load factor R<sub>load </sub>and a relationship between the jam occurrence rate R<sub>jam </sub>and the load factor R<sub>load</sub>. Many plots indicate results in the case that the number of memory nodes N<sub>node</sub>, the number of control computers Nc, and the probability Rr are changed in various ways.</div>
<div class="description-paragraph" id="p-0181" num="0180">The jam occurrence rate R<sub>jam </sub>is substantially zero in the case that the load factor R<sub>load </sub>is smaller than 0.2, if is found that the jam-free operational condition of the storage system is load factor R<sub>load</sub>&lt; 0.2. The jam occurrence rate R<sub>jam </sub>starts to be increased when the load factor R<sub>load </sub>becomes 0.2 or more. However, even in the case of load factor R<sub>load</sub>=2, the jam occurrence rate R<sub>jam </sub>is about 0.05 that is acceptable for practical usage. On the other hand, the jam occurrence rate R<sub>jam </sub>is rapidly increased when the load factor R<sub>load </sub>is more than 2. This is because a hung-up phenomenon in which the jam occurs in chain reaction due to the large R<sub>load</sub>.</div>
<div class="description-paragraph" id="p-0182" num="0181">When the load factor R<sub>load </sub>is increased, the bypass transfer occurrence rate R<sub>bypass </sub>rises earlier than the jam occurrence rate R<sub>jam </sub>by about one order. That is, the bypass forwarding algorithm improves the threshold R<sub>load </sub>by about one order.</div>
<div class="description-paragraph" id="p-0183" num="0182">A relationship between the number of control computers and the number of memory nodes, in which the jam generation rate is acceptable for practical usage, is obtained based on the simulation results. It is assumed that S<sub>avg </sub>is an average packet staying step time. The average packet staying step time S<sub>avg </sub>is the sum of the step time S<sub>request </sub>since the control computer <b>41</b> transmits the request packet until the request packet reaches the memory node of the destination address and a step time until the data packet sent back from the target memory node reaches the original control computer. The step times S<sub>request </sub>and S<sub>dat </sub>are (Nx/2+Ny/2) in the case that the jam is not generated. Accordingly, the average packet staying step time S<sub>avg </sub>is (Nx+Ny) that is about 2 √{square root over (N<sub>node</sub>)}.</div>
<div class="description-paragraph" id="p-0184" num="0183">On the other hand, Nc×Rr is the total number of request packets transmitted per unit step time by the control computer <b>41</b>. Accordingly, Nc×Rr×2√{square root over (N<sub>node</sub>)}is the average of the total number of packets existing in the storage system. Therefore, R<sub>load </sub>is approximately Nc×Rr×2√{square root over (N<sub>node</sub>)}/N<sub>node</sub>=Nc×Rr×2/√{square root over (N<sub>node</sub>)}. Assuming that R<sub>load</sub> <sup>limit </sup>is the limit R<sub>load </sub>below which jam generating rate is acceptable, the preferable operational condition of the storage system is R<sub>load</sub>&lt;R<sub>load</sub> <sup>limit</sup>. Accordingly, the maximum number of control computers Nc<sup>max</sup>, in which the jam generation rate is acceptable for practical usage, becomes Nc<sup>max</sup>&lt;R<sub>load</sub> <sup>limit</sup>×√{square root over (N<sub>node</sub>)}/(Rr×2). Because the Rr is increased up to 1, the stricter operational condition is Nc<sup>max</sup>&lt;R<sub>load</sub> <sup>limit</sup>×√{square root over (N<sub>node</sub>)}/2.</div>
<div class="description-paragraph" id="p-0185" num="0184">As described above, in forwarding the packet, the jam-free operational condition is R<sub>load</sub> <sup>limit</sup>0.2, and the operational condition, in which the jam generation rate is acceptable for practical usage, is R<sub>load</sub> <sup>limit</sup>=2. Accordingly, preferably the maximum number of control computers Nc<sup>max </sup>is Nc<sup>max</sup>&lt;√{square root over (N<sub>node</sub>)}, more preferably Nc<sup>max</sup>&lt;0.1×√{square root over (N<sub>node</sub>)}. Other configurations and effects are similar to those of the first embodiment.</div>
<div class="description-paragraph" id="h-0010" num="0000">[Fifth Embodiment]</div>
<div class="description-paragraph" id="p-0186" num="0185">A storage device according to a fifth embodiment includes forwarding-function-equipped memory nodes that are mutually connected as illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>, and each memory node is equipped with a distributed processing function.</div>
<div class="description-paragraph" id="p-0187" num="0186">[1] Configuration of Storage System</div>
<div class="description-paragraph" id="p-0188" num="0187"> <figref idrefs="DRAWINGS">FIG. 19</figref> is a view illustrating a configuration of the storage device of the fifth embodiment.</div>
<div class="description-paragraph" id="p-0189" num="0188">As illustrated in <figref idrefs="DRAWINGS">FIG. 19</figref>, a storage device <b>10</b> includes memory nodes <b>11</b> as illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>, and is equipped with the distributed processing function. In the fifth embodiment, each memory node <b>11</b> further includes an address converter <b>42</b>.</div>
<div class="description-paragraph" id="p-0190" num="0189">[2] Distributed Processing Function of Storage Device</div>
<div class="description-paragraph" id="p-0191" num="0190">The distributed processing function will be described with reference to <figref idrefs="DRAWINGS">FIG. 19</figref> by taking an AND search processing for searching a URL including both keywords of “apple” and “orange” as an example.</div>
<div class="description-paragraph" id="p-0192" num="0191">At this point, it is assumed that memory nodes (1,3) and (4,3) retain inverted files of “apple” and “orange”, respectively. The inverted file means a search file that is prepared for each keyword. For example, a list of all the URLs including “apple” is stored in the inverted file corresponding to the keyword of “apple”.</div>
<div class="description-paragraph" id="p-0193" num="0192">The gateway server transmits an AND search command to the memory nodes that manage the inverted files of “apple” and “orange”. The memory nodes that manage the inverted files perform mapping of contents of the inverted file into key-value type data. At this point, a key and a value are the URL and the keyword of the inverted file, respectively.</div>
<div class="description-paragraph" id="p-0194" num="0193">The memory node managing the inverted files of “apple” and “orange” convert the key into the address using the address converter <b>42</b> for each record of the key-value type data, and transmit the packet including the value to the converted address. The address converter <b>42</b> may directly calculate the address from the key according to a certain rule, or the address converter <b>42</b> may acquire the address corresponding to the key by making an inquiry to a server equipped with a function of converting the key into the address.</div>
<div class="description-paragraph" id="p-0195" num="0194">For example, the address converter <b>42</b> calculates the address from the key according to the following addressing rule.</div>
<div class="description-paragraph" id="p-0196" num="0195">address=hash (key) mod N</div>
<div class="description-paragraph" id="p-0197" num="0196">Where hash ( ) is a cryptologic hash function, N is the number of memory nodes in the storage device <b>10</b>, and mod N expresses residue operation with modulus N.</div>
<div class="description-paragraph" id="p-0198" num="0197">For example, the address converter <b>42</b> makes the inquiry of the address corresponding to the key to another server, and another server converts the key into the address by the consistent hashing and replies the original address converter <b>42</b>.</div>
<div class="description-paragraph" id="p-0199" num="0198">In the example illustrated in <figref idrefs="DRAWINGS">FIG. 19</figref>, it is assumed that both the inverted files of “apple” and “orange” include an URL<b>1</b>, and it is assumed, that the URL<b>1</b> is converted into the address (2,1). In this case, the memory node (2,1) plays a role in determining whether the URL<b>1</b> satisfies an AND search formula. The two packets having the values of “apple” and “orange” are delivered to the memory node (2,1). Therefore, the memory node (2,1) finds out that the URL<b>1</b> satisfies an AND search condition.</div>
<div class="description-paragraph" id="p-0200" num="0199">The gateway server that outputs query is notified of the fact that the URL<b>1</b> satisfies the AND search condition by the memory node (2,1). Many memory nodes make the same determinations for all the URLs described in the inverted files, whereby the gateway server that outputs the query can obtains the list of URLs satisfying the AND search condition.</div>
<div class="description-paragraph" id="p-0201" num="0200">In the case that the above AND search operation is performed by the single memory node, it is necessary to perform an operation expressed by the following code.</div>
<div class="description-paragraph" id="p-0202" num="0201">
<tables id="TABLE-US-00001" num="00001">
<patent-tables colsep="0" frame="none" rowsep="0">
<table align="left" class="description-table" cols="2" colsep="0" rowsep="0" width="100%">
<thead>
<tr class="description-tr">
<td class="description-td"> </td>
<td align="center" class="description-td" colspan="2" nameend="1" namest="offset" rowsep="1"> </td>
</tr>
</thead>
<tbody><tr class="description-tr">
<td class="description-td"> </td>
<td class="description-td">for (i = 0;i &lt; N<sub>apple</sub>;i+ +)</td>
</tr>
</tbody></table>
<table align="left" class="description-table" cols="2" colsep="0" rowsep="0" width="100%">
<tbody><tr class="description-tr">
<td class="description-td"> </td>
<td class="description-td">for (j = i;j &lt; N<sub>orange</sub>;j + +)</td>
</tr>
</tbody></table>
<table align="left" class="description-table" cols="2" colsep="0" rowsep="0" width="100%">
<tbody><tr class="description-tr">
<td class="description-td"> </td>
<td class="description-td">if (URLlist <sub>apple</sub>[ i ] == URLlist<sub>orange</sub>[ j ] )</td>
</tr>
<tr class="description-tr">
<td class="description-td"> </td>
<td align="center" class="description-td" colspan="2" nameend="1" namest="offset" rowsep="1"> </td>
</tr>
</tbody></table>
</patent-tables>
</tables>
</div>
<div class="description-paragraph" id="p-0203" num="0202">Where N<sub>apple </sub>and N<sub>orange </sub>are numbers of URLs stored in the inverted files of “apple” and “orange” and indicates an identity operation. The memory node needs to repeat the identity operation N<sub>apple</sub>×N<sub>orange</sub>/2 times. In the storage device of the fifth embodiment, the identity operation can be performed in the distributed manner by many memory nodes.</div>
<div class="description-paragraph" id="p-0204" num="0203">As described above, according to the fifth embodiment, each memory node can be equipped with not only the storage function of the first embodiment, but. also a distributed processing (distributed computing) function. Other configurations and effects are similar to those of the first embodiment.</div>
<div class="description-paragraph" id="h-0011" num="0000">[Sixth Embodiment]</div>
<div class="description-paragraph" id="p-0205" num="0204">A storage system according to a sixth embodiment includes a storage device that includes forwarding-function-equipped memory nodes, some memory nodes of the storage device include an extra input/output port (hereinafter referred to as a non-adjacent port) in addition to an input/output port (hereinafter referred to as an adjacent port) connected to the adjacent memory node (hereinafter referred to as an adjacent node), and the some memory nodes are connected to one of a control computer and a non-adjacent memory node (hereinafter referred to as a non-adjacent node) by the non-adjacent port.</div>
<div class="description-paragraph" id="p-0206" num="0205">[1] Configuration of Storage System</div>
<div class="description-paragraph" id="p-0207" num="0206"> <figref idrefs="DRAWINGS">FIG. 20</figref> is a view illustrating a configuration of the storage system of the sixth embodiment.</div>
<div class="description-paragraph" id="p-0208" num="0207">As illustrated in <figref idrefs="DRAWINGS">FIG. 20</figref>, the storage system includes a storage device <b>10</b> including memory nodes <b>11</b> and gateway servers <b>21</b>A and <b>21</b>B connected to the storage device <b>10</b>. The storage device <b>10</b> has the configuration in which the data-forwarding-function-equipped memory nodes are mutually connected as illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>. The gateway server <b>21</b>A is connected to a memory node (1,4) disposed in the outer peripheral portion of the storage device <b>10</b> through an adapter <b>22</b>A. A memory node (3,5) disposed in the central portion of the storage device <b>10</b> includes the input/output port (non-adjacent port) in addition to the input/output port connected to the adjacent node, and the gateway server <b>21</b>B is connected to the non-adjacent port through an adapter <b>22</b>B.</div>
<div class="description-paragraph" id="p-0209" num="0208">[2] Packet Forwarding of Storage System</div>
<div class="description-paragraph" id="p-0210" num="0209">An effect that the memory node including the input/output port (non-adjacent port) in addition to the input/output port connected to the adjacent node is introduced will be described with reference to <figref idrefs="DRAWINGS">FIG. 20</figref>. At this point, it is assumed that Nx is the number of memory nodes in the x-direction of the storage device <b>10</b>, and it is assumed that Ny is the number of memory nodes in the y-direction.</div>
<div class="description-paragraph" id="p-0211" num="0210">In the case that the connection destination of the gateway server is restricted to the memory node disposed in the outer peripheral portion of the storage device <b>10</b>, Nx/2+Ny/2 is the average number of forwarding times until the packet reaches the target memory node from the gateway server.</div>
<div class="description-paragraph" id="p-0212" num="0211">On the other hand, Nx/4+Ny/4 is the average number of forwarding times until the packet reaches the target memory node from the gateway server <b>21</b>B, when the number of input/output ports of the memory node (3,5) located in the central portion of the storage device <b>10</b> is increased, and the memory node (3,<b>5</b>) is connected to the gateway server <b>21</b>B by the additional input/output port (the non-adjacent port), as illustrated in <figref idrefs="DRAWINGS">FIG. 20</figref>.</div>
<div class="description-paragraph" id="p-0213" num="0212">In this way, increasing the numbers of input/output ports of some memory nodes in the storage device <b>10</b> and connecting the memory node to the gateway server by the additional input/output port, result in the decrease of the average number of forwarding times until the packet reaches the target memory node.</div>
<div class="description-paragraph" id="p-0214" num="0213">As illustrated in <figref idrefs="DRAWINGS">FIG. 21</figref>, plural memory nodes that are connected to the gateway server by the additional input/output ports may be disposed in the storage device <b>10</b>. That is, the memory node (4,1) includes the input/output port (non-adjacent port) in addition to the input/output port connected to the adjacent node, and the non-adjacent port is connected to a gateway server <b>21</b>C through an adapter <b>22</b>C.</div>
<div class="description-paragraph" id="p-0215" num="0214">The gateway servers <b>21</b>A, <b>21</b>B, <b>21</b>C, and <b>21</b>D connected to the memory nodes in the storage device <b>10</b> may be connected by a line <b>23</b> that is different front the line connecting the server and the memory node. An adapter <b>22</b>E may be connected between the gateway servers, for example, between the gateway servers <b>21</b>A and <b>21</b>B. Therefore, using the line <b>23</b>, the packet can be forwarded between the gateway servers and between the gateway server and the memory node. For example, the packet may be forwarded in the order of gateway server <b>21</b>A→gateway server <b>21</b>B→gateway server <b>21</b>C→memory node (4,7). The packet may also be forwarded in the order of gateway server <b>21</b>A→gateway server <b>21</b>D→memory node (5,4).</div>
<div class="description-paragraph" id="p-0216" num="0215">As described above, according to the sixth embodiment, the forwarding time can be shortened when the packet is forwarded between the gateway server and the memory node in the storage device. Other configurations and effects are similar to those of the first embodiment</div>
<div class="description-paragraph" id="h-0012" num="0000">[Seventh Embodiment]</div>
<div class="description-paragraph" id="p-0217" num="0216">A storage system according to a seventh embodiment includes a storage device that includes forwarding-function-equipped memory nodes, some memory nodes of the storage device include an input/output port (non-adjacent port) besides an input/output port connected to the adjacent node, and the some memory nodes are connected to a non-adjacent memory node by the non-adjacent port and the extra connection line.</div>
<div class="description-paragraph" id="p-0218" num="0217">[1] Con figuration of Storage System</div>
<div class="description-paragraph" id="p-0219" num="0218"> <figref idrefs="DRAWINGS">FIG. 22</figref> is a view illustrating a configuration of the storage system of the seventh embodiment.</div>
<div class="description-paragraph" id="p-0220" num="0219">As illustrated in <figref idrefs="DRAWINGS">FIG. 22</figref>, the storage system includes a storage device <b>10</b> composed of plural memory nodes and a gateway server <b>21</b>A connected to the storage device <b>10</b>. The storage device <b>10</b> has the configuration in which the data-forwarding-function-equipped memory nodes are mutually connected as illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>. The gateway server <b>21</b>A is connected to a memory node (7,1) disposed in the outer peripheral portion of the storage device <b>10</b> through an adapter <b>22</b>A.</div>
<div class="description-paragraph" id="p-0221" num="0220">Memory nodes (3,3), (3,8), (8,3), and (8,8) disposed in the storage device <b>10</b> include the input/output ports (non-adjacent ports) in addition to the input/output ports connected to the adjacent nodes. The non-adjacent ports are connected to each other by an extra connection line <b>24</b>. For example, the memory nodes (3,3) and (3,8), the memory nodes (3,8) and (8,8), the memory nodes (8,8) and (8,3), and the memory nodes (8,3) and (3,3) are connected to each other by the extra connection lines <b>24</b>.</div>
<div class="description-paragraph" id="p-0222" num="0221">The memory node connected to the non-adjacent node has the additional address decided by a relative physical position between the memory nodes connected to the non-adjacent node in addition to the address fixed by the physical position. In the case that the memory node connected to the non-adjacent node receives the packet addressed to the memory node except the self-node, the packet controller calculates the number of packet forwarding times for the candidate courses between the self-node and the destination node, based on the address fixed by the physical position and the additional address and finds the shortest route, then determines the output port of the packet.</div>
<div class="description-paragraph" id="p-0223" num="0222">[2] Packet Forwarding of Storage System</div>
<div class="description-paragraph" id="p-0224" num="0223">An influence of the direct connection between the non-adjacent memory nodes on the number of packet forwarding times in the storage device <b>10</b> will be described. As described above, <figref idrefs="DRAWINGS">FIG. 22</figref> illustrates the storage device in which some non-adjacent nodes are mutually connected by the non-adjacent ports and the additional lines. On the other hand, <figref idrefs="DRAWINGS">FIG. 23</figref> illustrates the storage device, in which the numbers of input/output ports of all the memory nodes are equal to one another while the non-adjacent nodes are not connected.</div>
<div class="description-paragraph" id="p-0225" num="0224">In the storage devices of <figref idrefs="DRAWINGS">FIGS. 22 and 23</figref>, the case in which the data packet is transmitted from the gateway server <b>21</b>A of an address (7,0) to a memory node (7,8) is discussed.</div>
<div class="description-paragraph" id="p-0226" num="0225">In the case that the non-adjacent nodes are not connected (see <figref idrefs="DRAWINGS">FIG. 23</figref>), the shortest data forwarding route is gateway server <b>21</b>A (7,0)→memory node (7,1)→(7,2)→(7,3)→(7,4)→(7,5)→(7,6)→(7,7)→(7,8). Therefore, the total number of packet forwarding times (between the gateway server and the memory node and between the memory nodes in the storage device <b>10</b>) is 8.</div>
<div class="description-paragraph" id="p-0227" num="0226">On the other hand, in the case that the non-adjacent nodes are connected (see <figref idrefs="DRAWINGS">FIG. 22</figref>), the shortest data forwarding route is gateway server <b>21</b>A→memory node (7,1)→(7,2)→(7,3)→(8,3)→(8,8)→(7,8), and the packet can be transmitted from the gateway server <b>21</b>A to the destination memory node (7,8) by the six-time forwarding.</div>
<div class="description-paragraph" id="p-0228" num="0227">In this way, connecting some non-adjacent memory nodes by the additional input/output ports and the extra lines makes decrease in the number of packet forwarding times until the packet reaches the destination node.</div>
<div class="description-paragraph" id="p-0229" num="0228">It should be noted that when some non-adjacent memory nodes in a storage device are directly connected with each other, the shortest, data forwarding route cannot be decided only by the addresses of nodes or gateway server determined by the physical positions.</div>
<div class="description-paragraph" id="p-0230" num="0229">In the case that the data packet is transmitted from the gateway server <b>21</b>A of the address (7,0) to the memory node (7,8), in the storage device in which the non-adjacent nodes are not connected (see <figref idrefs="DRAWINGS">FIG. 23</figref>), the minimum total number of packet forwarding times (8 times) is equal to a difference between the addresses (gateway server <b>21</b>A (7,0) and memory node (7,8)) that are determined by the physical positions of the packet, source and the packet destination.</div>
<div class="description-paragraph" id="p-0231" num="0230">On the other hand, in the storage device in which some of the non-adjacent, nodes are connected (see <figref idrefs="DRAWINGS">FIG. 22</figref>), the packet communication between the gateway server <b>21</b>A (7,0) and the destination memory node (7,8), which have the same physical addresses as the storage device of <figref idrefs="DRAWINGS">FIG. 23</figref>, can be performed by the six-time forwarding. Namely, the minimum total numbers of packet forwarding time differ from difference between the address of packet source and that of packet destination determined by the physical position.</div>
<div class="description-paragraph" id="p-0232" num="0231">In the storage device in which some of the non-adjacent nodes are connected, the addresses (hereinafter referred to as a sub-address) that reflects the relative physical positions of the memory nodes connected to the non-adjacent nodes are additionally provided to the memory nodes connected to the non-adjacent nodes. In <figref idrefs="DRAWINGS">FIG. 22</figref>, the address (hereinafter referred to as a main address) determined by the absolute physical position is expressed by a round bracket, and the sub-address is expressed by a square bracket. In this case, the data forwarding route, and therefore the packet forwarding destination, can be determined from both the main address and the sub-address.</div>
<div class="description-paragraph" id="p-0233" num="0232">The address information concerning the source node and the destination node is written in the header portion of the packet. When the packet forwarding is performed in the storage device in which some of the non-adjacent memory nodes are directly connected, it is necessary to decide the temporal source node and the temporal destination node, and to write their address information in the header portion of the packet. Furthermore, appropriate updating the address information is required as the packet transmission proceeds. The detailed procedure will be described below.</div>
<div class="description-paragraph" id="p-0234" num="0233"> <figref idrefs="DRAWINGS">FIG. 24</figref> illustrates an example of preferable address information on the header portion of the packet in the case that the packet forwarding is performed in the storage system including the memory nodes connected to the non-adjacent nodes.</div>
<div class="description-paragraph" id="p-0235" num="0234">In <figref idrefs="DRAWINGS">FIG. 24</figref>, the “final destination node” and the “source node” mean a node to which the packet is finally delivered and a node from which the packet transmission is started, respectively. On the other hand, the “temporary destination node address” and the “temporary source node address” are addresses, which are used to determine the packet forwarding destination in each memory node and are updated during a packet communication process. An update rule during the packet communication process is described later.</div>
<div class="description-paragraph" id="p-0236" num="0235">The “type” of a temporary node address in <figref idrefs="DRAWINGS">FIG. 24</figref> is used to determine whether it is the main address or the sub-address. Both the “first relay node” and the “second relay node” are memory nodes connected to the non-adjacent nodes through which the packet should be transmitted. Furthermore, the “first relay node” is the memory node closest to the source node, and the “second relay node” is the memory node closest to the final destination node.</div>
<div class="description-paragraph" id="p-0237" num="0236">When the packet is transmitted in the storage device via the memory node connected to the non-adjacent node, determination of the packet forwarding destination and the correction of the header portion of the packet should be performed by, for example, the following rule.</div>
<div class="description-paragraph" id="p-0238" num="0237">(a) In the case that the memory node without additional input/output port receives the packet, the packet controller checks the address information recorded in the header portion of the packet, and</div>
<div class="description-paragraph" id="p-0239" num="0238">(i) the packet is not forwarded when the address of the final destination node is matched with the address of the self-node.</div>
<div class="description-paragraph" id="p-0240" num="0239">(ii) when the address of the final destination node differs from the address of the self-node, the forwarding destination is determined toy referring to the main addresses of the temporary source node, the temporary destination node, and the self-node, and the packet is transmitted to the adjacent, memory node.</div>
<div class="description-paragraph" id="p-0241" num="0240">(b) In the case that the memory node connected to the non-adjacent node receives the packet, the packet controller checks the address information recorded in the header portion of the packet, and</div>
<div class="description-paragraph" id="p-0242" num="0241">(i) the packet is not forwarded when the main address of the self-node is matched with the address of the final destination node.</div>
<div class="description-paragraph" id="p-0243" num="0242">(ii) when the main address of the self-node differs from the address of the final destination node, and</div>
<div class="description-paragraph" id="p-0244" num="0243">(1) when the sub-address of the self-node is matched with the sub-address of the “first relay node”, the address of the “temporary destination node” and that of the “temporary source node” are updated to the sub-address of the “second relay node” and that of the “first relay node”, respectively. Furthermore, the “type” of the “temporary destination node address” and that of the “temporary source node address” are updated as sub-address. Then, the forwarding destination is determined by referring to the “temporary destination node address” and the “temporary source node address”, and the packet is transmitted to the memory node connected to another non-adjacent, node.</div>
<div class="description-paragraph" id="p-0245" num="0244">(2) when the sub-address of the self-node is matched with the sub-address of the “second relay node”, the “temporary destination node address” is changed, to the main address of the “final destination node”, and the “temporary source node address” is changed to the main address of the self-node. Furthermore, the “type” of the “temporary destination node address” and that of the “temporary source node address” are updated as main address. Additionally, the forwarding destination is determined by referring to the main addresses of the “temporary source node”, the “temporary destination node”, and the self-node, and the packet is forwarded to another adjacent memory node.</div>
<div class="description-paragraph" id="p-0246" num="0245">(3) when the sub-address of the self-node differs from the addresses of both the “first relay node” and the “second relay node”, and when the types of the “temporary destination address” and the “temporary source address”, which are written in the header portion of the packet, are the sub-addresses, the forwarding destination is determined by referring to the sub-addresses of the “temporary source node”, the “temporary destination node”, and the self-node, and the packet is forwarded to the memory node connected to another non-adjacent node.</div>
<div class="description-paragraph" id="p-0247" num="0246">(4) when the sub-address of the self-node differs from the addresses of both the “first relay node” and the “second relay node”, and when the types of the “temporary destination address” and the “temporary source address” are the main, addresses, the forwarding destination is determined by referring to the main addresses of the “temporary source node”, the “temporary destination node”, and the self-node, and the packet is forwarded to another adjacent memory node.</div>
<div class="description-paragraph" id="p-0248" num="0247">A procedure in which the client writes the file in the storage device through the gateway server <b>21</b>A in the storage system illustrated in <figref idrefs="DRAWINGS">FIG. 22</figref> will be described as an example in which the packet is transmitted by using the connection between the non-adjacent nodes together.</div>
<div class="description-paragraph" id="p-0249" num="0248"> <figref idrefs="DRAWINGS">FIG. 25</figref> is a view illustrating the write operation in the storage system of illustrated in <figref idrefs="DRAWINGS">FIG. 22</figref>.</div>
<div class="description-paragraph" id="p-0250" num="0249">The client transmits the file and the file ID to the gateway server <b>21</b>A (see (<b>1</b>) of <figref idrefs="DRAWINGS">FIG. 25</figref>). The file ID is an identifier that can uniquely identify the file.</div>
<div class="description-paragraph" id="p-0251" num="0250">The gateway server <b>21</b>A divides the file into pieces of data having a defined size and allocates a division data ID to each divided piece of data. The gateway server <b>21</b>A writes the file ID and the division data IDs in the file table. The division data ID is an identifier that can uniquely identify the divided data (see (<b>2</b>) of <figref idrefs="DRAWINGS">FIG. 25</figref>).</div>
<div class="description-paragraph" id="p-0252" num="0251">The gateway server <b>21</b>A determines the address of the memory node (hereinafter referred to as a write node) in which the divided data is written based on the information on the division data ID (in <figref idrefs="DRAWINGS">FIG. 22</figref>, the memory node of the main address (7,8)).</div>
<div class="description-paragraph" id="p-0253" num="0252">The route in which the number of communication times (the number of packet forwarding times) becomes the minimum is obtained by the following procedure when the gateway server <b>21</b>A forwards the packet to the write node:</div>
<div class="description-paragraph" id="p-0254" num="0253">1. The address of the “first relay node” that is the memory node closest, to the gateway server <b>21</b>A and connected to the non-adjacent node, and the address of the “second relay node” that is the memory node closest to the write node and connected to the non-adjacent node are checked. In the case that the data is written in the memory node (7,8) of <figref idrefs="DRAWINGS">FIG. 22</figref>, the “first relay node” and the “second relay node” are the memory nodes having the main addresses (8,3) and (8,8).</div>
<div class="description-paragraph" id="p-0255" num="0254">2. The number of forwarding times generated in transmitting the packet is calculated based on the main address with respect to the route between the memory nodes that are connected only to the adjacent nodes, and the number of forwarding times generated in transmitting the packet is calculated based on the sub-address with respect to the route between the memory nodes that are connected to the non-adjacent nodes. Then the shortest route including the connection between the non-adjacent nodes and the shortest route that does not include the connection between the non-adjacent nodes are decided. In the case that the data is written in the memory node (7,8) of <figref idrefs="DRAWINGS">FIG. 22</figref>, the former is gateway server <b>21</b>A→memory node (7,1)→(7,2)→(7,3)→(8,3) ([2,1])→(8,8) ([2,2])→(7,8), and the latter is gateway server <b>21</b>A→memory node (7,1)→(7,2)→(7,3)→(7,4)→(7,5)→(7,6)→(7,7)→(7,8).</div>
<div class="description-paragraph" id="p-0256" num="0255">3. The number of forwarding times of the shortest route through the memory nodes connected to the non-adjacent, and that of the shortest route that does not pass through the memory nodes connected to the non-adjacent nodes are compared and the default route is determined. In the case that the data is written in the memory node (7,8) of <figref idrefs="DRAWINGS">FIG. 22</figref>, the number of forwarding times of former route is 6, and the number of forwarding times of latter route is 8. Therefore, the shortest route through the memory nodes connected to the non-adjacent nodes is the default route (see (<b>3</b>) of <figref idrefs="DRAWINGS">FIG. 25</figref>).</div>
<div class="description-paragraph" id="p-0257" num="0256">The case in which the route including the connection between the non-adjacent nodes is the default route will be described below.
</div> <ul> <li id="ul0001-0001" num="0000"> <ul> <li id="ul0002-0001" num="0257">The gateway server <b>21</b>A produces the write packet in which the header portion including the address data and the write command is added to the write data. The “temporary destination node” of the address information recorded in the header portion of the packet, is set to the main address (in <figref idrefs="DRAWINGS">FIG. 22</figref>, (8,3)) of the “first relay node”, and the “temporary source node” is set to the main address (in <figref idrefs="DRAWINGS">FIG. 22</figref>, (7,0)) of the packet, source. Both “types” of the “temporary destination node address” and the “temporary source node address” are deiced as the main addresses. The “first relay node sub-address”, the “second relay node sub-address”, the “final destination node main address”, and the “source node main address” are also written in the header portion of the packet in this stage.</li> <li id="ul0002-0002" num="0258">The produced write packet is forwarded from the gateway server <b>21</b>A to the memory node connected to the gateway server <b>21</b>A (see (<b>4</b>) of <figref idrefs="DRAWINGS">FIG. 25</figref>).</li> <li id="ul0002-0003" num="0259">According to the above algorithm, the write packet is forwarded between the memory nodes by referring to the main addresses of the “temporary destination node”, the “temporary source node”, and the self-node until the write packet reaches the “temporary destination memory node”(in <figref idrefs="DRAWINGS">FIG. 22</figref>, the first relay node having the main address (8,3)) (see (<b>5</b>) of <figref idrefs="DRAWINGS">FIG. 25</figref>).</li> <li id="ul0002-0004" num="0260">The first relay node that receives the write packet reads the header portion of the packet. Because the final destination node of the packet is another memory node while the “first relay node sub-address” written in the header is same as that of the self-node, the “temporary destination node address” is changed to the sub-address (in <figref idrefs="DRAWINGS">FIG. 22</figref>, [2,2]) of the “second relay node” written in the header of the packet, and the “temporary source node address” is changed to the sub-address (in <figref idrefs="DRAWINGS">FIG. 22</figref>, [2,1]) of the self-node (see (<b>6</b>) of <figref idrefs="DRAWINGS">FIG. 25</figref>). Both “types” of the “temporary destination node address” and the “temporary source node address” are changed to the sub-addresses. The packet is forwarded to the memory node connected to the adjacent non-adjacent node (see (<b>7</b>) of <figref idrefs="DRAWINGS">FIG. 25</figref>).</li> <li id="ul0002-0005" num="0261">According to the above algorithm, the write packet is forwarded between the memory nodes connected to the non-adjacent nodes by referring to the sub-addresses of the temporary destination, the temporary source, and the self-node until the write packet reaches the second relay node that is the “temporary destination memory node”.</li> <li id="ul0002-0006" num="0262">The second relay node that receives the write packet reads the header portion of the packet. Because the final destination is another memory node while “the second relay node” written in the header position of the packet is self-node, the “temporary destination node address” is changed to the main address (in <figref idrefs="DRAWINGS">FIG. 22</figref>, write node (7,8)) of the final destination node, and the “temporary source node address” is changed to the main address (in <figref idrefs="DRAWINGS">FIG. 22</figref>, (8,8)) of the self-node (see (<b>8</b>) of <figref idrefs="DRAWINGS">FIG. 25</figref>). The write packet is forwarded to the adjacent memory node.</li> <li id="ul0002-0007" num="0263">The write packet is repeatedly forwarded between the memory nodes according to the above algorithm by referring to the main addresses of the “temporary source node”, the “temporary destination node”, and the self-node, and until the write packet reaches the write node (in <figref idrefs="DRAWINGS">FIG. 22</figref>, main address (7,8)) that is the final destination node (see (<b>9</b>) of <figref idrefs="DRAWINGS">FIG. 25</figref>).</li> <li id="ul0002-0008" num="0264">Because the “final destination node address” is the same as that of the self-node, the write node that receives the packet does not forward the packet, but writes the address information on the header portion and the write data in a memory <b>16</b> of the self-node (see (<b>10</b>) of <figref idrefs="DRAWINGS">FIG. 25</figref>). Then a write completion reporting packet is produced in which the header addresses of the “temporary source node” and the “temporary destination node” and those of the “first relay node” and the “second relay node” and those of the “final destination node” and the “source node” are reversed as follows. The “source node” is set to the write node having the main address (7,8), the “final destination node” is set to the gateway server <b>21</b>A having the main address (7,0), the “first relay node” is set to the node having the main address (8,8) (the sub-address [2,2]), and the “second relay node” is set to the node having the main address (<b>8</b>,<b>3</b>) (sub-address [2,1]). The “temporal source node” is set to the write node having the main address (7,8), the “temporal destination node” is set to the “first relay node” having the main address (8,8), and their “types” are changed to main, address. Then the write completion reporting packet is sent back to the gateway server <b>21</b>A by the similar procedure (see (<b>11</b>) of <figref idrefs="DRAWINGS">FIG. 25</figref>). After all the divided pieces of data are written, the gateway server <b>21</b>A performs the write completion reporting to the client.</li> </ul> </li> </ul>
<div class="description-paragraph" id="p-0258" num="0265">In the above example, the procedure how to write a client file in the storage device including memory nodes connected to another non-adjacent nodes is explained. In the case that a command such as read, erase, and free space reply is transmitted from the gateway server to the memory node of the storage device in order to read or erase the data written in the memory node or to confirm the free space, the packet forwarding time can foe shortened by conducting the communication through the connection between the non-adjacent nodes. In the case that the read data or the inquiry result are transmitted from the memory node to the gateway server, the packet forwarding time can also foe shortened by conducting the communication through the connection between the non-adjacent nodes.</div>
<div class="description-paragraph" id="p-0259" num="0266">As described above, the average number of packet forwarding times can be decreased by transmitting the data through the connection between the non-adjacent nodes. Preferably the memory nodes that are connected to the non-adjacent nodes by the additional input/output ports are disposed in the storage device with uniform distribution. One method to realize such layout is to divide the storage device such that each divided area has the same number of memory nodes, then to place the memory node with extra port in the center of each divided area.</div>
<div class="description-paragraph" id="p-0260" num="0267">For example, in the storage device of <figref idrefs="DRAWINGS">FIG. 22</figref> constructed by the 10-by-10 memory node, the storage device is divided into four areas including the 5-by-5 memory node (boundary is indicated by a dotted line), and the memory nodes with an additional port is placed in the center nodes of four areas, namely, memory nodes (3,3), (8,3), (3,8), and (8,8).</div>
<div class="description-paragraph" id="p-0261" num="0268">More generally, it is preferable to divide the storage device constructed by the al-by-bm memory node into 1-by-m areas, and to place the memory node with extra port in the center node of each area, namely the memory node with address (c<b>1</b>+round (<b>1</b>/<b>2</b>,<b>0</b>), em+round (m/<b>2</b>,<b>0</b>)) (a≥c≥0, b≥e≥0, 1≥d≥0, m≥f≥0; round (A,<b>0</b>) is a function that rounds off A to the nearest integer).</div>
<div class="description-paragraph" id="p-0262" num="0269">In the storage device, a trouble that is caused by connecting some non-adjacent memory nodes is that the jam of the packet communication is easily generated at the nodes, as the route of packet transmission via such nodes is preferred due to small numbers of packet forwarding time.</div>
<div class="description-paragraph" id="p-0263" num="0270">The jam of the packet forwarding can be relaxed by making the packet communication speed between the non-adjacent memory nodes higher than that between the adjacent memory nodes. However, in this case, it is important to note that the total packet communication time, which is necessary to be calculated to decide the shortest route of packet transmission, differs from the total number of packet forwarding times. The total packet communication time is equal to a product of the communication time between the memory nodes and the number of packet forwarding times. Accordingly, in the case that the speed of data communication between the adjacent memory nodes is equal to that of data communication between the non-adjacent memory nodes, as described above, the data communication time can be compared by the number of forwarding times of each route. On the other hand, in the case that the packet transmission speed between the adjacent memory nodes differs from the packet transmission speed between the non-adjacent memory nodes, the data communication times cannot be compared only by the number of forwarding times.</div>
<div class="description-paragraph" id="p-0264" num="0271">The total packet communication time of the route through the connection between the non-adjacent nodes and the route that does not pass through the connection between the non-adjacent nodes can correctly foe compared by referring to a product of an inverse number (because of speed=distance/time, the inverse number is proportional to the communication time) of the communication speed and the number of forwarding times. However, the calculation becomes complicated when the connection between the adjacent nodes and the connection between the non-adjacent nodes are mixed in the packet communication route, as in the case described above.</div>
<div class="description-paragraph" id="p-0265" num="0272">In the storage device in which the packet communication speed between the adjacent nodes differs from the packet communication speed between the non-adjacent nodes, the step of the provided address may inversely be proportional to the packet communication speed to regard an address difference thereof as the number of forwarding time.</div>
<div class="description-paragraph" id="p-0266" num="0273"> <figref idrefs="DRAWINGS">FIG. 26</figref> illustrates an example in which the address is provided, wherein the packet communication speed between the non-adjacent nodes is ten times higher than the packet communication speed between the adjacent nodes. In <figref idrefs="DRAWINGS">FIG. 26</figref>, while reflecting the relative physical position, the sub-address is provided so as to be different by one between a certain memory node and the non-adjacent nodes connected to the memory node (expressed by a square bracket). Additionally, while reflecting the mutual physical positional relationship, the main address is provided so as to be different by 10 between the adjacent memory nodes (expressed by a round bracket), as shown in <figref idrefs="DRAWINGS">FIG. 26</figref>.</div>
<div class="description-paragraph" id="p-0267" num="0274">In the storage device, a difference of the sub-address between the memory nodes is calculated in the case that the packet is transmitted between the memory nodes connected to the non-adjacent nodes, and a difference of the main address between the memory nodes is calculated in the case that the packet is transmitted between the adjacent memory nodes, and the differences are regarded as the number of forwarding times. When the rule to calculate the number of forwarding times is decided as described above, the packet communication time can be estimated and compared only by the number of forwarding times even if the connection speed between the adjacent nodes differs from the connection speed between the non-adjacent nodes.</div>
<div class="description-paragraph" id="p-0268" num="0275">As described above, according to the seventh embodiment, the forwarding time can be shortened when the packet is forwarded between the gateway server and the memory node in the storage device. Other configurations and effects are similar to those of the first, embodiment.</div>
<div class="description-paragraph" id="h-0013" num="0000">[Eighth Embodiment]</div>
<div class="description-paragraph" id="p-0269" num="0276">In a storage system according to an eighth embodiment, a switching relay is added between a gateway server and a storage device in order to decrease the average number of packet forwarding times.</div>
<div class="description-paragraph" id="p-0270" num="0277">[1] Configuration of Storage System</div>
<div class="description-paragraph" id="p-0271" num="0278"> <figref idrefs="DRAWINGS">FIG. 27</figref> is a view illustrating a configuration of the storage system of the eighth embodiment.</div>
<div class="description-paragraph" id="p-0272" num="0279">As illustrated in <figref idrefs="DRAWINGS">FIG. 27</figref>, the storage system includes a storage device <b>10</b> that includes memory nodes <b>11</b>, a switching relay <b>81</b> that is connected to the storage device <b>10</b>, and a gateway server <b>21</b>A that is connected to the switching relay <b>81</b>.</div>
<div class="description-paragraph" id="p-0273" num="0280">The storage device <b>10</b> has the configuration in which the data-forwarding-function-equipped memory nodes are mutually connected as illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>. The switching relay <b>81</b> is connected to all, memory nodes (1,1), (1,2), (1,3), (1,4), (1,5), (1,6), (1,7), (1,8), and (1,9), which are disposed on one end side (left end in <figref idrefs="DRAWINGS">FIG. 27</figref>) of the storage device <b>10</b>. The gateway server <b>21</b>A is connected to the switching relay <b>81</b> through an adapter <b>22</b>A,</div>
<div class="description-paragraph" id="p-0274" num="0281">The switching relay <b>81</b> forwards the received packet to the assigned destination node according to the address information recorded in the header portion of the packet. An address (in <figref idrefs="DRAWINGS">FIG. 27</figref>, expressed by a square bracket) that is different from that of the memory node in the storage device is provided to the switching relay <b>81</b>.</div>
<div class="description-paragraph" id="p-0275" num="0282">[2] Packet Forwarding of Storage System</div>
<div class="description-paragraph" id="p-0276" num="0283">The procedure to forward the packet in the storage device of the eighth embodiment will, be described.</div>
<div class="description-paragraph" id="p-0277" num="0284">The packet delivered from the gateway server <b>21</b>A enters the switching relay <b>81</b> through the adapter <b>22</b>A. The packet that enters the switching relay <b>81</b> is transmitted to one of the memory nodes (1,1), (1,2), (1,3), (1,4), (1,5), (1,6), (1,7), (1,8), and (1,9), which are connected to the switching relay <b>81</b>, and then the packet is forwarded to the memory node of the destination address.</div>
<div class="description-paragraph" id="p-0278" num="0285">On the contrary, the packet transmitted from the memory node in the storage device <b>10</b> is transmitted to one of the memory nodes (1,1) to (1,9), and forwarded to the gateway server <b>21</b>A through the switching relay <b>81</b> and the adapter <b>22</b>A.</div>
<div class="description-paragraph" id="p-0279" num="0286">In the storage system, illustrated in <figref idrefs="DRAWINGS">FIG. 27</figref>, the case in which the packet is transmitted to the memory node (<b>5</b>,<b>9</b>) from the gateway server <b>21</b>A through the switching relay <b>81</b> and the memory node (1,9) is as follows. The shortest route is switching relay <b>81</b>→memory node (1,9)→(2,9)→(3,9)→(4,9)→(5,9), and the number of packet forwarding times in the storage device <b>10</b> is 4.</div>
<div class="description-paragraph" id="p-0280" num="0287">On the other hand, as illustrated in <figref idrefs="DRAWINGS">FIG. 28</figref>, in a storage system in which the gateway server <b>21</b>A is connected to the memory node (1,4) of the storage device <b>10</b> without passing through the switching relay <b>81</b>, the case in which the packet is transmitted from the gateway server <b>21</b>A to the memory node (5,9) is as follows. One of the shortest route is gateway server <b>21</b>A→memory node (1,4)→(1,5)→(1,6)→(1,7)→(1,8)→(1,9)→(2,9)→(3,9)→(4,9)→(5,9), and the number of packet forwarding times in the storage device <b>10</b> is at least 9.</div>
<div class="description-paragraph" id="p-0281" num="0288">When the switching relay <b>81</b> is introduced between the gateway server <b>21</b>A and the storage device <b>10</b>, the number of packet forwarding times can be decreased to shorten the forwarding time.</div>
<div class="description-paragraph" id="p-0282" num="0289">The case in which the packet is transmitted from the gateway server <b>21</b>A to the storage device <b>10</b> is described above. Even in the case that the data stored in the memory node of the storage device <b>10</b> is transmitted to the gateway server <b>21</b>A, in the storage system in which the switching relay <b>81</b> exists between the gateway server <b>21</b>A and the storage device <b>10</b> (see <figref idrefs="DRAWINGS">FIG. 27</figref>), the number of packet forwarding times is decreased to shorten the forwarding time, compared with the storage system in which the gateway server <b>21</b>A and the storage device <b>10</b> are directly connected through the adapter (see <figref idrefs="DRAWINGS">FIG. 28</figref>).</div>
<div class="description-paragraph" id="p-0283" num="0290">However, in the storage system in which the switching relay is introduced, the number of packet forwarding times depends on the memory node that performs the relay in transmitting and receiving the packet between the switching relay and the storage device. For example, as described above, in the case that the gateway server <b>21</b>A forwards the packet to the memory node (5,9) in the storage system illustrated in <figref idrefs="DRAWINGS">FIG. 27</figref>, the number of packet forwarding times in the storage device <b>10</b> is at least <b>4</b> when the memory node (1,9) is used as the relay memory node. On the other hand, in the case that another memory node except the memory node (1,9) is used as the relay memory node, it is necessary to forward the packet five times or more.</div>
<div class="description-paragraph" id="p-0284" num="0291">In order to minimize the number of packet forwarding times, it is necessary that the memory node closest to the destination node be selected as the relay memory node in the memory nodes that are directly connected to the switching relay. The procedure to calculate the address of the relay memory node such that, the packet forwarding time becomes the minimum is described later.</div>
<div class="description-paragraph" id="p-0285" num="0292">In the storage system in which the gateway server and the storage device are connected without passing through the switching relay, in the case that the packet is forwarded between the gateway server and the memory node in the storage device, the source and the destination are one of the gateway server and the memory node, and the source and the destination are not changed while the packet is forwarded.</div>
<div class="description-paragraph" id="p-0286" num="0293">On the other hand, in the storage system in which the gateway server and the storage device are connected through the switching relay, in the case that the packet is forwarded, the packet is forwarded while the relay memory node is set to the destination. After the packet reaches the relay memory node, the packet is forwarded while the memory node (in the case that the packet is transmitted from the gateway server to the memory node) or the switching relay (in the case that the packet is transmitted from the memory node to the gateway server) is set to the destination. That is, it is necessary to change the destination of the packet before and after the packet reaches the relay memory node.</div>
<div class="description-paragraph" id="p-0287" num="0294"> <figref idrefs="DRAWINGS">FIG. 29</figref> illustrates an example of the address information recorded in the header portion of the packet in the storage system in which the switching relay is used. As used herein, a final destination node and a source node means a memory node having the address to which the packet is finally delivered and a memory node that initially produces and transmits the packet, respectively. On the other hand, a temporary destination node address and a temporary source node address are addresses, which are used to determine the packet forwarding destination in each memory node and updated by the relay memory node connected to the switching relay (an update rule is described later).</div>
<div class="description-paragraph" id="p-0288" num="0295">An address type is used to determine whether the address is the address of the memory node In the storage device <b>10</b> or the address of the switching relay <b>81</b>. A relay node address is an address of the memory node that is connected to the switching relay <b>81</b>, and the packet should he forwarded through the relay node address.</div>
<div class="description-paragraph" id="p-0289" num="0296">As described above, the address information recorded in the header portion of the packet is updated in the memory nodes connected to the switching relay. In the case that the address information on the packet is illustrated in <figref idrefs="DRAWINGS">FIG. 29</figref>, for example, the update rule is as follows.</div>
<div class="description-paragraph" id="p-0290" num="0297">1. In the case that the final destination node is the memory node except the self-node while the source is the switching relay, the temporary destination is changed to the final destination node and the temporary source is changed to the self-node.</div>
<div class="description-paragraph" id="p-0291" num="0298">2. In the case that the final destination node is the switching relay, the temporary destination is changed to the switching relay and the temporary source is changed to the self-node.</div>
<div class="description-paragraph" id="p-0292" num="0299">3. In the case that the final destination is the memory node except the self-node while the source is also the memory node, both the temporary destination and the temporary source are not changed.</div>
<div class="description-paragraph" id="p-0293" num="0300">For example, the procedure in which the client writes the file in the storage device <b>10</b> in the storage system illustrated in <figref idrefs="DRAWINGS">FIG. 27</figref> is as follow.</div>
<div class="description-paragraph" id="p-0294" num="0301"> <figref idrefs="DRAWINGS">FIG. 30</figref> is a view illustrating the write operation in the storage system Illustrated in <figref idrefs="DRAWINGS">FIG. 27</figref>.</div>
<div class="description-paragraph" id="p-0295" num="0302">The client transmits the file and the file ID to the gateway server <b>21</b>A (see (<b>1</b>) of <figref idrefs="DRAWINGS">FIG. 30</figref>). The file ID is an identifier that can uniquely identify the</div>
<div class="description-paragraph" id="p-0296" num="0303">The gateway server <b>21</b>A divides the file into pieces of data having a defined size and allocates a division data ID to each divided piece of data. The gateway server <b>21</b>A writes the file ID and the division data IDs in the file table. The division data ID is an identifier that can uniquely identify the divided data (see (<b>2</b>) of <figref idrefs="DRAWINGS">FIG. 30</figref>).</div>
<div class="description-paragraph" id="p-0297" num="0304">The gateway server <b>21</b>A determines the address of the memory node (write node) in which the divided data is written based on the information on the division data ID (in <figref idrefs="DRAWINGS">FIG. 27</figref>, address (5,9)). Assuming that the relay memory node is the memory node closest to the write node in the memory nodes connected to the switching relay <b>81</b>, the gateway server <b>21</b>A calculates the address of the relay memory node (in <figref idrefs="DRAWINGS">FIG. 27</figref>, address (1,9)) (see (<b>3</b>) of <figref idrefs="DRAWINGS">FIG. 30</figref>).</div>
<div class="description-paragraph" id="p-0298" num="0305">The gateway server <b>21</b>A produces the write packet in which the header portion including the address information is added to the write data. At this point, it is assumed that temporary destination address is the address of the relay node (in <figref idrefs="DRAWINGS">FIG. 27</figref>, address (1,9)), and if is assumed that the temporary source node address is the address of the switching relay <b>81</b> (in <figref idrefs="DRAWINGS">FIG. 27</figref>, [<b>1</b>]). Then the packet is transmitted to the switching relay <b>81</b> (see (<b>4</b>) of <figref idrefs="DRAWINGS">FIG. 30</figref>).</div>
<div class="description-paragraph" id="p-0299" num="0306">The switching relay <b>81</b> that receives the write packet transmits the write packet to the assigned temporary destination memory node (relay memory node (1,9)) (see (<b>5</b>) of <figref idrefs="DRAWINGS">FIG. 30</figref>).</div>
<div class="description-paragraph" id="p-0300" num="0307">The relay memory node that receives the write packet from the switching relay <b>81</b> reads the header portion of the packet. Because the final destination node is another memory node in the storage device <b>10</b>, the relay memory node produces the write packet in which the header portion is updated as follows. In the header portion, the temporary source address is changed to the self-node address, and the temporary destination node address is changed to the address (in <figref idrefs="DRAWINGS">FIG. 27</figref>, (5,9)) of the write node that is the final destination (see (<b>6</b>) of <figref idrefs="DRAWINGS">FIG. 30</figref>).</div>
<div class="description-paragraph" id="p-0301" num="0308">Then the write packet is forwarded to the adjacent memory node. The write packet is repeatedly forwarded in the storage device <b>10</b>, the write packet reaches the write node (in <figref idrefs="DRAWINGS">FIG. 27</figref>, memory node (5,9)) (see (<b>7</b>) of <figref idrefs="DRAWINGS">FIG. 30</figref>).</div>
<div class="description-paragraph" id="p-0302" num="0309">In the memory node in which the write packet is written, the addresses of the write data, packet source and the relay node of the received packet are written in a memory <b>16</b> of the self-node (see (<b>8</b>) of <figref idrefs="DRAWINGS">FIG. 30</figref>). Then the write completion reporting packet is produced and sent back to the gateway server <b>21</b>A through the inverse route (see (<b>9</b>) of <figref idrefs="DRAWINGS">FIG. 30</figref>). In the write completion reporting packet, the final destination node of the address information of the header portion is set to the switching relay, the source is set to the write node, the relay node is set to the same memory node as the case in which the gateway server <b>21</b>A forwards the packet to the write node, the temporary destination node is set to the relay node, and the temporary source node is set to the write node. As to the address information in the header portion of the packet, in the relay memory node, the temporary destination is updated to the switching relay, and the temporary source is updated to the relay node (see (<b>10</b>) of <figref idrefs="DRAWINGS">FIG. 30</figref>).</div>
<div class="description-paragraph" id="p-0303" num="0310">After all the divided pieces of data are written, the gateway server <b>21</b>A performs the write completion reporting to the client.</div>
<div class="description-paragraph" id="p-0304" num="0311">Not only in the case that the client writes the file in the storage device <b>10</b>, but also in the case that a read command, an erase command and a free space replay command are transmitted to the memory node of the storage device <b>10</b> in order to read or erase the written data or to confirm the free space, the packet can be forwarded through the memory node connected to the switching relay <b>81</b> according to the above procedure. In the case that command execution completion report of the write and erase operations and the data read from the memory node are transmitted from the memory node to the gateway server <b>21</b>A, similarly the packet can be forwarded through the memory node connected to the switching relay <b>81</b> according to the above procedure. Therefore, the forwarding time can be shortened.</div>
<div class="description-paragraph" id="p-0305" num="0312">The storage system in which only the memory nodes at the left end are connected to the switching relay <b>81</b> as illustrated in <figref idrefs="DRAWINGS">FIG. 27</figref> is described above. As illustrated in <figref idrefs="DRAWINGS">FIG. 31</figref>, in a storage system in which the memory nodes in the whole outer peripheral portion are connected to switching relays <b>81</b>, <b>82</b>, <b>83</b>, and <b>84</b>, the number of packet forwarding times can be decreased to shorten the packet forwarding time compared with the storage system in which the switching relay Is not introduced. In the storage system illustrated in <figref idrefs="DRAWINGS">FIG. 31</figref>, the switching relay <b>81</b> is connected to the memory nodes disposed at the left end of the storage device, the switching relay <b>82</b> is connected to the memory nodes disposed at the upper end, the switching relay <b>83</b> is connected to the memory nodes disposed at the right end, and the switching relay <b>84</b> is connected to the memory nodes disposed at the lower end. All the switching relays are connected to the gateway server <b>21</b>A through the adapter <b>22</b>A.</div>
<div class="description-paragraph" id="p-0306" num="0313">As illustrated in <figref idrefs="DRAWINGS">FIG. 32</figref>, in the storage system including the storage device in which the memory nodes including the input/output ports (non-adjacent ports) except the input/output port connected to the adjacent node are connected to the switching relay <b>81</b> by the non-adjacent ports, the average number of packet forwarding times can be decreased to shorten the packet forwarding time compared with the storage system in which the switching relay is not introduced. In the storage system illustrated in <figref idrefs="DRAWINGS">FIG. 32</figref>, the switching relay <b>81</b> is connected to the memory nodes (3,2), (3,7), (8,2), and (8,7) in the storage device <b>10</b>.</div>
<div class="description-paragraph" id="p-0307" num="0314">As described above, in the case that the packet is forwarded through the memory node connected to the switching relay, it is necessary that the memory node be selected as the relay memory node such that the packet forwarding time (the number of forwarding times) becomes the minimum. The method for calculating the address of the relay memory node will be described below.</div>
<div class="description-paragraph" id="p-0308" num="0315">As illustrated in <figref idrefs="DRAWINGS">FIG. 27</figref>, in the case that the data is forwarded between the gateway server <b>2</b>IA and the storage device <b>10</b> in which all the memory nodes at the left end are connected to the switching relay <b>81</b>, the memory node having the address (l,y) is the memory node, which is connected to the switching relay <b>81</b> and in which the packet forwarding distance (the number of forwarding times) becomes the minimum, with respect to the packet destination/source memory node of the address (x,y) in the storage device <b>10</b>.</div>
<div class="description-paragraph" id="p-0309" num="0316">The storage device includes the array in which c<b>0</b> memory nodes are horizontally disposed while d<b>0</b> memory nodes are vertically disposed, and the memory node disposed at a corner has the address (a<b>0</b>, b<b>0</b>). In this case, in the case that all the memory nodes in the outer peripheral portion are connected to the switching relay, when the memory node having the address (x,y) in the storage device <b>10</b> performs the packet forwarding with the gateway server <b>21</b>A, the address of the relay memory node in which the packet forwarding time (the number of forwarding times) becomes the minimum is as follows. At this point, as illustrated in <figref idrefs="DRAWINGS">FIG. 31</figref>, the address of the memory node connected to the switching relay is expressed by (a<b>0</b>, y), (a<b>0</b>+c<b>0</b>, y), (x ,b<b>0</b>), and (x, b<b>0</b>+d<b>0</b>) (x is any integer of a<b>0</b> to a<b>0</b>+c<b>0</b> and y is any integer of b<b>0</b> to b<b>0</b>+d<b>0</b>).</div>
<div class="description-paragraph" id="p-0310" num="0317">(x-a<b>0</b>, y) in the case of min (x−a<b>0</b>, a<b>0</b>+c<b>0</b>−x)≤min (y−b<b>0</b>, b<b>0</b>+d<b>0</b>−y) and min (x−a<b>0</b>, a<b>0</b>+c<b>0</b>−x)=x−a<b>0</b>;</div>
<div class="description-paragraph" id="p-0311" num="0318">(a<b>0</b>+c<b>0</b>−x,y) in the case of min (x−a<b>0</b>, a<b>0</b>+c<b>0</b>−x)≤min (y−b<b>0</b>, b<b>0</b>+d<b>0</b>−y) and min (x−a<b>0</b>, a<b>0</b>+c<b>0</b>−x)=a<b>0</b>+c<b>0</b>−x;</div>
<div class="description-paragraph" id="p-0312" num="0319">(x, y−b<b>0</b>); in the case of min (x-a<b>0</b>, a<b>0</b>+c<b>0</b>−x)≤min (y−b<b>0</b>, b<b>0</b>+d<b>0</b>−y) and min (y−b<b>0</b>, b<b>0</b>+d<b>0</b>−y)=y−b<b>0</b>; and</div>
<div class="description-paragraph" id="p-0313" num="0320">(x, b<b>0</b>+d<b>0</b>−y) in the case of min (x−a<b>0</b>, a<b>0</b>+c<b>0</b>−x)≤min (y−b<b>0</b>, b<b>0</b>+d<b>0</b>−y) and min (y−b<b>0</b>, b<b>0</b>+d<b>0</b>−y)=b<b>0</b>+d<b>0</b>−y.</div>
<div class="description-paragraph" id="p-0314" num="0321">Where min (x, y) is a function that gives a smaller one of two arguments x and y.</div>
<div class="description-paragraph" id="p-0315" num="0322">On the other hand, as illustrated in <figref idrefs="DRAWINGS">FIG. 32</figref>, in the case that the address of the memory node connected to the switching relay <b>81</b> is given by an integer (am+b, cn+d) (m and n are integers) (in <figref idrefs="DRAWINGS">FIG. 32</figref>, a=5, b=3, c=5, d=2, m=0 or 1, and n=0 or 1), the memory node (relay memory node), which is connected to the switching relay <b>81</b> and in which the packet forwarding time (the number of forwarding times) becomes the minimum, with respect to any memory node (address (x,y)) is given by (a (round (x/a, <b>0</b>)+b, c (round (y/c, 0)+d). Where round (u, 0) is a function that rounds off a numerical value u to the nearest Integer.</div>
<div class="description-paragraph" id="p-0316" num="0323">As described above, according to the eighth embodiment, the number of packet forwarding times can be decreased between the memory nodes in the storage device. Other configurations and effects are similar to those of the first embodiment.</div>
<div class="description-paragraph" id="h-0014" num="0000">[Ninth Embodiment]</div>
<div class="description-paragraph" id="p-0317" num="0324">A storage system according to a ninth embodiment includes a data processing procedure to select the memory node having a data forwarding time different from that of a gateway server as a storage destination of each of a plurality of pieces of data in data processing of storing the data in memory nodes.</div>
<div class="description-paragraph" id="p-0318" num="0325">[1] Configuration of Storage System</div>
<div class="description-paragraph" id="p-0319" num="0326"> <figref idrefs="DRAWINGS">FIG. 33A</figref> is a view illustrating a configuration of the storage device of the ninth embodiment.</div>
<div class="description-paragraph" id="p-0320" num="0327">As illustrated in <figref idrefs="DRAWINGS">FIG. 33A</figref>, the storage system includes a storage device <b>10</b> that includes memory nodes <b>11</b> and gateway servers <b>21</b>A that are connected to the storage device <b>10</b>. The storage device <b>10</b> has the configuration in which the data-forwarding-function-equipped memory nodes are mutually connected as illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>. The gateway servers <b>21</b>A are connected to a memory node (1,4) disposed in the outer peripheral portion of the storage device <b>10</b> through an adapter <b>22</b>A.</div>
<div class="description-paragraph" id="p-0321" num="0328">[2] Data Processing Method of Storage System</div>
<div class="description-paragraph" id="p-0322" num="0329">A data processing procedure in the storage system of the ninth embodiment will be described.</div>
<div class="description-paragraph" id="p-0323" num="0330"> <figref idrefs="DRAWINGS">FIGS. 33A to 33D</figref> and <figref idrefs="DRAWINGS">FIGS. 34A to 34E</figref> illustrate a storage system in which the storage device <b>10</b> is connected to the gateway servers <b>21</b>A through the adapter <b>22</b>A. The storage device includes the memory nodes <b>11</b> in which the adjacent memory nodes are mutually connected.</div>
<div class="description-paragraph" id="p-0324" num="0331">Each memory node <b>11</b> receives the packet when the packet is addressed to the self-node, and the memory node <b>11</b> forwards the packet to the adjacent memory node when the packet is addressed to another memory node. The packet communication can be conducted between the gateway server <b>21</b>A and the assigned memory node by the data forwarding function.</div>
<div class="description-paragraph" id="p-0325" num="0332">However, the number of forwarding times necessary for the packet forwarding depends on the memory node. For example, the minimum number of forwarding times necessary for the packet communication with the gateway server <b>21</b>A is 0 with respect to the memory node having an address (1,4), the minimum, number of forwarding times is 1 with respect to the memory nodes having addresses (1,5), (2,4), and (1,3), and the minimum number of forwarding times is 2 with respect to the memory nodes having addresses (1,6), (2,5), (3,4), (2,3), and (1,2). In <figref idrefs="DRAWINGS">FIGS. 33A to 33D</figref> and <figref idrefs="DRAWINGS">FIGS. 34A to 34E</figref>, the memory nodes having the same minimum number of forwarding times are expressed by the same hatching.</div>
<div class="description-paragraph" id="p-0326" num="0333">At this point, it is assumed that a packet forwarding time in the memory node of the storage device <b>10</b> and the packet transmission time between the memory nodes are kept constant irrespective of the memory node. In this case, a total packet forwarding time is identical anywhere in the memory nodes. The packet forwarding time means a time until a determination whether the packet is addressed to the self-node is made from the address recorded in the header portion of the packet to output the packet from the output port after the packet is received by the input port. The total packet forwarding time means a time until the packet transmitted to the adjacent node reaches the adjacent node since the memory node receives the packet.</div>
<div class="description-paragraph" id="p-0327" num="0334">One file is divided into three, and the three pieces of data to which ID=1, ID=2, and ID=3 are provided according to the order of the data after the division are stored in three memory nodes, respectively. The data processing in which the three pieces of data are read from the memory node and transmitted to the gateway server is discussed.</div>
<div class="description-paragraph" id="p-0328" num="0335">The read data forwarding processes in the storage device are compared with respect to the case that the three memory nodes in which the pieces of data are stored are memory nodes in which the minimum numbers of forwarding times necessary for the packet communication with the gateway server become identical and the case that the three memory nodes in which the pieces of data are stored are memory nodes in which the minimum numbers of forwarding times necessary for the packet communication with the gateway server differ from one another. It is assumed that the read command is simultaneously issued, and it is assumed that the transmission of the read data is simultaneously started, and therefore it is assumed that the three pieces of data are simultaneously forwarded,</div>
<div class="description-paragraph" id="p-0329" num="0336"> <figref idrefs="DRAWINGS">FIGS. 33A to 33D</figref> illustrate an example of a process, in which the three pieces of data stored in memory nodes (1,1), (2,2), and (3,5) in which the minimum number of forwarding times necessary for the packet communication with the gateway server <b>21</b>A is 3 is forwarded to the gateway server <b>21</b>A after the three pieces of data read from the memory nodes.</div>
<div class="description-paragraph" id="p-0330" num="0337"> <figref idrefs="DRAWINGS">FIG. 33A</figref> illustrates the state of the storage device <b>10</b> immediately after the data is read from the memory in each memory node (before the forwarding), and <figref idrefs="DRAWINGS">FIG. 33B</figref> illustrates the state in which all the three pieces of data are forwarded to the adjacent node of the memory node in which the data is stored after a given time elapses from the state of <figref idrefs="DRAWINGS">FIG. 33A</figref>. As illustrated in <figref idrefs="DRAWINGS">FIG. 33B</figref>, the three pieces of data stored in the memory nodes (1,1), (2,2), and (3,5) in the state of <figref idrefs="DRAWINGS">FIG. 33A</figref> are forwarded to memory nodes (1,2), (2,3), and (2,5), respectively.</div>
<div class="description-paragraph" id="p-0331" num="0338"> <figref idrefs="DRAWINGS">FIGS. 33C and 33D</figref> illustrate the state in which each piece of data is forwarded twice and triple. As illustrated in <figref idrefs="DRAWINGS">FIG. 330</figref>, the three pieces of data stored in the memory nodes (1,2), (2,3), and (2,5) in the state of <figref idrefs="DRAWINGS">FIG. 33B</figref> are forwarded to memory nodes (1,3), (2,4), and (1,5), respectively. As illustrated in <figref idrefs="DRAWINGS">FIG. 33D</figref>, the three pieces of data stored in the memory nodes (1,3), (2,4), and (1,5) in the state of <figref idrefs="DRAWINGS">FIG. 33C</figref> are forwarded to memory node (1,4). In the process illustrated in <figref idrefs="DRAWINGS">FIGS. 33A to 33D</figref>, because the data is forwarded from the memory node in which the data is stored toward the gateway server <b>21</b>A, the pieces of data are forwarded to the memory node having the smaller minimum number of forwarding times necessary for the packet communication with the gateway server <b>21</b>A as time advances.</div>
<div class="description-paragraph" id="p-0332" num="0339">In the storage device <b>10</b> Illustrated in <figref idrefs="DRAWINGS">FIGS. 33A to 33C</figref>, the three pieces of data exist separately in the memory nodes. On the other hand, in the storage device <b>10</b> illustrated in <figref idrefs="DRAWINGS">FIG. 33D</figref>, all the pieces of data are located on the memory node having the address (1,4). This expresses the state in which the three pieces of data simultaneously reaches the memory node having the address (1,4).</div>
<div class="description-paragraph" id="p-0333" num="0340">In the case that a storage capacity size of the temporarily storing memory (input port buffer) of the memory node is not as large as an extent in which the plurality of pieces of data can be stored, only one piece of data can be received once by the memory node (1,4). The temporarily storing memory is a memory in which the data is stored until the data is forwarded in the case that the temporarily storing memory receives the data that is not addressed to the self-node.</div>
<div class="description-paragraph" id="p-0334" num="0341">In this case, until the received one piece of data is forwarded to the adapter <b>22</b>A, other pieces of data cannot be forwarded to the memory node having the address (1,4), and it is necessary for other pieces of data to wait in the adjacent nodes.</div>
<div class="description-paragraph" id="p-0335" num="0342">Even if the temporarily storing memory of the memory node has the sufficiently large storage capacity size to be able to temporarily store the three pieces of data at the same time, because usually the three pieces of data cannot simultaneously be transmitted from the memory node having the address (1,4) to the gateway server <b>21</b>A, it is necessary for other pieces of data to wait in the memory node having the address (1,4) until one piece of data is transmitted to the gateway server <b>21</b>A. When the waiting of the data forwarding is generated, the time necessary to forward all the pieces of data is increased.</div>
<div class="description-paragraph" id="p-0336" num="0343">As can be seen from <figref idrefs="DRAWINGS">FIGS. 33A to 33D</figref>, the number of memory nodes in which the minimum numbers of forwarding times necessary for the packet communication with the gateway server <b>21</b>A become Identical is decreased with decreasing number of forwarding times. Accordingly, as illustrated in <figref idrefs="DRAWINGS">FIG. 33A</figref>, the plurality of pieces of data are stored in the different memory nodes in which the minimum numbers of forwarding times necessary for the packet communication with the gateway server <b>21</b>A become identical, and the plurality of pieces of data are simultaneously read to start the forwarding. In this case, as the data is closer to the gateway server <b>21</b>A with time, the number of memory nodes of the forwarding destinations is decreased to Increase a probability that the plurality of pieces of data are simultaneously forwarded to the same memory node. When the plurality of pieces of data are stored in the memory nodes in which the minimum numbers of forwarding times necessary for the packet communication with the gateway server <b>21</b>A become identical, the unnecessary waiting time is easily generated when the forwarding is performed after the data is read.</div>
<div class="description-paragraph" id="p-0337" num="0344">A data processing procedure to decrease the waiting time during the forwarding will be described with reference to <figref idrefs="DRAWINGS">FIGS. 34A to 34E</figref>, <figref idrefs="DRAWINGS">FIG. 35A</figref>, and <figref idrefs="DRAWINGS">FIG. 35B</figref>.</div>
<div class="description-paragraph" id="p-0338" num="0345"> <figref idrefs="DRAWINGS">FIGS. 34A to 34E</figref> are views illustrating an example of a process of forwarding the data read from the memory node toward the gateway server <b>21</b>A. <figref idrefs="DRAWINGS">FIGS. 34A to 34E</figref> illustrate the process in which, after the data of ID=2 is stored in the memory node (1,5) in which the minimum number of forwarding times necessary for the packet communication with the gateway server <b>21</b>A is 1,after the data of ID=1 is stored in the memory node (1,2) in which the minimum number of forwarding times is 2, after the data of ID=3 is stored in the memory node (4,4) in which the minimum number of forwarding times is 3, the pieces of data are simultaneously read and forwarded to the gateway server <b>21</b>A.</div>
<div class="description-paragraph" id="p-0339" num="0346">In this case, the pieces of data are forwarded to the memory node having the smaller minimum number of forwarding times necessary for the packet communication with the gateway server <b>21</b>A. However, in the case of <figref idrefs="DRAWINGS">FIGS. 34A to 34E</figref>, the forwarding of the plurality of pieces of data to the same memory node is not generated in the whole process unlike the case of <figref idrefs="DRAWINGS">FIG. 33D</figref>. This is because the pieces of data are stored in the memory nodes having the different minimum numbers of forwarding times necessary for the packet communication with the gateway server <b>21</b>A. In this case, although the pieces of data are also forwarded to the memory node having the smaller minimum number of forwarding times, because the forwarding of all the pieces of data is started from the memory node having the different minimum number of forwarding times, each piece of data is located in the memory node having the different minimum number of forwarding times anytime.</div>
<div class="description-paragraph" id="p-0340" num="0347">The pieces of data are stored in the memory nodes having the different minimum numbers of forwarding times necessary for the packet communication with the gateway server <b>21</b>A. Therefore, the simultaneous forwarding of the plurality of pieces of data to the same memory node is avoided when the read data is forwarded, which allows the data forwarding time to be shortened.</div>
<div class="description-paragraph" id="p-0341" num="0348">In the case that the pieces of data stored in the memory nodes having the different minimum numbers of forwarding times necessary for the packet communication with the gateway server are read and forwarded to the gateway server, the pieces of data reach the gateway server in the order in which the memory node in which the data is stored is closer to the gateway server. In <figref idrefs="DRAWINGS">FIG. 34A</figref>, the data of ID=2 is stored in the memory node that is closest to the gateway server <b>21</b>A, the data of ID=1 is stored in the memory node that is second closest to the gateway server <b>21</b>A, and the data of ID=3 is stored in the memory node that is farthest from the gateway server <b>21</b>A. Therefore, the pieces of data read and forwarded from the memory nodes reach the gateway server <b>21</b>A in the order of the data of ID=2, the data of ID=1, and the data of ID=3 as illustrated in <figref idrefs="DRAWINGS">FIGS. 34C to 34E</figref>.</div>
<div class="description-paragraph" id="p-0342" num="0349">As described above, the pieces of data are obtained by dividing the one file into three, and ID=1, ID=2, and ID=3 are provided according to the order of the pieces of data after the division. Therefore, in order to reconstruct the file from the divided pieces of data, it is necessary that the pieces of data that reach the gateway server <b>21</b>A are replaced in the order of the ID.</div>
<div class="description-paragraph" id="p-0343" num="0350">On the other hand, in <figref idrefs="DRAWINGS">FIG. 35A</figref>, the data of ID=1 is stored in the memory node in which the minimum number of forwarding time necessary for the packet communication with the gateway server <b>21</b>A is 1, the data of ID=2 is stored in the memory node in which the minimum number of forwarding times is 2, and the data of ID=3 is stored in the memory node in which the minimum number of forwarding times is 3. Therefore, when the pieces of data are read and forwarded from the memory nodes, the pieces of data reach the gateway server <b>21</b>A in the order of the data of ID=1, the data of ID=2, and the data of ID=3 as illustrated in <figref idrefs="DRAWINGS">FIG. 35B</figref>. Accordingly, it is not necessary to replace the pieces of data in reconstructing the file.</div>
<div class="description-paragraph" id="p-0344" num="0351">In the case that the plurality of pieces of data in which the data reading order has the meaning are stored in the memory nodes having the different minimum numbers of forwarding times necessary for the packet communication with the gateway server, the pieces of data are stored in the order from the memory node closer to the gateway server to the memory node farther from the gateway server. Therefore, work that replaces the pieces of data forwarded to the gateway server <b>21</b>A can foe eliminated.</div>
<div class="description-paragraph" id="p-0345" num="0352">The procedure to store the plurality of pieces of data in the storage device is described above in the storage system in which the single memory node and the gateway server of the storage device including the memory nodes equivalent to one another are connected through the adapter. As illustrated in <figref idrefs="DRAWINGS">FIG. 36A</figref>, in the storage device that includes an input/output port (non-adjacent port) except the input/output port connected to the adjacent node and memory nodes that are mutually connected by the non-adjacent ports, the pieces of data are stored in the memory nodes having the different minimum numbers of forwarding times necessary for; the packet communication with the gateway server <b>21</b>B, which allows the generation of the unnecessary waiting time to be avoided when the stored data is forwarded.</div>
<div class="description-paragraph" id="p-0346" num="0353">As illustrated in <figref idrefs="DRAWINGS">FIGS. 36B to 36D</figref>, in the case that the storage device <b>10</b> and the gateway server <b>21</b>A are connected through the switching relay, the pieces of data are stored in the memory nodes having the different minimum numbers of forwarding times necessary for the packet communication with the gateway server <b>21</b>A, which allows the generation of the unnecessary waiting time to be avoided when the stored data is forwarded. <figref idrefs="DRAWINGS">FIGS. 36A to 36D</figref> illustrate examples in which the pieces of data of ID=1, ID=2, and ID=3 are stored in the memory nodes in which the minimum numbers of forwarding times necessary for the packet communication is 1, 2,and 3,respectively.</div>
<div class="description-paragraph" id="p-0347" num="0354">As described above, there is the method (consistent hashing) for determining the address of the memory node in which the packet data is stored from the hash values of the address of the memory node and the packet ID. For example, in consideration of an ID space having integral values of 0 to 2<sup>160</sup>−1, the cryptological hash function SHA-1 is calculated (the calculation result becomes one of the integral values of 0 to 2<sup>160</sup>−1) with respect to the memory node and the packet with the address as the former and with the packet ID as the latter. Therefore, the memory node and the packet are allocated to each ID in the ID space. The ID space is traced clockwise from the ID of the hash value with respect to each packet, and the memory node initially confronted is determined to be the memory node in which the packet is stored.</div>
<div class="description-paragraph" id="p-0348" num="0355">The consistent hashing method has the advantages that not only the packets can be distributed and stored in memory node with high uniformity, but also the number of packets that needs to be change is decreased even if the number of memory nodes is increased or decreased (that is, the memory node has high scalability). However, when the memory node in which the packet is stored is determined by the consistent hashing method, possibly the packet is stored in the memory node having the same numbers of forwarding times necessary for the packet communication with the gateway server (as described above, the packets collide with each other when the data is read).</div>
<div class="description-paragraph" id="p-0349" num="0356">In order to uniformly distribute and store the N packets in the memory nodes having the different numbers of forwarding times necessary for the packet communication with the gateway server, for example, the hash value mod N of the packet ID is calculated (mod is a function of returning a remainder of division) to determine the number of forwarding times of the memory node in which the packet is stored (one of 0 to (N−1) (as a result of the calculation, when the packets in which the numbers of forwarding times are matched with each other exist, the adjustment is made such that the numbers of forwarding times have different values). For each packet, the memory node in which the packet is stored may be determined from the memory nodes having the fixed numbers of forwarding times toy the consistent hashing method.</div>
<div class="description-paragraph" id="p-0350" num="0357">In the procedure to determine the memory node in which the packet is stored, it is necessary to understand the addresses of the memory nodes having the fixed numbers of forwarding times. The memory node having a certain number of forwarding times is expressed as follows.</div>
<div class="description-paragraph" id="p-0351" num="0358">As illustrated in <figref idrefs="DRAWINGS">FIGS. 33A to 35B</figref>, in the storage system in which the gateway server <b>21</b>A is connected to a memory node (<b>1</b>, a<b>0</b>) located at an end of the storage device (at this point, it is assumed that the address of the memory node is a positive integral value) through the adapter <b>22</b>, in the case that the packet communication is conducted with the memory node (<b>1</b>, a<b>0</b>), the address of the memory node in which the minimum number of forwarding times is n is expressed by (1+b, a<b>0</b>+(n−b)) (n≥b≥0) and (1+c, a<b>0</b>−(n−c)) (a<b>0</b>−1≥n−c≥0).</div>
<div class="description-paragraph" id="p-0352" num="0359">As illustrated in <figref idrefs="DRAWINGS">FIGS. 36A and 36D</figref>, in the storage device (it is assumed that the address of the memory node is a positive Integral value) in which the non-adjacent memory nodes or the memory node and the switching relay are connected by the expansion port (non-adjacent port), in the case that the packet communication is conducted with the node (a<b>0</b>, b<b>0</b>) including the expansion port, the address of the memory node in which the minimum number of forwarding times is n is expressed by (a<b>0</b>+c, b<b>0</b>+(n−c)) (n≥c≥0), (a<b>0</b>+d, b<b>0</b>−(n−d)) (n≥d≥0 and b<b>0</b>−1≥n−d), (a<b>0</b>−e,b<b>0</b>+(n−e)) (min(a<b>0</b>−1,n)≥e≥0), (a<b>0</b>−f, b<b>0</b>−(n−f)) (a<b>0</b>−1≥f≥0 and b<b>0</b>−1≥n−f≥0).</div>
<div class="description-paragraph" id="p-0353" num="0360">As illustrated in <figref idrefs="DRAWINGS">FIG. 36B</figref>, in the storage system in which the memory node at the left end (address (<b>1</b>,y)) of the storage device (it is assumed that the address of all the memory nodes is a positive integral value) is connected to the switching relay, in the case that the packet communication is conducted with the relay memory node having the address (<b>1</b>, a<b>0</b>), the address of the memory node in which the minimum number of forwarding times is n is expressed by (<b>1</b>, a<b>0</b>+n).</div>
<div class="description-paragraph" id="p-0354" num="0361">In the above description, the storage system includes the storage device in which the memory nodes having the same data forwarding time are mutually connected. The ninth embodiment can be applied to the storage system, such as a storage system in which the memory nodes having the same data forwarding time are connected in the tree shape as illustrated in <figref idrefs="DRAWINGS">FIG. 36E</figref> and a storage system including the memory nodes having the different data forwarding times as illustrated in <figref idrefs="DRAWINGS">FIG. 36F</figref>, which includes the storage device in which the memory nodes having the data communication times different from those of the server exist.</div>
<div class="description-paragraph" id="p-0355" num="0362">In the storage system illustrated in <figref idrefs="DRAWINGS">FIG. 36E</figref>, the memory nodes having the same data forwarding time are connected in the tree structure, and the memory node having the same communication time as the gateway server <b>21</b>A is expressed by the same hatching. In the storage system illustrated in <figref idrefs="DRAWINGS">FIG. 38F</figref>, the data communication speed between the memory nodes is equal to the data communication speed between the memory node and the switching relay. The data communication speed between the memory nodes of the addresses (α, δ), (β, γ), and (β, ε) and the data communication speed between the memory nodes and the switching relay <b>81</b> are double the data communication speed between the memory nodes of addresses (a, l), (a,m), (a,n), (b, l), (b,m), and (b,n) and the data communication speed between the memory nodes and a switching relay <b>81</b>. The data excommunication speed between the address (A,B) and the switching relay <b>81</b> is four times the data communication speed between the memory nodes of addresses (a,l), (a,m), (,n), (b, l), (b, m), and (b,n) and the data communication speed between the memory nodes and a switching relay <b>81</b>. The memory node having the same data forwarding time as the switching relay <b>81</b> is expressed by the same hatching. However, it is assumed that the data forwarding time in the memory node is sufficiently smaller than the data forwarding time between the memory nodes and the data forwarding time between the switching relay and the memory node.</div>
<div class="description-paragraph" id="p-0356" num="0363">As described above, according to the ninth embodiment, the forwarding time can be shortened when the data is transmitted to the gateway server after the data stored in each of the memory nodes is read from, the memory node. Therefore, the data can be read at high speed. Other configurations and effects are similar to those of the first embodiment.</div>
<div class="description-paragraph" id="h-0015" num="0000">[Tenth Embodiment]</div>
<div class="description-paragraph" id="p-0357" num="0364">A storage system according to a tenth embodiment includes a data processing procedure to perform the data forwarding in order from data addressed to the memory node having the longer data communication time to data addressed to the memory node having the shorter data communication time in data processing of transmitting a plurality of pieces of data from a gateway server to memory nodes.</div>
<div class="description-paragraph" id="p-0358" num="0365">[1] Configuration of Storage System</div>
<div class="description-paragraph" id="p-0359" num="0366"> <figref idrefs="DRAWINGS">FIG. 37A</figref> is a view illustrating a configuration of the storage system of the tenth embodiment.</div>
<div class="description-paragraph" id="p-0360" num="0367">As illustrated In <figref idrefs="DRAWINGS">FIG. 37A</figref>, the storage system includes a storage device <b>10</b> that includes memory nodes <b>11</b> and gateway servers <b>21</b>A that are connected to the storage device <b>10</b>. The storage device <b>10</b> has the configuration in which the data-forwarding-function-equipped memory nodes are mutually connected as illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>. The gateway servers <b>21</b>A are connected to a memory node (1,4) disposed in the outer peripheral portion of the storage device <b>10</b> through an adapter <b>22</b>A.</div>
<div class="description-paragraph" id="p-0361" num="0368">[2] Data Processing Method of Storage System</div>
<div class="description-paragraph" id="p-0362" num="0369">The data processing procedure in the storage system, of the tenth embodiment will be described.</div>
<div class="description-paragraph" id="p-0363" num="0370"> <figref idrefs="DRAWINGS">FIGS. 37A to 37G</figref> and <figref idrefs="DRAWINGS">FIGS. 38A to 38B</figref> illustrate the storage system in which the storage device is connected to the gateway servers <b>21</b>A through the adapter <b>22</b>A similarly to the ninth embodiment. The storage device includes the memory nodes in which the adjacent memory nodes <b>11</b> are mutually connected.</div>
<div class="description-paragraph" id="p-0364" num="0371">A relationship between order of the data transmitted from gateway server <b>21</b>A and a time necessary to transmit all pieces of data in the case that three pieces of data ID=1, ID=2, and ID=3 are transmitted from the gateway server <b>21</b>A to the memory nodes having addresses (1,5), (1,2), and (4,4), respectively, will be discussed. It is assumed that only one packet can be stored in a temporarily storing memory (input port buffer) of the memory node, and it is assumed that only one packet can be transmitted once front the gateway server <b>21</b>A to the memory node having the address (1,4).</div>
<div class="description-paragraph" id="p-0365" num="0372"> <figref idrefs="DRAWINGS">FIGS. 37A to 37G</figref> illustrate the packet forwarding process in the case that the packet is transmitted from the gateway server <b>21</b>A to the storage device in the order from data addressed to the memory node closest to the gateway server <b>21</b>A to data addressed to the memory node farthest from the gateway server <b>21</b>A (that is, in the order of the data of ID=1, the data of ID=2, and the data of ID=3).</div>
<div class="description-paragraph" id="p-0366" num="0373">In this case, as illustrated in <figref idrefs="DRAWINGS">FIGS. 37B to 37C</figref>, the transmission of the data (ID=1) addressed to the memory node having the address (1,5) closest to the gateway server <b>21</b>A is ended earliest.</div>
<div class="description-paragraph" id="p-0367" num="0374">On the other hand, the data (ID=3) addressed to the memory node having the address (<b>4</b>,<b>4</b>) farthest from the gateway server <b>21</b>A cannot be transmitted to the address (<b>1</b>,<b>4</b>) until the two pieces of data (ID=1 and ID=2) are forwarded from the memory node having the address (1,4) to the adjacent memory node as illustrated in <figref idrefs="DRAWINGS">FIG. 37D</figref>, and meanwhile it is necessary that the data (ID=3) waits in the gateway server <b>21</b>A. Even if the data (ID=3) is transmitted to the memory node having the address (1,4) after the waiting, in order that the data reaches the address (4,4), it is necessary to perform the data forwarding at least three times as illustrated in <figref idrefs="DRAWINGS">FIGS. 37D to 37G</figref>.</div>
<div class="description-paragraph" id="p-0368" num="0375">On the other hand, <figref idrefs="DRAWINGS">FIGS. 38A to 38E</figref> illustrate the packet forwarding process in the case that the packet is transmitted from the gateway server <b>21</b>A to the storage device in the order from data addressed to the memory node farthest from the gateway server <b>21</b>A to data addressed to the memory node closest to the gateway server <b>21</b>A (that is, in the order of the data of ID=3, the data of ID=2, and the data of ID=1).</div>
<div class="description-paragraph" id="p-0369" num="0376">Even in this case, as illustrated in <figref idrefs="DRAWINGS">FIGS. 38B to 38D</figref>, the data (ID=1) cannot be transmitted to the address (1,4) until the two pieces of data (ID=3 and ID=2) are forwarded from the memory node having the address (1,4) to the adjacent node, and meanwhile it is necessary that the data (ID=1) waits in the gateway server <b>21</b>A.</div>
<div class="description-paragraph" id="p-0370" num="0377">However, the memory node having the address (1,5) that is the address of the lastly-transmitted data (ID=1) is close to the gateway server <b>21</b>A, and the data reaches the memory node of the destination by the smaller number of forwarding times. On the other hand, although the destination of the data (ID=3) previously transmitted from gateway server <b>21</b>A is distant from the gateway server <b>21</b>A, the data (ID=3) reaches the destination earlier because the forwarding is started while another piece of data waits in the gateway server <b>21</b>A. As a result, as illustrated in <figref idrefs="DRAWINGS">FIG. 38E</figref>, the three pieces of data simultaneously reach the memory nodes of the destinations.</div>
<div class="description-paragraph" id="p-0371" num="0378">As can be seen from the comparison of <figref idrefs="DRAWINGS">FIGS. 37A to 37G</figref> and <figref idrefs="DRAWINGS">FIGS. 38A to 38E</figref>, the pieces of data are transmitted from the gateway server <b>21</b>A in the order from the data in which the memory node of the destination is farthest from the gateway server <b>21</b>A to the data in which the memory node of the destination is closest to the gateway server <b>21</b>A, so that the time necessary to transmit all the pieces of data can be minimised.</div>
<div class="description-paragraph" id="p-0372" num="0379">The storage system includes the storage device in which the memory nodes having the same data forwarding time are mutually connected. The tenth embodiment can similarly be applied in the case that the plurality of pieces of data are transmitted to a storage device, such as a storage system in which the memory nodes having the same data forwarding time are connected in a tree shape (see <figref idrefs="DRAWINGS">FIG. 36E</figref>) and a storage system including the memory nodes having different data forwarding times (see <figref idrefs="DRAWINGS">FIG. 36F</figref>), in which the memory node having the data forwarding time different from that of the server exist.</div>
<div class="description-paragraph" id="p-0373" num="0380">As described above, according to the tenth embodiment, the necessary communication time can be minimized when the plurality of pieces of data are transmitted to the memory nodes in which the communication time is different from that of the gateway server. Other configurations and effects are similar to those of the first embodiment.</div>
<div class="description-paragraph" id="p-0374" num="0381">As described above, according to the first to tenth embodiments, the storage device in which the packet can efficiently be forwarded while the memory node needs not to manage the routing table and the data processing method can be provided.</div>
<div class="description-paragraph" id="p-0375" num="0382">In the embodiments, the storage device in which the packet can efficiently be forwarded while the memory node needs not to manage the routing table and the data processing method can be provided. While certain embodiments have been described, these embodiments have been presented by way of example only, and are not intended to limit the scope of the inventions. Indeed, the novel embodiments described herein may be embodied in a variety of other forms; furthermore, various omissions, substitutions and changes in the form of the embodiments described herein may be made without departing from the spirit of the inventions. The accompanying claims and their equivalents are intended to cover such forms or modifications as would fall within the scope and spirit of the inventions.</div>
</div>
</div>
</section><section itemprop="claims" itemscope="">
<h2>Claims (<span itemprop="count">18</span>)</h2>
<div html="" itemprop="content"><div class="claims" lang="EN" load-source="patent-office" mxw-id="PCLM194442229">
<claim-statement>What is claimed is:</claim-statement>
<div class="claim"> <div class="claim" id="CLM-00001" num="00001">
<div class="claim-text">1. A method of controlling a plurality of memory nodes, each of the memory nodes including a plurality of input ports, a plurality of output ports, and a memory in which data is stored, each of the memory nodes being configured to output a packet input to the input port to one of the output ports, the memory nodes being mutually connected at the input ports and the output ports and have addresses, the method comprising;
<div class="claim-text">determining a straight line connecting a memory node of a destination address and a memory node of a source address, the destination address indicating an address of a memory node of a target for the packet to be forwarded; and</div>
<div class="claim-text">forwarding a packet to a memory node adjacent to the memory node of a current position address such that the packet proceeds based on the straight line, wherein</div>
<div class="claim-text">while the packet is forwarded from the memory node of the source address to the memory node of the destination address, a trajectory of the packet forwarded from the memory node of the source address to the memory node of the destination address is along the straight line, and the packet proceeds across the straight line at least once.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00002" num="00002">
<div class="claim-text">2. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising switching the output port based on information including at least the destination address, the current position address, the source address and output port occupancy information of the memory node of the current position address.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00003" num="00003">
<div class="claim-text">3. The method according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising output buffers connected to the output ports,
<div class="claim-text">wherein the output port occupancy formation indicates whether each of the output buffers is occupied by a packet.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00004" num="00004">
<div class="claim-text">4. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the forwarding includes forwarding the packet to the adjacent memory node in a direction determined by output port occupancy information of the memory node of the current position address, and
<div class="claim-text">wherein the output port occupancy information indicates whether each of the output ports can forward the packet.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00005" num="00005">
<div class="claim-text">5. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the forwarding includes forwarding the packet to the memory node in which a distance between the memory node of the destination address and a memory node of an output position of the packet is minimized in the plurality of memory nodes adjacent to the memory node of the current position address.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00006" num="00006">
<div class="claim-text">6. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein a part of the memory nodes includes additional input ports and additional output ports and is connected to at least one of computers and non-adjacent memory nodes by the additional input ports and the additional output ports.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00007" num="00007">
<div class="claim-text">7. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the memory node connected to the non-adjacent memory node includes an additional address that is determined by relative physical positions of the memory nodes connected to the non-adjacent memory node in addition to the address, and
<div class="claim-text">in the case that the memory node connected to the non-adjacent memory node receives a packet addressed to other memory node, the packet controller of the memory node switches the output port based on information including at least one of the addresses and the additional addresses of the self-node and a connected non-adjacent memory node.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00008" num="00008">
<div class="claim-text">8. The method according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the plurality of memory nodes are divided into areas including the same number of memory nodes, and wherein memory nodes located in centers of the area are connected to other non-adjacent nodes by the additional input ports and the additional output ports.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00009" num="00009">
<div class="claim-text">9. The method according to, <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising a relay that is connected to the plurality of memory nodes, wherein the relay transmits the packet to the memory node that has a minimum distance to the memory node of the destination address.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00010" num="00010">
<div class="claim-text">10. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the memory node further comprises an address converter, and wherein the m node uses the address converter to convert a key into an address with respect to each record of key-value type data held by the memory node and transmits the packet including the value to the address.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00011" num="00011">
<div class="claim-text">11. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the memory nodes are arranged on a lattice coordinate, and wherein the destination address, the current position address and the source address are determined by their physical positions on the lattice coordinate.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00012" num="00012">
<div class="claim-text">12. The method according to <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the memory nodes are three-dimensionally arranged on a lattice coordinate.</div>
</div>
</div> <div class="claim"> <div class="claim" id="CLM-00013" num="00013">
<div class="claim-text">13. A method of controlling a plurality of memory nodes, each of the memory nodes including a plurality of input ports, a plurality of output ports, and a memory in which data is stored, each of the memory nodes being configured to output a packet input to the input port to one of the output ports, the memory nodes being mutually connected at the input ports and the output ports and have addresses, the method comprising:
<div class="claim-text">determining which one of four areas separated by a first straight line connecting the memory node of a destination address and the memory node of a source address and a second straight line orthogonal to the first straight line the memory node of a current position address belongs to, the destination address indicating an address of a memory node of a target for the packet to be forwarded, and</div>
<div class="claim-text">forwarding a packet to an adjacent memory node in a direction determined by output port occupancy information of the memory node of the current position address in two directions allocated to the area to which the memory node of the current position address belongs, wherein</div>
<div class="claim-text">while the packet is forwarded from tine memory node of the source address to the memory node of the destination address, a trajectory of the packet forwarded from the memory node of the source address to the memory node of the destination address is along the straight line, and the output port occupancy information indicates whether each of the output ports can forward the packet.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00014" num="00014">
<div class="claim-text">14. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein while the packet is forwarded from the memory node of the source address to the memory node of the destination address, the packet proceeds across the straight line at least once.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00015" num="00015">
<div class="claim-text">15. The method according to <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising output buffers connected to the output ports,
<div class="claim-text">wherein the output port occupancy information indicates whether each of the output buffers is occupied by a packet.</div>
</div>
</div>
</div> <div class="claim"> <div class="claim" id="CLM-00016" num="00016">
<div class="claim-text">16. A method of controlling a plurality of memory nodes, each of the memory nodes including a plurality of input ports, a plurality of output ports, and a memory in which data is stored, each of the memory nodes being configured to output a packet input to the input port to one of the output ports, the memory nodes being mutually connected at the input ports and the output ports and have addresses, the method comprising:
<div class="claim-text">determining which one of eight areas separated by a first straight line connecting the memory node of a destination address and the memory node of a source address, a second straight line orthogonal to the first straight line, and two straight lines passing through the memory node of the destination address and extending along a direction in which the memory nodes are arrayed the memory node of a current position address belongs to, the destination address indicating an address of a memory node of a target for the packet to be forwarded, and</div>
<div class="claim-text">forwarding a packet to an adjacent memory node in a direction determined by output port occupancy information of the memory node of the current position address in two directions allocated to the area to which the memory node of the current position address belongs, wherein</div>
<div class="claim-text">while the packet is forwarded from the memory node of the source address to the memory node of the destination address, a trajectory of the packet forwarded from the memory node of the source address to the memory node of the destination address is along the straight line, and the output port occupancy information indicates whether each of the output ports can forward the packet.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00017" num="00017">
<div class="claim-text">17. The method according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein while the packet is forwarded from the memory node of the source address to the memory node of the destination address, the packet proceed s across the straight line at least once.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00018" num="00018">
<div class="claim-text">18. The method according to <claim-ref idref="CLM-00016">claim 16</claim-ref>, further comprising output buffers connected to the output ports,
<div class="claim-text">wherein the output port occupancy information indicates whether each of the output buffers is occupied by a packet.</div>
</div>
</div>
</div> </div>
</div>
</section>
                </article>
            </search-app>
        </body>
    </html>
    