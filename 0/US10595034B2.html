
    <html>
        <body>
            <search-app>
                <article class="result" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
    <h1 itemprop="pageTitle">US10595034B2 - Decoding device and decoding method, and coding device and coding method 
        - Google Patents</h1><section itemprop="abstract" itemscope="">
<h2>Abstract</h2>
<div html="" itemprop="content"><abstract lang="EN" load-source="docdb" mxw-id="PA381270921" source="national office">
<div class="abstract">There is provided a decoding device including circuitry configured to receive coded data and conversion information, the coded data pertaining to an image having luminance in a first dynamic range and the conversion information pertaining to a conversion of dynamic range of the luminance of the image from the first dynamic range into a second dynamic range; and decode the received coded data so as to generate the image, wherein the conversion uses a knee function.</div>
</abstract>
</div>
</section><section itemprop="description" itemscope="">
<h2>Description</h2>
<div html="" itemprop="content"><div class="description" lang="EN" load-source="patent-office" mxw-id="PDES248747579">
<heading id="h-0001">CROSS REFERENCE TO PRIOR APPLICATION</heading>
<div class="description-paragraph" id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 15/152,027 (filed on May 11, 2016), which is a continuation of U.S. patent application Ser. No. 14/980,780 (filed on Dec. 28, 2015, and issued as U.S. Pat. No. 9,826,248 on Nov. 21, 2017), which is a continuation of U.S. patent application Ser. No. 14/491,539 (filed on Sep. 19, 2014, and issued as U.S. Pat. No. 9,253,497 on Feb. 2, 2016), which claims priority to Japanese Patent Application Nos. 2013-215060 (filed on Oct. 15, 2013), 2013-272945 (filed on Dec. 27, 2013), and 2014-042174 (filed on Mar. 4, 2014), which are all hereby incorporated by reference in their entirety.</div>
<heading id="h-0002">TECHNICAL FIELD</heading>
<div class="description-paragraph" id="p-0003" num="0002">The present disclosure relates to a decoding device and a decoding method, and a coding device and a coding method, and particularly to a decoding device and a decoding method, and a coding device and a coding method capable of converting a decoded image into a desired image with a different dynamic range.</div>
<heading id="h-0003">BACKGROUND ART</heading>
<div class="description-paragraph" id="p-0004" num="0003">In recent years, apparatuses which conform to a method such as Moving Picture Experts Group (MPEG) have been widely spread for both of information delivery in broadcasting stations or the like and information reception in ordinary homes. MPEG compresses the image information through orthogonal transform such as discrete cosine trans form and motion compensation by using redundancy unique to the image information.</div>
<div class="description-paragraph" id="p-0005" num="0004">Particularly, an MPEG2 (ISO/IEC 13818-2) method is defined as a general use image coding method, and is currently widely used in extensive applications for professional use and consumer use as a standard covering both an interlaced scanning image and a progressive scanning image, and a standard resolution image and a high definition image. By the use of the MPEG2 method, it is possible to realize a high compression ratio and good image quality, for example, by assigning a bit rate of 4 Mbps to 8 Mbps to an interlaced scanning image of a standard resolution having 720×480 pixels and assigning a bit rate of 18 Mbps to 22 Mbps to an interlaced scanning image of a high resolution having 1920×1088 pixels.</div>
<div class="description-paragraph" id="p-0006" num="0005">MPEG2 has mainly targeted high image quality coding suitable for broadcasting, but has not handled a coding method at a bit rate lower than that in MPEG1, that is, at a higher compression ratio. With the wide use of portable terminals, the desire for such a coding method has been considered to increase, and thus an MPEG4 coding method has been standardized so as to correspond thereto. In relation to an image coding method of MPEG4, a standard thereof was approved as an international standard entitled ISO/IEC 14496-2 in December 1998.</div>
<div class="description-paragraph" id="p-0007" num="0006">In addition, in recent years, standardization of a standard called H.26L (ITU-T Q6/16 VCEG) has progressed for the original purpose of image coding for video conference use. H.26L uses a larger calculation amount due to coding and decoding than the coding method of the related art such as MPEG2 or MPEG4, but is known for realizing higher coding efficiency.</div>
<div class="description-paragraph" id="p-0008" num="0007">Further, as part of activities of MPEG4, Joint Model of Enhanced-Compression Video Coding is currently being standardized in order to realize higher coding efficiency by also incorporating functions which are not supported by H.26L, on the basis of H.26L. As for the standardization schedule thereof, the coding method has become an international standard under the name of H.26L and MPEG-4 Part 10 ((Advanced Video Coding (AVC)) in March 2003.</div>
<div class="description-paragraph" id="p-0009" num="0008">In addition, as an extension of the AVC method, Fidelity Range Extension (FRExt) which includes coding tools for use in business such as RGB or YUS422 and YUV444 and also includes 8×8 DCT or quantization matrix defined in MPEG2 was standardized in February 2005. This realizes a coding method in which even film noise included in a movie can be favorably expressed by using the AVC method, and thus leads to use for various applications such as a Blu-Ray (registered trademark) disc (BD).</div>
<div class="description-paragraph" id="p-0010" num="0009">However, recently, there have been increasing demands for higher compression ratio coding, such as a demand for compression of an image with about 4000×2000 pixels which is four times the size of a high-vision image or a demand for delivery of a high-vision image in limited transmission capacity circumstances such as the Internet. For this reason, study of improvement of coding efficiency is being currently performed in Video Coding Expert Group (VCEG) affiliated to the above ITU-T.</div>
<div class="description-paragraph" id="p-0011" num="0010">In addition, currently, for the purpose of improvement in higher coding efficiency than that of AVC, standardization of a coding method called High Efficiency Video Coding (HEVC) is in progress by Joint Collaboration Team-Video Coding (JCTVC) which is a joint standardization organization of ITU-T and ISO/IEC. NPL 1 has been currently published, as a draft in August 2013.</div>
<div class="description-paragraph" id="p-0012" num="0011">Meanwhile, recently, with the progress of techniques, a high dynamic range (HDR) display with the maximum luminance of 500 nit or 1000 nit has been started to be sold on the market.</div>
<div class="description-paragraph" id="p-0013" num="0012">In a case where a standard dynamic range (SDR) display and an HDR display are mixed, it is necessary to encode each of an SDR image and an HDR image in the AVC met nod or the HEVC method, and thus a data amount increases. Therefore, a method is considered in which one of the SDR image and the HDR image is coded, and then a dynamic range, is converted after decoding is performed as necessary, thereby generating the other.</div>
<heading id="h-0004">CITATION LIST</heading>
<heading id="h-0005">Non Patent Literature</heading>
<div class="description-paragraph" id="p-0014" num="0013">[NPL 1]</div>
<div class="description-paragraph" id="p-0015" num="0014">Benjamin Bross, Gary J. Sullivan, Ye-Kui Wang, “Editors' proposed corrections to HEVC version 1”, JCTVC-M0432_v3, 2013. 4, 18-4. 26</div>
<heading id="h-0006">SUMMARY</heading>
<heading id="h-0007">Technical Problem</heading>
<div class="description-paragraph" id="p-0016" num="0015">However, conversion into an image which is intended by a producer is not considered when conversion of a dynamic range is converted,</div>
<div class="description-paragraph" id="p-0017" num="0016">It is desirable to convert a decoded image into a desired image with a different dynamic range.</div>
<heading id="h-0008">Solution to Problem</heading>
<div class="description-paragraph" id="p-0018" num="0017">According to an embodiment of the present disclosure, there is provided a decoding device including: circuitry configured to receive coded data and conversion information, the coded data pertaining to an image having luminance in a first dynamic range and the conversion information pertaining to a conversion, of dynamic range of the luminance of the image from the first dynamic range into a second dynamic range; and decode the received coded data so as to generate the image, wherein the conversion uses a knee function.</div>
<div class="description-paragraph" id="p-0019" num="0018">A decoding method of causing a decoding device to perform: receiving coded data and conversion information, the coded data pertaining to an image having luminance in a first dynamic range and the conversion information pertaining to a conversion of dynamic range of the luminance of the image from the first dynamic range into a second dynamic range; and decoding the received coded data so as to generate the image, wherein the conversion uses a knee function.</div>
<div class="description-paragraph" id="p-0020" num="0019">A coding device including: circuitry configured to set conversion information pertaining to a conversion of dynamic range of a luminance of an image from a first dynamic range into a second dynamic range; and code the image having luminance in the first dynamic range so as to generate coded data, wherein the conversion uses a knee function.</div>
<div class="description-paragraph" id="p-0021" num="0020">A non-transitory computer-readable medium having stored thereon coded data and conversion information, the coded data pertaining to an image having luminance in a first dynamic range and the conversion information pertaining to a conversion of dynamic range of the luminance of the image from the first dynamic range into a second dynamic range, wherein a decoding device decodes coded data, generates the image based on the decoded data, and converts the dynamic range based on the conversion information including a knee point.</div>
<div class="description-paragraph" id="p-0022" num="0021">According to an embodiment of the present disclosure, there is provided a decoding device including an extraction unit that extracts coded data and conversion information, from a coded stream including the coded data of a first image which is an image having luminance in a first dynamic range and the conversion information regarding conversion of a dynamic range of the luminance of the image from the first dynamic range into a second dynamic range; and a decoding unit that decodes the coded data extracted by the extraction unit so as to generate the first image.</div>
<div class="description-paragraph" id="p-0023" num="0022">A decoding method according to an embodiment of the present disclosure corresponds to the decoding device according to the embodiment of the present disclosure.</div>
<div class="description-paragraph" id="p-0024" num="0023">According to an embodiment of the present disclosure, coded data and conversion information are extracted from at coded stream including the coded data of a first image which is an image having luminance in a first dynamic range and the conversion information which is information regarding conversion of a dynamic range of the luminance of the image from the first dynamic range into a second dynamic range, and the extracted coded data is decoded so that the first image is generated.</div>
<div class="description-paragraph" id="p-0025" num="0024">According to another embodiment of the present disclosure, there is provided a coding device including a setting unit that sets conversion information which is information regarding conversion of a dynamic range, of luminance of an image from a first dynamic range into a second dynamic range; a coding unit that codes a first image which is the image having luminance in the first dynamic range so as to generate coded data; and a transmission unit that transmits a coded stream including the conversion information, set by the setting unit and the coded data of the first image generated by the coding unit.</div>
<div class="description-paragraph" id="p-0026" num="0025">A coding method of another embodiment of the present disclosure corresponds to the coding device according to another embodiment of the present disclosure.</div>
<div class="description-paragraph" id="p-0027" num="0026">According to an embodiment of the present disclosure, conversion information is set which is information regarding conversion of a dynamic range of luminance of an image from a first dynamic range into a second dynamic range, a first image which is the image having luminance in the first dynamic range is coded so that coded data is generated, and a coded stream including the conversion information and the coded data of the first image is transmitted.</div>
<div class="description-paragraph" id="p-0028" num="0027">In addition, the decoding device and the coding device according to the embodiments may be implemented by executing a program in a computer.</div>
<div class="description-paragraph" id="p-0029" num="0028">Further, the program executed in the computer in order to implement the decoding device and the coding device according to an embodiment may be provided by transmitting the program via a transmission medium or by recording the program on a recording medium.</div>
<div class="description-paragraph" id="p-0030" num="0029">The decoding device and the coding device according to embodiments may be standalone devices, and may be an internal block forming a single apparatus.</div>
<heading id="h-0009">Advantageous Effects of Invention</heading>
<div class="description-paragraph" id="p-0031" num="0030">According to an embodiment of the present disclosure, it is possible to decode coded data of an image. In addition, according to the embodiment of the present disclosure, it is possible to convert a decoded image into a desired image with a different dynamic range.</div>
<div class="description-paragraph" id="p-0032" num="0031">According to another embodiment of the present disclosure, it is possible to code an image. In addition, according to another embodiment of the present disclosure, it is possible, to code an image so that a decoded image can be converted, into a desired image with a different dynamic range during decoding.</div>
<div class="description-paragraph" id="p-0033" num="0032">In addition, the effects described here are not necessarily limited, and there may be any one of effects described in the present disclosure.</div>
<description-of-drawings>
<heading id="h-0010">BRIEF DESCRIPTION OF DRAWINGS</heading>
<div class="description-paragraph" id="p-0034" num="0033"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a diagram illustrating an SDR image.</div>
<div class="description-paragraph" id="p-0035" num="0034"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a diagram illustrating an HDR image.</div>
<div class="description-paragraph" id="p-0036" num="0035"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a diagram illustrating an overview of coding in an embodiment of the present disclosure.</div>
<div class="description-paragraph" id="p-0037" num="0036"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a diagram illustrating an overview of decoding in an embodiment of the present disclosure.</div>
<div class="description-paragraph" id="p-0038" num="0037"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a diagram illustrating knee decompression.</div>
<div class="description-paragraph" id="p-0039" num="0038"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a block diagram illustrating a configuration example of an embodiment of a coding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0040" num="0039"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a diagram illustrating an example of syntax of knee_function_info SEI.</div>
<div class="description-paragraph" id="p-0041" num="0040"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a diagram illustrating each piece of information, set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 7</figref>.</div>
<div class="description-paragraph" id="p-0042" num="0041"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a diagram illustrating an example of conversion information set in the knee, function_info SEI.</div>
<div class="description-paragraph" id="p-0043" num="0042"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a diagram illustrating an example of conversion information set in the knee_function_info SEI.</div>
<div class="description-paragraph" id="p-0044" num="0043"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a flowchart illustrating a stream generation process performed by the coding device.</div>
<div class="description-paragraph" id="p-0045" num="0044"> <figref idrefs="DRAWINGS">FIG. 12</figref> is a block diagram illustrating a configuration example of an embodiment of a decoding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0046" num="0045"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a flowchart illustrating an image generation process performed by the decoding device of <figref idrefs="DRAWINGS">FIG. 12</figref>.</div>
<div class="description-paragraph" id="p-0047" num="0046"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a diagram, illustrating another example of syntax of the knee_function_info SEI.</div>
<div class="description-paragraph" id="p-0048" num="0047"> <figref idrefs="DRAWINGS">FIG. 15</figref> is a diagram, illustrating each piece of information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 14</figref>.</div>
<div class="description-paragraph" id="p-0049" num="0048"> <figref idrefs="DRAWINGS">FIG. 16</figref> is a block diagram illustrating a configuration example of a first embodiment of a coding device to which an embodiment of the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0050" num="0049"> <figref idrefs="DRAWINGS">FIG. 17</figref> is a diagram illustrating a first example of syntax of knee_function_info SEI set by a setting unit of <figref idrefs="DRAWINGS">FIG. 16</figref>.</div>
<div class="description-paragraph" id="p-0051" num="0050"> <figref idrefs="DRAWINGS">FIG. 18</figref> is a diagram illustrating each piece of information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 17</figref>.</div>
<div class="description-paragraph" id="p-0052" num="0051"> <figref idrefs="DRAWINGS">FIG. 19</figref> is a diagram illustrating an example of DR conversion information of <figref idrefs="DRAWINGS">FIG. 17</figref>.</div>
<div class="description-paragraph" id="p-0053" num="0052"> <figref idrefs="DRAWINGS">FIG. 20</figref> is a diagram illustrating an example of DR conversion information of <figref idrefs="DRAWINGS">FIG. 17</figref>.</div>
<div class="description-paragraph" id="p-0054" num="0053"> <figref idrefs="DRAWINGS">FIG. 21</figref> is a flowchart illustrating a stream generation process performed by the coding device of <figref idrefs="DRAWINGS">FIG. 16</figref>.</div>
<div class="description-paragraph" id="p-0055" num="0054"> <figref idrefs="DRAWINGS">FIG. 22</figref> is a block diagram illustrating a configuration example of a second embodiment of a decoding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0056" num="0055"> <figref idrefs="DRAWINGS">FIG. 23</figref> is a flowchart illustrating an image generation process performed by the decoding device of <figref idrefs="DRAWINGS">FIG. 22</figref>.</div>
<div class="description-paragraph" id="p-0057" num="0056"> <figref idrefs="DRAWINGS">FIG. 24</figref> is a diagram illustrating another example of DR conversion information of <figref idrefs="DRAWINGS">FIG. 17</figref>.</div>
<div class="description-paragraph" id="p-0058" num="0057"> <figref idrefs="DRAWINGS">FIG. 25</figref> is at diagram illustrating still another example of DR conversion information of <figref idrefs="DRAWINGS">FIG. 17</figref>.</div>
<div class="description-paragraph" id="p-0059" num="0058"> <figref idrefs="DRAWINGS">FIG. 26</figref> is a diagram illustrating an example of syntax of tone_mapping_info_SEI including the DR conversion information of <figref idrefs="DRAWINGS">FIG. 17</figref>.</div>
<div class="description-paragraph" id="p-0060" num="0059"> <figref idrefs="DRAWINGS">FIG. 27</figref> is a diagram illustrating another example of syntax of tone_mapping_info_SEI including the DR conversion information of <figref idrefs="DRAWINGS">FIG. 17</figref>.</div>
<div class="description-paragraph" id="p-0061" num="0060"> <figref idrefs="DRAWINGS">FIG. 28</figref> is a diagram illustrating a second example of syntax of knee_function_info SEI set by the setting unit of <figref idrefs="DRAWINGS">FIG. 16</figref>.</div>
<div class="description-paragraph" id="p-0062" num="0061"> <figref idrefs="DRAWINGS">FIG. 29</figref> is a diagram illustrating each piece of information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 28</figref>.</div>
<div class="description-paragraph" id="p-0063" num="0062"> <figref idrefs="DRAWINGS">FIG. 30</figref> is a diagram, illustrating an example of DR conversion information of <figref idrefs="DRAWINGS">FIG. 28</figref>.</div>
<div class="description-paragraph" id="p-0064" num="0063"> <figref idrefs="DRAWINGS">FIG. 31</figref> is a diagram illustrating an example of DR conversion information of <figref idrefs="DRAWINGS">FIG. 28</figref>.</div>
<div class="description-paragraph" id="p-0065" num="0064"> <figref idrefs="DRAWINGS">FIG. 32</figref> is a diagram illustrating an example of syntax of tone_mapping_info_SEI including the DR conversion information of <figref idrefs="DRAWINGS">FIG. 28</figref>.</div>
<div class="description-paragraph" id="p-0066" num="0065"> <figref idrefs="DRAWINGS">FIG. 33</figref> is a diagram illustrating each piece of information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 28</figref> in a case where the number of knee points is restricted.</div>
<div class="description-paragraph" id="p-0067" num="0066"> <figref idrefs="DRAWINGS">FIG. 34</figref> is a diagram illustrating an example of the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 28</figref> in a case where the number of knee points is restricted.</div>
<div class="description-paragraph" id="p-0068" num="0067"> <figref idrefs="DRAWINGS">FIG. 35</figref> is a diagram illustrating an example of the tone_mapping_info_SEI of <figref idrefs="DRAWINGS">FIG. 32</figref> in a case where the number of knee points is restricted.</div>
<div class="description-paragraph" id="p-0069" num="0068"> <figref idrefs="DRAWINGS">FIG. 36</figref> is a diagram illustrating a third example of syntax of knee_function_info SEI set by the setting unit of <figref idrefs="DRAWINGS">FIG. 16</figref>.</div>
<div class="description-paragraph" id="p-0070" num="0069"> <figref idrefs="DRAWINGS">FIG. 37</figref> is a diagram illustrating each piece of information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 36</figref>.</div>
<div class="description-paragraph" id="p-0071" num="0070"> <figref idrefs="DRAWINGS">FIG. 38</figref> is a diagram, illustrating an example of DR conversion information of <figref idrefs="DRAWINGS">FIG. 36</figref>.</div>
<div class="description-paragraph" id="p-0072" num="0071"> <figref idrefs="DRAWINGS">FIG. 39</figref> is a diagram illustrating an example of syntax of tone_mapping_info_SEI including the DR conversion information of <figref idrefs="DRAWINGS">FIG. 36</figref>.</div>
<div class="description-paragraph" id="p-0073" num="0072"> <figref idrefs="DRAWINGS">FIG. 40</figref> is a diagram illustrating a fourth example of syntax of knee_function_info SEI set by the setting unit of <figref idrefs="DRAWINGS">FIG. 16</figref>.</div>
<div class="description-paragraph" id="p-0074" num="0073"> <figref idrefs="DRAWINGS">FIG. 41</figref> is a diagram illustrating each, piece of information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 40</figref>.</div>
<div class="description-paragraph" id="p-0075" num="0074"> <figref idrefs="DRAWINGS">FIG. 42</figref> is a diagram illustrating an example of DR conversion information of <figref idrefs="DRAWINGS">FIG. 40</figref>.</div>
<div class="description-paragraph" id="p-0076" num="0075"> <figref idrefs="DRAWINGS">FIG. 43</figref> is a diagram illustrating an example of DR conversion information of <figref idrefs="DRAWINGS">FIG. 40</figref>.</div>
<div class="description-paragraph" id="p-0077" num="0076"> <figref idrefs="DRAWINGS">FIG. 44</figref> is a diagram illustrating an operation of the decoding device in a case where the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 40</figref> is set in a plurality.</div>
<div class="description-paragraph" id="p-0078" num="0077"> <figref idrefs="DRAWINGS">FIG. 45</figref> is a diagram illustrating an example of syntax of tone_mapping_info_SEI including the DR conversion information of <figref idrefs="DRAWINGS">FIG. 40</figref>.</div>
<div class="description-paragraph" id="p-0079" num="0078"> <figref idrefs="DRAWINGS">FIG. 46</figref> is a diagram illustrating a box of MP4 in which DR conversion information is disposed.</div>
<div class="description-paragraph" id="p-0080" num="0079"> <figref idrefs="DRAWINGS">FIG. 47</figref> is a diagram illustrating an example of syntax of ToneMapInfo.</div>
<div class="description-paragraph" id="p-0081" num="0080"> <figref idrefs="DRAWINGS">FIG. 48</figref> is a diagram illustrating that semantics in a first configuration of a third embodiment of a coding device to which the present disclosure is applied is different from that in the second embodiment.</div>
<div class="description-paragraph" id="p-0082" num="0081"> <figref idrefs="DRAWINGS">FIG. 49</figref> is a block diagram illustrating a first configuration example of an embodiment of a decoding system to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0083" num="0082"> <figref idrefs="DRAWINGS">FIG. 50A</figref> is a diagram illustrating an example of a knee point, and a function of knee conversion defined by knee_function_info SEI which is received by the decoding system of <figref idrefs="DRAWINGS">FIG. 49</figref>.</div>
<div class="description-paragraph" id="p-0084" num="0083"> <figref idrefs="DRAWINGS">FIG. 50B</figref> is a diagram illustrating an example of a knee point, and a function of knee conversion defined by knee_function_info SEI which is received by the decoding system of <figref idrefs="DRAWINGS">FIG. 49</figref>.</div>
<div class="description-paragraph" id="p-0085" num="0084"> <figref idrefs="DRAWINGS">FIG. 51</figref> is a diagram illustrating an example of an approximate function of the knee conversion of <figref idrefs="DRAWINGS">FIG. 50</figref>.</div>
<div class="description-paragraph" id="p-0086" num="0085"> <figref idrefs="DRAWINGS">FIG. 52</figref> is a diagram illustrating an example of an approximate function of the knee conversion of <figref idrefs="DRAWINGS">FIG. 50</figref>.</div>
<div class="description-paragraph" id="p-0087" num="0086"> <figref idrefs="DRAWINGS">FIG. 53</figref> is a flowchart illustrating a decoding process performed by the decoding device of <figref idrefs="DRAWINGS">FIG. 49</figref>.</div>
<div class="description-paragraph" id="p-0088" num="0087"> <figref idrefs="DRAWINGS">FIG. 54</figref> is a flowchart illustrating a display process performed by a display device of <figref idrefs="DRAWINGS">FIG. 49</figref>.</div>
<div class="description-paragraph" id="p-0089" num="0088"> <figref idrefs="DRAWINGS">FIG. 55</figref> is a diagram illustrating an example of syntax of knee_function_info SEI in a second configuration of the third embodiment of the coding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0090" num="0089"> <figref idrefs="DRAWINGS">FIG. 56</figref> is a diagram, illustrating a difference in semantics of <figref idrefs="DRAWINGS">FIG. 55</figref> from the second embodiment.</div>
<div class="description-paragraph" id="p-0091" num="0090"> <figref idrefs="DRAWINGS">FIG. 57A</figref> is a diagram illustrating an example of a knee point and a function of knee conversion defined by knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 55</figref>.</div>
<div class="description-paragraph" id="p-0092" num="0091"> <figref idrefs="DRAWINGS">FIG. 57B</figref> is a diagram illustrating an example of a knee point and a function of knee conversion defined by knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 55</figref>.</div>
<div class="description-paragraph" id="p-0093" num="0092"> <figref idrefs="DRAWINGS">FIG. 58</figref> is a diagram illustrating an example of an approximate function of the knee conversion of <figref idrefs="DRAWINGS">FIG. 57</figref>.</div>
<div class="description-paragraph" id="p-0094" num="0093"> <figref idrefs="DRAWINGS">FIG. 59</figref> is a diagram illustrating an example of an approximate function of the knee conversion of <figref idrefs="DRAWINGS">FIG. 57</figref>.</div>
<div class="description-paragraph" id="p-0095" num="0094"> <figref idrefs="DRAWINGS">FIG. 60</figref> is a diagram illustrating an example of syntax of approximate_knee_function_info SEI.</div>
<div class="description-paragraph" id="p-0096" num="0095"> <figref idrefs="DRAWINGS">FIG. 61</figref> is a diagram illustrating a relationship between an input electrical signal and display luminance of a CRT.</div>
<div class="description-paragraph" id="p-0097" num="0096"> <figref idrefs="DRAWINGS">FIG. 62</figref> is a diagram illustrating an electrical signal which is proportional to luminance.</div>
<div class="description-paragraph" id="p-0098" num="0097"> <figref idrefs="DRAWINGS">FIG. 63</figref> is a diagram illustrating a relationship between an input electrical signal and display luminance.</div>
<div class="description-paragraph" id="p-0099" num="0098"> <figref idrefs="DRAWINGS">FIG. 64</figref> is a diagram illustrating a function with a characteristic reverse to a function of <figref idrefs="DRAWINGS">FIG. 61</figref>.</div>
<div class="description-paragraph" id="p-0100" num="0099"> <figref idrefs="DRAWINGS">FIG. 65</figref> is a diagram illustrating an example of a flow of a process until an image is displayed from capturing of the image.</div>
<div class="description-paragraph" id="p-0101" num="0100"> <figref idrefs="DRAWINGS">FIG. 66</figref> is a diagram illustrating OETF for use in an SDR image,</div>
<div class="description-paragraph" id="p-0102" num="0101"> <figref idrefs="DRAWINGS">FIG. 67</figref> is a diagram illustrating OETF for use in an HDR image.</div>
<div class="description-paragraph" id="p-0103" num="0102"> <figref idrefs="DRAWINGS">FIG. 68</figref> is a diagram illustrating an overview of a photoelectric conversion process in a fourth embodiment.</div>
<div class="description-paragraph" id="p-0104" num="0103"> <figref idrefs="DRAWINGS">FIG. 69</figref> is a diagram illustrating an overview of an electro-optical conversion in the fourth embodiment.</div>
<div class="description-paragraph" id="p-0105" num="0104"> <figref idrefs="DRAWINGS">FIG. 70</figref> is a block diagram illustrating a configuration example of the fourth embodiment of a coding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0106" num="0105"> <figref idrefs="DRAWINGS">FIG. 71</figref> is a flowchart illustrating a stream generation process performed by the coding device of <figref idrefs="DRAWINGS">FIG. 70</figref>.</div>
<div class="description-paragraph" id="p-0107" num="0106"> <figref idrefs="DRAWINGS">FIG. 72</figref> is a block diagram illustrating a configuration example of the fourth embodiment of a decoding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0108" num="0107"> <figref idrefs="DRAWINGS">FIG. 73</figref> is a flowchart illustrating an image generation process performed by the decoding device of <figref idrefs="DRAWINGS">FIG. 72</figref>.</div>
<div class="description-paragraph" id="p-0109" num="0108"> <figref idrefs="DRAWINGS">FIG. 74</figref> is a block diagram illustrating a hardware configuration example of a computer.</div>
<div class="description-paragraph" id="p-0110" num="0109"> <figref idrefs="DRAWINGS">FIG. 75</figref> is a diagram illustrating an example of a multi-viewpoint image coding method.</div>
<div class="description-paragraph" id="p-0111" num="0110"> <figref idrefs="DRAWINGS">FIG. 76</figref> is a diagram illustrating a configuration example of a multi-view image coding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0112" num="0111"> <figref idrefs="DRAWINGS">FIG. 77</figref> is a diagram illustrating a configuration example of a multi-view image decoding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0113" num="0112"> <figref idrefs="DRAWINGS">FIG. 78</figref> is a diagram illustrating an example of a layer image coding method.</div>
<div class="description-paragraph" id="p-0114" num="0113"> <figref idrefs="DRAWINGS">FIG. 79</figref> is a diagram illustrating an example of spatially scalable coding.</div>
<div class="description-paragraph" id="p-0115" num="0114"> <figref idrefs="DRAWINGS">FIG. 80</figref> is a diagram illustrating an example of a temporally sealable coding.</div>
<div class="description-paragraph" id="p-0116" num="0115"> <figref idrefs="DRAWINGS">FIG. 81</figref> is a diagram illustrating an example of scalable coding of an S/N ratio.</div>
<div class="description-paragraph" id="p-0117" num="0116"> <figref idrefs="DRAWINGS">FIG. 82</figref> is a diagram illustrating a configuration example of a layer image coding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0118" num="0117"> <figref idrefs="DRAWINGS">FIG. 83</figref> is a diagram illustrating a configuration example of a layer image decoding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0119" num="0118"> <figref idrefs="DRAWINGS">FIG. 84</figref> is a block diagram illustrating a schematic configuration example of a television apparatus to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0120" num="0119"> <figref idrefs="DRAWINGS">FIG. 85</figref> is a block diagram illustrating a schematic configuration example of a mobile phone to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0121" num="0120"> <figref idrefs="DRAWINGS">FIG. 86</figref> is a block diagram, illustrating a schematic configuration example of a recording/reproducing apparatus to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0122" num="0121"> <figref idrefs="DRAWINGS">FIG. 87</figref> is a block diagram illustrating a schematic configuration example of an imaging apparatus to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0123" num="0122"> <figref idrefs="DRAWINGS">FIG. 88</figref> is a block diagram illustrating an example of using scalable coding.</div>
<div class="description-paragraph" id="p-0124" num="0123"> <figref idrefs="DRAWINGS">FIG. 89</figref> is a block diagram illustrating another example of using scalable coding.</div>
<div class="description-paragraph" id="p-0125" num="0124"> <figref idrefs="DRAWINGS">FIG. 90</figref> is a block diagram illustrating still another example of using scalable coding.</div>
<div class="description-paragraph" id="p-0126" num="0125"> <figref idrefs="DRAWINGS">FIG. 91</figref> is a diagram illustrating a schematic configuration example of a video set to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0127" num="0126"> <figref idrefs="DRAWINGS">FIG. 92</figref> is a diagram illustrating a schematic configuration example of a video processor to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0128" num="0127"> <figref idrefs="DRAWINGS">FIG. 93</figref> is a diagram illustrating another schematic configuration example of a video processor to which the present disclosure is applied.</div>
</description-of-drawings>
<heading id="h-0011">DESCRIPTION OF EMBODIMENTS</heading>
<div class="description-paragraph" id="p-0129" num="0128">[Base of Present Disclosure]</div>
<div class="description-paragraph" id="p-0130" num="0129">[Description of SDR Image]</div>
<div class="description-paragraph" id="p-0131" num="0130"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a diagram illustrating an SDR image.</div>
<div class="description-paragraph" id="p-0132" num="0131">As illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>, an SDR image is, for example, an image whose image quality is adjusted so as to correspond to a display device with the maximum luminance 100 nit (candela per square meter). Since the maximum luminance in the natural system reaches 20000 nit or more in sortie cases, in the SDR image, a brightness dynamic range is greatly compressed.</div>
<div class="description-paragraph" id="p-0133" num="0132">[Description of HDR Image]</div>
<div class="description-paragraph" id="p-0134" num="0133"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a diagram illustrating an HDR image.</div>
<div class="description-paragraph" id="p-0135" num="0134">As illustrated in <figref idrefs="DRAWINGS">FIG. 2</figref>, an HDR image is an image in which a dynamic range of luminance is greater than 0 to 100%. In the present specification, unless otherwise described, a dynamic range of a luminance of the HDR image is 0 to 400%. For example, as illustrated in <figref idrefs="DRAWINGS">FIG. 2</figref>, in a case where an HDR image in which a dynamic range of luminance is 0 to 800% (800 nit) is coded, and is recorded on a Blu-ray (registered trademark) disc (BD) or the like, attribute information indicating the luminance is also recorded along with the HDR image. In addition, the attribute information is input to a display device along with a decoded HDR image, and the HDR image is displayed as an image in which a dynamic range of luminance is 0 to 800%.</div>
<div class="description-paragraph" id="p-0136" num="0135">Further, in a case where the maximum luminance of the display device is 1000 nit, for example, luminance of an HDR image is scaled to 1000 nit and is displayed. Even in a case where the scaling is performed in this way, an HDR image has a dynamic range of luminance of 0 to 800%, and thus image quality deterioration thereof due to the scaling is smaller than that of an SDR image.</div>
<heading id="h-0012">First Embodiment</heading>
<div class="description-paragraph" id="p-0137" num="0136">(Overview of Coding in First Embodiment)</div>
<div class="description-paragraph" id="p-0138" num="0137"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a diagram illustrating an overview of coding in a first embodiment of a coding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0139" num="0138">In <figref idrefs="DRAWINGS">FIG. 3</figref>, the transverse axis expresses a luminance value (input code value), and the longitudinal axis expresses luminance (output video level). In addition, the luminance value of the transverse axis of <figref idrefs="DRAWINGS">FIG. 3</figref> is a value obtained by setting the number of bits of the luminance value to 10 bits and setting white luminance having undergone knee conversion to 100%, but a luminance value converted, into luminance in practice is a value which is normalized to 0 or more and 1 or less. This is also the same for <figref idrefs="DRAWINGS">FIG. 5</figref> described later.</div>
<div class="description-paragraph" id="p-0140" num="0139">As illustrated in <figref idrefs="DRAWINGS">FIG. 3</figref>, in the first embodiment, 80% to 400% of an HDR image in which a dynamic, range of luminance is 0 to 400% is knee-compressed to 80% to 100%, so that an SDR image in which a dynamic range of luminance is 0 to 100% is generated and is then coded.</div>
<div class="description-paragraph" id="p-0141" num="0140">[Overview of Decoding in First Embodiment]</div>
<div class="description-paragraph" id="p-0142" num="0141"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a diagram illustrating an overview of decoding in the first embodiment of a decoding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0143" num="0142">As illustrated in <figref idrefs="DRAWINGS">FIG. 4</figref>, in the first embodiment, coded data of the SDR image in which a dynamic range of luminance is 0 to 100%, generated as described in <figref idrefs="DRAWINGS">FIG. 3</figref>, is decoded. In a case where a display unit is an SDR display, the SDR image which is obtained as a result of the decoding is input to and is displayed on the display unit without change. On the other hand, in a case where the display unit is an HDR display, the SDR image obtained as a result of the decoding is scaled to an HDR image, and is input to and is displayed on the display unit.</div>
<div class="description-paragraph" id="p-0144" num="0143">Specifically, as illustrated in <figref idrefs="DRAWINGS">FIG. 5</figref>, 80% to 100% of the SDR image in which a dynamic range of luminance is 0 to 100% is knee-decompressed to 80% to 400%, and thus an HDR image in which a dynamic range of luminance is 0 to 400% is generated. In addition, the generated HDR image is displayed.</div>
<div class="description-paragraph" id="p-0145" num="0144">In addition, at this time, in order to generate a desired HDR image, information regarding conversion from an SDR image into the desired HDR image, such as a range (80% to 100% in the example of <figref idrefs="DRAWINGS">FIG. 5</figref>) of luminance of an SDR image which is knee-decompressed, and a range (80% to 400% in the example of <figref idrefs="DRAWINGS">FIG. 5</figref>) of luminance of an HDR image corresponding to the range, is necessary. Therefore, in the first, embodiment, conversion information regarding conversion from an SDR image into an HDR image is transmitted from the coding device to the decoding device, and thus a desired HDR image can be generated from a decoded SDR image in the decoding device.</div>
<div class="description-paragraph" id="p-0146" num="0145">(Configuration Example of First Embodiment of Coding Device)</div>
<div class="description-paragraph" id="p-0147" num="0146"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a block diagram illustrating a configuration example of the first embodiment of a coding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0148" num="0147">A coding device <b>10</b> of <figref idrefs="DRAWINGS">FIG. 6</figref> includes a setting unit <b>11</b>, a coding unit <b>12</b>, a transmission unit <b>13</b>, and a conversion unit <b>14</b>, and codes an SDR image which is converted from an HDR image in a method conforming to the HEVC method.</div>
<div class="description-paragraph" id="p-0149" num="0148">Specifically, the setting unit <b>11</b> of the coding device <b>10</b> sets a sequence parameter set (SPS), a picture parameter set (PPS), VUI, and the like. In addition, the setting unit <b>11</b> sets knee_function_info Supplemental Enhancement Information (SEI) including conversion information in response to a command from a user (producer). The setting unit <b>11</b> supplies the parameter sets including the set SPS, PPS, VUI, knee_function_info SEI, and the like to the coding unit <b>12</b>.</div>
<div class="description-paragraph" id="p-0150" num="0149">The coding unit <b>12</b> codes the SDR image supplied from the conversion unit <b>14</b> in the HEVC method. The coding unit <b>12</b> generates a coded stream from coded data, which is obtained as a result of the coding and the parameter sets which are supplied from the setting unit <b>11</b>, and transmits the generated coded stream to the transmission unit <b>13</b>.</div>
<div class="description-paragraph" id="p-0151" num="0150">The transmission unit <b>13</b> transmits the coded stream supplied from the coding unit <b>12</b>, to a decoding device described later. In addition, the transmission unit <b>13</b> may transmit the coded stream to a recording device which records the coded stream on a recording medium such as a BD. In this case, the coded stream is transmitted to the decoding device via the recording medium.</div>
<div class="description-paragraph" id="p-0152" num="0151">The conversion unit <b>14</b> converts an HDR image input from an external device into an SDR image through knee compression, and supplies the SDR image to the coding unit <b>12</b>.</div>
<div class="description-paragraph" id="p-0153" num="0152">(Example of Syntax of Knee_Function_Info SEI)</div>
<div class="description-paragraph" id="p-0154" num="0153"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a diagram illustrating an example of syntax of knee_function_info SEI, and <figref idrefs="DRAWINGS">FIG. 8</figref> is a diagram illustrating each piece of information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 7</figref>.</div>
<div class="description-paragraph" id="p-0155" num="0154">As illustrated in <figref idrefs="DRAWINGS">FIG. 7</figref>, input knee position information (knee_point_of_input), output knee position information (knee_point_of_input), output luminance range information (output_white_level_range), output luminance information (output_white_level_range_luminance), and the like are set in the knee_function_info SEI as conversion information.</div>
<div class="description-paragraph" id="p-0156" num="0155">The input knee position information is information indicating the minimum value (knee point) of luminance which is knee decompression of an SDR image which is an unconverted image.</div>
<div class="description-paragraph" id="p-0157" num="0156">The input knee position information is a permillage of a knee point when the maximum value of luminance of an SDR image is set to 1000 permil.</div>
<div class="description-paragraph" id="p-0158" num="0157">The output knee position information is information indicating luminance of an HDR image which is a converted image, corresponding to the minimum, value (knee point) of luminance which is a knee decompression target of an SDR image which is an unconverted image. The output knee position information is a permillage of luminance corresponding to a knee point when the maximum value of luminance of an HDR image is set to 1000 permil.</div>
<div class="description-paragraph" id="p-0159" num="0158">The output luminance range information is information indicating white luminance of an HDR image which is a converted image. In addition, the output luminance information is information indicating brightness (luminance) of the display unit, corresponding to white of the HDR image which is a converted image.</div>
<div class="description-paragraph" id="p-0160" num="0159">(Example of Conversion Information)</div>
<div class="description-paragraph" id="p-0161" num="0160"> <figref idrefs="DRAWINGS">FIGS. 9 and 10</figref> are diagrams illustrating examples of conversion information set in the knee_function_info SEI.</div>
<div class="description-paragraph" id="p-0162" num="0161">In the example of <figref idrefs="DRAWINGS">FIG. 9</figref>, the user sets an HDR image which is obtained as a result of knee-decompressing 80% to 100% of luminance of an SDR image to 80% to 400% is used as a desired HDR image. In this case, in the knee_function_info SEI, 800as the input knee position information (knee_point_of_input), and 200 is set as the output knee position information (knee_point_of_output).</div>
<div class="description-paragraph" id="p-0163" num="0162">Therefore, a decoding device described later can knee-decompress 80% to 100% of luminance of an SDR image which is obtained, as a result of decoding to 80% to 400% on the basis of the input knee position information and the output knee position information. As a result, the decoding device can convert the SDR image obtained as a result of the decoding into a desired HDR image.</div>
<div class="description-paragraph" id="p-0164" num="0163">In addition, in the example of <figref idrefs="DRAWINGS">FIG. 9</figref>, the output luminance range information (output_white_level_range) is 400, and the output luminance information (output_white_level_range_luminace) is 800 (candela per square meter).</div>
<div class="description-paragraph" id="p-0165" num="0164">In the example of <figref idrefs="DRAWINGS">FIG. 10</figref>, the user sets an HDR image which is obtained as a result of knee-decompressing 80% to 100% of luminance of an SDR image to 100% to 400% as a desired HDR image. In this case, in the knee_function_info SEI, 800 is set as the input knee position information (knee_point_of_input), and 250is set as the output knee position information (knee_point_of_output).</div>
<div class="description-paragraph" id="p-0166" num="0165">Therefore, the decoding device described later can knee-decompress 80% to 100% of luminance of an SDR image which is obtained as a result of decoding to 100% to 400% on the basis of the input knee position information and the output knee position information. As a result, the decoding device can convert the SDR image obtained as a result, of the decoding into a desired HDR image.</div>
<div class="description-paragraph" id="p-0167" num="0166">In addition, in the example of <figref idrefs="DRAWINGS">FIG. 10</figref>, the output luminance range information (output_white_level_range) is 400, and the output luminance information (output_white_level_range_luminace) is 800 (candela per square meter).</div>
<div class="description-paragraph" id="p-0168" num="0167">&lt;Description of Process in Coding Device&gt;</div>
<div class="description-paragraph" id="p-0169" num="0168"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a flowchart illustrating a stream generation process performed by the coding device <b>10</b>.</div>
<div class="description-paragraph" id="p-0170" num="0169">In step S<b>10</b> of <figref idrefs="DRAWINGS">FIG. 11</figref>, the conversion unit <b>14</b> of the coding device <b>10</b> converts an HDR image which is input from an external device, into an SDR image which is then supplied to the coding unit <b>12</b>.</div>
<div class="description-paragraph" id="p-0171" num="0170">In step S<b>11</b>, the setting unit <b>11</b> sets an SPS. In step S<b>12</b>, the setting unit <b>11</b> sets VUI. In step S<b>13</b>, the setting unit <b>11</b> sets a PPS.</div>
<div class="description-paragraph" id="p-0172" num="0171">In step S<b>14</b>, the setting unit <b>11</b> sets knee_function_info SEI in response to an instruction or the like from a user. The setting unit <b>11</b> supplies the parameter sets including the set SPS, PPS, VUI, knee_function_info SEI, and the like to the coding unit <b>12</b>.</div>
<div class="description-paragraph" id="p-0173" num="0172">In step S<b>15</b>, the coding unit <b>12</b> codes the SDR image supplied from, the conversion unit <b>14</b> in the HEVC method. In step S<b>16</b>, the coding unit <b>12</b> generates a coded stream from coded data which is obtained as a result of the coding and the parameter sets which are supplied from the setting unit <b>11</b>, and transmits the generated coded stream, to the transmission unit <b>13</b>.</div>
<div class="description-paragraph" id="p-0174" num="0173">In step S<b>17</b>, the transmission unit <b>13</b> transmits the coded stream supplied from the coding unit <b>12</b>, to the decoding device described, later, and then finishes the process.</div>
<div class="description-paragraph" id="p-0175" num="0174">As mentioned above, the coding device <b>10</b> sets and transmits knee_function_info SEI including conversion information, and thus the decoding device described later can convert an SDR image obtained as a result of decoding into a desired HDR image on the basis of the conversion information. Therefore, it can be said that the coding device <b>10</b> can code an SDR image so that a decoded SDR image can be converted into a desired HDR image during decoding.</div>
<div class="description-paragraph" id="p-0176" num="0175">In addition, since the conversion information is set, the coding device <b>10</b> can generate a coded stream of an image corresponding to an HDR display and an SDR display only by coding an SDR image. Therefore, it is possible to further reduce a data amount of a coded stream than in a case of coding both an HDR image and an SDR image.</div>
<div class="description-paragraph" id="p-0177" num="0176">(Configuration Example of First Embodiment of Decoding Device)</div>
<div class="description-paragraph" id="p-0178" num="0177"> <figref idrefs="DRAWINGS">FIG. 12</figref> is a block diagram illustrating a configuration example of an embodiment of a decoding device which decodes a coded stream transmitted from the coding device <b>10</b> of <figref idrefs="DRAWINGS">FIG. 6</figref> and to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0179" num="0178">A decoding device <b>50</b> of <figref idrefs="DRAWINGS">FIG. 12</figref> includes a reception unit <b>51</b>, an extraction unit <b>52</b>, a decoding unit <b>53</b>, a conversion unit <b>54</b>, a display control unit <b>55</b>, and a display unit <b>56</b>.</div>
<div class="description-paragraph" id="p-0180" num="0179">The reception unit <b>51</b> of the decoding device <b>50</b> receives the coded stream transmitted from the coding device <b>10</b> of <figref idrefs="DRAWINGS">FIG. 6</figref>, and supplies the coded stream to the extraction unit <b>52</b>.</div>
<div class="description-paragraph" id="p-0181" num="0180">The extraction unit <b>52</b> extracts the parameter sets and the coded data of the SDR image from the coded stream, which is supplied from the reception unit <b>51</b>. The extraction unit <b>52</b> supplies the parameter sets and the coded data to the decoding unit <b>53</b>. In addition, the extraction unit <b>52</b> supplies the knee_function_info SEI among the parameter sets, to the conversion unit <b>54</b>.</div>
<div class="description-paragraph" id="p-0182" num="0181">The decoding unit <b>53</b> decodes the coded data of the SDR image supplied from the extraction unit <b>52</b> in the HEVC method. At this time, the decoding unit <b>53</b> also refers to the parameter sets supplied from the extraction unit <b>52</b> as necessary. The decoding unit <b>53</b> supplies the SDR image which is obtained as a result of decoding to the conversion unit <b>54</b>.</div>
<div class="description-paragraph" id="p-0183" num="0182">The conversion unit <b>54</b> converts the SDR image supplied from the decoding unit <b>53</b> into an HDR image through knee decompression on the basis of the conversion information included in the knee_function_info SEI supplied from the extraction unit <b>52</b>, and supplies the HDR image to the display control unit <b>55</b>.</div>
<div class="description-paragraph" id="p-0184" num="0183">The display control unit <b>55</b> displays the HDR image supplied from the conversion unit <b>54</b> on the display unit <b>56</b>. The display unit <b>56</b> is an HDR display.</div>
<div class="description-paragraph" id="p-0185" num="0184">&lt;Description of Process in Decoding Device&gt;</div>
<div class="description-paragraph" id="p-0186" num="0185"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a flowchart illustrating an image generation process performed by the decoding device <b>50</b> of <figref idrefs="DRAWINGS">FIG. 12</figref>.</div>
<div class="description-paragraph" id="p-0187" num="0186">In step S<b>51</b> of <figref idrefs="DRAWINGS">FIG. 13</figref>, the reception unit <b>51</b> of the decoding device <b>50</b> receives the coded stream transmitted from the coding device <b>10</b> of <figref idrefs="DRAWINGS">FIG. 6</figref>, and supplies the coded stream to the extraction unit <b>52</b>.</div>
<div class="description-paragraph" id="p-0188" num="0187">In step S<b>52</b>, the extraction unit <b>52</b> extracts the parameter sets and the coded data of the SDR image from the coded, stream which is supplied from the reception unit <b>51</b>. The extraction unit <b>52</b> supplies the parameter sets and the coded data of the SDR image to the decoding unit <b>53</b>. In addition, the extraction unit <b>52</b> supplies the knee_function_info SEI among the parameter sets, to the conversion unit <b>54</b>.</div>
<div class="description-paragraph" id="p-0189" num="0188">In step S<b>53</b>, the decoding unit <b>53</b> decodes the coded data of the SDR image supplied from the extraction unit <b>52</b> in the HEVC method. At this time, the decoding unit <b>53</b> also refers to the parameter sets supplied from the extraction unit <b>52</b> as necessary. The decoding unit <b>53</b> supplies the SDR image which is obtained as a result of decoding to the conversion unit <b>54</b>.</div>
<div class="description-paragraph" id="p-0190" num="0189">In step S<b>54</b>, the conversion unit <b>54</b> acquires the conversion information from the knee_function_info SEI which is supplied from the extraction unit <b>52</b>.</div>
<div class="description-paragraph" id="p-0191" num="0190">In step S<b>55</b>, the conversion unit <b>54</b> converts the SDR image supplied from the decoding unit <b>53</b> into an HDR image on the basis of the conversion information, and supplies the HDR image to the display control unit <b>55</b>.</div>
<div class="description-paragraph" id="p-0192" num="0191">In step S<b>56</b>, the display control unit <b>55</b> displays the HDR image supplied from the conversion unit <b>54</b> on the display unit <b>56</b>, and finishes the process.</div>
<div class="description-paragraph" id="p-0193" num="0192">As mentioned above, the decoding device <b>50</b> converts the SDR image obtained as a result of decoding into the HDR image on the basis of the conversion information, and thus can convert the SDR image obtained as a result of decoding into a desired HDR image.</div>
<div class="description-paragraph" id="p-0194" num="0193">(Another Example of Syntax of Knee_Function_Info SEI)</div>
<div class="description-paragraph" id="p-0195" num="0194"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a diagram illustrating another example of syntax of knee_function_info SEI, and <figref idrefs="DRAWINGS">FIG. 15</figref> is a diagram illustrating each piece of information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 14</figref>.</div>
<div class="description-paragraph" id="p-0196" num="0195">The knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 14</figref> is the same as the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 7</figref> except that luminance range information (white_level_range) and luminance information (white_level_range_luminance) are set instead of the output luminance range information (output_white_level_range) and the output luminance information (output_white_level_range_luminance).</div>
<div class="description-paragraph" id="p-0197" num="0196">The luminance range information is output luminance range information when input knee position information (knee_point_of_input) is equal to or more than output knee position information (knee_point_of_output), that is, when knee decompression is performed on a decoding side in the same manner as in the first, embodiment.</div>
<div class="description-paragraph" id="p-0198" num="0197">On the other hand, when the input knee position information is less than the output knee position information, that is, when knee compression is performed on the decoding side, the luminance range information is information indicating white luminance of an unconverted image (for example, an HDR image).</div>
<div class="description-paragraph" id="p-0199" num="0198">Similarly, the luminance information (white_level_range_luminance) is output luminance information when input knee position information is equal to or more than output knee position information in the same manner as in the first embodiment, and is information indicating white luminance (value) of an unconverted image (for example, an HDR image) when the input, knee position information is less than the output knee position information.</div>
<div class="description-paragraph" id="p-0200" num="0199">In addition, in the first embodiment, only an SDR image is coded in the coding device <b>10</b>, but only an HDR image converted from the SDR image may be coded. In this case, information regarding conversion from the SDR image into the HDR image is set in SEI end is transmitted to the decoding device <b>50</b>. Specifically, the knee_function_info SEI illustrated in <figref idrefs="DRAWINGS">FIG. 7</figref> or <figref idrefs="DRAWINGS">FIG. 15</figref> in which an unconverted image is set as an HDR image, and a converted image is set as an SDR image is transmitted to the decoding device <b>50</b>. In addition, the decoding device <b>50</b> converts an HDR image into an original SDR image with high accuracy on the basis of the knee_function_info SEI.</div>
<div class="description-paragraph" id="p-0201" num="0200">In addition, in the first embodiment, the display unit <b>56</b> is an HDR display, but the display unit <b>56</b> may be an SDR display. In this case, the conversion unit <b>54</b> supplies an SDR image to the display control unit <b>55</b> without conversion into an HDR image. Accordingly, the SDR image is displayed on the display unit <b>56</b>.</div>
<div class="description-paragraph" id="p-0202" num="0201">In addition, a desired image may be an HDR image which is input, to the coding device <b>10</b>.</div>
<div class="description-paragraph" id="p-0203" num="0202">In addition, in the first embodiment, the coding device <b>10</b> converts an HDR image which is input from an external device into an SDR image which is then coded, but may code an SDR image which is input from the external device without conversion.</div>
<heading id="h-0013">Second Embodiment</heading>
<div class="description-paragraph" id="p-0204" num="0203">(Configuration Example of Second Embodiment of Coding Device)</div>
<div class="description-paragraph" id="p-0205" num="0204"> <figref idrefs="DRAWINGS">FIG. 16</figref> is a block diagram illustrating a configuration example of a second embodiment of a coding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0206" num="0205">Among constituent elements illustrated in <figref idrefs="DRAWINGS">FIG. 16</figref>, the same constituent elements as the constituent elements of <figref idrefs="DRAWINGS">FIG. 6</figref> are given the same reference numeral. Repeated description will be omitted as appropriate.</div>
<div class="description-paragraph" id="p-0207" num="0206">A configuration of a coding device <b>70</b> of <figref idrefs="DRAWINGS">FIG. 16</figref> is different from the configuration of the coding device <b>10</b> of <figref idrefs="DRAWINGS">FIG. 6</figref> in that a setting unit <b>71</b>, a coding unit <b>72</b>, and a conversion unit <b>73</b> are provided instead of the setting unit <b>11</b>, the coding unit <b>12</b>, and the conversion unit <b>14</b>. The coding device <b>70</b> codes an HDR image which is input from an external device, or codes an SDR image which is converted from an HDR image, in a method conforming to the HEVC method.</div>
<div class="description-paragraph" id="p-0208" num="0207">Specifically, the setting unit <b>71</b> of the coding device <b>70</b> sets, an SPS, a PPS, VUI, and the like. In addition, the setting unit <b>71</b> sets SEI such as knee_function_info SEI including DR conversion information in response to a command from a user (producer). The DR conversion information is information regarding conversion from a dynamic range of luminance of an image which is a coding target into a different dynamic range. The setting unit <b>71</b> supplies the parameter sets including the set SPS, PPS, VUI, knee_function_info SEI, and the like to the coding unit <b>72</b>.</div>
<div class="description-paragraph" id="p-0209" num="0208">The coding unit <b>72</b> sets an HDR image or an SDR image supplied from the conversion unit <b>73</b> as a coding target image, and codes the coding target image in the HEVC method. The coding unit <b>72</b> generates a coded stream from coded data which is obtained as a result of the coding and the parameter sets which are supplied from the setting unit <b>71</b>, and transmits the generated coded stream to the transmission unit <b>13</b>.</div>
<div class="description-paragraph" id="p-0210" num="0209">The conversion unit <b>73</b> knee-compresses luminance of an HDR image which is input from an external device so as to generate an SDR image which is then supplied to the coding unit <b>72</b>, or supplies an HDR image which is input from the external device to the coding unit <b>72</b> without compression.</div>
<div class="description-paragraph" id="p-0211" num="0210">(First Example of Syntax of Knee_Function_Info SEI)</div>
<div class="description-paragraph" id="p-0212" num="0211"> <figref idrefs="DRAWINGS">FIG. 17</figref> is a diagram illustrating a first example of syntax of knee_function_info SEI set by the setting unit <b>71</b> of <figref idrefs="DRAWINGS">FIG. 16</figref>, and <figref idrefs="DRAWINGS">FIG. 18</figref> is a diagram illustrating each piece of information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 17</figref>.</div>
<div class="description-paragraph" id="p-0213" num="0212">As illustrated in <figref idrefs="DRAWINGS">FIG. 17</figref>, a knee conversion ID (knee_function_id) and a knee conversion cancel flag (knee_function_cancel_flag) are set in the knee_function_info SEI.</div>
<div class="description-paragraph" id="p-0214" num="0213">The knee conversion ID is an ID unique to the purpose of knee conversion which is knee compression or knee decompression as illustrated in <figref idrefs="DRAWINGS">FIG. 18</figref>. In addition, the knee conversion cancel flag is a flag illustrating whether or not persistence of previous knee_function_info SEI is canceled. The knee conversion cancel flag is set to 1 when indicating that persistence of previous knee_function_info SEI is canceled, and is set to 0 when the persistence is not canceled.</div>
<div class="description-paragraph" id="p-0215" num="0214">If the knee conversion cancel flag is 0, as illustrated in <figref idrefs="DRAWINGS">FIG. 17</figref>, a single piece of pre-conversion position information (input_knee_point), a single piece of post-conversion position information (output_knee_point), HDR luminance range information (d_range), and display luminance information (d_range_disp_luminance) are set in the knee_function_info SEI as DR conversion information.</div>
<div class="description-paragraph" id="p-0216" num="0215">The pre-conversion position information is information indicating a knee point of a coding target image which is an unconverted image in conversion corresponding to the DR conversion information, and is a permillage of a knee point when the maximum value of luminance of the coding target image is set to 1000 permil. The knee point is luminance (which is a value obtained by normalizing linear RGB values in the range of 0.0 to 1.1) other than 0 which is a start point of a range of luminance which is knee-converted at the same conversion ratio as that of a dynamic range of luminance of the coding target image.</div>
<div class="description-paragraph" id="p-0217" num="0216">The post-conversion position information is information indicating a start point of a range of luminance corresponding to a range of knee-converted luminance which has a knee point as a start point in an image after being converted (hereinafter, referred to as a converted image) in conversion corresponding to the DR conversion information. Specifically, the post-conversion position information is a permillage of luminance of a converted image corresponding to a knee point when the maximum value of luminance of the converted image is set to 1000 permil.</div>
<div class="description-paragraph" id="p-0218" num="0217">The HDR luminance range information is information indicating a permillage of the maximum value of luminance of an HDR image which is a coding target image or a converted image. In addition, the display luminance information is information indicating an expected value of brightness (luminance) of the display unit corresponding to the maximum value of luminance of an HDR image.</div>
<div class="description-paragraph" id="p-0219" num="0218">(First Example of DR Conversion Information)</div>
<div class="description-paragraph" id="p-0220" num="0219"> <figref idrefs="DRAWINGS">FIGS. 19 and 20</figref> are diagrams illustrating examples of the DR conversion information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 17</figref>.</div>
<div class="description-paragraph" id="p-0221" num="0220">In the example of <figref idrefs="DRAWINGS">FIG. 19</figref>, a coding target image is an SDR image, and a user sets an HDR image which is obtained as a result of knee-decompressing 80% to 100% of luminance of the SDR image to 80% to 400%, as a desired converted image. In this case, in the knee_function_info SEI, 800 is set as the pre-conversion position information (input_knee_point), and 200 is set as the post-conversion position information (output_knee_point).</div>
<div class="description-paragraph" id="p-0222" num="0221">In addition, in the example of <figref idrefs="DRAWINGS">FIG. 19</figref>, the HDR luminance range information (d_range) is 4000, and the display luminance range information (d_range_disp_luminance) is 800 (candela per square meter).</div>
<div class="description-paragraph" id="p-0223" num="0222">As in the case of <figref idrefs="DRAWINGS">FIG. 19</figref>, in a case where a coding target image is an SDR image, and a converted image is an HDR image, a knee point input_knee_joint PER (%) and luminance output_knee_point_PER (%) of a converted image corresponding to the knee point are defined by the following Equation (1).</div>
<div class="description-paragraph" id="p-0224" num="0223">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
<mtr>
<mtd>
<mrow>
<mo>[</mo>
<mrow>
<mi>Math</mi>
<mo>.</mo>
<mstyle>
<mspace height="0.8ex" width="0.8em"> </mspace>
</mstyle>
<mo>⁢</mo>
<mn>1</mn>
</mrow>
<mo>]</mo>
</mrow>
</mtd>
<mtd>
<mstyle>
<mspace height="0.3ex" width="0.3em"> </mspace>
</mstyle>
</mtd>
</mtr>
<mtr>
<mtd>
<mrow>
<mrow>
<mrow>
<mi>input_knee</mi>
<mo>⁢</mo>
<mi>_point</mi>
<mo>⁢</mo>
<mi>_DR</mi>
</mrow>
<mo>=</mo>
<mrow>
<mn>100</mn>
<mo>×</mo>
<mfrac>
<mrow>
<mi>input_knee</mi>
<mo>⁢</mo>
<mi>_point</mi>
</mrow>
<mn>1000</mn>
</mfrac>
</mrow>
</mrow>
<mo>⁢</mo>
<mstyle>
<mtext>
</mtext>
</mstyle>
<mo>⁢</mo>
<mrow>
<mrow>
<mi>output_knee</mi>
<mo>⁢</mo>
<mi>_point</mi>
<mo>⁢</mo>
<mi>_DR</mi>
</mrow>
<mo>=</mo>
<mrow>
<mfrac>
<mi>d_range</mi>
<mn>10</mn>
</mfrac>
<mo>×</mo>
<mfrac>
<mrow>
<mi>output_knee</mi>
<mo>⁢</mo>
<mi>_point</mi>
</mrow>
<mn>1000</mn>
</mfrac>
</mrow>
</mrow>
</mrow>
</mtd>
<mtd>
<mrow>
<mo>(</mo>
<mn>1</mn>
<mo>)</mo>
</mrow>
</mtd>
</mtr>
</mtable>
</math>
</maths>
</div>
<div class="description-paragraph" id="p-0225" num="0224">Therefore, a decoding device described later recognizes that the knee point input_knee_point_PER and the luminance output_knee_point_PER are 80% according to Equation (1). In addition, the decoding device described later recognizes that knee conversion corresponding to the DR conversion information is knee decompression since the pre-conversion position information is equal to or more than the post-conversion position information. Further, the decoding device described later recognizes that the maximum value of luminance of the converted image is 400% from the HDR luminance range information.</div>
<div class="description-paragraph" id="p-0226" num="0225">As mentioned above, the decoding device described, later knee-decompresses 80% to 100% of luminance of the SDR image which is obtained, as a result of decoding to, 80% to 400%. Therefore, the decoding device can convert the SDR image obtained as a result, of decoding into a desired HDP image.</div>
<div class="description-paragraph" id="p-0227" num="0226">In the example of <figref idrefs="DRAWINGS">FIG. 20</figref>, a coding target image is an HDR image, and the user sets an SDR image which is obtained as a result, of knee-compressing 80% to 400% of luminance of the HDR image to 80% to 100%, as a desired converted image. In this case, in the knee_function_info SEI, <b>200</b> is set as the pre-conversion position information (input_knee_point), and <b>800</b> is set as the post-conversion position information (output_knee_point).</div>
<div class="description-paragraph" id="p-0228" num="0227">In addition, in the example of <figref idrefs="DRAWINGS">FIG. 20</figref>, the HDR luminance range information (d_range) is 4000, and the display luminance range information (d_range_disp_luminance) is 800 (candela per square meter).</div>
<div class="description-paragraph" id="p-0229" num="0228">As in the case of <figref idrefs="DRAWINGS">FIG. 20</figref>, in a case where a coding target image is an HDR image, and a converted image is an SDR image, a knee point input_knee_point_PER (%) and luminance output_knee_point_PER (%) of a converted image corresponding to the knee point are defined by the following Equation (2).</div>
<div class="description-paragraph" id="p-0230" num="0229">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mtable>
<mtr>
<mtd>
<mrow>
<mo>[</mo>
<mrow>
<mi>Math</mi>
<mo>.</mo>
<mstyle>
<mspace height="0.8ex" width="0.8em"> </mspace>
</mstyle>
<mo>⁢</mo>
<mn>2</mn>
</mrow>
<mo>]</mo>
</mrow>
</mtd>
<mtd>
<mstyle>
<mspace height="0.3ex" width="0.3em"> </mspace>
</mstyle>
</mtd>
</mtr>
<mtr>
<mtd>
<mrow>
<mrow>
<mrow>
<mi>input_knee</mi>
<mo>⁢</mo>
<mi>_point</mi>
<mo>⁢</mo>
<mi>_DR</mi>
</mrow>
<mo>=</mo>
<mrow>
<mfrac>
<mi>d_range</mi>
<mn>10</mn>
</mfrac>
<mo>×</mo>
<mfrac>
<mrow>
<mi>input_knee</mi>
<mo>⁢</mo>
<mi>_point</mi>
</mrow>
<mn>1000</mn>
</mfrac>
</mrow>
</mrow>
<mo>⁢</mo>
<mstyle>
<mtext>
</mtext>
</mstyle>
<mo>⁢</mo>
<mrow>
<mrow>
<mi>output_knee</mi>
<mo>⁢</mo>
<mi>_point</mi>
<mo>⁢</mo>
<mi>_DR</mi>
</mrow>
<mo>=</mo>
<mrow>
<mn>100</mn>
<mo>×</mo>
<mfrac>
<mrow>
<mi>output_knee</mi>
<mo>⁢</mo>
<mi>_point</mi>
</mrow>
<mn>1000</mn>
</mfrac>
</mrow>
</mrow>
</mrow>
</mtd>
<mtd>
<mrow>
<mo>(</mo>
<mn>2</mn>
<mo>)</mo>
</mrow>
</mtd>
</mtr>
</mtable>
</math>
</maths>
</div>
<div class="description-paragraph" id="p-0231" num="0230">Therefore, the decoding device described later recognizes that the knee point input_knee_point_PER and the luminance output_knee_point_PER are 80% according to Equation (2). In addition, the decoding device described later recognizes that knee conversion corresponding to the DR conversion information is knee compression since the pre-conversion position information is less than the post-conversion position information. Further, the decoding device described later recognizes that the maximum value of luminance of the converted image is 400% from the HDR luminance range information.</div>
<div class="description-paragraph" id="p-0232" num="0231">As mentioned above, the decoding device described later knee-compresses 80% to 400% of luminance of the SDR image which is obtained as a result of decoding, to 80% to 100%. Therefore, the decoding device can convert the HDR image obtained as a result of decoding into a desired SDR image.</div>
<div class="description-paragraph" id="p-0233" num="0232">&lt;Description of Process in Coding Device&gt;</div>
<div class="description-paragraph" id="p-0234" num="0233"> <figref idrefs="DRAWINGS">FIG. 21</figref> is a flowchart illustrating a stream generation process performed by the coding device <b>70</b> of <figref idrefs="DRAWINGS">FIG. 16</figref>.</div>
<div class="description-paragraph" id="p-0235" num="0234">In step S<b>71</b> of <figref idrefs="DRAWINGS">FIG. 21</figref>, the conversion unit <b>73</b> of the coding device <b>70</b> determines whether or not, for example, a coding target image is an SDR image in response to an instruction or the like from the user. If it is determined, that a coding target image is an SDR image in step S<b>71</b>, the process proceeds to step S<b>72</b>.</div>
<div class="description-paragraph" id="p-0236" num="0235">In step S<b>72</b>, the conversion unit <b>73</b> converts an HDR image which is input from an external device into an SDR image through knee compression of luminance of the HDR image, and supplies the SDR image to the coding unit <b>72</b>.</div>
<div class="description-paragraph" id="p-0237" num="0236">On the other hand, if it is determined that a coding target image is not an SDR image in step S<b>71</b>, that is, a coding target image is an HDR image, the conversion unit <b>73</b> supplies an HDR image which is input from an external device to the coding unit <b>72</b> without change, and the process proceeds to step S<b>73</b>.</div>
<div class="description-paragraph" id="p-0238" num="0237">In step S<b>73</b>, the setting unit <b>71</b> sets an SPS. In step S<b>74</b>, the setting unit <b>71</b> sets VUI. In step S<b>75</b>, the setting unit <b>71</b> sets a PPS.</div>
<div class="description-paragraph" id="p-0239" num="0238">In step S<b>76</b>, the setting unit <b>71</b> sets knee_function_info SEI in response to an instruction or the like from a user. The setting unit <b>71</b> supplies the parameter sets including the set SPS, PPS, VUI, knee_function_info SEI, and the like to the coding unit <b>72</b>.</div>
<div class="description-paragraph" id="p-0240" num="0239">In step S<b>77</b>, the coding unit <b>72</b> codes an SDR image or an HDR image supplied from the conversion unit <b>73</b> as a coding target, image in the HEVC method. In step S<b>78</b>, the coding unit <b>72</b> generates a coded, stream from coded data which is obtained as a result of the coding and the parameter sets which are supplied from the setting unit <b>71</b>, and transmits the generated coded stream to the transmission unit <b>13</b>.</div>
<div class="description-paragraph" id="p-0241" num="0240">In step S<b>79</b>, the transmission unit <b>13</b> transmits the coded stream supplied from the coding unit <b>72</b>, to the decoding device described later, and then finishes the process.</div>
<div class="description-paragraph" id="p-0242" num="0241">As mentioned above, the coding device <b>70</b> sets and transmits knee_function_info SEI including DR conversion information, and thus the decoding device described later can convert a coding target image obtained as a result of decoding into a desired converted image on the basis of the DR conversion information. Therefore, it can be said that, the coding device <b>70</b> can code an image so that a decoded image can be converted into a desired converted image during decoding.</div>
<div class="description-paragraph" id="p-0243" num="0242">In addition, since the DR conversion information is set, the coding device <b>70</b> can generate a coded stream of an image corresponding to an HDR display and an SDR display only by coding either an SDR image or an HDR image. Therefore, it is possible to further reduce a data amount of a coded stream than in a case of coding both an HDR image and an SDR image.</div>
<div class="description-paragraph" id="p-0244" num="0243">(Configuration Example of Second Embodiment of Decoding Device)</div>
<div class="description-paragraph" id="p-0245" num="0244"> <figref idrefs="DRAWINGS">FIG. 22</figref> is a block diagram illustrating a configuration example of a second embodiment of a decoding device which decodes a coded stream transmitted from the coding device <b>70</b> of <figref idrefs="DRAWINGS">FIG. 16</figref> and to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0246" num="0245">Among constituent elements illustrated in <figref idrefs="DRAWINGS">FIG. 22</figref>, the same constituent elements as the constituent elements of <figref idrefs="DRAWINGS">FIG. 12</figref> are given the same reference numerals. Repeated description will be omitted as appropriate.</div>
<div class="description-paragraph" id="p-0247" num="0246">A configuration of a decoding device <b>90</b> of <figref idrefs="DRAWINGS">FIG. 22</figref> is different from, the configuration of the decoding device <b>50</b> of <figref idrefs="DRAWINGS">FIG. 12</figref> in that an extraction unit <b>91</b>, a decoding unit <b>92</b>, a conversion unit <b>93</b>, a display control unit <b>94</b>, and a display unit <b>95</b> are provided instead of the extraction unit <b>52</b>, the decoding unit <b>53</b>, the conversion unit <b>54</b>, the display control unit <b>55</b>, and the display unit <b>56</b>. The decoding device <b>90</b> converts a decoded image into a converted image according to the type of display unit <b>95</b>, and displays the converted image on the display unit <b>95</b>.</div>
<div class="description-paragraph" id="p-0248" num="0247">Specifically, the extraction unit <b>91</b> of the decoding device <b>90</b> extracts parameter sets and coded data from a coded stream which is supplied from the reception unit <b>51</b>. The extraction unit <b>91</b> supplies the parameter sets and the coded data to the decoding unit <b>92</b>. In addition, the extraction, unit <b>91</b> supplies knee_function_info SEI among the parameter sets, to the conversion unit <b>93</b>.</div>
<div class="description-paragraph" id="p-0249" num="0248">The decoding unit <b>92</b> decodes the coded data supplied from the extraction unit <b>91</b> in the HEVC method. At this time, the decoding unit <b>92</b> also refers to the parameter sets supplied from the extraction unit <b>91</b> as necessary. The decoding unit <b>92</b> supplies a decoded image to the conversion unit <b>93</b>.</div>
<div class="description-paragraph" id="p-0250" num="0249">In a case where a dynamic range of luminance corresponding to the display unit <b>95</b> is a dynamic range of luminance of the decoded image, the conversion unit <b>93</b> supplies the decoded image which is supplied from the decoding unit <b>92</b>, to the display control unit <b>94</b> without change. On the other hand, in a case where a dynamic range of luminance corresponding to the display unit <b>95</b> is not a dynamic range of luminance of the decoded image, the conversion unit <b>93</b> converts the decoded image into an converted image through knee conversion on the basis of DR conversion information included in the knee_function_info SEI supplied from the extraction unit <b>91</b>. In addition, the conversion unit <b>93</b> supplies the converted image to the display control unit <b>94</b> as a display image.</div>
<div class="description-paragraph" id="p-0251" num="0250">Specifically, in a case where the display unit <b>95</b> is an HDR display, and the decoded image is an HDR image, or in a case where the display unit <b>95</b> is an SDR display, and the decoded image is an SDR image, the conversion unit <b>93</b> supplies the decoded, image to the display control unit <b>94</b> without change. On the other hand, in a case where the display unit <b>95</b> is an SDR display, and the decoded image is an HDR image, or in a case where the display unit <b>95</b> is an HDR display, and the decoded image is an SDR image, the conversion unit <b>93</b> performs knee conversion on the decoded image on the basis of the DR conversion information so as to generate a converted image. In addition, the conversion unit <b>93</b> supplies the converted image to the display control unit <b>94</b> as a display image.</div>
<div class="description-paragraph" id="p-0252" num="0251">The display control unit <b>94</b> displays the display image supplied from the conversion unit <b>93</b> on the display unit <b>95</b>. Accordingly, in a case where the display unit <b>95</b> is an HDR display, an HDR image is displayed on the display unit <b>95</b> and in a case where the display unit <b>95</b> is an SDR display, an SDR image is displayed on the display unit <b>95</b>. The display unit <b>95</b> is an HDR display or an SDR display, and displays a display image supplied from the display control unit <b>94</b>.</div>
<div class="description-paragraph" id="p-0253" num="0252">&lt;Description of Process in Decoding Device&gt;</div>
<div class="description-paragraph" id="p-0254" num="0253"> <figref idrefs="DRAWINGS">FIG. 23</figref> is a flowchart illustrating an image generation process performed by the decoding device <b>90</b> of <figref idrefs="DRAWINGS">FIG. 22</figref>.</div>
<div class="description-paragraph" id="p-0255" num="0254">In step S<b>91</b> of <figref idrefs="DRAWINGS">FIG. 23</figref>, the reception unit <b>51</b> of the decoding device <b>90</b> receives a coded stream transmitted from the coding device <b>70</b> of <figref idrefs="DRAWINGS">FIG. 16</figref>, and supplies the coded stream to the extraction unit <b>91</b>.</div>
<div class="description-paragraph" id="p-0256" num="0255">In step S<b>92</b>, the extraction unit <b>91</b> extracts parameter sets and coded data from the coded stream which is supplied from the reception unit <b>51</b>. The extraction unit <b>91</b> supplies the parameter sets and the coded data to the decoding unit <b>92</b>. In addition, the extraction unit <b>91</b> supplies knee_function_info SEI among the parameter sets, to the conversion unit <b>93</b>.</div>
<div class="description-paragraph" id="p-0257" num="0256">In step S<b>93</b>, the decoding unit <b>92</b> decodes the coded data supplied from the extraction unit <b>91</b> in the HEVC method. At this time, the decoding unit <b>92</b> also refers to the parameter sets supplied from the extraction unit <b>91</b> as necessary. The decoding unit <b>92</b> supplies a decoded image to the conversion unit <b>93</b>.</div>
<div class="description-paragraph" id="p-0258" num="0257">In step S<b>94</b>, the conversion unit <b>93</b> acquires DR conversion information from the knee_function_info SEI which is supplied from the extraction unit <b>91</b>.</div>
<div class="description-paragraph" id="p-0259" num="0258">In step S<b>95</b>, the conversion unit <b>93</b> determines whether or not a dynamic range of luminance corresponding to the display unit <b>95</b> is a dynamic range of luminance of the decoded image. If it is determined that a dynamic range of luminance corresponding to the display unit <b>95</b> is not a dynamic range of luminance of the decoded image, the process proceeds to step S<b>96</b>.</div>
<div class="description-paragraph" id="p-0260" num="0259">In step S<b>96</b>, the conversion unit <b>93</b> converts the decoded image supplied from the decoding unit <b>92</b> into a converted image on the basis of the DR conversion information, arid supplies the converted, image to the display control unit <b>94</b> as a display image. In addition, the process proceeds to step S<b>97</b>.</div>
<div class="description-paragraph" id="p-0261" num="0260">On the other hand, it is determined in step S<b>95</b> that a dynamic range of luminance corresponding to the display unit <b>95</b> is a dynamic range of luminance of the decoded image, the conversion unit <b>93</b> supplies the decoded image which is supplied from the decoding unit <b>92</b>, to the display control unit <b>94</b> as a display image without change. In addition, the process proceeds to step S<b>97</b>.</div>
<div class="description-paragraph" id="p-0262" num="0261">In step S<b>97</b>, the display control unit <b>94</b> displays the display image supplied from the conversion unit <b>93</b> on the display unit <b>95</b>, and finishes the process.</div>
<div class="description-paragraph" id="p-0263" num="0262">As mentioned above, the decoding device <b>90</b> converts the decoded image into the converted image on the basis of the DR conversion information, and thus can convert a decoded image to a desired converted image.</div>
<div class="description-paragraph" id="p-0264" num="0263">In addition, in the second, embodiment, one of an SDR image and an HDR image is a coding target image, and the other is a converted image, but an SDR image may be replaced with a desensitized development image of an HDR image in which an expected value of brightness of the display unit corresponding to the maximum value of luminance is greater than that of the SDR image.</div>
<div class="description-paragraph" id="p-0265" num="0264">(Second Example of DR Conversion Information)</div>
<div class="description-paragraph" id="p-0266" num="0265"> <figref idrefs="DRAWINGS">FIGS. 24 and 25</figref> are diagrams illustrating examples of DR conversion information set in knee_function_info SEI in a case where one of a desensitized development image and an HDR image is a coding target image and the other is a converted image.</div>
<div class="description-paragraph" id="p-0267" num="0266">In addition, in the examples of <figref idrefs="DRAWINGS">FIGS. 24 and 25</figref>, the desensitized development image is an image in which a dynamic range of luminance is 0 to 200%, obtained by performing desensitised development of 1 EV (exposure value) on an HDR image. Further, an expected value of brightness of the display unit corresponding to the maximum value of luminance of the desensitized development image is 400 (candela per square meter) higher than 200 (candela per square meter) which is an expected value of brightness corresponding to the maximum value of luminance in an SDR image.</div>
<div class="description-paragraph" id="p-0268" num="0267">Information indicating that a coding target image or a converted image is an image obtained by performing desensitized development on an HDR image, and a dynamic range of luminance of the desensitized development image are set in tone_mapping_info_SEI by the setting unit <b>71</b>.</div>
<div class="description-paragraph" id="p-0269" num="0268">In the example of <figref idrefs="DRAWINGS">FIG. 24</figref>, a coding target image is a desensitized development image, and the user sets an HDR image which is obtained as a result of knee-decompressing 160% to 200% of luminance of the desensitized development image to 160% to 400%, as a desired, converted image. In this case, in the knee_function_info SEI, <b>800</b> is set as the pre-conversion position information (input_knee_point), and <b>400</b> is set as the post-conversion, position information (output_knee_point).</div>
<div class="description-paragraph" id="p-0270" num="0269">In addition, in the example of <figref idrefs="DRAWINGS">FIG. 24</figref>, the HDR luminance range information (d_range) is 4000, and the display luminance range (d_range_disp_luminance) is 800 (candela per square meter).</div>
<div class="description-paragraph" id="p-0271" num="0270">As in the case of <figref idrefs="DRAWINGS">FIG. 24</figref>, in a case where a coding target image is a desensitized development image, and a converted image is an HDR image, a knee point input_knee_point PER (%) and luminance output_knee_point_PER (%) of a converted image corresponding to the knee point are defined by the above Equation (1).</div>
<div class="description-paragraph" id="p-0272" num="0271">Therefore, the decoding device <b>90</b> recognizes that the knee point input_knee_joint_PER and the luminance output_knee_point_PER are 160% according to Equation (1). In addition, the decoding device <b>90</b> recognizes that the maximum value of luminance of the converted image is 400% from the HDR luminance range information. Further, the decoding device <b>90</b> recognizes that, a dynamic range of luminance of the coding target image is 0 to 200% from the tone_mapping_info_SSI. Furthermore, in a case where the display unit <b>95</b> is an HDR display, 160% to 200% of luminance of a desensitized development image which is obtained as a result of decoding is knee-decompressed to 160% to 400% so as to be displayed as a display image.</div>
<div class="description-paragraph" id="p-0273" num="0272">On the other hand, in a case where the display unit <b>95</b> is an SDR display, the decoding device <b>90</b> displays a desensitized development image as a display image without change. At this time, an expected value of brightness of the display unit corresponding to the maximum value of luminance of the desensitized development image is greater than that of an SDR image, and thus brightness of the display image is insufficient.</div>
<div class="description-paragraph" id="p-0274" num="0273">However, recently, an SDR display (hereinafter, referred to as a high luminance SDR display) of which brightness corresponding to the maximum value of luminance is relatively high 300 (candela per square meter) or the like has been developed. In a case where the display unit <b>95</b> is a high luminance SDR display, brightness of a display image can be sufficiently maintained even if a desensitized development image is displayed as the display image without change. In addition, since a compression ratio of knee compression during generation of a coding target image is lower than in a case where a coding target image is an SDR image, quality of a display image can be improved.</div>
<div class="description-paragraph" id="p-0275" num="0274">In the example of <figref idrefs="DRAWINGS">FIG. 25</figref>, a coding target image is an HDR image, and the user sets a desensitized development image which is obtained as a result of knee-compressing 160% to 400% of luminance of the HDR image to 160% to 200%, as a desired converted image. In this case, in the knee_function_info SEI, 400 is set as the pre-convers ion position information (input_knee_point), and 800 is set as the post-conversion position information (output_knee_point).</div>
<div class="description-paragraph" id="p-0276" num="0275">In addition, in the example of <figref idrefs="DRAWINGS">FIG. 25</figref>, the HDR luminance range information (d_range) is 4000, and the display luminance range (d_range disp luminance) is 800 (candela per square meter).</div>
<div class="description-paragraph" id="p-0277" num="0276">As in the case of <figref idrefs="DRAWINGS">FIG. 25</figref>, in a case where a coding target image is an HDR image, and a converted image is a desensitized development image, a knee point input_knee_point_PER (%) and luminance output knee_point_PER (%) of a converted image corresponding to the knee point are defined by the above Equation (2).</div>
<div class="description-paragraph" id="p-0278" num="0277">Therefore, the decoding device <b>90</b> recognizes that the knee point input_knee_point_PER and the luminance output_knee_point_PER are 160% according to Equation (2). In addition, the decoding device <b>90</b> recognizes that the maximum value of luminance of the coding target, image is 400% from the HDR luminance range information. Further, the decoding device <b>90</b> recognizes that a dynamic range of luminance of the converted image is 0 to 200% from the tone_mapping_info_SEI.</div>
<div class="description-paragraph" id="p-0279" num="0278">Furthermore, in a case where the display unit <b>95</b> is an SDR display, the decoding device <b>90</b> knee-compresses 160% to 400% of luminance of an HDR image which is obtained as a result of decoding to 160% to 200% so as to display a compressed result as a display image. In this case, as described above, brightness of the display image is insufficient. However, in a case where the display unit <b>95</b> is a high luminance SDR display, brightness of a display image can be sufficiently maintained as described above. In addition, quality of a display image can be improved.</div>
<div class="description-paragraph" id="p-0280" num="0279">On the other hand, in a case where the display unit <b>95</b> is an HDR display, the decoding device <b>90</b> displays an HDR image which is obtained as a result of decoding as a display image without change.</div>
<div class="description-paragraph" id="p-0281" num="0280">In addition, the DR conversion information of <figref idrefs="DRAWINGS">FIG. 17</figref> may be included in SEI such as tone_mapping_info_SEI other than knee_function_info_SEI.</div>
<div class="description-paragraph" id="p-0282" num="0281">(First Example of Syntax of Tone_Mapping_Info_SEI)</div>
<div class="description-paragraph" id="p-0283" num="0282"> <figref idrefs="DRAWINGS">FIG. 26</figref> is a diagram illustrating an example of syntax of tone_mapping_info_SEI in a case where the DR conversion information of <figref idrefs="DRAWINGS">FIG. 17</figref> is included in the tone_mapping_info_SEI.</div>
<div class="description-paragraph" id="p-0284" num="0283">The tone_mapping_info_SEI is SEI regarding conversion of luminance. As illustrated in <figref idrefs="DRAWINGS">FIG. 26</figref>, in a case where the DR conversion information of <figref idrefs="DRAWINGS">FIG. 17</figref> is included in the tone_mapping_info_SEI, tone_map_model_id indicating a conversion model of luminance is set to, for example, 5. In addition, in the tone_mapping_info_SEI, pre-conversion position information (input_knee_point), post-conversion position information (output_knee_point), HDR luminance range information (d_range), and display luminance information (d_range_disp_luminance) are set in the tone_mapping_info_SEI as DR conversion information.</div>
<div class="description-paragraph" id="p-0285" num="0284">In addition, the HDR luminance range information (d_range) and the display luminance information (d_range_disp_luminance) are included in tone_mapping_info_SEI when, tone_map_model_id is 4. Therefore, as illustrated, in <figref idrefs="DRAWINGS">FIG. 27</figref>, the HDR luminance range information (d_range) and the display luminance information (d_range_disp_luminance) may not be included in the tone_mapping_info_SEI. Further, only one of the HDR luminance range information (d_range) and the display luminance information (d_range_disp_luminance) may be included.</div>
<div class="description-paragraph" id="p-0286" num="0285">(Second Example of Syntax of Knee_Function_Info SEI)</div>
<div class="description-paragraph" id="p-0287" num="0286"> <figref idrefs="DRAWINGS">FIG. 28</figref> is a diagram illustrating a second, example of syntax of knee_function_info SEI set by the setting unit <b>71</b> of <figref idrefs="DRAWINGS">FIG. 16</figref>, and <figref idrefs="DRAWINGS">FIG. 29</figref> is a diagram, illustrating each, piece of information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 28</figref>.</div>
<div class="description-paragraph" id="p-0288" num="0287">A plurality of knee points are set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 28</figref>. Specifically, in the same manner as in the case of <figref idrefs="DRAWINGS">FIG. 17</figref>, a knee conversion ID (knee_function_id) and a knee conversion cancel flag (knee_function_cancel_flag) are set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 28</figref>.</div>
<div class="description-paragraph" id="p-0289" num="0288">In addition, if the knee conversion cancel flag is 0, as illustrated in <figref idrefs="DRAWINGS">FIG. 28</figref>, DR conversion information is set in the knee_function_info SEI. The DR conversion information is the same as in the case of <figref idrefs="DRAWINGS">FIG. 17</figref> except that a compression flag (compression_flag) and a knee point number (num_knee_point_minus1) are included, and pre-conversion position information (input_knee_point) and post-conversion position information (output_knee_point) are set for each knee point. Description of the same part, as in the case of <figref idrefs="DRAWINGS">FIG. 17</figref> is repeated and thus will be omitted as appropriate.</div>
<div class="description-paragraph" id="p-0290" num="0289">As illustrated in <figref idrefs="DRAWINGS">FIG. 29</figref>, the compression flag is a flag indicating whether or not knee conversion is knee compression. In other words, in a case where the number of knee points is one, when the pre-conversion position information (input_knee_point) is equal to or more than that the post-conversion position information (output_knee_point), it can be determined that knee conversion is knee decompression, and when the pre-conversion position information (input_knee_point) is less than the post-conversion position information (output_knee_point), it can be determined that knee conversion is knee compression.</div>
<div class="description-paragraph" id="p-0291" num="0290">However, in a case where there are a number of knee points, it is unable to be accurately determined whether knee conversion is knee decompression or knee compression by using the magnitude correlation between the pre-conversion position information and the post-conversion position information, and thus the compression flag is set. In addition, even in a case where the number of knee points is one, the compression flag may be set. The compression flag is set to 1 when knee conversion is knee compression, and is set to 0 when knee conversion is knee decompression.</div>
<div class="description-paragraph" id="p-0292" num="0291">The knee point number is a value obtained by subtracting 1 from the number of knee points. In addition, an order i (where is an integer of 0 or more) in which pre-conversion position information and post-conversion position information of knee points are set is an order in which the pre-conversion position information is reduced.</div>
<div class="description-paragraph" id="p-0293" num="0292">(Third Example of DR Conversion Information)</div>
<div class="description-paragraph" id="p-0294" num="0293"> <figref idrefs="DRAWINGS">FIGS. 30 and 31</figref> are diagrams illustrating examples of DR conversion information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 28</figref>.</div>
<div class="description-paragraph" id="p-0295" num="0294">In the example of <figref idrefs="DRAWINGS">FIG. 30</figref>, a coding target image is an SDR image. In addition, the user sets an HDR image which is obtained as a result of respectively converting 0 to 60%, 60% to 80%, 80% to 90%, and 90% to 100% of an SDR image into 0 to 40%, 40% to 100%, 100% to 180%, and 180% to 400%, as a desired converted image.</div>
<div class="description-paragraph" id="p-0296" num="0295">In this case, in the knee_function_info SEI, 600 is set as pre-conversion position information (input_knee_point[0]) of the 0-th knee point, and 100 is set as post-conversion position information (output_knee_point[0]) thereof. 800 is set as pre-conversion position information (input_knee_point[1]) of the first knee point, and 250 is set as post-conversion position information (output_knee_point[1]) thereof. 900 is set as pre-conversion position information (input_knee_point[2]) of the second knee point, and 450 is set as post-conversion position information (output_knee_point [2]) thereof.</div>
<div class="description-paragraph" id="p-0297" num="0296">In addition, in the example of <figref idrefs="DRAWINGS">FIG. 30</figref>, the HDR luminance range information (d_range) is 4000, the display luminance range (d_range_disp_luminance) is 800 (candela per square meter), and the compression flag (compression_flag) is 0.</div>
<div class="description-paragraph" id="p-0298" num="0297">As described above, in a case where a coding target image is an SDR image, and a converted image is an HDR image, a knee point input_knee_point PER (%) and luminance output_knee_point_PER (%) of a converted image corresponding to the knee point are defined by the above Equation (1).</div>
<div class="description-paragraph" id="p-0299" num="0298">Therefore, the decoding device <b>90</b> recognizes that the 0-th to second knee points input_knee_point PER are respectively 60%, 80%, and 90% according to Equation (1). In addition, the decoding device <b>90</b> recognizes that the 0-th to second, luminances output_knee_point_PER are respectively 40%, 100%, and 180%. Further, the decoding device <b>90</b> recognizes that the maximum value of luminance, of the converted image is 400% from the HDR luminance range information.</div>
<div class="description-paragraph" id="p-0300" num="0299">Furthermore, the decoding device <b>90</b> respectively knee-converts 0 to 60%, 60% to 80%, 80% to 90%, and 90% to 100% of an SDR image which is obtained as a result of decoding into 0 to 40%, 40% to 100%, 100% to 180%, and 180% to 400%, according to a conversion straight line in which the knee points are connected to each other in a set order. Therefore, the decoding device <b>90</b> can convert the SDR image which is obtained as a result of decoding, into a desired HDR image.</div>
<div class="description-paragraph" id="p-0301" num="0300">In the example of <figref idrefs="DRAWINGS">FIG. 31</figref>, a coding target image is an HDR image. In addition, the user sets an SDR image which is obtained as a result of respectively converting 0 to 40%, 40% to 100%, 100% to 180%, and 180% to 400% of luminance of an HDR image into 0 to 60%, 60% to 80%, 80% to 90%, and 90% to 100%, as a desired converted image.</div>
<div class="description-paragraph" id="p-0302" num="0301">In this case, in the knee_function_info SEI, 100 is set as pre-conversion position information (input_knee_point[0]) of the 0-th knee point, and 600 is set as post-conversion position information (output_knee_point [0]). 250 is set as pre-conversion position information (input_knee_point[1]) of the first knee point, and 800 is set as post-conversion position information (output_knee_point[1]). 450 is set as pre-conversion position information (input_knee_point[2]) of the second knee point, and 900 is set as post-conversion position information (output_knee_point[2]).</div>
<div class="description-paragraph" id="p-0303" num="0302">In addition, in the example of <figref idrefs="DRAWINGS">FIG. 31</figref>, the HDR luminance range information (d_range) is 4000, the display luminance range (d_range_disp_luminance) is 800 (candela per square meter), and the compression flag (compression flag) is 1.</div>
<div class="description-paragraph" id="p-0304" num="0303">As described above, in a case where a coding target image is an HDR image, and a converted image is an SDR image, a knee point input knee_point_PER (%) and luminance output knee_point_PER (%) of a converted image corresponding to the knee point are defined by the above Equation (2).</div>
<div class="description-paragraph" id="p-0305" num="0304">Therefore, the decoding device <b>90</b> recognizes that the 0-th to second knee points input_knee_point PER are respectively 40%, 100%, and 180% according to Equation (2). In addition, the 0-th to second luminances output_knee_point PER (%) are respectively 60%, 80%, and 90%. In addition, the decoding device <b>90</b> recognizes that the maximum value of luminance of the converted image is 400% from the HDR luminance range information.</div>
<div class="description-paragraph" id="p-0306" num="0305">Further, the decoding device <b>90</b> knee-converts 0 to 40%, 40% to 100%, 100% to 130%, and 180% to 400% of an HDR image which is obtained as a result, of decoding into 0 to 60%, 60% to 80%, 80% to 90%, and 90% to 100% by connecting the knee points to each other in a set order. Therefore, the decoding device <b>90</b> can convert the HDR image which is obtained as a result of decoding, into a desired SDR image.</div>
<div class="description-paragraph" id="p-0307" num="0306">As mentioned above, in a case where a plurality of knee points are set, a compression ratio can be more finely set than in a case where a single knee point, is set. Therefore, it is possible to perform knee conversion with higher accuracy.</div>
<div class="description-paragraph" id="p-0308" num="0307">In addition, the DR conversion information of <figref idrefs="DRAWINGS">FIG. 28</figref> may be included in SEI such as tone_mapping_info_SEI other than knee_function_info SEI.</div>
<div class="description-paragraph" id="p-0309" num="0308">(Second Example of Syntax of Tone_Mapping_Info_SEI)</div>
<div class="description-paragraph" id="p-0310" num="0309"> <figref idrefs="DRAWINGS">FIG. 32</figref> is a diagram illustrating an example of syntax of tone_mapping_info_SEI in a case where the DR conversion information of <figref idrefs="DRAWINGS">FIG. 28</figref> is included in the tone_mapping_info_SEI.</div>
<div class="description-paragraph" id="p-0311" num="0310">As illustrated in <figref idrefs="DRAWINGS">FIG. 32</figref>, in a case where the DR conversion information of <figref idrefs="DRAWINGS">FIG. 28</figref> is included in the tone_mapping_info_SEI, tone_map_model_id is set to, for example, 5. In addition, in the tone_mapping_info_SEI, compression flag (compression_flag (mapping_flag)), HDR luminance range information (d_range), display luminance information (d_range_disp_luminance), a knee point number (num_knee_point_minus), and pre-conversion position information (input_knee_point) and post-conversion position information (output_knee_point) of each knee point are set in the tone_mapping_info_SEI as DR conversion information.</div>
<div class="description-paragraph" id="p-0312" num="0311">In addition, in the same manner as in the tone_mapping_info_SEI of <figref idrefs="DRAWINGS">FIG. 27</figref>, the HDR luminance range information (d_range) and the display luminance information (d_range_disp_luminance) may not be included in the tone_mapping_info_SEI of <figref idrefs="DRAWINGS">FIG. 32</figref>. Further, only one of the HDR luminance range information (d_range) and the display luminance information (d_range_disp_luminance) may be included.</div>
<div class="description-paragraph" id="p-0313" num="0312">Furthermore, the knee point number (num_knee_point_minus1) may be any one of 0, 1, and 2 as illustrated in <figref idrefs="DRAWINGS">FIGS. 33 to 35</figref>. In other words, the knee point number (num_knee_point_minus1) may be limited to 2 or less. In this case, as illustrated in <figref idrefs="DRAWINGS">FIGS. 33 to 35</figref>, the number of bits of the knee point number (num_knee_point_minus1) included in the knee_function_info SEI or the tone_mapping_info_SEI is fixed to 2 bits (u(2)).</div>
<div class="description-paragraph" id="p-0314" num="0313">As mentioned above, the maximum value of the knee point number (num_knee_point_minus1) is determined, and thus an amount of DR conversion information can be reduced. Accordingly, the DR conversion information can be transmitted with a small packet as in AVI InfoFrame of High-Definition Multimedia Interface (HDMI™).</div>
<div class="description-paragraph" id="p-0315" num="0314">(Third Example of Syntax of Knee_Function_Info SEI)</div>
<div class="description-paragraph" id="p-0316" num="0315"> <figref idrefs="DRAWINGS">FIG. 36</figref> is a diagram illustrating a third example of syntax of knee_function_info SEI set by the setting unit <b>71</b> of <figref idrefs="DRAWINGS">FIG. 16</figref>, and <figref idrefs="DRAWINGS">FIG. 37</figref> is a diagram illustrating each piece of information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 36</figref>.</div>
<div class="description-paragraph" id="p-0317" num="0316">A plurality of knee points and a knee point (hereinafter, referred to as a representative knee point) which is representatively used are set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 36</figref>.</div>
<div class="description-paragraph" id="p-0318" num="0317">Specifically, in the same manner as in the case of <figref idrefs="DRAWINGS">FIG. 17</figref>, a knee conversion ID (knee_functioned_id) and a knee conversion cancel flag (knee_function_cancel_flag) are set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 36</figref>.</div>
<div class="description-paragraph" id="p-0319" num="0318">In addition, if the knee conversion cancel flag is 0, as illustrated in <figref idrefs="DRAWINGS">FIG. 36</figref>, DR conversion information is set in the knee_function_info SEI. The DR conversion information is the same as in the case of <figref idrefs="DRAWINGS">FIG. 28</figref> except that representative pre-conversion position information (representative input_knee_point) and representative post-conversion position information (representative_output_knee_point) are included. Description of the same part as in the case of <figref idrefs="DRAWINGS">FIG. 28</figref> is repeated and thus will be omitted as appropriate.</div>
<div class="description-paragraph" id="p-0320" num="0319">As illustrated in <figref idrefs="DRAWINGS">FIG. 37</figref>, the representative pre-conversion position information is information indicating a representative knee point of a coding target image which is an unconverted image in conversion corresponding to the DR conversion information, and is a permillage of the representative knee point when the maximum value of luminance of the coding target image is set to 1000 permil.</div>
<div class="description-paragraph" id="p-0321" num="0320">The representative pre-conversion position information is information indicating luminance corresponding to a representative knee point of a converted image in conversion corresponding to the DR conversion information, and is a permillage of luminance corresponding to a knee point when the maximum value of luminance of the converted image is set to 1000 permil.</div>
<div class="description-paragraph" id="p-0322" num="0321">In addition, the representative knee point may be one of knee points corresponding to a plurality of pre-conversion position information pieces included in the DR conversion information, and may be a knee point which is completely different from the knee point.</div>
<div class="description-paragraph" id="p-0323" num="0322">(Fourth Example of DR Conversion Information)</div>
<div class="description-paragraph" id="p-0324" num="0323"> <figref idrefs="DRAWINGS">FIG. 38</figref> is a diagram illustrating an example of DR conversion information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 36</figref>.</div>
<div class="description-paragraph" id="p-0325" num="0324">In the example of <figref idrefs="DRAWINGS">FIG. 38</figref>, a coding target image is an SDR image. In addition, the user sets an HDR image which is obtained as a result of respectively converting 0 to 60%, 60% to 80%, 80% to 30%, and 90% to 100% of an SDR image into 0 to 40%, 40% to 100%, 100% to 180%, and 180% to 400%, as a desired converted image when the decoding device <b>90</b> performs the knee conversion with high accuracy. Further, the user sets an HDR image which is obtained by knee-decompressing 80% to 100% of luminance of an SDR image to 80% to 400%, as a desired converted image when the decoding device <b>90</b> performs simple knee conversion, with low accuracy.</div>
<div class="description-paragraph" id="p-0326" num="0325">In this case, in the knee_function_info SEI, the same values as in <figref idrefs="DRAWINGS">FIG. 30</figref> are set as pre-conversion position information (input_knee_point) and post-conversion position, information (output_knee_point) of the 0-th to second knee points. In addition, the representative pre-conversion position information (representative_input_knee_point) is 800, and the representative post-conversion position, information (representative_output_knee_point) is 200.</div>
<div class="description-paragraph" id="p-0327" num="0326">In addition, in the example of <figref idrefs="DRAWINGS">FIG. 38</figref>, the HDR luminance range information (d_range) is 4000, the display luminance range (d_range_disp_luminance) is 800 (candela per square meter), and the compression flag (compression_flag) is 0.</div>
<div class="description-paragraph" id="p-0328" num="0327">As illustrated in <figref idrefs="DRAWINGS">FIG. 38</figref>, in a case where the decoding device <b>90</b> performs simple knee conversion with low accuracy, the decoding device <b>90</b> recognises that the representative knee point representative_input_knee_point_PER (%) and luminance representative_output_knee_point PER (%) of a converted image corresponding to the representative knee point are 80% according to the above Equation (1). In addition, the decoding device <b>90</b> recognizes that the maximum value of luminance of the converted image is 400% from the HDR luminance range information. Further, the decoding device <b>90</b> knee-decompresses 80% to 100% of luminance of an SDR image which is obtained as a result of decoding, to 80% to 400%. Therefore, the decoding device <b>90</b> can convert the SDR image which is obtained as a result, of decoding into a desired HDR image.</div>
<div class="description-paragraph" id="p-0329" num="0328">On the other hand, in a case where the decoding device <b>90</b> performs knee conversion with high accuracy, the decoding device <b>90</b> performs the same process as in <figref idrefs="DRAWINGS">FIG. 30</figref>, and converts an SDR image which is obtained as a result of decoding into a desired HDR image.</div>
<div class="description-paragraph" id="p-0330" num="0329">As mentioned above, the representative pre-conversion position information (representative_input_knee_point) and the representative post-conversion position information (representative_output_knee_point) are included in the DR conversion information of <figref idrefs="DRAWINGS">FIG. 36</figref>. Therefore, even in a case where a processing rate or a resource such as a memory capacity is unable to be sufficiently secured in the decoding device <b>90</b>, knee conversion can be performed on the basis of a representative knee point. In addition, since the representative pre-conversion position information and the representative post-conversion position information are transmitted to the decoding device <b>90</b>, the decoding device <b>90</b> does not have to generate representative pre-conversion position information and representative post-conversion position information on the basis of pre-conversion position information and post-conversion position information of a plurality of knee points.</div>
<div class="description-paragraph" id="p-0331" num="0330">In addition, the DR conversion information of <figref idrefs="DRAWINGS">FIG. 36</figref> may be included in SEI such as tone_mapping_info_SEI other than knee_function_info SEI.</div>
<div class="description-paragraph" id="p-0332" num="0331">(Third Example of Syntax of Tone_mapping_info_SEI)</div>
<div class="description-paragraph" id="p-0333" num="0332"> <figref idrefs="DRAWINGS">FIG. 39</figref> is a diagram illustrating an example of syntax of tone_mapping_info_SEI in a case where the DR conversion information of <figref idrefs="DRAWINGS">FIG. 36</figref> is included in the tone_mapping_info_SEI.</div>
<div class="description-paragraph" id="p-0334" num="0333">As illustrated in <figref idrefs="DRAWINGS">FIG. 39</figref>, in a case where the DR conversion information of <figref idrefs="DRAWINGS">FIG. 36</figref> is included in the tone_mapping_info_SEI, tone_map_model_id is set to, for example, 5. In addition, in the tone_mapping_info_SEI, a compression flag (compression_flag), representative pre-conversion position information (representative_input_knee_point), representative post-conversion position information (representative_output_knee_point), HDR luminance range information (d_range), display luminance information (d_range_disp_luminance), a knee point number (num_knee_point_minus1), and pre-conversion position information (input_knee_point) and post-conversion position information (output_knee_point) of each knee point are set in the tone_mapping_info_SEI as DR conversion information.</div>
<div class="description-paragraph" id="p-0335" num="0334">In addition, in the same manner as in the tone_mapping_info_SEI of <figref idrefs="DRAWINGS">FIG. 27</figref>, the HDR luminance range information (d_range) and the display luminance information (d_range_disp_luminance) may not be included in the tone mapping info SEI of <figref idrefs="DRAWINGS">FIG. 39</figref>. Further, only one of the HDR luminance range information (d_range) and the display luminance information (d_range_disp_luminance) may be included.</div>
<div class="description-paragraph" id="p-0336" num="0335">(Fourth Example of Syntax of Knee_Function_Info SEI)</div>
<div class="description-paragraph" id="p-0337" num="0336"> <figref idrefs="DRAWINGS">FIG. 40</figref> is a diagram illustrating a fourth example of syntax of knee_function_info SEI set by the setting unit <b>71</b> of <figref idrefs="DRAWINGS">FIG. 16</figref>, and <figref idrefs="DRAWINGS">FIG. 41</figref> is a diagram illustrating (semantics of) each piece of information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 40</figref>.</div>
<div class="description-paragraph" id="p-0338" num="0337">In the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 40</figref>, images other than an SDR image can be employed as one of a coding target, image and a converted image.</div>
<div class="description-paragraph" id="p-0339" num="0338">Specifically, in the same manner as in the case of <figref idrefs="DRAWINGS">FIG. 17</figref>, a knee conversion ID (knee_function_id) and a knee conversion cancel flag (knee_function_cancel_flag) are set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 40</figref>.</div>
<div class="description-paragraph" id="p-0340" num="0339">In addition, if the knee conversion cancel flag is 0, as illustrated in <figref idrefs="DRAWINGS">FIG. 40</figref>, DR conversion information is set in the knee_function_info SEI. The DR conversion information is the same as in the case of <figref idrefs="DRAWINGS">FIG. 28</figref> except that knee conversion persistence flag (knee_function_persistence_flag) is newly included, and unconverted display range information (input_d_range), unconverted display luminance information (input_disp_luminance), converted display range information (output_d_range), and converted display luminance information (output_disp_luminance) are included instead of the HDR luminance range information (d_range) and the display luminance information (d_range_disp_luminance). Description of the same part as in the case of <figref idrefs="DRAWINGS">FIG. 28</figref> is repeated and thus will be omitted as appropriate.</div>
<div class="description-paragraph" id="p-0341" num="0340">As illustrated in <figref idrefs="DRAWINGS">FIG. 41</figref>, the knee conversion persistence flag is a flag indicating whether or not the DR conversion information is applied to a plurality of pictures which are continuously located. The knee conversion persistence flag is set to 1 when the DR conversion information is applied to a plurality of pictures which are continuously located, and is set to 0 when the DR conversion information is applied to only one picture. The knee conversion persistence flag may also be set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIGS. 17, 28, 34 and 36</figref>.</div>
<div class="description-paragraph" id="p-0342" num="0341">In addition, the unconverted luminance range information is information indicating a permillage of the maximum value of luminance of a coding target image which is an unconverted image in conversion corresponding to the DR conversion information, and the converted luminance range information is information indicating a permillage of the maximum value of luminance of a converted image.</div>
<div class="description-paragraph" id="p-0343" num="0342">In addition, the unconverted display luminance information is information indicating an expected value of brightness of the display unit corresponding to the maximum value of luminance of a coding target image, and the converted display luminance information is information indicating an expected value of brightness of the display unit corresponding to the maximum value of luminance of a converted image.</div>
<div class="description-paragraph" id="p-0344" num="0343">(Fifth Example of DR Conversion Information)</div>
<div class="description-paragraph" id="p-0345" num="0344"> <figref idrefs="DRAWINGS">FIGS. 42 and 43</figref> are diagrams illustrating examples of DR conversion information set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 40</figref>.</div>
<div class="description-paragraph" id="p-0346" num="0345">In the example of <figref idrefs="DRAWINGS">FIG. 42</figref>, a coding target image is an HDR image (hereinafter, referred to as a 200% HDR image) whose dynamic range is 0 to 200%, In addition, the user sets a 400% HDR image which is obtained as a result of respectively knee-converting 0 to 120%, 120% no 160%, 160% to 180%, and 180% to 200% of luminance of a 200% HDR image into 0 to 40%, 40% to 100%, 100% to 180%, and 180% to 400%, as a desired converted image. The 400% HDR image is an HDR image whose dynamic range is 0 to 400%.</div>
<div class="description-paragraph" id="p-0347" num="0346">In this case, in the knee_function_info SEI, the same values as in <figref idrefs="DRAWINGS">FIG. 30</figref> are set as pre-conversion position information (input_knee_point) and post-conversion position information (output_knee_point) of the 0-th to second knee points. In addition, 2000 is set as the unconverted luminance range information (input_d_range), and 4000 is set as the converted luminance range information (output_d_range).</div>
<div class="description-paragraph" id="p-0348" num="0347">Further, in the example of <figref idrefs="DRAWINGS">FIG. 42</figref>, the unconverted display luminance information (input_disp_luminance) is 400 (candela per square meter), and the converted display luminance information (output_disp_luminance) is 800 (candela per square meter). The compression flag (compression_flag) is 0.</div>
<div class="description-paragraph" id="p-0349" num="0348">As illustrated in <figref idrefs="DRAWINGS">FIG. 42</figref>, in a case where a coding target image is an image with a dynamic range corresponding to the unconverted luminance range information, and a converted image is an image with a dynamic range corresponding to the converted luminance range information, a knee point input_knee_point_PER (%) and luminance output_knee_point PER (%) of a converted image corresponding to the knee point are defined by the following Equation (3).</div>
<div class="description-paragraph" id="p-0350" num="0349">
<maths id="MATH-US-00003" num="00003">
<math overflow="scroll">
<mtable>
<mtr>
<mtd>
<mrow>
<mo>[</mo>
<mrow>
<mi>Math</mi>
<mo>.</mo>
<mstyle>
<mspace height="0.8ex" width="0.8em"> </mspace>
</mstyle>
<mo>⁢</mo>
<mn>3</mn>
</mrow>
<mo>]</mo>
</mrow>
</mtd>
<mtd>
<mstyle>
<mspace height="0.3ex" width="0.3em"> </mspace>
</mstyle>
</mtd>
</mtr>
<mtr>
<mtd>
<mrow>
<mrow>
<mrow>
<mi>input_knee</mi>
<mo>⁢</mo>
<mi>_point</mi>
<mo>⁢</mo>
<mi>_DR</mi>
</mrow>
<mo>=</mo>
<mrow>
<mfrac>
<mrow>
<mi>input_d</mi>
<mo>⁢</mo>
<mi>_range</mi>
</mrow>
<mn>10</mn>
</mfrac>
<mo>×</mo>
<mfrac>
<mrow>
<mi>input_knee</mi>
<mo>⁢</mo>
<mi>_point</mi>
</mrow>
<mn>1000</mn>
</mfrac>
</mrow>
</mrow>
<mo>⁢</mo>
<mstyle>
<mtext>
</mtext>
</mstyle>
<mo>⁢</mo>
<mrow>
<mrow>
<mi>output_knee</mi>
<mo>⁢</mo>
<mi>_point</mi>
<mo>⁢</mo>
<mi>_DR</mi>
</mrow>
<mo>=</mo>
<mrow>
<mfrac>
<mrow>
<mi>output_d</mi>
<mo>⁢</mo>
<mi>_range</mi>
</mrow>
<mn>10</mn>
</mfrac>
<mo>×</mo>
<mfrac>
<mrow>
<mi>output_knee</mi>
<mo>⁢</mo>
<mi>_point</mi>
</mrow>
<mn>1000</mn>
</mfrac>
</mrow>
</mrow>
</mrow>
</mtd>
<mtd>
<mrow>
<mo>(</mo>
<mn>3</mn>
<mo>)</mo>
</mrow>
</mtd>
</mtr>
</mtable>
</math>
</maths>
</div>
<div class="description-paragraph" id="p-0351" num="0350">Therefore, the decoding device <b>90</b> recognizes that the 0-th to second knee points input_knee_point_PER are respectively 120%, 160%, and 180% according to Equation (3). In addition, the decoding device <b>90</b> recognizes that the 0-th to second luminances output_knee_point_PER are respectively 40%, 100%, and 180%. Further, the decoding device <b>90</b> recognizes that the maximum value of luminance of the coding target image is 200% from the input luminance range information, and the maximum value of luminance of the converted image is 400% from the output luminance range information.</div>
<div class="description-paragraph" id="p-0352" num="0351">Furthermore, the decoding device <b>90</b> respectively knee-converts 0 to 120%, 120% to 160%, 160% to 180%, and 180% to 200% of a 200% HDR image which is obtained as a result of decoding into 0 to 40%, 40% to 100%, 100% to 180%, and 180% to 400%, according to a conversion straight line in which the knee points are connected to each other in a set order. Therefore, the decoding device <b>90</b> can convert the 200% HDR image which is obtained as a result of decoding, into a desired 400% HDR image.</div>
<div class="description-paragraph" id="p-0353" num="0352">In the example of <figref idrefs="DRAWINGS">FIG. 43</figref>, a coding target image is a 400% HDR image. In addition, the user sets a 200% HDR image which is obtained as a result of respectively kneeconverting0 to 40%, 40% to 100%, 100% to 180%, and 180% to 400% of luminance of a 400% HDR image, into 0 to 120%, 120% to 160%, 160% to 180%, and 180% to 200% as a desired converted image.</div>
<div class="description-paragraph" id="p-0354" num="0353">In this case, in the knee_function_info SEI, the same values as in <figref idrefs="DRAWINGS">FIG. 31</figref> are set as pre-conversion position information (input_knee_point) and post-conversion position information (output_knee_point) of the 0-th to second knee_points. In addition, 4000 is set as the unconverted luminance range information (input_d_range), and 2000 is set as the converted luminance range information (output_d_range).</div>
<div class="description-paragraph" id="p-0355" num="0354">Further, in the example of <figref idrefs="DRAWINGS">FIG. 43</figref>, the unconverted display luminance information (input_disp_luminance) is 800 (candela per square meter), and the converted display luminance information (output_disp_luminance) is 400 (candela per square meter). The compression flag (compression_flag) is 1.</div>
<div class="description-paragraph" id="p-0356" num="0355">As described above, in a case where a coding target image is an image with a dynamic range corresponding to the unconverted luminance range information, and a converted image is an image with a dynamic range corresponding to the converted luminance range information, a knee point input_knee_point_PER (%) and luminance output_knee_point_PER (%) of a converted image corresponding to the knee point are defined by the above Equation (3).</div>
<div class="description-paragraph" id="p-0357" num="0356">Therefore, the decoding device <b>90</b> recognizes that the 0-th to second knee points input_knee_point_PER are respectively 40%, 100%, and 180% according to Equation (3). In addition, the decoding device <b>90</b> recognizes that the 0-th to second luminances output_knee_point_PER (%) are respectively 120%, 160%, and 180%. Further, the decoding device <b>90</b> recognizes that the maximum value of luminance of the coding target image is 400% from the input luminance range information, and the maximum value of luminance of the converted image is 200% from the output luminance range information.</div>
<div class="description-paragraph" id="p-0358" num="0357">Furthermore, the decoding device <b>90</b> respectively knee-converts 0 to 40%, 40% to 100%, 100% to 180%, and 180% to 400% of a 400% HDR image which is obtained, as a result of decoding into 0 to 120%, 120% to 160%, 160% to 130%, and 180% to 200%, by connecting the knee points to each other in a set order. Therefore, the decoding device <b>90</b> can convert the 400% HDR image which is obtained as a result of decoding, into a desired 200% HDR image.</div>
<div class="description-paragraph" id="p-0359" num="0358">As mentioned above, according to the DR conversion information of <figref idrefs="DRAWINGS">FIG. 40</figref>, not only conversion between an SDR image and an HDR image but also conversion between HDR images with different dynamic, ranges can be performed as desired by a user in the decoding device <b>90</b>. A dynamic range of an HDP. image may be greater than 0 to 100%, and may be 0 to 400%, 0 to 800%, 0 to 1300%, and the like. In addition, an expected value of brightness of the display corresponding to the maximum value of luminance of an HDR image may be greater than 100 (candela per square meter), and may be 800 (candela per square meter), 4000 (candela per square meter), 1500 (candela per square meter), and the like.</div>
<div class="description-paragraph" id="p-0360" num="0359">[Description of Operation of Decoding Device]</div>
<div class="description-paragraph" id="p-0361" num="0360"> <figref idrefs="DRAWINGS">FIG. 44</figref> is a diagram illustrating an operation of the decoding device <b>90</b> in a case where the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 40</figref> is set in a plurality.</div>
<div class="description-paragraph" id="p-0362" num="0361">In an example of <figref idrefs="DRAWINGS">FIG. 44</figref>, a coding target image is a 400% HDR image. In addition, knee_function_info SEI (hereinafter, referred to as 800% HDR image knee_function_info SEI) for setting a desired converted image to a 800% HDR image whose dynamic range is 0 to 800%, and knee_function_info SEI (hereinafter, referred to as SDR image knee_function_info SEI) for setting a desired converted, image to an SDR image, are set. In this case, different knee conversion IDs are given to the 800% HDR image knee_function_info SEI and the SDR image knee_function_info SEI.</div>
<div class="description-paragraph" id="p-0363" num="0362">In a case where the display unit <b>95</b> is an HDR display which can display a 800% HDR image, the decoding device <b>90</b> knee-decompresses luminance of a 400% HDR image which is a decoded image on the basis of the 800% HDR image knee_function_info SEI, so as to generate a desired 800% HDR image as a display image.</div>
<div class="description-paragraph" id="p-0364" num="0363">On the other hand, in a case where the display unit <b>95</b> is an HDR display which can display a 400% HDR image, the decoding device <b>90</b> uses a 400% HDR image which is a decoded image as a display image without change. In addition, in a case where the display unit <b>95</b> is an SDR display, the decoding device <b>90</b> knee-compresses luminance of a 400% HDR image which is a decoded image on the basis of the SDR image knee_function_info SEI, so as to generate a desired SDR image as a display image.</div>
<div class="description-paragraph" id="p-0365" num="0364">In addition, the DR conversion information of <figref idrefs="DRAWINGS">FIG. 40</figref> may be included in SEI such as tone_mapping_info_SET other than knee_function_info SEI.</div>
<div class="description-paragraph" id="p-0366" num="0365">(Fourth Example of Syntax of Tone_Mapping_Info_SEI)</div>
<div class="description-paragraph" id="p-0367" num="0366"> <figref idrefs="DRAWINGS">FIG. 45</figref> is a diagram, illustrating an example of syntax of tone_mapping_info_SEI in a case where the DR conversion information of <figref idrefs="DRAWINGS">FIG. 40</figref> is included in the tone_mapping_info_SEI.</div>
<div class="description-paragraph" id="p-0368" num="0367">As illustrated in <figref idrefs="DRAWINGS">FIG. 45</figref>, in a case where the DR conversion information of <figref idrefs="DRAWINGS">FIG. 40</figref> is included in the tone_mapping_info_SEI, tone_map_model_id is set to, for example, 5. In addition, in the tone_mapping_info_SEI, a compression flag (compression_flag), input luminance range information (input_d_range), input display luminance range (input_d_range_disp_luminance), output luminance range information (output_d_range), output display luminance range (output_d_range_disp_luminance), a knee point number (num_knee_point_minus1), and pre-conversion position information (input_knee_point) and post-conversion position information (output_knee_point) of each knee point are set in the tone_mapping_info_SEI as DR conversion information.</div>
<div class="description-paragraph" id="p-0369" num="0368">In addition, at least one of the input luminance range information (input_d_range), the input display luminance range (input_d_range_disp_luminance), the output luminance range information (output_d_range), and the output, display luminance range (output_d_range_disp_luminance) may not be included in the tone_mapping_info_SEI of <figref idrefs="DRAWINGS">FIG. 45</figref>.</div>
<div class="description-paragraph" id="p-0370" num="0369">In addition, in the above description, the DR conversion information is disposed in SEI, but may be disposed in a system layer.</div>
<div class="description-paragraph" id="p-0371" num="0370">(Example of Disposing DR Conversion Information in Box of MP4)</div>
<div class="description-paragraph" id="p-0372" num="0371">[Description of Box of MP4 in Which DR Conversion Information is Disposed]</div>
<div class="description-paragraph" id="p-0373" num="0372"> <figref idrefs="DRAWINGS">FIG. 46</figref> is a diagram illustrating a box of MP4 as a system layer in which DR conversion information is disposed.</div>
<div class="description-paragraph" id="p-0374" num="0373">As illustrated in <figref idrefs="DRAWINGS">FIG. 46</figref>, in a case where DR conversion information is disposed in a box of MP4, a tinf (Tone Mapping Information Box) box which stores DR conversion information as ToneMapInfo is newly defined. The tinf box is stored in a trak box (track box) (a stbl box stored therein) or a traf box (track fragment box).</div>
<div class="description-paragraph" id="p-0375" num="0374">(Example of Syntax of ToneMapInfo)</div>
<div class="description-paragraph" id="p-0376" num="0375"> <figref idrefs="DRAWINGS">FIG. 47</figref> is a diagram illustrating an example of syntax of ToneMapInfo.</div>
<div class="description-paragraph" id="p-0377" num="0376">ToneMapInfo of <figref idrefs="DRAWINGS">FIG. 47</figref> has the same configuration as that of the tone_mapping_info_SEI of <figref idrefs="DRAWINGS">FIG. 32</figref> except that padding value for byte alignment is inserted thereinto.</div>
<div class="description-paragraph" id="p-0378" num="0377">In addition, although not illustrated, ToneMapInfo may have the same configuration as that of the tone_mapping_info_SEI of <figref idrefs="DRAWINGS">FIG. 26, 27, 39</figref>, or <b>45</b> except that padding_value for byte alignment is inserted thereinto.</div>
<div class="description-paragraph" id="p-0379" num="0378">In addition, in the same manner as in the second embodiment, the conversion information in the first, embodiment may be disposed in a system layer.</div>
<div class="description-paragraph" id="p-0380" num="0379">In addition, an HDR image desired by a user may be an HDR image which is input to the coding device <b>70</b>.</div>
<div class="description-paragraph" id="p-0381" num="0380">Further, in the second embodiment, an HDR image is input to the coding device <b>70</b>, but an SDR image may be input thereto. In this case, when a coding target image is an HDR image, the coding device <b>70</b> converts an SDR image which is input from an external device into an HDR image which is then set as a coding target image.</div>
<div class="description-paragraph" id="p-0382" num="0381">In addition, a plurality of knee points are set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 40</figref>. Therefore, knee conversion of a smoother and more complex function can be defined than in a case where only one knee point is set. As a result, the conversion unit <b>93</b> can perform the optimal knee conversion.</div>
<div class="description-paragraph" id="p-0383" num="0382">However, if the number of knee points increases, an amount of DR conversion information increases. Therefore, for example, in a case where a decoded image and DR conversion information are transmitted with HDMI, an amount of the DR conversion information is equal to or larger than 27 bytes which is a size of one packet of AVI InfoFrame of HDMI, and thus the DR conversion information may not be included in AVI InfoFrame.</div>
<div class="description-paragraph" id="p-0384" num="0383">Therefore, in a third embodiment described later, a decoding device performs thinning-out of an optimal knee point in a case where an amount of DR conversion information is reduced, such as a case where the DR conversion information is transmitted with HDMI.</div>
<heading id="h-0014">Third Embodiment</heading>
<div class="description-paragraph" id="p-0385" num="0384">(First Example of Semantics)</div>
<div class="description-paragraph" id="p-0386" num="0385">A first configuration of a third embodiment of a coding device to which the present disclosure is applied is the same as the configuration of the coding device <b>70</b> of <figref idrefs="DRAWINGS">FIG. 16</figref> except for the order i of knee points and semantics indicated by the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 40</figref> set by the setting unit <b>71</b>. Therefore, hereinafter, only the order i of knee points and semantics indicated by the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 40</figref> will be described.</div>
<div class="description-paragraph" id="p-0387" num="0386">In the first configuration of the third embodiment of the coding device to which the present disclosure is applied, the order i of knee points is set in an order in which priorities for representing a desired function of knee conversion are higher in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 40</figref>.</div>
<div class="description-paragraph" id="p-0388" num="0387">In addition, <figref idrefs="DRAWINGS">FIG. 48</figref> is a diagram illustrating that semantics in the first configuration of the third embodiment of the coding device to which the present disclosure is applied is different from that in the second embodiment.</div>
<div class="description-paragraph" id="p-0389" num="0388">As illustrated in <figref idrefs="DRAWINGS">FIG. 48</figref>, in the semantics of <figref idrefs="DRAWINGS">FIG. 40</figref> in the first configuration of the third embodiment of the coding device to which the present disclosure is applied, pre-conversion position information (input_knee_point[i]) of an i-th knee point may be equal to or less than pre-conversion position information (input_knee_point[i-1]) of a (i-1)-th knee point. In other words, the order i (where i is an integer of 0 or more) in which the pre-conversion position information and the post-conversion position information of a knee point, are set may not be an order in which the post-conversion position information is less.</div>
<div class="description-paragraph" id="p-0390" num="0389">In addition, a function (knee function) of knee conversion is a straight line -which connects knee points to each other in an order (ascending order) in which the pre-conversion position information (input_knee_point) is smaller.</div>
<div class="description-paragraph" id="p-0391" num="0390">Further, a decoded image may be knee-converted by using an approximate function of knee conversion. The approximate function of knee conversion is a straight line which connects 0-th to N-th (where N is equal to or greater than 0 and equal to or smaller than num_knee_point_minus1) knee points to each other in an order in which the pre-conversion position information is less. Since the order i of knee points is set in an order in which a priority for representing a desired function of knee conversion is higher, an approximate function of knee conversion is more approximate to a desired function of knee conversion as N is greater.</div>
<div class="description-paragraph" id="p-0392" num="0391">(First Configuration Example of One Embodiment of Decoding System)</div>
<div class="description-paragraph" id="p-0393" num="0392"> <figref idrefs="DRAWINGS">FIG. 49</figref> is a block diagram illustrating a first configuration example of an embodiment of a decoding system to which the present disclosure is applied and which decodes a coded stream transmitted, from the first configuration of the third embodiment of the coding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0394" num="0393">Among constituent elements illustrated in <figref idrefs="DRAWINGS">FIG. 49</figref>, the same constituent elements as the constituent elements of <figref idrefs="DRAWINGS">FIGS. 12 and 22</figref> are given the same reference numerals. Repeated description will be omitted as appropriate.</div>
<div class="description-paragraph" id="p-0395" num="0394">A decoding system <b>110</b> of <figref idrefs="DRAWINGS">FIG. 49</figref> includes a decoding device <b>111</b> and a display device <b>112</b>. The decoding device <b>111</b> includes a reception unit <b>51</b>, an extraction unit <b>91</b>, a decoding unit <b>92</b>, a selection unit <b>121</b>, and a transmission unit <b>122</b>.</div>
<div class="description-paragraph" id="p-0396" num="0395">The selection unit <b>121</b> of the decoding device <b>111</b> acquires knee_function_info SEI among parameter sets extracted by the extraction unit <b>91</b>. The selection unit <b>121</b> selects DR conversion information of the number (for example, 3) of knee points included in a single packet of AVI InfoFrame of HDMI in an order in which the order i is lower from among DR conversion information pieces of a plurality of knee points included in the knee_function_info SEI. The selection unit <b>121</b> supplies the selected DR conversion information of the knee point to the transmission unit <b>122</b>.</div>
<div class="description-paragraph" id="p-0397" num="0396">The transmission unit <b>122</b> disposes the DR conversion information selected by the selection unit <b>121</b> in a single packet of AVI InfoFrame of HDMI, and transmits a result thereof to the display device <b>112</b> with HDMI along with a decoded image generated by the decoding unit <b>92</b>.</div>
<div class="description-paragraph" id="p-0398" num="0397">The display device <b>112</b> includes a reception unit <b>131</b>, a conversion unit <b>93</b>, a display control unit <b>94</b>, and a display unit <b>95</b>.</div>
<div class="description-paragraph" id="p-0399" num="0398">The reception unit <b>131</b> of the display device <b>112</b> receives AVI InfoFrame and the decoded image which are transmitted from the transmission unit <b>122</b> with HDMI. The reception unit <b>131</b> supplies the DR conversion information disposed, in AVI InfoFrame and the decoded, image to the conversion unit <b>93</b>.</div>
<div class="description-paragraph" id="p-0400" num="0399">[Description of First Selection Method of Knee Point]</div>
<div class="description-paragraph" id="p-0401" num="0400"> <figref idrefs="DRAWINGS">FIG. 50</figref> is a diagram illustrating an example of a knee point and a function of knee conversion defined by the knee_function_info SEI which is received by the decoding system <b>110</b> of <figref idrefs="DRAWINGS">FIG. 49</figref>.</div>
<div class="description-paragraph" id="p-0402" num="0401">In addition, in the example of <figref idrefs="DRAWINGS">FIG. 50</figref>, a knee point number (number_knee_point_minus1) set in the knee_function_info SEI is 8.</div>
<div class="description-paragraph" id="p-0403" num="0402">As illustrated in <figref idrefs="DRAWINGS">FIG. 50A</figref>, among eight knee points set in the knee_function_info SEI, pre-conversion position information (input_knee_point[0])) of the 0-th knee point is 200, and post-conversion position information (output_knee_point[0]) thereof is 433. In addition, pre-conversion position information (input_knee_point[1]) of the first knee point is 600, and post-conversion position information (output_knee_point[1]) thereof is 774, and pre-conversion position information (input_knee_point[2]) of the second knee point is 100, and post-conversion position information (output_knee_point[2]) thereof is 290.</div>
<div class="description-paragraph" id="p-0404" num="0403">Further, pre-conversion position information (input_knee_point[3]) of the third knee point is 400, and post-conversion position information (output_knee_point[3]) thereof is 628, and pre-conversion position information (input_knee_point[4]) of the fourth knee point is 800, and post-conversion position information (output_knee_point[4]) thereof is 894.</div>
<div class="description-paragraph" id="p-0405" num="0404">Furthermore, pre-conversion position information (input_knee_point[5]) of the fifth knee point is 300, and post-conversion position information (output_knee_point [5]) thereof is 540, and pre-conversion position information (input_knee_point[6]) of the sixth knee point is 500, and post-conversion position information (output_knee_point[6]) thereof is 705.</div>
<div class="description-paragraph" id="p-0406" num="0405">In addition, pre-conversion position information (input_knee_point[7]) of the seventh knee point is 700, and post-conversion position information (output_knee_point[7]) thereof is 836, and pre-conversion position information (input_knee_point[8]) of the eighth knee point is 900, and post-conversion position information (output_knee_point [8]) thereof is 949.</div>
<div class="description-paragraph" id="p-0407" num="0406">In this case, the respective knee points are connected to each other in an order in which the pre-conversion position information is less, and thus a function of knee conversion is as illustrated in <figref idrefs="DRAWINGS">FIG. 50B</figref>. In other words, a straight line which connects the knee points to each other in an order of the second, 0-th, fifth, third, sixth, first, seventh, fourth and eighth knee points, serves as a function of knee conversion. In addition, the transverse axis of <figref idrefs="DRAWINGS">FIG. 50B</figref> expresses luminance of a coding target image, and the longitudinal axis expresses luminance of a converted image. This is also the same for <figref idrefs="DRAWINGS">FIGS. 51, 52, and 57 to 59</figref> described later.</div>
<div class="description-paragraph" id="p-0408" num="0407">In a case where the selection unit <b>121</b> selects DR conversion information pieces of three knee points from the DR conversion information pieces of the knee points defined by the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 50A</figref>, an approximate function of knee conversion having the selected knee points is as illustrated in <figref idrefs="DRAWINGS">FIG. 51</figref>.</div>
<div class="description-paragraph" id="p-0409" num="0408">In other words, in this case, the selection unit <b>121</b> selects DR conversion information pieces of the 0-th to second knee points from among the DR conversion information pieces of the 0-th to eighth knee points defined by the knee_function_info SEI. Therefore, a knee conversion function having the selected knee points is a straight line which connects the 0-th to second knee points to each other in an order in which the pre-conversion position information is less, that is, in an order of the second, 0-th and first knee points.</div>
<div class="description-paragraph" id="p-0410" num="0409">Meanwhile, in a case where the selection unit <b>121</b> selects DR conversion information pieces of five knee points from among the DR conversion information pieces of the knee points defined by the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 50A</figref>, an approximate function of knee conversion having the selected knee points is as illustrated in <figref idrefs="DRAWINGS">FIG. 52</figref>.</div>
<div class="description-paragraph" id="p-0411" num="0410">In other words, in this case, the selection unit <b>121</b> selects DR conversion information pieces of the 0-th to fourth knee points from among the DR conversion, information pieces of the 0-th to eighth knee points defined by the knee_function_info SEI. Therefore, a knee conversion function having the selected knee points is a straight line which connects the 0-th to fourth knee points to each other in an order in which the pre-conversion position information is less, that, is, in an order of the second, 0-th, third, first and fourth knee points.</div>
<div class="description-paragraph" id="p-0412" num="0411">The order i of the knee points is set in an order of a priority for representing the function of <figref idrefs="DRAWINGS">FIG. 50B</figref> which is a desired function of knee conversion is higher, and DR conversion information pieces of a predetermined number of knee points are selected from the lower order i. Therefore, as illustrated in <figref idrefs="DRAWINGS">FIGS. 51 and 52</figref>, an approximate function of knee conversion is more approximate to the function of <figref idrefs="DRAWINGS">FIG. 50B</figref> than in a case where other knee points of the same number are selected.</div>
<div class="description-paragraph" id="p-0413" num="0412">In addition, a larger number of knee points lead to a smoother and more complex function. Therefore, an approximate function of knee conversion of <figref idrefs="DRAWINGS">FIG. 52</figref> in which the number of knee points is five is more approximate to the function of knee conversion of <figref idrefs="DRAWINGS">FIG. 50B</figref> than an approximate function of knee conversion of <figref idrefs="DRAWINGS">FIG. 51</figref> in which the number of knee points is three.</div>
<div class="description-paragraph" id="p-0414" num="0413">[Description of Process in Decoding System]</div>
<div class="description-paragraph" id="p-0415" num="0414"> <figref idrefs="DRAWINGS">FIG. 53</figref> is a flowchart illustrating a decoding process performed by the decoding device <b>111</b> of the decoding system <b>110</b> of <figref idrefs="DRAWINGS">FIG. 49</figref>.</div>
<div class="description-paragraph" id="p-0416" num="0415">In step S<b>111</b> of <figref idrefs="DRAWINGS">FIG. 53</figref>, the reception unit <b>51</b> of the decoding device <b>111</b> receives a coded stream transmitted from the coding device <b>70</b> of <figref idrefs="DRAWINGS">FIG. 16</figref>, and supplies the coded stream to the extraction unit <b>91</b>.</div>
<div class="description-paragraph" id="p-0417" num="0416">In step S<b>112</b>, the extraction unit <b>91</b> extracts parameter sets and coded data from the coded stream which is supplied from the reception unit <b>51</b>. The extraction unit <b>91</b> supplies the parameter sets and the coded data to the decoding unit <b>92</b>. In addition, the extraction unit <b>91</b> supplies knee_function_info SEI among the parameter sets to the selection unit <b>121</b>.</div>
<div class="description-paragraph" id="p-0418" num="0417">In step S<b>113</b>, the decoding unit <b>92</b> decodes the coded data supplied from the extraction unit <b>91</b> in the HEVC method. At this time, the decoding unit <b>92</b> also refers to the parameter sets supplied from the extraction unit <b>91</b> as necessary. The decoding unit <b>92</b> supplies the decoded image to the transmission unit <b>122</b>.</div>
<div class="description-paragraph" id="p-0419" num="0418">In step S<b>114</b>, the selection unit <b>121</b> selects DR conversion information of the number of knee points included in a single packet of AVI InfoFrame of HDMI in an order in which the order i is lower from among DR conversion information pieces of a plurality of knee points included in the knee_function_info SEI from the extraction unit <b>91</b>. The selection unit <b>121</b> supplies the selected DR conversion information of the knee point to the transmission unit <b>122</b>.</div>
<div class="description-paragraph" id="p-0420" num="0419">In step S<b>115</b>, the transmission unit <b>122</b> disposes the DR conversion information selected by the selection unit <b>121</b> in a single packet of AVI InfoFrame of HDMI, and transmits a result thereof to the display device <b>112</b> with HDMI along with a decoded image generated by the decoding unit <b>92</b>. In addition, the process is finished.</div>
<div class="description-paragraph" id="p-0421" num="0420"> <figref idrefs="DRAWINGS">FIG. 54</figref> is a flowchart illustrating a display process performed by the display device <b>112</b> of the decoding system <b>110</b>.</div>
<div class="description-paragraph" id="p-0422" num="0421">In step S<b>131</b> of <figref idrefs="DRAWINGS">FIG. 54</figref>, the reception unit <b>131</b> of the display device <b>112</b> receives the DR conversion information disposed in AVI InfoFrame and the decoded image which are transmitted from the transmission unit <b>122</b> with HDMI. The reception unit <b>131</b> supplies the DR conversion information and the decoded image to the conversion unit <b>93</b>.</div>
<div class="description-paragraph" id="p-0423" num="0422">Processes in steps S<b>132</b> to S<b>134</b> are the same as the processes in steps S<b>95</b> and S<b>97</b> of <figref idrefs="DRAWINGS">FIG. 23</figref>, and thus description thereof will not be repeated.</div>
<div class="description-paragraph" id="p-0424" num="0423">As mentioned above, in the first configuration of the third embodiment to which the present disclosure is applied, the DR conversion information of the knee point in which the order is set in an order in which a priority for representing a desired, knee conversion is higher is set in the knee_function_info SEI and is transmitted. Therefore, the decoding device <b>111</b> selects DR conversion information of the number of knee points included in a single packet of AVI InfoFrame in an order in which the order i is lower, and thus can dispose DR conversion information of the knee point indicating an approximate function of knee conversion which is more approximate to a desired function of knee conversion, in a single packet of AVI InfoFrame.</div>
<div class="description-paragraph" id="p-0425" num="0424">(Example of Syntax of Knee_Function_Info SEI)</div>
<div class="description-paragraph" id="p-0426" num="0425">A second configuration of the third embodiment of the coding device to which, the present disclosure is applied, is the same as the configuration of the coding device <b>70</b> of <figref idrefs="DRAWINGS">FIG. 16</figref> except for the knee_function_info SEI set by the setting unit <b>71</b> and semantics. Therefore, hereinafter, only the knee_function_info SEI and semantics will be described.</div>
<div class="description-paragraph" id="p-0427" num="0426"> <figref idrefs="DRAWINGS">FIG. 55</figref> is a diagram illustrating an example of syntax of knee_function_info SEI set by the setting unit <b>71</b> in the second configuration of the third embodiment of the coding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0428" num="0427">The knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 55</figref> is the same as the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 40</figref> except that an approximate knee point index (approximate_knee_point_index) (priority information) indicating the order i is set in an order in which a priority for representing a desired function of knee conversion is higher.</div>
<div class="description-paragraph" id="p-0429" num="0428">In the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 55</figref>, the order i of knee points is an order in which the pre-conversion position information is less in the same manner as in the case of <figref idrefs="DRAWINGS">FIG. 40</figref>, but the approximate knee point index (approximate_knee_point_index) is newly set. A value of the approximate knee point index (approximate_knee_point_index) is equal to or less than the knee point number (number_knee_point_minus1).</div>
<div class="description-paragraph" id="p-0430" num="0429">(Second Example of Semantics)</div>
<div class="description-paragraph" id="p-0431" num="0430"> <figref idrefs="DRAWINGS">FIG. 56</figref> is a diagram illustrating that semantics of <figref idrefs="DRAWINGS">FIG. 55</figref> is different from that of the second embodiment.</div>
<div class="description-paragraph" id="p-0432" num="0431">As illustrated in <figref idrefs="DRAWINGS">FIG. 56</figref>, in the semantics of <figref idrefs="DRAWINGS">FIG. 55</figref>, a decoded image may be knee-converted by using an approximate function of knee conversion. This approximate function of knee conversion is a straight line which connects knee points in which the order i is 0-th to N-th (where N is equal to or greater than 0 and equal to or smaller than num_knee_point_minus1) approximate knee point index (approximate_knee_point_index [0] to approximate_knee_point_index[N]) in an order in which the order i is lower. An order j of the approximate knee point indexes is an order in which a priority for representing a desired function of knee conversion is higher, and thus an approximate function of knee conversion is more approximate to a desired function of knee conversion as N is greater.</div>
<div class="description-paragraph" id="p-0433" num="0432">(Configuration Example of One Embodiment of Coding System)</div>
<div class="description-paragraph" id="p-0434" num="0433">A second configuration of an embodiment of the decoding system to which the present disclosure is applied is the same as the configuration of the decoding system <b>110</b> of <figref idrefs="DRAWINGS">FIG. 49</figref> except that selection by the selection unit <b>121</b> is performed on the basis of not the order i of knee points but the order j of the approximate knee point, indexes. Therefore, hereinafter, only selection by the selection unit <b>121</b> will be described.</div>
<div class="description-paragraph" id="p-0435" num="0434">[Description of Second Selection Method of Knee Point]</div>
<div class="description-paragraph" id="p-0436" num="0435"> <figref idrefs="DRAWINGS">FIGS. 57A and 57B</figref> are diagrams illustrating an example of a knee point and a function of knee conversion defined by the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 55</figref>.</div>
<div class="description-paragraph" id="p-0437" num="0436">In addition, in the example of <figref idrefs="DRAWINGS">FIGS. 57A and 57B</figref>, a knee point number (number_knee_point_minus1) set in the knee_function_info SEI is 8 in the same manner as in <figref idrefs="DRAWINGS">FIGS. 50A and 50B</figref>, and knee points are also the same as in <figref idrefs="DRAWINGS">FIGS. 50A and 50B</figref>. However, in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 55</figref>, the order i of knee points is an order in which the pre-conversion position information is less, and is thus different from that of <figref idrefs="DRAWINGS">FIGS. 50A and 50B</figref>.</div>
<div class="description-paragraph" id="p-0438" num="0437">As illustrated in <figref idrefs="DRAWINGS">FIG. 57A</figref>, among eight knee points set in the knee_function_info SEI, pre-conversion position information (input_knee_point[0]) of the 0-th knee point is 100, and post-conversion position information (output_knee_point[0]) thereof is 290. In addition, pre-conversion position information (input_knee_point[1]) of the first knee point is 200, and post-conversion position information (output_knee_point[1]) thereof is 433, and pre-conversion position information (input_knee_point[2]) of the second knee point is 300, and post-conversion position information (output_knee_point[2]) thereof is 540.</div>
<div class="description-paragraph" id="p-0439" num="0438">Further, pre-conversion position information (input_knee_point [3]) of the third knee point is 400, and post-conversion position information (output_knee_point[3]) thereof is 628, and pre-conversion position information (input_knee_point[4]) of the fourth knee point is 500, and post-conversion position information (output_knee_point[4]) thereof is 705.</div>
<div class="description-paragraph" id="p-0440" num="0439">Furthermore, pre-conversion position information (input_knee_point[5]) of the fifth knee point is 600, and post-conversion position information (output_knee_point[5]) thereof is 774, and pre-conversion position information (input_knee_point [6]) of the sixth knee_point is 700, and post-conversion position information (output_knee_point [6]) thereof is 836.</div>
<div class="description-paragraph" id="p-0441" num="0440">In addition, pre-conversion position information (input_knee_point [7]) of the seventh knee_point, is 800, and post-conversion position information (output_knee_point[7]) thereof is 894, and pre-conversion position information (input_knee_point [8]) of the eighth knee point, is 900, and post-conversion position information (output_knee_point[8]) thereof is 949.</div>
<div class="description-paragraph" id="p-0442" num="0441">In this case, the respective knee points are connected to each other in an order in which the order i is lower, and thus a function of knee conversion is as illustrated in <figref idrefs="DRAWINGS">FIG. 57B</figref>.</div>
<div class="description-paragraph" id="p-0443" num="0442">In addition, as illustrated in <figref idrefs="DRAWINGS">FIG. 57A</figref>, the approximate knee point indexes (approximate_knee_point_index) in which the order j is 0 to 8 are 1, 5, 0, 3, 7, 2, 4, 6, and 8 in order.</div>
<div class="description-paragraph" id="p-0444" num="0443">In a case where the selection unit <b>121</b> selects DR conversion information pieces of three knee points from among the DR conversion information pieces of the knee points defined by the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 57A</figref>, a function of knee conversion having the selected knee points is as illustrated in <figref idrefs="DRAWINGS">FIG. 58</figref>.</div>
<div class="description-paragraph" id="p-0445" num="0444">In other words, in this case, the selection unit <b>121</b> selects DR conversion information pieces of the knee points in which the order i is the 0-th to second approximate, knee point indexes (approximate_knee_point_index) from among the DR conversion information pieces of the 0-th to eighth knee points defined by the knee_function_info SEI. In other words, the selection unit <b>121</b> selects the DR conversion information pieces of the first, fifth and 0-th knee points. Therefore, a knee conversion function having the selected knee points is a straight line which connects the first, fifth and 0-th knee points to each other in an order in which the order is lower, that is, in an order of the 0-th, first and fifth knee points.</div>
<div class="description-paragraph" id="p-0446" num="0445">Meanwhile, in a case where the selection unit <b>121</b> selects DR conversion information pieces of five knee points from among the DR conversion information pieces of the knee points defined by the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 57A</figref>, a function of knee conversion having the selected knee points is as illustrated in <figref idrefs="DRAWINGS">FIG. 59</figref>.</div>
<div class="description-paragraph" id="p-0447" num="0446">In other words, in this case, the selection unit <b>121</b> selects DR conversion information pieces of the knee points in which the order i is the 0-th to fourth approximate knee point indexes (approximate_knee_point_index) from among the DR conversion information pieces of the 0-th to eighth knee points defined by the knee_function_info SEI. In other words, the selection unit <b>121</b> selects the DR conversion information pieces of the first, fifth, 0-th, third and seventh knee points. Therefore, a knee conversion function having the selected knee points is a straight line which connects the first, fifth, 0-th, third and seventh knee points to each other in an order in which the order i is lower, that is, in an order of the 0-th, first, third, fifth and seventh knee points.</div>
<div class="description-paragraph" id="p-0448" num="0447">The order j of the approximate knee point indexes is set in an order of priorities for representing the function of <figref idrefs="DRAWINGS">FIG. 57B</figref> which is a desired function of knee conversion is higher, and DR conversion information pieces of knee points with a predetermined number of approximate knee point, indexes in the order i are selected from the lower order j. Therefore, as illustrated in <figref idrefs="DRAWINGS">FIGS. 58 and 59</figref>, an approximate function of knee conversion is more approximate to the function of <figref idrefs="DRAWINGS">FIG. 57B</figref> than in a case where other knee points of the same number are selected.</div>
<div class="description-paragraph" id="p-0449" num="0448">In addition, a larger number of knee points lead to a smoother and more complex function. Therefore, an approximate function of knee conversion of <figref idrefs="DRAWINGS">FIG. 59</figref> in which the number of knee points is five is more approximate to the function of knee conversion of <figref idrefs="DRAWINGS">FIG. 57B</figref> than an approximate function of knee conversion of <figref idrefs="DRAWINGS">FIG. 58</figref> in which the number of knee points is three.</div>
<div class="description-paragraph" id="p-0450" num="0449">In addition, as illustrated in <figref idrefs="DRAWINGS">FIG. 60</figref>, the approximate knee point index (approximate_knee_point_index) may be set in approximate_knee_function_info SEI different from knee_function_info SEI.</div>
<div class="description-paragraph" id="p-0451" num="0450">In this case, an approximate knee conversion ID (approximate_knee_function_id) and an approximate knee conversion cancel flag (approximate_knee_function_cancel_flag) are set in the approximate_knee_function_info SEI.</div>
<div class="description-paragraph" id="p-0452" num="0451">The approximate knee conversion ID is an ID unique to the purpose of knee conversion using an approximate function. In addition, the approximate knee conversion cancel flag is a flag illustrating whether or not persistence of previous approximate_knee_function_info SEI is canceled. The approximate knee conversion cancel flag is set to 1 when indicating that persistence of previous approximate_knee_function_info SEI is canceled, and is set to 0 when the persistence is not canceled.</div>
<div class="description-paragraph" id="p-0453" num="0452">In a case where the approximate knee conversion cancel flag is 0, a reference knee conversion ID (ref_knee_function_id) is set in the approximate knee_function_info SEI. The reference knee conversion ID is a knee conversion ID of knee_function_info SEI including DR information of a knee point indicating a function, of knee conversion which is approximated by using an approximate knee point index of the approximate_knee_function_info SEI.</div>
<div class="description-paragraph" id="p-0454" num="0453">In addition, an approximate knee_point index number (num_approximate_knee_point_indices_minus1) which is a value, obtained by subtracting 1 from the number of approximate knee point indexes, and an approximately knee_point index (approximate_knee_point_index) are set.</div>
<div class="description-paragraph" id="p-0455" num="0454">As mentioned above, also in a case where the approximate knee point index (approximate_knee_point_index) is set in the approximate_knee_function_info SEI, semantics is the same as the semantics described in <figref idrefs="DRAWINGS">FIG. 56</figref>.</div>
<div class="description-paragraph" id="p-0456" num="0455">In addition, in the above description, only the knee_function_info SEI including DR information of a knee point indicating a function of knee conversion is set, but knee_function_info SEI including DR information of a knee point indicating an approximate function of knee conversion may be set. In this case, for example, DR information of a knee point indicating a function of knee conversion is set to knee_function_info SEI in which a knee conversion ID is 0, and DR information of a knee point indicating an approximate function of knee conversion is set to knee_function_info SEI in which a knee conversion ID is 1. Further, in a case where DR information is transmitted with HDMI, the decoding device disposes the DR information included in the knee_function_info SEI in which the knee conversion ID is 1, in a single packet of AVI InfoFrame, and transmits the DR information.</div>
<div class="description-paragraph" id="p-0457" num="0456">In addition, a unique ID is set in predetermined brightness as the unconverted display luminance information (input_disp_luminance) and the converted luminance range information (output_d_range), and thus it is possible to reduce a DR information amount. In this case, for example, 0 may be assigned to 400 candela per square meter, and 1 may be assigned to 800 candela per square meter, as an ID. A correspondence relationship between an ID and brightness assigned with the ID is set in common to a coding side and a display side, and thus the display side can recognize the brightness from the ID.</div>
<div class="description-paragraph" id="p-0458" num="0457">In the third embodiment, a knee point is selected in an order in which priorities for representing a desired function of knee conversion are higher, but a knee point may be selected in other orders.</div>
<div class="description-paragraph" id="p-0459" num="0458">In addition, in the third embodiment, the number of selected knee points is the number which can be included in a single packet of AVI InfoFrame, but is not limited thereto. For example, in a case where the decoding device <b>111</b> has a function of the display device <b>112</b>, the number of selected knee points may be the number of knee points corresponding to knee conversion which can be processed by the conversion unit <b>93</b>, or the like.</div>
<heading id="h-0015">Fourth Embodiment</heading>
<div class="description-paragraph" id="p-0460" num="0459">Basis of Fourth Embodiment</div>
<div class="description-paragraph" id="p-0461" num="0460">As illustrated in <figref idrefs="DRAWINGS">FIG. 61</figref>, in a cathode ray tube (CRT) used in a CRT display, an input electrical signal and display luminance have no proportional relationship, and it is necessary to input, a higher electrical signal in order to display high luminance. Therefore, if an electrical signal which is proportional to luminance of an image is input to the CRT display as illustrated in <figref idrefs="DRAWINGS">FIG. 62</figref>, display luminance is lower than original luminance of the image as illustrated in <figref idrefs="DRAWINGS">FIG. 63</figref>. Therefore, in order to display an image with the original luminance of the image, as illustrated in <figref idrefs="DRAWINGS">FIG. 64</figref>, it is necessary to convert luminance of an image into an electrical signal by using a function having a characteristic reverse to that of the function of <figref idrefs="DRAWINGS">FIG. 61</figref>.</div>
<div class="description-paragraph" id="p-0462" num="0461">In addition, in <figref idrefs="DRAWINGS">FIGS. 61 and 63</figref>, the transverse axis expresses a value obtained by normalizing an input electrical signal when a value of the input electrical signal for displaying with the maximum luminance in the CRT display is set to 1, and the longitudinal axis expresses a value obtained by normalizing display luminance when the maximum value of the display luminance of the CRT display is set to 1. In <figref idrefs="DRAWINGS">FIGS. 62 and 64</figref>, the transverse axis expresses a value obtained by normalizing luminance of a display target image when the maximum value of the luminance of a display target image is set to 1, and the longitudinal axis expresses a value obtained by normalizing an electrical signal when a value of the electrical signal corresponding to the maximum value of the luminance of a display target image is set to 1.</div>
<div class="description-paragraph" id="p-0463" num="0462">A function for converting an input electrical signal into display luminance as illustrated in <figref idrefs="DRAWINGS">FIG. 61</figref> is referred to as electro-optical transfer function (EOTF), and a function for converting luminance of an image into an electrical signal as illustrated in <figref idrefs="DRAWINGS">FIG. 64</figref> is referred to as an optical-electro transfer function (OETF).</div>
<div class="description-paragraph" id="p-0464" num="0463">Other displays such as a light emitting diode (LED) panel have characteristics different from the characteristics of the CRT display. However, in order not to change generation procedures of an input electrical signal depending on displays, processes using the EOTF and the OETF are also performed in the same manner as in the CRT display in a case of performing display with other displays.</div>
<div class="description-paragraph" id="p-0465" num="0464"> <figref idrefs="DRAWINGS">FIG. 65</figref> is a diagram illustrating an example of a flow of a process until an image is displayed from capturing of the image.</div>
<div class="description-paragraph" id="p-0466" num="0465">In addition, in the example of <figref idrefs="DRAWINGS">FIG. 65</figref>, an electrical signal is a code value of 10 bits (0 to 1023), and the OETF and the EOFT are defined in BT.709.</div>
<div class="description-paragraph" id="p-0467" num="0466">As illustrated in <figref idrefs="DRAWINGS">FIG. 65</figref>, when an image is captured by a camera or the like, a photoelectric conversion process of converting luminance (light) into an electrical signal (code value) by using the OETF is performed on the captured image. Then, the electrical signal is coded, and the coded electrical signal is decoded. In addition, an electro-optical conversion process of converting an electrical signal into luminance by using the EOTF is performed on the decoded electrical signal.</div>
<div class="description-paragraph" id="p-0468" num="0467">Meanwhile, the human visual sense has a characteristic of being sensitive to a luminance difference at low luminance and being insensitive to a luminance difference at high luminance. Therefore, as illustrated in <figref idrefs="DRAWINGS">FIG. 65</figref>, the OETF of BT.709 is a function in which more code values are assigned to a low luminance part than a high luminance part. As a result, subjectively sufficient image quality is realized.</div>
<div class="description-paragraph" id="p-0469" num="0468">In a case where the maximum luminance of an image is about 100 candela per square meter, satisfactory code values can be assigned to a low luminance part by using the OETF of BT.709. However, the maximum luminance of displays has recently tended to increase, and is expected to be accelerated in the future. If the maximum luminance of an image increases in accordance therewith, code values to be assigned to a low luminance part are insufficient in the OETF of BT.709, and thus satisfactory image quality is unable to be obtained.</div>
<div class="description-paragraph" id="p-0470" num="0469">Therefore, it is considered that a new OETF for use in an HDR image in which a ratio of code values assigned to a low luminance part is increased is generated, and thus satisfactory image quality is obtained in an HDR image. However, in this case, in order to perform a photoelectric conversion process and an electro-optical conversion process, it is necessary to prepare for both an OETF and an EOTF for an HDR image and an OETF and an EOTF for an SDR image.</div>
<div class="description-paragraph" id="p-0471" num="0470">On the other hand, in a case where electro-optical conversion is performed on an SDR image by using an OETF for an HDR image, grayscale expression of luminance is roughened.</div>
<div class="description-paragraph" id="p-0472" num="0471">For example, as illustrated in <figref idrefs="DRAWINGS">FIG. 66</figref>, in a case where photoelectric conversion is performed on an SDR image by using an OETF of BT.709 for an SDR image having the maximum luminance of 100 candela per square meter, luminance of the SDR image is expressed in codes of 1024 including 0 to 1023. In contrast, as illustrated in <figref idrefs="DRAWINGS">FIG. 67</figref>, in a case where photoelectric conversion is performed on an SDR image by using an OETF for an HDR image having the maximum luminance of 400 candela per square meter, luminance of the SDR image is expressed, for example, in 502 code values including 0 to 501.</div>
<div class="description-paragraph" id="p-0473" num="0472">Therefore, an OETF and an EOTF are preferably variable in order to assign sufficient code values to a low luminance part in both an HDR image having high maximum luminance and an SDR image having low maximum luminance. Therefore, in the fourth embodiment, knee conversion is performed before the OETF of BT.709 and after the EOTF of BT.709, and thus sufficient code values can be assigned to a low luminance part.</div>
<div class="description-paragraph" id="p-0474" num="0473">[Overview of Photoelectric Conversion Process in Fourth Embodiment. ]</div>
<div class="description-paragraph" id="p-0475" num="0474"> <figref idrefs="DRAWINGS">FIG. 68</figref> is a diagram illustrating an overview of a photoelectric conversion process in the fourth embodiment.</div>
<div class="description-paragraph" id="p-0476" num="0475">As illustrated in the left part of <figref idrefs="DRAWINGS">FIG. 68</figref>, in the fourth embodiment, first, predetermined, knee conversion is performed on luminance (input luminance) of a captured image. In an example of <figref idrefs="DRAWINGS">FIG. 68</figref>, through the knee conversion, 10% of a low luminance part of the input luminance is converted into 90% of the low luminance part of input luminance', and 90% of a high luminance part of the input luminance is converted into 10% of the high luminance part, of the input luminance'. Accordingly, there is a generation of the input luminance' in which more values are assigned to the low luminance part than the high luminance part.</div>
<div class="description-paragraph" id="p-0477" num="0476">Next, as illustrated in the central part, of <figref idrefs="DRAWINGS">FIG. 68</figref>, a photoelectric conversion process using the OETF of BT.709 is performed on the input luminance' so as to generate a code value of a predetermined number of bits (10 bits in the example of <figref idrefs="DRAWINGS">FIG. 68</figref>). As described above, since, in the input luminance', more values are assigned to the low luminance part, than the high luminance part, as illustrated, in the right part of <figref idrefs="DRAWINGS">FIG. 68</figref>, more values are assigned in code values converted from the input luminance' due to the low luminance part of the input luminance than in the OETF of BT.709. In the example of <figref idrefs="DRAWINGS">FIG. 68</figref>, 10% of the low luminance part of the input luminance is assigned to 94% of code values.</div>
<div class="description-paragraph" id="p-0478" num="0477">As mentioned above, in the fourth embodiment, an extent of assigning code values to a low luminance part (dark part) and an extent of assigning the code values to a high luminance part (bright part) are adjusted by using a function of knee conversion as a parameter.</div>
<div class="description-paragraph" id="p-0479" num="0478">In addition, information on a knee point of knee conversion performed on the input luminance is set in the knee_function_info SEI of <figref idrefs="DRAWINGS">FIG. 40</figref> and is transmitted to a decoding side.</div>
<div class="description-paragraph" id="p-0480" num="0479">[Overview of Electro-Optical Conversion Process in Fourth Embodiment]</div>
<div class="description-paragraph" id="p-0481" num="0480"> <figref idrefs="DRAWINGS">FIG. 69</figref> is a diagram illustrating an overview of an electro-optical conversion process in the fourth embodiment.</div>
<div class="description-paragraph" id="p-0482" num="0481">As illustrated in the left part of <figref idrefs="DRAWINGS">FIG. 69</figref>, in the fourth embodiment, first, an electro-optical conversion process using the EOTF of BT.709 is performed on code values of a decoded image so as to generate luminance (output luminance). Next, as illustrated in the central part of <figref idrefs="DRAWINGS">FIG. 69</figref>, predetermined knee conversion is performed on the output luminance. In an example of <figref idrefs="DRAWINGS">FIG. 68</figref>, through the knee conversion, 90% of a low luminance part of the output luminance is converted into 10% of a low luminance part, of output luminance', and 10% of a high luminance part of the output luminance is converted into 90% of a high luminance part of the output luminance'.</div>
<div class="description-paragraph" id="p-0483" num="0482">Accordingly, as illustrated in the right part of <figref idrefs="DRAWINGS">FIG. 69</figref>, code values in which more values are assigned due to the low luminance part of the input luminance than in the EOTF of BT.709 can be converted into the same output luminance' as input luminance corresponding to the code values.</div>
<div class="description-paragraph" id="p-0484" num="0483">As mentioned above, in the fourth embodiment, code values in which an extent of assignment to a low luminance part (dark part) and an extent of assignment to a high luminance part (bright part) are adjusted are converted, into luminance by using a function of knee conversion as a parameter.</div>
<div class="description-paragraph" id="p-0485" num="0484">In addition, information on a knee point of knee conversion performed on the output luminance is determined on the basis of information set in knee_function_info SET or the like transmitted from a coding side.</div>
<div class="description-paragraph" id="p-0486" num="0485">(Configuration Example of Fourth Embodiment, of Coding Device)</div>
<div class="description-paragraph" id="p-0487" num="0486"> <figref idrefs="DRAWINGS">FIG. 70</figref> is a block diagram illustrating a configuration example of the fourth embodiment, of a coding device to which the present disclosure is applied.</div>
<div class="description-paragraph" id="p-0488" num="0487">Among constituent elements illustrated, in <figref idrefs="DRAWINGS">FIG. 70</figref>, the same constituent elements as the constituent elements of <figref idrefs="DRAWINGS">FIG. 6 or 16</figref> are given the same reference numerals. Repeated description will be omitted as appropriate.</div>
<div class="description-paragraph" id="p-0489" num="0488">A configuration of a coding device <b>150</b> of <figref idrefs="DRAWINGS">FIG. 70</figref> is different from the configuration of <figref idrefs="DRAWINGS">FIG. 16</figref> in that a quantization unit <b>151</b> is provided instead of the conversion unit <b>73</b>. The coding device <b>150</b> performs a photoelectric conversion process on a captured image which is input from an external device so as to perform coding.</div>
<div class="description-paragraph" id="p-0490" num="0489">Specifically, the quantization unit <b>151</b> of the coding device <b>150</b> knee-converts luminance of the captured, image which is input from the external device. Information on a knee point of the knee conversion is set in knee_function_info SEI by the setting unit <b>71</b>. The quantization unit <b>151</b> performs a photoelectric conversion process using the OETF of BT.709 on the knee-converted luminance so as to generate a code value. The quantization unit <b>151</b> supplies the generated code value to the coding unit <b>72</b> as a coding target image.</div>
<div class="description-paragraph" id="p-0491" num="0490">&lt;Description of Process in Coding Device&gt;</div>
<div class="description-paragraph" id="p-0492" num="0491"> <figref idrefs="DRAWINGS">FIG. 71</figref> is a flowchart illustrating a stream generation process performed by the coding device <b>150</b> of <figref idrefs="DRAWINGS">FIG. 70</figref>.</div>
<div class="description-paragraph" id="p-0493" num="0492">In step S<b>150</b> of <figref idrefs="DRAWINGS">FIG. 71</figref>, the quantization unit <b>151</b> of the coding device <b>150</b> knee-converts luminance of a captured image which is input, from an external device. In step S<b>152</b>, the quantization unit <b>151</b> performs a photoelectric conversion process using the EOTF of BT.709 on the knee-converted luminance so as to generate a code value. The quantization unit <b>151</b> supplies the generated code value to the coding unit <b>72</b> as a coding target image.</div>
<div class="description-paragraph" id="p-0494" num="0493">Processes in steps S<b>152</b> to S<b>154</b> are the same as the processes in steps S<b>73</b> to S<b>75</b> of <figref idrefs="DRAWINGS">FIG. 21</figref>, and thus description thereof will be omitted.</div>
<div class="description-paragraph" id="p-0495" num="0494">In step S<b>155</b>, the setting unit <b>71</b> sets knee_function_info SEI including information on a knee point of the knee conversion performed due to the process in step S<b>150</b>. The setting unit <b>71</b> supplies parameter sets such, as the set SPS, PPS, VUI and knee_function_info SEI to the coding unit <b>72</b>.</div>
<div class="description-paragraph" id="p-0496" num="0495">In step S<b>156</b>, the coding unit <b>72</b> codes the coding target image which is supplied from the conversion unit <b>73</b> in the HEVC method. Processes in steps S<b>157</b> and S<b>158</b> are the same as the processes in steps S<b>78</b> and S<b>79</b> of <figref idrefs="DRAWINGS">FIG. 21</figref>, and thus description thereof will be omitted.</div>
<div class="description-paragraph" id="p-0497" num="0496">As mentioned above, the coding device <b>150</b> performs the knee conversion before the OETF of BT.709, and thus can perform a photoelectric conversion process suitable for both an SDR image and an HDR image by using the OETF of BT.709.</div>
<div class="description-paragraph" id="p-0498" num="0497">(Configuration Example of Fourth Embodiment of Decoding Device)</div>
<div class="description-paragraph" id="p-0499" num="0498"> <figref idrefs="DRAWINGS">FIG. 72</figref> is a block diagram illustrating a configuration example of the fourth embodiment of a decoding device to which the present disclosure is applied and which decodes a coded stream transmitted from the coding device <b>150</b> of <figref idrefs="DRAWINGS">FIG. 70</figref>.</div>
<div class="description-paragraph" id="p-0500" num="0499">Among constituent elements illustrated in <figref idrefs="DRAWINGS">FIG. 72</figref>, the same constituent, elements as the constituent elements of <figref idrefs="DRAWINGS">FIG. 12 or 22</figref> are given the same reference numerals. Repeated description will be omitted as appropriate.</div>
<div class="description-paragraph" id="p-0501" num="0500">A configuration of a decoding device <b>170</b> of <figref idrefs="DRAWINGS">FIG. 72</figref> is different from the configuration of the decoding device <b>90</b> of <figref idrefs="DRAWINGS">FIG. 22</figref> in that a conversion unit <b>171</b> is provided instead of the conversion unit <b>93</b>. The decoding device <b>170</b> decodes a coded stream, and performs an electro-optical conversion process on a decoded image, which is obtained, as a result thereof.</div>
<div class="description-paragraph" id="p-0502" num="0501">Specifically, the conversion unit <b>171</b> of the decoding device <b>170</b> performs an electro-optical conversion process using the EOTF of BT.709 on a code value as a decoded image supplied from the decoding unit <b>92</b>, so as to generate luminance. The conversion unit <b>171</b> performs knee conversion on the luminance on the basis of knee_function_info SEI from the extraction unit <b>91</b>. The conversion unit <b>171</b> supplies luminance which is obtained as a result of the knee conversion to the display control unit <b>94</b> as a display image.</div>
<div class="description-paragraph" id="p-0503" num="0502">&lt;Description of Process in Decoding Device&gt;</div>
<div class="description-paragraph" id="p-0504" num="0503"> <figref idrefs="DRAWINGS">FIG. 73</figref> is a flowchart illustrating an image generation process performed by the decoding device <b>170</b> of <figref idrefs="DRAWINGS">FIG. 72</figref>.</div>
<div class="description-paragraph" id="p-0505" num="0504">Processes in steps S<b>171</b> to S<b>173</b> of <figref idrefs="DRAWINGS">FIG. 73</figref> are the same as the processes in steps S<b>91</b> to S<b>93</b> of <figref idrefs="DRAWINGS">FIG. 23</figref>, and thus description thereof will be omitted.</div>
<div class="description-paragraph" id="p-0506" num="0505">In step S<b>174</b>, the conversion unit <b>171</b> of the decoding device <b>170</b> performs an electro-optical conversion process using the EOTF of BT.709 on a code value as a decoded image supplied from the decoding unit <b>92</b>, so as to generate luminance.</div>
<div class="description-paragraph" id="p-0507" num="0506">In step S<b>175</b>, the conversion unit <b>171</b> performs knee conversion on the generated luminance on the basis of knee_function_info SEI from the extraction unit <b>91</b>. The conversion unit <b>171</b> supplies luminance which is obtained as a result of the knee conversion to the display control unit <b>94</b> as a display image.</div>
<div class="description-paragraph" id="p-0508" num="0507">In step S<b>176</b>, the display control unit <b>94</b> displays the display image supplied from the conversion unit <b>93</b> on the display unit <b>95</b>, and finishes the process.</div>
<div class="description-paragraph" id="p-0509" num="0508">As mentioned above, the decoding device <b>170</b> performs the knee conversion after the EOTF of BT.709, and thus can perform an electro-optical conversion process suitable for both an SDR image and an HDR image by using the EOTF of BT.709.</div>
<div class="description-paragraph" id="p-0510" num="0509">In addition, the maximum luminance of a coding target image may be included in a coded stream along with coded data and may be transmitted to the decoding device <b>170</b> from the coding device <b>150</b>, and may be determined in advance as a value common to the coding device <b>150</b> and the decoding device <b>170</b>. Further, knee_function_info SEI may be set for each item of the maximum, luminance of a coding target image.</div>
<div class="description-paragraph" id="p-0511" num="0510">In addition, in the fourth embodiment, the knee_function_info SEI of the first to third embodiments may be set. In this case, the decoding side performs knee conversion by using DR conversion information, and thus it is possible to perform conversion into an image which is suitable for various luminance displays.</div>
<div class="description-paragraph" id="p-0512" num="0511">In addition, the decoding device <b>170</b> in the fourth embodiment may be divided into a decoding device and a display device in the same manner as in the third embodiment.</div>
<div class="description-paragraph" id="p-0513" num="0512">Further, in the fourth embodiment, an extent of assigning code values to a low luminance part and an extent of assigning the code values to a high luminance part are adjusted by using a function of knee conversion as a parameter, but may be adjusted by using functions other than the function of knee conversion as a parameter.</div>
<div class="description-paragraph" id="p-0514" num="0513">Furthermore, the present disclosure may be applied to the AVC method.</div>
<heading id="h-0016">Fifth Embodiment</heading>
<div class="description-paragraph" id="p-0515" num="0514">[Description of Computer to Which Present Disclosure is Applied]</div>
<div class="description-paragraph" id="p-0516" num="0515">The above-described, series of processes may be performed by hardware or software. When the above-described series of processes is performed by the software, programs constituting the software are; installed in a computer. Here, the computer includes a computer incorporated into dedicated hardware, or a general purpose personal computer or the like which can execute various kinds of functions by installing various kinds of programs.</div>
<div class="description-paragraph" id="p-0517" num="0516"> <figref idrefs="DRAWINGS">FIG. 74</figref> is a block diagram illustrating a configuration example of hardware of a computer which performs the above-described series of processes according to a program.</div>
<div class="description-paragraph" id="p-0518" num="0517">In the computer, a central processing unit (CPU) <b>201</b>, a read only memory (ROM) <b>202</b>, and a random access memory (RAM) <b>203</b> are connected to each other via a bus <b>204</b>.</div>
<div class="description-paragraph" id="p-0519" num="0518">The bus <b>204</b> is also connected to an input and output interface <b>205</b>. The input and output interface <b>205</b> is connected to an input unit <b>206</b>, an output unit <b>207</b>, a storage unit <b>208</b>, a communication unit <b>209</b>, and a drive <b>210</b>.</div>
<div class="description-paragraph" id="p-0520" num="0519">The input unit <b>206</b> includes a keyboard, a mouse, a microphone, and the like. The output unit <b>207</b> includes a display, a speaker, and the like. The storage unit <b>208</b> includes a hard disk, a nonvolatile memory, or the like. The communication unit <b>209</b> includes a network interface or the like. The drive <b>210</b> drives a removable medium <b>211</b> such as a magnetic disk, an optical disc, a magneto-optical disc, or the like.</div>
<div class="description-paragraph" id="p-0521" num="0520">In the computer configured in this way, the CPU <b>201</b> performs the above-described series of processes, for example, by loading the program stored in the storage unit <b>208</b> to the RAM <b>203</b> via the input and output interface <b>205</b> and the bus <b>204</b> and executing the program.</div>
<div class="description-paragraph" id="p-0522" num="0521">The program executed by the computer (the CPU <b>201</b>) may be recorded on the removable medium <b>211</b>, for example, as a package medium, and may be provided. In addition, the program, may be provided via a wired or wireless transmission medium such as a local area network, the Internet, or a digital satellite broadcast.</div>
<div class="description-paragraph" id="p-0523" num="0522">In the computer, the program may be installed in the storage unit <b>208</b> via the input and output interface <b>205</b> by installing the removable medium <b>211</b> in the drive <b>210</b>. In addition, the program may be received by the communication unit <b>209</b> via a wired or wireless transmission medium and may be installed, in the storage unit <b>208</b>. Further, the program may be installed in the ROM <b>202</b> or the storage unit <b>208</b> in advance.</div>
<div class="description-paragraph" id="p-0524" num="0523">In addition, the program executed by the computer may be a program which performs processes in a time series according to the order described in the present specification, and may be a program which performs processes in parallel or at a necessary timing such as when accessed.</div>
<heading id="h-0017">Sixth Embodiment</heading>
<div class="description-paragraph" id="p-0525" num="0524">[Application to Multi-View Image Coding and Multi-View Image Decoding]</div>
<div class="description-paragraph" id="p-0526" num="0525">The above-described series of processes may be applied to multi-view image coding and multi-view image decoding. <figref idrefs="DRAWINGS">FIG. 75</figref> is a diagram illustrating an example of a multi-view image coding method.</div>
<div class="description-paragraph" id="p-0527" num="0526">As illustrated in <figref idrefs="DRAWINGS">FIG. 75</figref>, multi-view images include images at a plurality of views. The plurality of views of the multi-view images includes a base view in which coding/decoding is performed by using only an image at its own view, and a non-base view in which coding/decoding is performed by using images at other views. The non-base view may use a base view image and may use other non-base view images.</div>
<div class="description-paragraph" id="p-0528" num="0527">In a case of coding/decoding multi-view images as in <figref idrefs="DRAWINGS">FIG. 75</figref>, each view image is coded/decoded, and the above-described method of the first embodiment may be applied to coding/decoding of each view. In this way, a decoded image can be converted into a desired image with a different dynamic range.</div>
<div class="description-paragraph" id="p-0529" num="0528">In addition, in coding/coding of each view, the flag or the parameter used in the method of the first embodiment may be shared. More specifically, for example, the syntax element or the like of the knee_function_info SEI may be snared in coding/decoding of each view. Of course, necessary information other than these elements may be shared in coding/decoding of each view.</div>
<div class="description-paragraph" id="p-0530" num="0529">In this way, it is possible to minimize transmission of redundant information and thus to reduce transmitted information amount (bit rate) (that is, it is possible to minimise a reduction in coding efficiency).</div>
<div class="description-paragraph" id="p-0531" num="0530">[Multi-View Image Coding Device]</div>
<div class="description-paragraph" id="p-0532" num="0531"> <figref idrefs="DRAWINGS">FIG. 76</figref> is a diagram illustrating a multi-view image coding device which performs the above-described multi-view image coding. As illustrated in <figref idrefs="DRAWINGS">FIG. 76</figref>, the multi-view image coding device <b>600</b> includes a coding unit <b>601</b>, a coding unit <b>602</b>, and a multiplexer <b>603</b>.</div>
<div class="description-paragraph" id="p-0533" num="0532">The coding unit <b>601</b> codes a base view image so as to generate a base view image coded stream. The coding unit <b>602</b> codes a non-base view image so as to generate a non-base view image coded stream. The multiplexer <b>603</b> multiplexes the base view image coded stream generated in the coding unit <b>601</b> and the non-base view image coded stream generated in the coding unit <b>602</b>, so as to generate a multi-view image coded stream.</div>
<div class="description-paragraph" id="p-0534" num="0533">The coding device <b>10</b> (<figref idrefs="DRAWINGS">FIG. 6</figref>) is applicable to the coding unit <b>601</b> and the coding unit <b>602</b> of the multi-view image coding device <b>600</b>. In other words, in coding of each view, an image can be coded so that a decoded image can be converted, into a desired image with a different dynamic range during decoding. In addition, the coding unit <b>601</b> and the coding unit <b>602</b> can perform coding (that is, a flag or a parameter can be shared) by using the mutually same flags or parameters (for example, a syntax element or the like regarding a process of images), and thus it is possible to minimize a reduction in coding efficiency.</div>
<div class="description-paragraph" id="p-0535" num="0534">[Multi-View Image Decoding Device]</div>
<div class="description-paragraph" id="p-0536" num="0535"> <figref idrefs="DRAWINGS">FIG. 77</figref> is a diagram illustrating a multi-view image decoding device which performs the above-described multi-view image decoding. As illustrated in <figref idrefs="DRAWINGS">FIG. 77</figref>, the multi-view image decoding device <b>610</b> includes a demultiplexer <b>611</b>, a decoding unit <b>612</b>, and a decoding unit <b>613</b>.</div>
<div class="description-paragraph" id="p-0537" num="0536">The demultiplexer <b>611</b> demultiplexes the multi-view image coded stream into which the base view image coded stream and the non-base view image coded stream are multiplexed, so as to extract the base view image coded stream and the non-base view image coded stream. The decoding unit <b>612</b> decodes the base view image coded stream, extracted by the demultiplexer <b>611</b> so as to obtain a base view image. The decoding unit <b>513</b> decodes the non-base view image coded stream extracted by the demultiplexer <b>611</b> so as to obtain a non-base view image.</div>
<div class="description-paragraph" id="p-0538" num="0537">The decoding device <b>50</b> (<figref idrefs="DRAWINGS">FIG. 12</figref>) is applicable to the decoding unit <b>612</b> and the decoding unit <b>613</b> of the multi-view image decoding device <b>610</b>. In other words, in decoding of each view, a decoded image can be converted into a desired image with a different dynamic range. In addition, the decoding unit <b>612</b> and the decoding unit <b>613</b> can perform coding (that is, a flag or a parameter can be shared) by using the mutually same flags or parameters (for example, a syntax element or the like regarding a process of images), and thus it is possible to minimize a reduction in coding efficiency.</div>
<heading id="h-0018">Seventh Embodiment</heading>
<div class="description-paragraph" id="p-0539" num="0538">[Application to Layer Image Coding and Layer Image Decoding]</div>
<div class="description-paragraph" id="p-0540" num="0539">The above-described series of processes may be applied, to layer image coding and layer image decoding <figref idrefs="DRAWINGS">FIG. 78</figref> illustrates an example of a layer image coding method.</div>
<div class="description-paragraph" id="p-0541" num="0540">The layer image coding (scalable coding) is to generate a plurality of layers of an image and to code each layer so that image data has a scalable function with respect to a predetermined parameter. The layer image decoding (scalable decoding) is decoding corresponding to the layer image coding.</div>
<div class="description-paragraph" id="p-0542" num="0541">As illustrated, in <figref idrefs="DRAWINGS">FIG. 78</figref>, in layering of an image, a single image is divided into a plurality of images (layers) with a predetermined parameter having a scalable function as a reference. In other words, layered images (layer images) include images of a plurality of layers in which values of the predetermined parameter are different from each other. A plurality of layers of the layer images include a base layer in which coding/decoding is performed by using only an image of its own layer and a non-base layer (also referred to as an enhancement layer) in which coding/decoding is performed by using images of other layers. The non-base layer may use a base layer image and may use other non-base layer images.</div>
<div class="description-paragraph" id="p-0543" num="0542">Generally, the non-base layer is formed by its own image and data (difference data) on a difference image with images of other layers. For example, in a case where a single image is generated as two layers including a base layer and a non-base layer (also referred to as an enhancement layer), an image with quality lower than that of an original image is obtained only by using data of the base layer, and thus data of the base layer and data of the non-base layer are combined with each other so as to obtain the original image (that is, high quality image).</div>
<div class="description-paragraph" id="p-0544" num="0543">An image is layered as mentioned above, and thus various quality images can be easily obtained depending on circumstances. For example, image compression information of only a base layer is transmitted to a terminal having low processing performance, such as a mobile phone, so that a moving image of which spatial and temporal resolution is low or image quality is low is reproduced, and image compression information of an enhancement layer as well as a base layer is transmitted to a terminal with high processing performance, such as a television set or a personal computer, so that, a moving image of which spatial and temporal resolution is high or image quality is high is reproduced. In this way, image compression information can be transmitted from a server depending on a terminal or network performance without performing a trans code process.</div>
<div class="description-paragraph" id="p-0545" num="0544">A layer image as in the example of <figref idrefs="DRAWINGS">FIG. 78</figref> is coded/decoded, an image of each layer is coded/decoded, the above-described method of the first embodiment may be applied to coding/decoding of each layer. In this way, a decoded image can be converted into a desired image with a different dynamic range.</div>
<div class="description-paragraph" id="p-0546" num="0545">In addition, in coding/coding of each layer, the flag or the parameter used in the method of the first embodiment may be shared. More specifically, for example, the syntax element or the like of the knee_function_info SEI may be shared in coding/decoding of each layer. Of course, necessary information other than these elements may be shared in coding/decoding of each layer.</div>
<div class="description-paragraph" id="p-0547" num="0546">In this way, it is possible to minimize transmission of redundant information and thus to reduce transmitted information amount (bit rate) (that is, it is possible to minimize a reduction in coding efficiency).</div>
<div class="description-paragraph" id="p-0548" num="0547">[Scalable Parameters]</div>
<div class="description-paragraph" id="p-0549" num="0548">In such layer image coding and layer image decoding (scalable coding and scalable decoding), a parameter having a scalable function is arbitrary. For example, a spatial resolution as illustrated in <figref idrefs="DRAWINGS">FIG. 79</figref> may be a parameter (spatial scalability). In a case of the spatial scalability, a resolution of an image is different for each layer. In other words, in this case, as illustrated in <figref idrefs="DRAWINGS">FIG. 79</figref>, each picture is generated as two layers including a base layer of which a spatial resolution is lower than that of an original image, and an enhancement layer which allows an original spatial resolution to be obtained through combination with the base layer. Of course, the number of layers is an example, and any number of layers may be generated.</div>
<div class="description-paragraph" id="p-0550" num="0549">In addition, as a parameter which gives such scalability, for example, a temporal resolution may be employed (temporal scalability) as illustrated in <figref idrefs="DRAWINGS">FIG. 80</figref>. In a case of the temporal scalability, a frame rate is different for each layer. In other words, in this case, as illustrated in <figref idrefs="DRAWINGS">FIG. 80</figref>, each picture is generated as two layers including a base layer of which a frame rate is lower than that of an original moving image, and an enhancement layer which allows an original frame rate to be obtained through combination with the base layer. Of course, the number of layers is an example, and any number of layers may be generated.</div>
<div class="description-paragraph" id="p-0551" num="0550">Further, as a parameter which gives such scalability, for example, a signal to noise ratio (SNR) may be employed (SNR scalability). In a case of the SNR scalability, an SNR is different for each layer. In other words, in this case, as illustrated in <figref idrefs="DRAWINGS">FIG. 81</figref>, each picture is generated as two layers including a base layer of which an SNR is lower than that of an original image, and an enhancement layer which allows an original SNR to be obtained through combination with the base layer. Of course, the number of layers is an example, and any number of layers may be generated.</div>
<div class="description-paragraph" id="p-0552" num="0551">Parameters which give scalability may use parameters other than the above-described examples. For example, as a parameter which gives scalability, a bit depth may be used (bit-depth scalability). In a case of the bit-depth scalability, a bit depth is different for each layer. In this case, for example, a base layer is formed by an 8-bit image, and an enhancement layer is added thereto so that a 10-bit image can be obtained.</div>
<div class="description-paragraph" id="p-0553" num="0552">In addition, as a parameter which gives scalability, a chroma format may be used (chroma scalability). In a case of the chroma, scalability, a chroma format is different for each layer. In this case, for example, a base layer is formed by a component image with a 4:2:0 format, and an enhancement layer is added thereto so that a component image with a 4:2:2 format can be obtained.</div>
<div class="description-paragraph" id="p-0554" num="0553">Further, as a parameter which gives scalability, a dynamic range of luminance may be used (DR scalability). In a case of the DR scalability, a dynamic range of luminance is different for each layer. In this case, for example, a base layer is formed by an SDR image, and an enhancement layer is added thereto so that an HDR image can be obtained.</div>
<div class="description-paragraph" id="p-0555" num="0554">In a case of applying the above-described series of processes to the dynamic range scalability, for example, information regarding knee decompression from an SDR image to an HDR image is set in a coded stream of a base layer image as DR conversion information. In addition, information regarding knee compression of a dynamic range of luminance of a HDR image is set in a coded stream of an enhancement layer image as DR conversion information.</div>
<div class="description-paragraph" id="p-0556" num="0555">In addition, a decoding device, which can decode only a coded stream of a base layer image and includes an HDR display, converts an SDR image which is a decoded image into an HDR image on the basis of the DR conversion information, and sets the HDR image as a display image. On the other hand, a decoding device, which can also decode a coded stream of an enhancement layer image and includes an HDR display which can display an HDR image with a low dynamic range, knee-compresses a dynamic range of luminance of an HDR image which is a decoded image on the basis of the DR conversion information, and sets a result thereof as a display image.</div>
<div class="description-paragraph" id="p-0557" num="0556">Further, information on decompression of a dynamic range of luminance of an HDR image may be set in a coded stream of an enhancement layer image as DR conversion information. In this case, a decoding device, which can also decode a coded stream of an enhancement layer image and includes an HDR display which can display an HDR image with a high dynamic range, knee-decompresses a dynamic range of luminance of an HDR image which is a decoded image on the basis of the DR conversion information, and sets a result thereof as a display image.</div>
<div class="description-paragraph" id="p-0558" num="0557">As mentioned above, the DR conversion information is set in a coded stream of a base layer image or an enhancement layer image, and thus it is possible to display an image which is more suitable for display performance.</div>
<div class="description-paragraph" id="p-0559" num="0558">[Layer Image Coding Device]</div>
<div class="description-paragraph" id="p-0560" num="0559"> <figref idrefs="DRAWINGS">FIG. 82</figref> is a diagram illustrating a layer image coding device which performs the above-described layer image coding. As illustrated in <figref idrefs="DRAWINGS">FIG. 82</figref>, the layer image coding device <b>620</b> includes a coding unit <b>621</b>, a coding unit <b>622</b>, and a multiplexer <b>623</b>.</div>
<div class="description-paragraph" id="p-0561" num="0560">The coding unit <b>621</b> codes a base layer image so as to generate a base layer image coded stream. The coding unit <b>622</b> codes a non-base layer image so as to generate a non-base layer image coded stream. The multiplexer <b>623</b> multiplexes the base layer image coded stream generated in the coding unit <b>621</b> and the non-base layer image coded stream generated in the coding unit <b>622</b>, so as to generate a layer image coded stream.</div>
<div class="description-paragraph" id="p-0562" num="0561">The coding device <b>10</b> (<figref idrefs="DRAWINGS">FIG. 6</figref>) is applicable to the coding unit <b>621</b> and the coding unit <b>622</b> of the layer image coding device <b>620</b>. In other words, in coding of each layer, an image can be coded so that a decoded, image can be converted into a desired image with a different dynamic range during decoding. In addition, the coding unit <b>621</b> and the coding unit <b>622</b> can perform control or the like of an intra-prediction filter process (that is, a flag or a parameter can be shared) by using the mutually same flags or parameters (for example, a syntax element or the like regarding a process of images), and thus it is possible to minimize a reduction in coding efficiency.</div>
<div class="description-paragraph" id="p-0563" num="0562">[Layer Image Decoding Device]</div>
<div class="description-paragraph" id="p-0564" num="0563"> <figref idrefs="DRAWINGS">FIG. 83</figref> is a diagram illustrating a layer image decoding device which performs the above-described layer image decoding. As illustrated in <figref idrefs="DRAWINGS">FIG. 83</figref>, the layer image decoding device <b>630</b> includes a demultiplexer <b>631</b>, a decoding unit <b>632</b>, and a decoding unit <b>633</b>.</div>
<div class="description-paragraph" id="p-0565" num="0564">The demultiplexer <b>631</b> demultiplexes the layer image coded stream Into which the base layer image coded stream and the non-base layer image coded stream are multiplexed, so as to extract the base layer image coded stream and the non-base layer image coded stream. The decoding unit <b>632</b> decodes the base layer image coded stream extracted by the demultiplexer <b>631</b> so as to obtain a base layer image. The decoding unit <b>633</b> decodes the non-base layer image coded stream extracted by the demultiplexer <b>631</b>, so as to obtain a non-base layer image.</div>
<div class="description-paragraph" id="p-0566" num="0565">The decoding device <b>50</b> (<figref idrefs="DRAWINGS">FIG. 12</figref>) is applicable to the decoding unit <b>632</b> and the coding unit <b>633</b> of the layer image decoding device <b>630</b>. In other words, in decoding of each layer, a decoded image can be converted into a desired image with a different dynamic range. In addition, the decoding unit <b>612</b> and the decoding unit <b>613</b> can perform coding (that is, a flag or a parameter can be shared) by using the mutually same flags or parameters (for example, a syntax element or the like regarding a process of images), and thus it is possible to minimize a reduction in coding efficiency.</div>
<heading id="h-0019">Eighth Embodiment</heading>
<div class="description-paragraph" id="p-0567" num="0566">(Configuration Example Of Television Apparatus)</div>
<div class="description-paragraph" id="p-0568" num="0567"> <figref idrefs="DRAWINGS">FIG. 84</figref> exemplifies a television apparatus to which the present technology is applied. The television apparatus <b>900</b> includes an antenna <b>901</b>, a tuner <b>902</b>, a demultiplexer <b>903</b>, a decoder <b>904</b>, a video signal processing unit <b>905</b>, a display unit <b>906</b>, an audio signal processing unit <b>907</b>, a speaker <b>908</b>, and an external interface unit <b>909</b>. In addition, the television apparatus <b>900</b> includes a control unit <b>910</b>, a user interface <b>911</b>, and the like.</div>
<div class="description-paragraph" id="p-0569" num="0568">The tuner <b>902</b> selects a desired channel from a broadcast signal which is received via the antenna <b>901</b>, demodulates the selected channel, and outputs a coded, bit stream which is obtained through demodulation, to the demultiplexer <b>903</b>.</div>
<div class="description-paragraph" id="p-0570" num="0569">The demultiplexer <b>903</b> extracts a video or an audio packet of a program which is a viewing target from the coded bit stream, and outputs the data on the extracted packet to the decoder <b>904</b>. In addition, the demultiplexer <b>903</b> supplies a packet of data such as electronic program guide (EPG) to the control unit <b>910</b>. Further, the demultiplexer or the like may per form descrambling when the coded stream is scrambled.</div>
<div class="description-paragraph" id="p-0571" num="0570">The decoder <b>904</b> decodes the packet, and outputs video data and audio data generated through the decoding to the video signal processing unit <b>905</b> and the audio signal processing unit <b>907</b>, respectively.</div>
<div class="description-paragraph" id="p-0572" num="0571">The video signal processing unit <b>905</b> performs noise removal or a video process or the like in accordance; with user's settings on the video data. The video signal processing unit <b>905</b> generates video data of a program which is displayed on the display unit <b>906</b>, or image data or the like through a process based on an application which is supplied via a network. In addition, the video signal processing unit <b>905</b> generates video data for displaying a menu screen such as selection of items, and superimposes the video data on the video data of a program. The video signal processing unit <b>905</b> generates a driving signal on the basis of the video data generated in this way, so as to generate the display unit <b>906</b>.</div>
<div class="description-paragraph" id="p-0573" num="0572">The display unit <b>906</b> drives a display device (for example, a liquid crystal display element) on the basis of the driving signal from the video signal processing unit <b>905</b> so as to display a video of a program or the like.</div>
<div class="description-paragraph" id="p-0574" num="0573">The audio signal processing unit <b>907</b> performs a process such as noise removal on the audio data, and performs D/A conversion or amplification on the processed audio data which is then supplied to the speaker <b>908</b>, thereby outputting sounds.</div>
<div class="description-paragraph" id="p-0575" num="0574">The external interface unit <b>909</b> is an interface for connection to an external apparatus or the network, and transmits and receives data such as video data or audio data.</div>
<div class="description-paragraph" id="p-0576" num="0575">The control unit <b>901</b> is connected to the user interface unit <b>911</b>. The user interface unit <b>911</b> is constituted by an operation switch, a remote control signal reception portion, and the like, and supplies an operation signal corresponding to a user's operation to the control unit <b>910</b>.</div>
<div class="description-paragraph" id="p-0577" num="0576">The control unit <b>910</b> is formed by using a central processing unit (CPU), memories, and the like. The memories store a program executed by the CPU, a variety of data which is necessary in the CPU performing a process, EPS data, data acquired via the network, and the like. The program stored in the memories is read and executed by the CPU, for example, when the television apparatus <b>900</b> is started. The CPU executes the program, and thus controls each unit so that the television apparatus <b>900</b> performs an operation responding to a user's operation.</div>
<div class="description-paragraph" id="p-0578" num="0577">In addition, the television apparatus <b>900</b> is provided with a bus <b>912</b> which connects the tuner <b>902</b>, the demultiplexer <b>903</b>, the video signal processing unit <b>905</b>, the audio signal processing unit <b>907</b>, the external interface unit <b>909</b>, and the control unit <b>910</b>, to each other.</div>
<div class="description-paragraph" id="p-0579" num="0578">In the television apparatus having the configuration, a function of the decoding device (decoding method) of the present application is provided in the decoder <b>904</b>. For this reason, it is possible to convert a decoded image into a desired image with a different dynamic range.</div>
<heading id="h-0020">Ninth Embodiment</heading>
<div class="description-paragraph" id="p-0580" num="0579">(Configuration Example of Mobile Phone)</div>
<div class="description-paragraph" id="p-0581" num="0580"> <figref idrefs="DRAWINGS">FIG. 85</figref> exemplifies a schematic configuration of a mobile phone to which the present disclosure is applied. The mobile phone <b>920</b> includes a communication unit <b>922</b>, an audio codec <b>923</b>, a camera unit <b>926</b>, an image processing unit <b>927</b>, a multiplexer/demultiplexer <b>928</b>, a recording/reproducing unit <b>929</b>, a display unit <b>930</b>, and a control unit <b>931</b>. Theses constituent elements are connected to each other via a bus <b>933</b>.</div>
<div class="description-paragraph" id="p-0582" num="0581">In addition, the communication unit <b>922</b> is connected to an antenna <b>921</b>, and the audio codec <b>923</b> is connected to a speaker <b>924</b> and a microphone <b>925</b>. Further, the control unit <b>931</b> is connected to an operation unit <b>932</b>.</div>
<div class="description-paragraph" id="p-0583" num="0582">The mobile phone <b>920</b> performs various operations such as transmission and reception of audio signals, transmission and reception of electronic mails or image data, capturing of an image, and recording of data in various operation modes such as a speech mode and a data communication mode.</div>
<div class="description-paragraph" id="p-0584" num="0583">In the speech mode, an audio signal generated by the microphone <b>925</b> undergoes conversion into audio data or data compression in the audio codec <b>923</b>, and is then supplied to the communication unit <b>922</b>. The communication unit <b>922</b> performs a modulation process or a frequency conversion process on the audio data so as to generate a transmission signal. Further, the communication unit <b>922</b> transmits the transmission signal to the antenna <b>921</b> so as to transmit the transmission signal to a base station (not illustrated). Furthermore, the communication unit <b>922</b> performs amplification, a frequency conversion process, and a demodulation process on a signal which is received via the antenna <b>921</b>, and supplies the generated audio data to the audio codec <b>923</b>. The audio codec <b>923</b> performs data decompression on the audio data or converts the audio data into an analog audio signal, and outputs the generated audio signal to the speaker <b>924</b>.</div>
<div class="description-paragraph" id="p-0585" num="0584">Further, in the data communication mode, in a case of transmitting a mail, the control unit <b>931</b> receives text, data which is input by using the operation unit <b>932</b>, and displays the input text, on the display unit <b>930</b>. Moreover, the control unit <b>931</b> generates mail data in response to an instruction made by the user by using the operation unit <b>932</b>, and supplies the generated mail data to the communication unit <b>922</b>. The communication unit <b>922</b> performs a modulation process or a frequency conversion process on the mail data, and transmits the generated transmission signal from the antenna <b>921</b>. Further, the communication unit <b>922</b> performs amplification, a frequency conversion process, and a demodulation process on a signal which is received, via the antenna <b>921</b>, so as to recover mail data. The mail data is supplied to the display unit <b>930</b>, and thus content of the mail is displayed.</div>
<div class="description-paragraph" id="p-0586" num="0585">In addition, the mobile phone <b>920</b> may store the received mail data on a recording medium by using the recording/reproducing unit <b>929</b>. The recording medium is any rewritable recording medium. For example, the recording medium is a semiconductor memory such as a RAM or a built-in flash memory, or a removable medium such as a hard disk, a magnetic disk, a magneto-optical disc, an optical disc, a universal, serial bus (USB) memory, or a memory card.</div>
<div class="description-paragraph" id="p-0587" num="0586">In a case where image data is transmitted in the data communication mode, image data generated by the camera unit <b>926</b> is supplied to the image processing unit <b>927</b>. The image processing unit <b>927</b> performs a coding process on the image data so as to generate coded data.</div>
<div class="description-paragraph" id="p-0588" num="0587">Further, the multiplexer/demultiplexer <b>928</b> multiplexes the image stream which has been generated by the image processing unit <b>927</b> and the audio data which is supplied from the audio codec <b>923</b>, and supplies the multiplexed data to the communication unit <b>922</b>. The communication unit <b>922</b> performs a modulation process or a frequency conversion process on the multiplexed data, and transmits an obtained transmission signal to the antenna <b>921</b>. Furthermore, the communication unit <b>922</b> performs an amplification process, a frequency conversion process, and a demodulation process on a signal which is received via the antenna <b>921</b> so as to recover multiplexed data. The multiplexed data is supplied to the multiplexer/demultiplexer <b>928</b>. The multiplexer/demultiplexer <b>928</b> demultiplexes the multiplexed data, and supplies coded data to the image processing unit <b>927</b> and audio data to the audio codec <b>923</b>. The image processing unit <b>927</b> decodes the coded data so as to generate image data. The image data is supplied to the display unit <b>930</b> so as to allow the received image to be displayed. The audio codec <b>923</b> converts the audio data into an analog audio signal which is then supplied to the speaker <b>924</b> so as to output a received sound.</div>
<div class="description-paragraph" id="p-0589" num="0588">In the mobile phone apparatus having the configuration, functions of the coding device and the decoding device (the coding method and the decoding method) of the present application are provided in the image processing unit <b>927</b>. For this reason, an image can be coded so that a decoded image can be converted into a desired image with a different dynamic range during decoding. In addition, it is possible to convert a decoded image into a desired image with a different dynamic range.</div>
<heading id="h-0021">Tenth Embodiment</heading>
<div class="description-paragraph" id="p-0590" num="0589">(Configuration Example of Recording/Reproducing Apparatus)</div>
<div class="description-paragraph" id="p-0591" num="0590"> <figref idrefs="DRAWINGS">FIG. 86</figref> exemplifies a schematic configuration of a recording/reproducing apparatus to which the present technology is applied. The recording/reproducing apparatus <b>940</b> records, for example, audio data and video data of a received broadcast program on a recording medium, and provides the recorded data to a user at a timing responding to an instruction from, the user. In addition, the recording/reproducing apparatus <b>940</b> may acquire, for example, audio data and image data from other apparatuses, and may record the data on the recording medium. Further, the recording/reproducing apparatus <b>940</b> codes and outputs the audio data or video data recorded on the recording medium so that image display or sound output can be performed in a monitor device.</div>
<div class="description-paragraph" id="p-0592" num="0591">The recording/reproducing apparatus <b>940</b> includes a tuner <b>941</b>, an external interface unit <b>942</b>, an encoder <b>943</b>, a hard disk drive (HDD) unit <b>944</b>, a disc drive <b>945</b>, a selector <b>946</b>, a decoder <b>947</b>, an on-screen display (OSD) unit <b>948</b>, a control unit <b>949</b>, said a user interface unit <b>950</b>.</div>
<div class="description-paragraph" id="p-0593" num="0592">The tuner <b>941</b> selects a desired channel from, a broadcast signal which is received via an antenna (not illustrated). In addition, the tuner <b>941</b> outputs a coded bit stream which is obtained by demodulating the received signal of the desired channel, to the selector <b>946</b>.</div>
<div class="description-paragraph" id="p-0594" num="0593">The external interface unit <b>942</b> includes any one of an IEEE1394 interface, a network interface, a USB interface, a flash memory interface, or the like. The external interface unit <b>942</b> is an interface which is connected to an external apparatus, a network, a memory card, or the like, and receives data such as video data or audio data to be recorded.</div>
<div class="description-paragraph" id="p-0595" num="0594">The encoder <b>943</b> codes vide data or audio data in a predetermined method in a case where the video data and the audio data supplied from the external interface unit <b>942</b> are not coded, and outputs a coded bit stream to the selector <b>946</b>.</div>
<div class="description-paragraph" id="p-0596" num="0595">The HDD unit <b>944</b> records content data such as a video and a sound, various programs, and other data in a built-in hard disk, and reads the data from the hard disk when the video and the sound are reproduced.</div>
<div class="description-paragraph" id="p-0597" num="0596">The disc drive <b>945</b> records and reproduces data on and from an optical disc which is installed therein. The optical disc may be, for example, a DVD disc (DVD-Video, DVD-RAM, DVD-R, DVD-RW, DVD+R, DVD+RW, or the like), a Blu-ray (registered trademark) disc, or the like.</div>
<div class="description-paragraph" id="p-0598" num="0597">When a video and a sound, are recorded, the selector <b>946</b> selects a coded bit stream which is input from the tuner <b>941</b> or the encoder <b>943</b>, and outputs the selected coded bit stream to the HDD unit <b>944</b> or the disc drive <b>945</b>. In addition, when, a video and a sound are reproduced, the selector <b>946</b> outputs a coded bit stream which is output from the HDD unit <b>944</b> or the disc drive <b>945</b>, to the decoder <b>947</b>.</div>
<div class="description-paragraph" id="p-0599" num="0598">The decoder <b>947</b> decodes the coded bit stream. In addition, the decoder <b>947</b> supplies video data generated through the decoding process, to the OSD unit <b>948</b>. Further, the decoder <b>947</b> outputs audio data generated through the decoding process.</div>
<div class="description-paragraph" id="p-0600" num="0599">The OSD unit <b>948</b> generates video data for displaying a menu screen such as selection of items, and superimposes and outputs the video data on video data which is output, from the decoder <b>947</b>.</div>
<div class="description-paragraph" id="p-0601" num="0600">The control unit <b>949</b> is connected to the user interface unit <b>950</b>. The user interface unit <b>950</b> is constituted by an operation switch, a remote control signal reception portion, and the like, and supplies an operation signal corresponding to a user's operation to the control unit <b>949</b>.</div>
<div class="description-paragraph" id="p-0602" num="0601">The control unit <b>949</b> is formed by using a central processing unit (CPU), memories, and the like. The memories store a program executed by the CPU, a variety of data which is necessary in the CPU performing a process, EPG data, data acquired via the network, and the like. The program stored in the memories is read and executed by the CPU at a predetermined timing, for example, when the recording/reproducing apparatus <b>940</b> is started. The CPU executes the program, and thus controls each unit so that the recording/reproducing apparatus <b>940</b> performs an operation responding to a user's operation.</div>
<div class="description-paragraph" id="p-0603" num="0602">In the recording/reproducing apparatus having the configuration, a function of the decoding device (decoding method) of the present application is provided in the decoder <b>947</b>. For this reason, it is possible to convert a decoded image into a desired image with a different dynamic range.</div>
<heading id="h-0022">Eleventh Embodiment</heading>
<div class="description-paragraph" id="p-0604" num="0603">(Configuration Example of Imaging Apparatus)</div>
<div class="description-paragraph" id="p-0605" num="0604"> <figref idrefs="DRAWINGS">FIG. 87</figref> exemplifies a schematic configuration of an imaging apparatus to which the present technology is applied. The imaging apparatus <b>960</b> captures an image of a subject, and displays the image of the subject on a display unit or records the image on a recording medium as image data.</div>
<div class="description-paragraph" id="p-0606" num="0605">The imaging apparatus <b>960</b> includes an optical block <b>961</b>, an imaging unit <b>962</b>, a camera signal processing unit <b>963</b>, an image data processing unit <b>964</b>, a display unit <b>965</b>, an external interface unit <b>966</b>, a memory unit <b>967</b>, a medium drive <b>968</b>, an OSD unit <b>969</b>, and a control unit <b>970</b>. In addition, the control unit <b>970</b> is connected to a user interface <b>971</b>. Further, the image data processing unit <b>964</b>, the external interface unit <b>966</b>, the memory unit <b>967</b>, the medium drive <b>968</b>, the OSD unit <b>969</b>, the control unit <b>970</b>, and the like are connected to each other via a bus <b>972</b>.</div>
<div class="description-paragraph" id="p-0607" num="0606">The optical block <b>961</b> includes a focus lens, a diaphragm mechanism, and the like. The optical block <b>961</b> forms an optical image of a subject on an imaging surface of the imaging unit <b>962</b>. The imaging unit <b>962</b> includes an image sensor such as a CCD or a CMOS, and generates an electrical signal corresponding to the optical image through photoelectric conversion, and supplies the electrical signal to the camera signal processing unit <b>963</b>.</div>
<div class="description-paragraph" id="p-0608" num="0607">The camera signal processing unit <b>963</b> performs various camera signal processes such as knee correction, gamma correction, and color correction, on the image signal which is input from the imaging unit <b>962</b>. The camera signal processing unit <b>963</b> supplies the image data having undergone the camera signal processes to the image data processing unit <b>964</b>.</div>
<div class="description-paragraph" id="p-0609" num="0608">The image data processing unit <b>964</b> codes the image data which is supplied from the camera signal processing unit <b>963</b>. The image data processing unit <b>964</b> supplies coded data generated through the coding process to the external interface unit <b>966</b> or the medium, drive <b>968</b>. Further, the image data processing unit <b>964</b> decodes the coded data which is supplied from the external interface unit <b>966</b> or the medium drive <b>968</b>. Furthermore, the image data processing unit <b>964</b> supplies image data generated through the decoding process to the display unit <b>965</b>. Moreover, the image data processing unit <b>964</b> supplies image data which is supplied from the camera signal processing unit <b>963</b>, to the display unit <b>965</b>, or superimposes display data which is acquired from the OSD unit <b>969</b>, on image data which is then output to the display unit <b>965</b>.</div>
<div class="description-paragraph" id="p-0610" num="0609">The OSD unit <b>969</b> generates and outputs display data such as a menu screen formed by symbols, characters, or figures, or an icon, to the image data processing unit <b>964</b>.</div>
<div class="description-paragraph" id="p-0611" num="0610">The external interface unit <b>966</b> is formed by, for example, a USB input and output terminal, and is connected to a printer when an image is printed. In addition, the external interface unit <b>966</b> is connected to a drive as necessary. A removable medium, such as a magnetic disk or an optical disc is installed in the drive as appropriate, and a computer program read from, the removable medium is installed therein as necessary. Further, the external interface unit <b>966</b> includes a network interface which is connected to a predetermined network such as a LAN or the Internet. The control unit <b>970</b> may read coded data from the medium drive <b>968</b>, for example, in response to an instruction from the user interface <b>971</b>, and may supply the coded data to other apparatuses which is connected thereto via the network, from the external interface unit <b>966</b>. In addition, the control unit <b>970</b> may acquire coded data or image which is supplied from other apparatuses via the network, through the external interface unit <b>966</b>, and may supply the data to the image data processing unit <b>964</b>.</div>
<div class="description-paragraph" id="p-0612" num="0611">A recording medium driven by the medium drive <b>968</b> may be any readable and writable removable medium such as a magnetic disk, a magneto-optical disc, an optical disc, or a semiconductor memory. In addition, the recording medium may be any kind of removable medium, may be a tape device, may be a disk, and may be a memory card. Of course, a noncontact integrated circuit (IC) card or the like may be used.</div>
<div class="description-paragraph" id="p-0613" num="0612">Further, the medium drive and a recording medium may be integrally formed so as to be constituted by a non-portable storage unit such as a built-in hard, disk drive or a solid state drive (SSD).</div>
<div class="description-paragraph" id="p-0614" num="0613">The control unit <b>970</b> is formed by using a CPU. The memory unit <b>967</b> stores a program executed by the control unit <b>970</b>, a variety of data which is necessary in the control unit <b>970</b> performing a process, and the like. The program stored in the memory unit <b>967</b> is read and executed by the control unit <b>970</b>, a predetermined timing, for example, when the imaging apparatus <b>960</b> is started. The control unit <b>970</b> executes the program, and thus controls each unit so that the imaging apparatus <b>960</b> performs an operation responding to a user's operation.</div>
<div class="description-paragraph" id="p-0615" num="0614">In the imaging apparatus having the configuration, functions of the coding device and the decoding device (the coding method and the decoding method) of the present application are provided in the image data processing unit <b>964</b>. For this reason, an image can be coded so that a decoded image can be converted into a desired image with a different dynamic range during decoding. In addition, it is possible to convert a decoded image into a desired image with a different dynamic range.</div>
<div class="description-paragraph" id="p-0616" num="0615">(Application Examples of Scalable Coding)</div>
<div class="description-paragraph" id="p-0617" num="0616">[First System]</div>
<div class="description-paragraph" id="p-0618" num="0617">Next, description will be made of a specific example of using scalable coded (layer coded) data which is seal ably coded. The scalable coding is used, for example, to select data to be transmitted as in an example illustrated in <figref idrefs="DRAWINGS">FIG. 88</figref>.</div>
<div class="description-paragraph" id="p-0619" num="0618">In a data transmission system <b>1000</b> illustrated in <figref idrefs="DRAWINGS">FIG. 88</figref>, a delivery server <b>1002</b> reads the scalable coded data stored in the scalable coded data storage unit <b>1001</b>, and delivers the scalable coded data to terminal apparatuses such as a personal computer <b>1004</b>, an AV apparatus <b>1005</b>, a tablet device <b>1006</b>, and a mobile phone <b>1007</b> via a network <b>1003</b>.</div>
<div class="description-paragraph" id="p-0620" num="0619">At this time, the delivery server <b>1002</b> selects and transmits coded data with appropriate quality on the basis of performances of the terminal apparatuses, communication circumstances, or the like. If the delivery server <b>1002</b> unnecessarily transmits high quality data, it is unable to be said that a high quality image is obtained in the terminal apparatus, and there is a concern that delay or overflow may occur. In addition, there is a concern that high quality data may unnecessarily occupy a communication band, and may unnecessarily increase a load on the terminal apparatus. Conversely, if the delivery server <b>1002</b> unnecessarily transmits low quality data, there is a concern that an image with sufficient image quality may not be obtained in the terminal apparatus. For this reason, the delivery server <b>1002</b> reads and transmits coded data with quality (layer) which is suitable for the performances of the terminal apparatuses or the communication circumstances from the scalable coded data storage unit <b>1001</b>.</div>
<div class="description-paragraph" id="p-0621" num="0620">Here, it is assumed that, the scalable coded data storage unit <b>1001</b> stores scalable coded data (BL+EL) <b>1011</b> which is scalably coded. The scalable coded data (BL+EL) <b>1011</b> is coded data including both a base layer and an enhancement layer, and is data which allows both a base layer image and an enhancement layer image to be obtained through decoding.</div>
<div class="description-paragraph" id="p-0622" num="0621">The delivery server <b>1002</b> selects an appropriate layer on the basis of a performance of a terminal apparatus to which data is transmitted or communication circumstances, and reads data of the layer. For example, the delivery server <b>1002</b> reads the scalable coded data (BL+EL) <b>1011</b> which has high quality from the scalable coded data storage unit <b>1001</b>, and transmits the data as it is, in relation to the personal computer <b>1004</b> or the tablet device <b>1006</b> having a high processing performance. In contrast, for example, in relation to the AV apparatus <b>1005</b> or the mobile phone <b>1007</b> having a low processing performance, the delivery server <b>1002</b> extracts base layer data from the scalable coded, data (BL+BL) <b>1011</b>, and transmits the data as scalable coded data (BL) <b>1012</b> which is the same content data as the scalable coded data (BL+EL) <b>1011</b> in terms of content but has lower quality than the scalable coded, data (BL+EL) <b>1011</b>.</div>
<div class="description-paragraph" id="p-0623" num="0622">As mentioned above, since a data amount can be easily adjusted by using the scalable coded data, it is possible to minimize the occurrence of delay or overflow or to minimize an unnecessary increase in a load on a terminal apparatus or a communication medium. In addition, redundancy between layers is reduced in the scalable coded data (BL+EL) <b>1011</b>, and thus a data amount thereof can be further reduced than in a case where coded data of each layer is used as separate data. Therefore, a storage region of the scalable coded data storage unit <b>1001</b> can be used more efficiently.</div>
<div class="description-paragraph" id="p-0624" num="0623">In addition, various apparatuses such as the personal computer <b>1004</b> to the mobile phone <b>1007</b> can be employed as terminal apparatuses and thus performances of hardware of the terminal apparatuses are different depending on the apparatuses. Further, there are various applications which are executed by the terminal apparatuses, and thus there are also various performances of software thereof. Furthermore, all communication line networks including a wired network, a wireless network, or both networks such as, for example, the Internet or a local area network (LAN) can be employed as the network <b>1003</b> which is a communication medium, and there are various data transmission performances. Moreover, there is a concern that a data transmission performance may vary depending on other communication circumstances or the like.</div>
<div class="description-paragraph" id="p-0625" num="0624">Therefore, before starting data transmission, the delivery server <b>1002</b> may perform communication with a terminal apparatus which is a transmission destination of the data, so as to obtain information regarding performances of the terminal apparatus such as a hardware performance of the terminal apparatus and a performance of an application (software) executed by the terminal apparatus, and information regarding communication circumstances such as an available bandwidth of the network <b>1003</b>. In addition, the delivery server <b>1002</b> may select an appropriate layer on the basis of the information obtained here,</div>
<div class="description-paragraph" id="p-0626" num="0625">Further, the extraction of a layer may be performed by the terminal apparatus. For example, the personal computer <b>1004</b> may decode the transmitted scalable coded data (BL+EL) <b>1011</b> so as to display a base layer image and display an enhancement layer image. Furthermore, for example, the personal computer <b>1004</b> may extract, the base layer scalable coded data (BL) <b>1012</b> from the transmitted scalable coded data (BL+EL) <b>1011</b> so as to store the data, to transmit the data to other devices, or to decode the data for display of a base layer image.</div>
<div class="description-paragraph" id="p-0627" num="0626">Of course, the number of scalable coded data storage units <b>1001</b>, the number of delivery servers <b>1002</b>, the number of networks <b>1003</b>, and the number of terminal apparatuses are all arbitrary. In addition, in the above description, a description has been made of an example in which the delivery server <b>1002</b> transmits data to the terminal apparatus, but a usage example is not limited thereto. The data transmission system <b>1000</b> is applicable to any system as long as the system selects and transmits an appropriate layer on the basis of a performance of a terminal apparatus, communication circumstances, or the like when coded, data which is scalably coded, is transmitted to the terminal apparatus.</div>
<div class="description-paragraph" id="p-0628" num="0627">[Second System]</div>
<div class="description-paragraph" id="p-0629" num="0628">The scalable coding is used, for example, for transmission using a plurality of communication media as in an example illustrated in <figref idrefs="DRAWINGS">FIG. 89</figref>.</div>
<div class="description-paragraph" id="p-0630" num="0629">In a data transmission system <b>1100</b> illustrated in <figref idrefs="DRAWINGS">FIG. 89</figref>, a broadcasting station <b>1101</b> transmits base layer scalable coded data (BL) <b>1121</b> by using a terrestrial broadcast <b>1111</b>. In addition, the broadcasting station <b>1101</b> transmits (for example, packetizes and transmits) enhancement layer scalable coded data (EL) <b>1122</b> via any network <b>1112</b> formed by a wired network, a wireless network, or both networks.</div>
<div class="description-paragraph" id="p-0631" num="0630">A terminal apparatus <b>1102</b> has a reception function of the terrestrial broadcast <b>1111</b> which is broadcasted by the broadcasting station <b>1101</b>, and receives the base layer scalable coded data (BL) <b>1121</b> which is transmitted via the terrestrial broadcast <b>1111</b>. In addition, the terminal apparatus <b>1102</b> further has a communication function of performing communication using the network <b>1112</b>, and receives the enhancement layer scalable coded data (EL) <b>1122</b> which is transmitted via the network <b>1112</b>.</div>
<div class="description-paragraph" id="p-0632" num="0631">The terminal apparatus <b>1102</b> may decode the base layer scalable coded data (BL) <b>1121</b> which is acquired via the terrestrial broadcast <b>1111</b>, for example, in response to an instruction from a user, so as to obtain a base layer image, to store the image, and to transmit the image to other apparatuses.</div>
<div class="description-paragraph" id="p-0633" num="0632">In addition, for example, in response to an instruction from a user, the terminal apparatus <b>1102</b> may combine the base layer scalable coded, data (BL) <b>1121</b> which is acquired via the terrestrial broadcast <b>1111</b> with the non-base layer scalable coded data (EL) <b>1122</b> which is acquired via the network <b>1112</b> so as to obtain scalable coded data (BL+EL), and may decode the data so as to obtain a base layer image, to store the image, and to transmit the image to other apparatuses.</div>
<div class="description-paragraph" id="p-0634" num="0633">As mentioned, above, the scalable coded data may be transmitted via a communication medium which is different for each layer, for example. In this case, a load can be distributed, and thus it is possible to minimize the occurrence of delay or overflow.</div>
<div class="description-paragraph" id="p-0635" num="0634">In addition, a communication medium used, for transmission may be selected for each layer depending on circumstances. For example, the base layer scalable coded data (BL) <b>1121</b> having a relatively large amount of data may be transmitted, via a communication media having a wide bandwidth, and the enhancement layer scalable coded data (EL) <b>1122</b> having a relatively small amount of data may be transmitted via a communication medium having a narrow bandwidth. In addition, for example, a communication medium for transmitting the enhancement layer scalable coded data (EL) <b>1122</b> may be changed between the network <b>1112</b> and the terrestrial broadcast <b>1111</b> depending on an available bandwidth of the network <b>1112</b>. Of course, this is also the same for data of any layer.</div>
<div class="description-paragraph" id="p-0636" num="0635">The control is performed as mentioned above, and thus it is possible to further minimize an increase in a load in data transmission.</div>
<div class="description-paragraph" id="p-0637" num="0636">Of course, the number of layers is arbitrary, and the number of communication media used for transmission is also arbitrary. Further, the number of terminal apparatuses <b>1102</b> serving as a data transmission destination is also arbitrary. Furthermore, in the above description, the description has been made of broadcasting from the broadcasting station <b>1101</b> as an example, but a usage example is not limited thereto. The data transmission system <b>1100</b> is applicable to any system as long as the system splits coded data which is scalably coded into a plurality of data, items in the unit of layers and transmits the data items via a plurality of lines.</div>
<div class="description-paragraph" id="p-0638" num="0637">[Third System]</div>
<div class="description-paragraph" id="p-0639" num="0638">The scalable coding is used, for example, to store coded data as in an example, illustrated in <figref idrefs="DRAWINGS">FIG. 90</figref>.</div>
<div class="description-paragraph" id="p-0640" num="0639">In an imaging system <b>1200</b> illustrated in <figref idrefs="DRAWINGS">FIG. 90</figref>, an imaging apparatus <b>1201</b> scalably codes image data which is obtained by imaging a subject <b>1211</b>, and supplies resultant data to a scalable coded data storage device <b>1202</b> as scalable coded data (BL+EL) <b>1221</b>.</div>
<div class="description-paragraph" id="p-0641" num="0640">The scalable coded data storage device <b>1202</b> stores the scalable coded data (BL+EL) <b>1221</b> which is supplied from, the imaging apparatus <b>1201</b>, with quality based on circumstances. For example, in a case of the normal time, the scalable coded data storage device <b>1202</b> extracts base layer data from the scalable coded data (BL+EL) <b>1221</b>, and stores the data as base layer scalable coded, data (RL) <b>1222</b> having a small amount of data with low quality. In contrast, for example, in a case of the notice time, the scalable coded data storage device <b>1202</b> stores the scalable coded data (BL+EL) <b>1221</b> having a large amount of data with high quality as it is.</div>
<div class="description-paragraph" id="p-0642" num="0641">Accordingly, since the scalable coded data storage device <b>1202</b> can preserve a high quality image as necessary only, it is possible to minimize an increase in a data amount while minimizing a reduction in the value of an image due to image quality deterioration, and thus to improve use efficiency of a storage region.</div>
<div class="description-paragraph" id="p-0643" num="0642">For example, the imaging apparatus <b>1201</b> is assumed to be a monitoring camera. In a case (a case of the normal time) where a monitoring target (for example, an trespasser) is not reflected in a captured image, there is a high probability that content of the captured image may not be important, and thus a reduction in a data amount is prioritized, and the image data (scalable coded data) is stored with low quality. In contrast, in a case (a case of the notice time) where a monitoring target is reflected in a captured image as the subject <b>1211</b>, there is a high probability that content of the captured image may be important, and thus image quality is prioritized, and the image data (scalable coded data) is stored with high quality.</div>
<div class="description-paragraph" id="p-0644" num="0643">In addition, the normal time arid the notice time may be determined, for example, by the scalable coded data storage device <b>1202</b> analyzing an image. Further, the normal time and the notice time may be determined, for example, by the imaging apparatus <b>1201</b>, and a determination result may be transmitted to the scalable coded data storage device <b>1202</b>.</div>
<div class="description-paragraph" id="p-0645" num="0644">In addition, a determination criterion of the normal time and the notice time is arbitrary, and content of a captured image which is used as a determination criterion is arbitrary. Of course, conditions other than the content of a captured image may be used as a determination criterion. For example, the normal time and the notice time may be changed on the basis of the magnitude, a waveform, or the like of a recorded sound, and may be changed, for example, for each predetermined time interval, or by an external instruction such as an instruction from a user.</div>
<div class="description-paragraph" id="p-0646" num="0645">In addition, in the above description, an example of changing two states including the normal time, and the notice time has been described, but the number of states is arbitrary, and, for example, three or more states such as the normal time, the slight notice time, the notice time, the great notice time, may be changed. Here, an upper limit number of changed states depends on the number of layers of scalable coded data.</div>
<div class="description-paragraph" id="p-0647" num="0646">In addition, the imaging apparatus <b>1201</b> may determine the number of scalable coded layers on the basis of a state. For example, in a case of the normal time, the imaging apparatus <b>1201</b> may generate the base layer scalable coded, data (BL) <b>1222</b> having a small amount of data with low quality, and may supply the data to the scalable coded data storage device <b>1202</b>. Further, for example, in a case of the notice time, the imaging apparatus <b>1201</b> may generate the base layer and non-base layer scalable coded data (BL+EL) <b>1221</b> having a large amount of data with high quality, and may supply the data to the scalable coded, data storage device <b>1202</b>.</div>
<div class="description-paragraph" id="p-0648" num="0647">In the above description, the description has been made of the monitoring camera as an example, but usage of the imaging system <b>1200</b> is arbitrary and is not limited to a monitoring camera.</div>
<heading id="h-0023">Twelfth Embodiment</heading>
<div class="description-paragraph" id="p-0649" num="0648">Other Examples</div>
<div class="description-paragraph" id="p-0650" num="0649">In the above description, examples of apparatuses or systems to which the present technology is applied have been described, but the present, technology is not limited thereto, and may be realized by ail configurations mounted in a device forming the apparatus or the system, for example, a processor as system large scale integration (LSI) or the like, a module using a plurality of processors, a unit using a plurality of modules, a set in which other functions are added to the unit, and the like (a configuration of a part of an apparatus).</div>
<div class="description-paragraph" id="p-0651" num="0650">(Configuration Example of Video Set)</div>
<div class="description-paragraph" id="p-0652" num="0651">With reference to <figref idrefs="DRAWINGS">FIG. 91</figref>, description will be made of an example in which the present technology is realized by a set. <figref idrefs="DRAWINGS">FIG. 91</figref> illustrates an example of a schematic configuration of a video set to which the present technology is applied.</div>
<div class="description-paragraph" id="p-0653" num="0652">Multi-functioning of an electronic apparatus has recently progressed, and thus there are many cases where, when a partial configuration is sold or provided in development or manufacturing thereof, not only a configuration having a single function is realized but also a set having a plurality of functions through combination of a plurality of configurations having related functions is implemented.</div>
<div class="description-paragraph" id="p-0654" num="0653">A video set <b>1300</b> illustrated in <figref idrefs="DRAWINGS">FIG. 91</figref> has a multi-functional configuration, and is one in which a device having a function regarding coding or decoding (one or both of the coding or decoding may be used) of an image is combined with a device having other functions related to the function.</div>
<div class="description-paragraph" id="p-0655" num="0654">As illustrated in <figref idrefs="DRAWINGS">FIG. 91</figref>, the video set <b>1300</b> includes a module group such as a video module <b>1311</b>, an external memory <b>1312</b>, a power management, module <b>1313</b>, and a front end module <b>1314</b>, and devices having related functions, such as a connectivity <b>1321</b>, a camera <b>1322</b>, and a sensor <b>1323</b>.</div>
<div class="description-paragraph" id="p-0656" num="0655">The module is a component having a unified function by collecting several mutually related component functions. A specific physical configuration of the module is arbitrary, and, for example, a plurality of processors having each function, electronic circuit elements such as resistors and capacitors, other devices, and the like may be disposed on a wiring board and integrally formed. In addition, a module may be combined with other modules, processors, or the like, so as to form a new module.</div>
<div class="description-paragraph" id="p-0657" num="0656">In a case of the example of <figref idrefs="DRAWINGS">FIG. 91</figref>, the video module <b>1311</b> is a combination of configurations having functions regarding image processing, and includes an application processor, a video processor, a broadband modem <b>1333</b>, and an RF module <b>1334</b>.</div>
<div class="description-paragraph" id="p-0658" num="0657">The processor is one in which configurations having predetermined functions are integrated into a semiconductor chip by using a system on a chip (SoC), and there may be a processor which is called, for example, system large scale integration (LSI). The configurations having predetermined functions may be logic circuits (hardware configuration), may be a CPU, a ROM, a RAM, and the like, and programs (software configuration) executed by using the configurations, and may be a combination of both thereof. For example, the process includes a logic circuit, a CPU, a ROM, a RAM, and the like, some functions may be realized by the logic circuit, (hardware configuration), and other functions may be realized by the program (software configuration) executed by the CPU.</div>
<div class="description-paragraph" id="p-0659" num="0658">The application processor <b>1331</b> of <figref idrefs="DRAWINGS">FIG. 91</figref> is a processor which executes an application related to image processing. The application executed by the application processor <b>1331</b> may perform a calculation process in order to realize a predetermined function, and may also control constituent elements inside and outside the video module <b>1311</b>, such as the video processor <b>1332</b>.</div>
<div class="description-paragraph" id="p-0660" num="0659">The video processor <b>1332</b> is a processor having a function related to coding/decoding (one or both thereof) of an image,</div>
<div class="description-paragraph" id="p-0661" num="0660">The broadband modem <b>1333</b> is a processor (or a module) which performs a process related to wired or wireless (or both thereof) broadband communication which is performed via a broadband line such as the Internet or a public telephone line. For example, the broadband modem <b>1333</b> digitally modulates data (digital signal) to be transmitted, for conversion into an analog signal, or demodulates a received analog signal for conversion into data (digital signal). For example, the broadband modem <b>1333</b> can digitally modulate/demodulate any information such as image data processed by the video processor <b>1332</b>, a stream in which the image data is coded, an application program, or setting data.</div>
<div class="description-paragraph" id="p-0662" num="0661">The RF module <b>1334</b> is a module which performs frequency conversion, modulation/demodulation, amplification, filtering, and the like on a radio frequency (RF) signal which is transmitted and received via an antenna. For example, the RF module <b>1334</b> performs frequency conversion or the like on a baseband signal generated by the broadband modem <b>1333</b> so as to generate an RF signal. In addition, for example, the RF module <b>1334</b> performs frequency conversion or the like on an RF signal which is received via the front end module <b>1314</b>, so as to generate a baseband signal.</div>
<div class="description-paragraph" id="p-0663" num="0662">Further, in <figref idrefs="DRAWINGS">FIG. 91</figref>, as indicated by a dotted line <b>1341</b>, the application processor <b>1331</b> and the video processor <b>1332</b> may be integrally formed so as to configure a single processor.</div>
<div class="description-paragraph" id="p-0664" num="0663">The external memory <b>1312</b> is a module which is provided outside the video module <b>1311</b> and includes a storage device used by the video module <b>1311</b>. The storage device of the external memory <b>1312</b> may be implemented by any physical configuration, but is generally used to store a large volume of data such as image data of frame units, and is thus preferably implemented by a large capacity semiconductor memory which is relatively cheap, such as a dynamic random access memory (DRAM).</div>
<div class="description-paragraph" id="p-0665" num="0664">The power management module <b>1313</b> manages and control power which is supplied to the video module <b>1311</b> (each constituent element in the video module <b>1311</b>).</div>
<div class="description-paragraph" id="p-0666" num="0665">The front end module <b>1314</b> is a module which provides a front end function (a circuit of a transmission and reception end of an antenna side) to the RF module <b>1334</b>. As illustrated in <figref idrefs="DRAWINGS">FIG. 91</figref>, the front end module <b>1314</b> includes, for example, an antenna portion <b>1351</b>, a filter <b>1352</b>, and an amplification portion <b>1353</b>.</div>
<div class="description-paragraph" id="p-0667" num="0666">The antenna portion <b>1351</b> includes an antenna and peripheral constituent elements which transmit and receive a wireless signal. The antenna portion <b>1351</b> transmits a signal which is supplied from the amplification portion <b>1353</b> as a wireless signal, and supplies the received wireless signal to the filter <b>1352</b> as an electrical signal (RF signal). The filter <b>1352</b> performs a filter process on the received RF signal which is received via the antenna portion <b>1351</b>, and supplies a processed RF signal to the RF module <b>1334</b>. The amplification portion <b>1353</b> amplifies the RF signal supplied from the RF module <b>1334</b>, and supplies the amplified signal to the antenna portion <b>1351</b>.</div>
<div class="description-paragraph" id="p-0668" num="0667">The connectivity <b>1321</b> is a module having a function related to connection to an external device. A physical configuration of the connectivity <b>1321</b> is arbitrary. For example, the connectivity <b>1321</b> includes a constituent element having a communication function other than a communication standard supported by the broadband modem <b>1333</b>, an external input and output terminal, and the like.</div>
<div class="description-paragraph" id="p-0669" num="0668">For example, the connectivity <b>1321</b> may include a module having a communication function conforming to a wireless communication standard such as Bluetooth (registered trademark) or IEEE 802.11 (for example, Wireless Fidelity (Wi-Fi, registered trademark), near field communication (NFC), or Infrared Data Association (IrDA)), an antenna which transmits and receives a signal conforming to the standard, and the like. In addition, for example, the connectivity <b>1321</b> may include a module having a communication function conforming to a wired communication standard such as Universal Serial Bus (USB) or High-Definition Multimedia Interface (HDMI) (registered trademark), or a terminal conforming to the standard. Further, for example, the connectivity <b>1321</b> may have other data (signal) transmission functions in an analog input and output terminal or the like.</div>
<div class="description-paragraph" id="p-0670" num="0669">In addition, the connectivity <b>1321</b> may include a device of a transmission destination of data (signal). For example, the connectivity <b>1321</b> may include a drive (including not only a removable medium drive but also a hard disk, a solid, state drive (SSD), and a network attached storage (NSA)) which performs reading or writing of data from or to a recording medium, such as a magnetic disk, an optical disc, a magnet, optical disc, or a semiconductor memory. Further, the connectivity <b>1321</b> may include an image or sound output, device (a monitor, a speaker, or the like).</div>
<div class="description-paragraph" id="p-0671" num="0670">The camera <b>1322</b> is a module having a function of capturing an image of a subject, and acquiring image data of the subject. The image data, acquired by the camera <b>1322</b> capturing an image of the subject is supplied to, for example, the video processor <b>1332</b>, and is coded.</div>
<div class="description-paragraph" id="p-0672" num="0671">The sensor <b>1323</b> is a module having any sensor function, such as an audio sensor, an ultrasonic sensor, an optical sensor, an illuminance sensor, an infrared sensor, an image sensor, a rotation sensor, an angle sensor, an angular velocity sensor, a speed sensor, an acceleration sensor, a tilt sensor, a magnetic identification sensor, an impact, sensor, or a temperature sensor. Data detected by the sensor <b>1323</b> is supplied to, for example, the application processor <b>1331</b>, and is used by an application or the like.</div>
<div class="description-paragraph" id="p-0673" num="0672">In the above description, a configuration described as a module maybe realized, as a processor, and, conversely, a configuration described as a processor may be realized as a module.</div>
<div class="description-paragraph" id="p-0674" num="0673">In the video set <b>1300</b> having the above-described configuration, the present disclosure is applicable to the video processor <b>1332</b> as described later. Therefore, the video set <b>1300</b> may be implemented as a set to which the present technology is applied.</div>
<div class="description-paragraph" id="p-0675" num="0674">(Configuration Example of Video Processor)</div>
<div class="description-paragraph" id="p-0676" num="0675"> <figref idrefs="DRAWINGS">FIG. 92</figref> illustrates an example of a schematic, configuration of the video processor <b>1332</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) to which the present technology is applied.</div>
<div class="description-paragraph" id="p-0677" num="0676">In a case of the example of <figref idrefs="DRAWINGS">FIG. 92</figref>, the video processor <b>1332</b> has a function of receiving a video signal and an audio signal and coding the signals in a predetermined method, and a function of decoding coded video data and audio data, so as to reproduce a video signal and an audio signal.</div>
<div class="description-paragraph" id="p-0678" num="0677">As illustrated in <figref idrefs="DRAWINGS">FIG. 92</figref>, the video processor <b>1332</b> includes a video input processing portion <b>1401</b>, a first image enlargement/reduction portion <b>1402</b>, a second image enlargement/reduction portion <b>1403</b>, a video output processing portion <b>1404</b>, a frame memory <b>1405</b>, and a memory control portion <b>1406</b>. In addition, the video processor <b>1332</b> includes an encode/decode engine <b>1407</b>, video elementary stream (ES) buffers <b>1403</b>A and <b>1408</b>E, and audio ES buffers <b>1409</b>A and <b>1409</b>B. Further, the video processor <b>1332</b> includes an audio encoder <b>1410</b>, an audio decoder <b>1411</b>, a multiplexer (MUX) <b>1412</b>, a demultiplexer (DMUX) <b>1413</b>, and a stream buffer <b>1414</b>.</div>
<div class="description-paragraph" id="p-0679" num="0678">The video input processing portion <b>1401</b> acquires a video signal which is input from, for example, the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) or the like, and converts the video signal into digital image data. The first image enlargement/reduction portion <b>1402</b> performs format conversion or an image enlargement, or reduction process on the image data. The second image enlargement/reduction portion <b>1403</b> performs an image enlargement or reduction process in accordance with a format at a destination of a video which is output, via the video output processing portion <b>1404</b> on the image data, or performs the same format conversion or image enlargement or reduction process as in the first image enlargement./reduction portion <b>1402</b> on the image data. The video output processing portion <b>1404</b> performs format conversion, conversion into an analog signal, or the like on the image data, and outputs a converted signal to, for example, the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) or the like as a reproduced video signal.</div>
<div class="description-paragraph" id="p-0680" num="0679">The frame memory <b>1405</b> is a memory for image data, shared by the video input processing portion <b>1401</b>, the first image enlargement/reduction portion <b>1402</b>, the second image enlargement/reduction portion <b>1403</b>, the video output processing portion <b>1404</b>, and the encode/decode engine <b>1407</b>. The frame memory <b>1405</b> is implemented by a semiconductor memory such as a DRAM.</div>
<div class="description-paragraph" id="p-0681" num="0680">The memory control portion <b>1406</b> receives a synchronization signal from the encode/decode engine <b>1407</b>, and controls writing/reading access to the frame memory <b>1405</b> according to a schedule for access to the frame memory <b>1405</b>, written in an access management table <b>1406</b>A. The access management table <b>1406</b>A is updated by the memory control portion <b>1406</b> in accordance with processes performed by the encode/decode engine <b>1407</b>, the first image enlargement/reduction portion <b>1402</b>, the second image enlargement/reduction portion <b>1403</b>, and the like.</div>
<div class="description-paragraph" id="p-0682" num="0681">The encode/decode engine <b>1407</b> performs an encode process on image data, and a decode process on a video stream which is coded data of image data. For example, the encode/decode engine <b>1407</b> codes image data read from, the frame memory <b>1405</b>, and sequentially writes the coded image data to the video ES buffer <b>1408</b>A as a video stream. In addition, for example, video streams are sequentially read from the video ES buffer <b>1408</b>B so as to be decoded, and are sequentially written to the frame memory <b>1405</b> as image data. The encode/decode engine <b>1407</b> uses the frame memory <b>1405</b> as a work area in the coding or decoding. Further, the encode/decode engine <b>1407</b> outputs an synchronization signal to the memory control portion <b>1406</b>, for example, at a timing of starting a process on each macroblock.</div>
<div class="description-paragraph" id="p-0683" num="0682">The video ES buffer <b>1408</b>A buffers a video stream generated by the encode/decode engine <b>1407</b>, and supplies the buffered video stream to the multiplexer (MUX) <b>1412</b>. The video ES buffer <b>1408</b>B buffers a video stream supplied from, the demultiplexer (DMUX) <b>1413</b>, and supplies the buffered video stream to the encode/decode engine <b>1407</b>.</div>
<div class="description-paragraph" id="p-0684" num="0683">The audio ES buffer <b>1409</b>A buffers an audio stream generated by the audio encoder <b>1410</b>, and supplies the buffered audio stream to the multiplexer (MUX) <b>1412</b>. The audio ES buffer <b>1409</b>B buffers an audio stream supplied from the demultiplexer (DMUX) <b>1413</b>, and supplies the buffered audio stream to the audio decoder <b>1411</b>.</div>
<div class="description-paragraph" id="p-0685" num="0684">The audio encoder <b>1410</b>, for example, digitally converts an audio signal which is input from, for example, the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) or the like, and codes the converted, audio signal in a predetermined method such as an MPEG audio method or AudioCode number 3 (AC3). The audio encoder <b>1410</b> sequentially writes an audio stream which is coded data, of the audio signal to the audio ES buffer <b>1409</b>A. The audio decoder <b>1411</b> decodes an audio stream, supplied, from, the audio ES buffer <b>1409</b>R so as to perform conversion into an analog signal, or the like, and supplies the analog signal to, for example, the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) or the like as a reproduced audio signal.</div>
<div class="description-paragraph" id="p-0686" num="0685">The multiplexer (MUX) <b>1412</b> multiplexes the video stream and the audio stream. A method of the multiplexing (that is, a format of a bit stream generated through the multiplexing) is arbitrary. In addition, during the multiplexing, the multiplexer (MUX) <b>1412</b> may add predetermined header information to a bit stream. In other words, the multiplexer (MUX) <b>1412</b> can convert a format of the stream through the multiplexing. For example, the multiplexer (MUX) <b>1412</b> multiplexes the video stream and the audio stream so as to perform conversion into a transport stream which is a bit stream with a transmission format. Further, for example, the multiplexer (MUX) <b>1412</b> multiplexes the video stream and the audio stream so as to perform conversion into data (file data) with a recording file format.</div>
<div class="description-paragraph" id="p-0687" num="0686">The demultiplexer (DMUX) <b>1413</b> demultiplexes a bit stream into which a video stream and an audio stream are multiplexed, in a method corresponding to the multiplexing by the multiplexer (MUX) <b>1412</b>. In other words, the demultiplexer (DMUX) <b>1413</b> extracts a video stream and an audio stream from a bit stream which is read from the stream buffer <b>1414</b> (separates the video stream and the audio stream therefrom). That is, the demultiplexer (DMUX) <b>1413</b> can convert a format, of the stream through the demultiplexing (inverse conversion of the conversion in the multiplexer (MUX) <b>1412</b>). For example, the demultiplexer (DMUX) <b>1413</b> may acquire a transport stream which is supplied from, for example, the connectivity <b>1321</b> or the broadband modem <b>1333</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>), via the stream buffer <b>1414</b>, and demultiplexes the transport stream so as to perform conversion into a video stream and an audio stream. In addition, for example, the demultiplexer (DMUX) <b>1413</b> may acquire file data which is read from, various recording media by, for example, the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>), via the stream buffer <b>1414</b>, and demultiplexes the transport stream so as to perform conversion into a video stream and an audio stream.</div>
<div class="description-paragraph" id="p-0688" num="0687">The stream buffer <b>1414</b> buffers a bit stream. For example, the stream buffer <b>1414</b> buffers a transport stream supplied from the multiplexer (MUX) <b>1412</b>, and supplies the buffered transport stream to, for example, the connectivity <b>1321</b> or the broadband modem <b>1333</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) at a predetermined timing, or on the basis of a request or the like from an external device.</div>
<div class="description-paragraph" id="p-0689" num="0688">In addition, for example, the stream, buffer <b>1414</b> buffers file data supplied from the multiplexer (MUX) <b>1412</b>, and supplies the buffered file data to, for example, the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) so as to record the file data on various recording media at a predetermined timing, or on the basis of a request or the like from an external device.</div>
<div class="description-paragraph" id="p-0690" num="0689">Further, the stream buffer <b>1414</b> buffers a transport stream which is acquired via, for example, the connectivity <b>1321</b> or the broadband, modem <b>1333</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>), and supplies the buffered transport stream to the demultiplexer (DMUX) <b>1413</b> at a predetermined timing, or on the basis of a request, or the like from an external device.</div>
<div class="description-paragraph" id="p-0691" num="0690">Furthermore, the stream buffer <b>1414</b> buffers file data which is read from various recording media in the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) or the like, and supplies the buffered transport stream to the demultiplexer (DMUX) <b>1413</b> at a predetermined timing, or on the basis of a request or the like from an external device.</div>
<div class="description-paragraph" id="p-0692" num="0691">Next, an example of an operation of the video processor <b>1332</b> having the configuration will be described. For example, a video signal which is input to the video processor <b>1332</b> from the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) or the like is converted into digital image data in a predetermined scheme such as a 4:2:2 Y/Cb/Cr scheme by the video input processing portion <b>1401</b>, and is sequentially written to the frame memory <b>1405</b>. The digital image data is read to the first image enlargement/reduction portion <b>1402</b> or the second image enlargement/reduction portion <b>1403</b>, and undergoes format conversion and an enlargement or reduction process in a predetermined scheme such as a 4:2:0 Y/Cb/Cr scheme so as to be written to the frame memory <b>1405</b> again. The image data is coded by the encode/decode engine <b>1407</b> and is then written to the video ES buffer <b>1408</b>A as a video stream,</div>
<div class="description-paragraph" id="p-0693" num="0692">In addition, an audio signal which is input to the video processor <b>1332</b> from the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) or the like is coded by the audio encoder <b>1410</b>, and is written to the audio ES buffer <b>1409</b>A an audio stream.</div>
<div class="description-paragraph" id="p-0694" num="0693">The video stream of the video ES buffer <b>1408</b>A and the audio stream of the audio ES buffer <b>1409</b>A are read to the multiplexer (MUX) <b>1412</b> so as to be multiplexed and be converted, into a transport stream, file data, or the like. The transport stream generated by the multiplexer (MUX) <b>1412</b> is buffered in the stream buffer <b>1414</b>, and is then output, to an external network via, for example, the connectivity <b>1321</b> or the broadband modem <b>1333</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>). In addition, the file data generated by the multiplexer (MUX) <b>1412</b> is buffered in the stream buffer <b>1414</b>, and is then output to, for example, the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) so as to be recorded on various recording media.</div>
<div class="description-paragraph" id="p-0695" num="0694">Further, a transport stream which is input to the video processor <b>1332</b> from an external network via, for example, the connectivity <b>1321</b> or the broadband modem <b>1333</b> (<figref idrefs="DRAWINGS">FIG. 31</figref>) is buffered in the stream buffer <b>1414</b>, and is then demultiplexed by the demultiplexer (DMUX) <b>1413</b>. Furthermore, for example, file data which is read from various recording media, for example, in the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) and is input to the video processor <b>1332</b> is buffered in the stream buffer <b>1414</b>, and is then demultiplexed by the demultiplexer (DMUX) <b>1413</b>. In other words, the transport stream or the file data which is input, to the video processor <b>1332</b> is separated into a video stream and an audio stream by the demultiplexer (DMUX) <b>1413</b>.</div>
<div class="description-paragraph" id="p-0696" num="0695">The audio stream is supplied to the audio decoder <b>1411</b> via the audio ES buffer <b>1409</b>B so as to be decoded, and to be reproduced as an audio signal. In addition, the video stream which is written to the video ES buffer <b>1408</b>B is then sequentially read by the encode/decode engine <b>1407</b> so as to be decoded and to be written to the frame memory <b>1405</b>. The decoded image data undergoes an enlargement or reduction process in the second image enlargement/reduction portion <b>1403</b> so as to be written to the frame memory <b>1405</b>. Further, the decoded image data is read to the video output processing portion <b>1404</b> so as to undergo format conversion in a predetermined scheme such as a 4:2:2 Y/Cb/Cr scheme and further to undergo conversion into an analog signal, and thus a video signal is reproduced and output.</div>
<div class="description-paragraph" id="p-0697" num="0696">In a case where the present technology is applied to the video processor <b>1332</b> having the configuration, the present, disclosure related to each embodiment described above may be applied to the encode/decode engine <b>1407</b>. In other words, for example, the encode/decode engine <b>1407</b> may have the function of the coding device or the decoding device related to the first embodiment. Accordingly, the video processor <b>1332</b> can achieve the same effects as the effects described with reference to <figref idrefs="DRAWINGS">FIGS. 6 to 13</figref>.</div>
<div class="description-paragraph" id="p-0698" num="0697">In addition, in the encode/decode engine <b>1407</b>, the present technology (that is, the function of the image coding device or the image decoding device related to each embodiment described above) may be realized by hardware such as a logic circuit, may be realized by software such as an embedded program, and may be realized by both thereof.</div>
<div class="description-paragraph" id="p-0699" num="0698">(Another Configuration Example of Video Processor)</div>
<div class="description-paragraph" id="p-0700" num="0699"> <figref idrefs="DRAWINGS">FIG. 93</figref> illustrates another schematic configuration example of the video processor <b>1332</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) to which the present technology is applied. In a case of the example of <figref idrefs="DRAWINGS">FIG. 93</figref>, the video processor <b>1332</b> has a function of coding and decoding video data in a predetermined method.</div>
<div class="description-paragraph" id="p-0701" num="0700">More specifically, as illustrated in <figref idrefs="DRAWINGS">FIG. 93</figref>, the video processor <b>1332</b> includes a control portion <b>1511</b>, a display interface <b>1512</b>, a display engine <b>1513</b>, an image processing engine <b>1514</b>, and an internal memory <b>1515</b>. In addition, the video processor <b>1332</b> includes a codec engine <b>1516</b>, a memory interface <b>1517</b>, a multiplexer/demultiplexer (MUX DEMUX) <b>1518</b>, a network interface <b>1519</b>, and a video interface <b>1520</b>.</div>
<div class="description-paragraph" id="p-0702" num="0701">The control portion <b>1511</b> controls an operation of each processing portion of the video processor <b>1332</b>, such as the display interface <b>1512</b>, the display engine <b>1513</b>, the image processing engine <b>1514</b>, and the codec engine <b>1516</b>.</div>
<div class="description-paragraph" id="p-0703" num="0702">As illustrated in <figref idrefs="DRAWINGS">FIG. 93</figref>, the control portion <b>1511</b> includes, for example, a main CPU <b>1531</b>, a sub-CPU <b>1532</b>, and a system controller <b>1533</b>. The main CPU <b>1531</b> executes a program, or the like for controlling an operation of each processing portion of the video processor <b>1332</b>. The main CPU <b>1531</b> generates a control signal according to the program, or the like, and supplies the control signal to each processing portion (that is, controls an operation of each processing portion). The sub-CPU <b>1532</b> assists the main CPU <b>1531</b>. For example, the sub-CPU <b>1532</b> executes a child process, a sub-routine, or the like of a program executed by the main CPU <b>1531</b>. The system controller <b>1533</b> controls operations of the main CPU <b>1531</b> and the sub-CPU <b>1532</b> by designating a program which is to be executed by the main CPU <b>1531</b> and the sub-CPU <b>1532</b>.</div>
<div class="description-paragraph" id="p-0704" num="0703">The display interface <b>1512</b> outputs image data to, for example, the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 31</figref>) under the control of the control portion <b>1511</b>. For example, the display interface <b>1512</b> converts digital image data into an analog signal and outputs the analog signal to a monitor device or the like of the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 31</figref>), or outputs the digital image data to the monitor device as it is.</div>
<div class="description-paragraph" id="p-0705" num="0704">The display engine <b>1513</b> performs various conversion processes such as format conversion, size conversion, and color gamut conversion on image data, so as to be suitable for a hardware specification of a monitor device or the like which displays an image, under the control of the control portion <b>1511</b>.</div>
<div class="description-paragraph" id="p-0706" num="0705">The image processing engine <b>1514</b> performs a predetermined image process such as a filter process for improving image quality, on the image data, under the control of the control portion <b>1511</b>.</div>
<div class="description-paragraph" id="p-0707" num="0706">The internal memory <b>1515</b> is a memory which is shared by the display engine <b>1513</b>, the image processing engine <b>1514</b>, and the codec engine <b>1516</b>, and is provided in the video processor <b>1332</b>. The internal memory <b>1515</b> is used to transmit and receive data among, for example, the display engine <b>1513</b>, the image processing engine <b>1514</b>, and the codec, engine <b>1516</b>. For example, the internal memory <b>1515</b> stores data supplied from the display engine <b>1513</b>, the image processing engine <b>1514</b>, or the codec engine <b>1516</b>, and supplies the data to the display engine <b>1513</b>, the image processing engine <b>1514</b>, or the codec engine <b>1516</b> as necessary (for example, in response to a request). The internal memory <b>1515</b> may be realized by any storage device, but is generally often used to store a small volume of data such as image data of the block unit or a parameter, and is thus preferably implemented by a semiconductor memory which has a relatively (for example, compared to the external memory <b>1312</b>) small capacity but has a high response speed, such as a static random access memory (SRAM).</div>
<div class="description-paragraph" id="p-0708" num="0707">The codec engine <b>1516</b> performs a process regarding coding or decoding of image data. A coding or decoding method supported by the codec engine <b>1516</b> is arbitrary, and the number thereof may be one, and may be plural. For example, the codec engine <b>1516</b> may have codec functions of a plurality of coding/decoding methods, and may perform coding of image data or decoding of coded data in a method selected from among the methods.</div>
<div class="description-paragraph" id="p-0709" num="0708">In the example illustrated in <figref idrefs="DRAWINGS">FIG. 93</figref>, the codec engine <b>1516</b> includes, for example, MPEG-2 Video <b>1541</b>, AVC/H.264 <b>1542</b>, HEVC/H.265 <b>1543</b>, HEVC/H.265 (Scalable) <b>1544</b>, HEVC/H.265 (Multi-view) <b>1545</b>, and MPEG-DASH <b>1551</b>, as functional blocks of processes regarding codec.</div>
<div class="description-paragraph" id="p-0710" num="0709">The MPEG-2 Video <b>1541</b> is a functional block which codes or decodes image data in the MPEG-2 method. The AVC/H.264 <b>1542</b> is a functional block which codes or decodes image data in the AVC method. The HEVC/H.265 <b>1543</b> is a functional block which codes or decodes image data in the HEVC method. The HEVC/H.265 (Scalable) <b>1544</b> is a functional block which scalably codes or decodes image data in the HEVC method. HEVC/H.265 (Multi-view) <b>1545</b> is a functional block which multi-view-codes or multi-view-decodes image data in the HEVC method.</div>
<div class="description-paragraph" id="p-0711" num="0710">The MPEG-DASH <b>1551</b> is a functional block which transmits and receives image data in the MPEG-Dynamic Adaptive Streaming over HTTP (MPEG-DASH) method. The MPEG-DASH is a technique of performing streaming of a video by using Hyper Text Transfer Protocol (HTTP), has one of features in which appropriate data is selected in the segment unit from among a plurality of coded data items which are prepared in advance and have resolutions or the like different, from each other, and is transmitted. The MPEG-DASH <b>1551</b> performs generation of a stream conforming to a standard, transmission control of the stream, or the like, and uses the above-described MPEG-2 Video <b>1541</b>, or HEVC/H.265 (Multi-view) <b>1545</b> for coding/decoding of image data.</div>
<div class="description-paragraph" id="p-0712" num="0711">The memory interface <b>1517</b> is an interface for use in the external memory <b>1312</b>. Data supplied from the image processing engine <b>1514</b> or the codec engine <b>1516</b> is supplied to the external memory <b>1312</b> via the memory interface <b>1517</b>. In addition, data read from the external memory <b>1312</b> is supplied to the video processor <b>1332</b> (the image processing engine <b>1514</b> or the codec engine <b>1516</b>) via the memory interface <b>1517</b>.</div>
<div class="description-paragraph" id="p-0713" num="0712">The multiplexer/demultiplexer (MUX DEMUX) <b>1518</b> multiplexes or demultiplexes various data items regarding an image, such as a bit stream of coded data, image data, and a video signal. A method of multiplexing and demultiplexing is arbitrary. For example, during multiplexing, the multiplexer/demultiplexer (MUX DEMUX) <b>1518</b> may not only collect a plurality of data items into a single data item, but may also add predetermined header information or the like to the data. In addition, during demultiplexing, the multiplexer/demultiplexer (MUX DEMUX) <b>1518</b> may not only divide a single data item into a plurality of a plurality of data items, but may also add predetermined header information or the like to each divided data item. In other words, the multiplexer/demultiplexer (MUX DEMUX) <b>1518</b> can convert: a format of data through the multiplexing and demultiplexing. For example, the multiplexer/demultiplexer (MUX DEMUX) <b>1518</b> multiplexes a bit string so as to perform conversion into a transport stream which is a bit string with a transmission format or data (file data) with a recording file format. Of course, inverse conversion thereof can be performed through demultiplexing.</div>
<div class="description-paragraph" id="p-0714" num="0713">The network interface <b>1519</b> is an interface dedicated to, for example, the broadband modem <b>1333</b> or the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>). The video interface <b>1520</b> is an interface dedicated to, for example, the connectivity <b>1321</b> or the camera <b>1322</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>).</div>
<div class="description-paragraph" id="p-0715" num="0714">Next, an example of an operation of the video processor <b>1332</b> will be described. For example, when a transport stream is received from an external network via, for example, the connectivity <b>1321</b> or the broadband modem <b>1333</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>), the transport stream is supplied to the multiplexer/demultiplexer (MUX DEMUX) <b>1518</b> via the network interface <b>1519</b> so as to be demultiplexed, and is then decoded by the codec engine <b>1516</b>. Image data which is obtained through the coding in the codec engine <b>1516</b> undergoes a predetermined image process by, for example, the image processing engine <b>1514</b> so as to undergo predetermined conversion, and is then, is supplied to, for example, the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) via the display interface <b>1512</b>, and an image thereof is displayed on a monitor. In addition, for example, the image data obtained through the coding in the codec engine <b>1516</b> is decoded again by the codec engine <b>1516</b> so as to be multiplexed by the multiplexer/demultiplexer (MUX DEMUX) <b>1518</b> and to be converted into file data, and is then output, to, for example, the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) via the video interface <b>1520</b> so as to be recorded on various recording media.</div>
<div class="description-paragraph" id="p-0716" num="0715">Further, for example, file data of coded data which is coded image data and is read from a recording medium (not illustrated) by the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) is supplied to the multiplexer/demultiplexer (MUX DEMUX) <b>1518</b> via the video interface <b>1520</b>, and is then decoded by the codec engine <b>1516</b>. The image data obtained through the decoding in the codec engine <b>1516</b> undergoes a predetermined image process by the image processing engine <b>1514</b> so as to undergo predetermined conversion by the display engine <b>1513</b>, and is then supplied to, for example, the connectivity <b>1321</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) via the display interface <b>1512</b>, and an image thereof is displayed on the monitor. In addition, for example, the image data obtained through the decoding in the codec engine <b>1516</b> is coded again by the codec engine <b>1516</b> so as to be multiplexed by the multiplexer/demultiplexer (MUX DEMUX) <b>1518</b> and to be converted into a transport stream, and is then output to, for example, the connectivity <b>1321</b> or the broadband modem <b>1333</b> (<figref idrefs="DRAWINGS">FIG. 91</figref>) via the network interface <b>1519</b> so as to be supplied to other apparatuses (not illustrated).</div>
<div class="description-paragraph" id="p-0717" num="0716">Further, transmission and reception, of image data or other data between the respective processing portions of the video processor <b>1332</b> are performed by using, for example, the internal memory <b>1515</b> or the external memory <b>1312</b>. In addition, the power management module <b>1313</b> controls the supply of power to, for example, the control portion <b>1511</b>.</div>
<div class="description-paragraph" id="p-0718" num="0717">If the present technology is applied to the video processor <b>1332</b> having the configuration, the present technology related to each embodiment described above may be applied to the codec engine <b>1516</b>. In other words, for example, the codec engine <b>1516</b> may include a functional block for realizing the coding device or the decoding device related to the first embodiment. In addition, for example, if the codec engine <b>1516</b> includes the above-described functional block, the video processor <b>1332</b> can achieve the same effects as the effects described with reference to <figref idrefs="DRAWINGS">FIGS. 6 to 13</figref>.</div>
<div class="description-paragraph" id="p-0719" num="0718">In addition, in the codec engine <b>1516</b>, the present, technology (that is, the function of the image coding device or the image decoding device related to each embodiment described above) may be realized by hardware such as a logic circuit, may be realized by software such as an embedded program, and may be realized by both thereof.</div>
<div class="description-paragraph" id="p-0720" num="0719">As mentioned above, the two exemplary configurations of the video processor <b>1332</b> have been described, but the video processor <b>1332</b> may have any configuration, and may have configurations other than the two exemplary configurations. In addition, the video processor <b>1332</b> may be configured by a single semiconductor chip, and may be configured, by a plurality of semiconductor chips. For example, a three-dimensional stacked LSI in which a plurality of semiconductors are stacked may be used. Further, the video processor <b>1332</b> may be implemented by a plurality of LSIs.</div>
<div class="description-paragraph" id="p-0721" num="0720">(Application Examples to Apparatus)</div>
<div class="description-paragraph" id="p-0722" num="0721">The video set <b>1300</b> may be incorporated into various apparatuses which process image data. For example, the video set <b>1300</b> may be incorporated into the television apparatus <b>900</b> (<figref idrefs="DRAWINGS">FIG. 84</figref>), the mobile phone <b>920</b> (<figref idrefs="DRAWINGS">FIG. 85</figref>), the recording/reproducing apparatus <b>940</b> (<figref idrefs="DRAWINGS">FIG. 86</figref>), the imaging apparatus <b>960</b> (<figref idrefs="DRAWINGS">FIG. 87</figref>), and the like. The video set <b>1300</b> is incorporated into the apparatus, and thus the apparatus can achieve the same effects as the effects described with reference to <figref idrefs="DRAWINGS">FIGS. 6 to 13</figref>.</div>
<div class="description-paragraph" id="p-0723" num="0722">In addition, the video set <b>1300</b> may be incorporated into, for example, the terminal apparatuses such as the personal computer <b>1004</b>, the AV apparatus <b>1005</b>, the tablet device <b>1006</b>, and the mobile phone <b>1007</b> of the data transmission system <b>1000</b> of <figref idrefs="DRAWINGS">FIG. 88</figref>, the broadcasting station <b>1101</b> and the terminal apparatus <b>1102</b> of the data transmission system <b>1100</b> of <figref idrefs="DRAWINGS">FIG. 89</figref>, the imaging apparatus <b>1201</b> and the scalable coded data storage device <b>1202</b> of the imaging system <b>1200</b> of <figref idrefs="DRAWINGS">FIG. 90</figref>, and the like. The video set <b>1300</b> is incorporated into the apparatus, and thus the apparatus can achieve the same effects as the effects described with reference to <figref idrefs="DRAWINGS">FIGS. 6 to 13</figref>.</div>
<div class="description-paragraph" id="p-0724" num="0723">In addition, even if only some of the above-described configurations of the video set <b>1300</b> include the video processor <b>1332</b>, the configurations can be implemented as configurations to which the present technology is applied. For example, only the video processor <b>1332</b> may be implemented as a video processor to which the present technology is applied. In addition, for example, as described above, the processor, the video module <b>1311</b>, or the like indicated by the dotted line <b>1341</b> may be implemented as a processor, a module, or the like to which the present technology is applied. Further, a combination of the video module <b>1311</b>, the external memory <b>1312</b>, the power management module <b>1313</b>, and the front end module <b>1314</b> may be implemented as the video unit <b>1361</b> to which the present technology is applied. Any configuration can achieve the same effects as the effects described with reference to <figref idrefs="DRAWINGS">FIGS. 6 to 13</figref>.</div>
<div class="description-paragraph" id="p-0725" num="0724">In other words, any configuration including the video processor <b>1332</b> can be incorporated into various apparatuses which process image data in the same manner as in the video set <b>1300</b>. For example, the video processor <b>1332</b>, the processor indicated by the dotted line <b>1341</b>, the video module <b>1311</b>, or the video unit <b>1361</b> can be incorporated into the television apparatus <b>900</b> (<figref idrefs="DRAWINGS">FIG. 84</figref>), the mobile phone <b>920</b> (<figref idrefs="DRAWINGS">FIG. 85</figref>), the recording/reproducing apparatus <b>940</b> (<figref idrefs="DRAWINGS">FIG. 86</figref>), the imaging apparatus <b>960</b> (<figref idrefs="DRAWINGS">FIG. 87</figref>), the terminal apparatuses such, as the personal computer <b>1004</b>, the AV apparatus <b>1005</b>, the tablet device <b>1006</b>, and the mobile phone <b>1007</b> of the data transmission system <b>1000</b> of <figref idrefs="DRAWINGS">FIG. 88</figref>, the broadcasting station <b>1101</b> and the terminal apparatus <b>1102</b> of the data transmission system <b>1100</b> of <figref idrefs="DRAWINGS">FIG. 89</figref>, the imaging apparatus <b>1201</b> and the scalable coded, data storage device <b>1202</b> of the imaging system <b>1200</b> of <figref idrefs="DRAWINGS">FIG. 90</figref>, and the like. Any one of configurations to which the present technology is applied is incorporated into the apparatus, and thus the apparatus can achieve the same effects as the effects described with reference to <figref idrefs="DRAWINGS">FIGS. 6 to 13</figref> in the same manner as in the video set <b>1300</b>.</div>
<div class="description-paragraph" id="p-0726" num="0725">In addition, in the present specification, description has been made of an example in which various information pieces such as conversion information, DR conversion information, and an approximate knee point index are multiplexed into coded data, and are transmitted from a coding side to a decoding side. However, a method of transmitting the information is not limited to this example. For example, the information may be transmitted or recorded as separate data associated with coded data without being multiplexed, into the coded data. Here, the term “associated” indicates that an image (which may be a part of the image, such as a slice or a block) included in a bit stream is made to be linked to information corresponding to the image during decoding. In other words, the information may be transmitted on a transmission path different from that of the coded data. In addition, the information may be recorded on a recording medium (or a different recording area of the same recording medium) different from that of the coded data. Further, the information and the coded data may be associated with each other in any unit such as a plurality of frames, a single frame, or a part of a frame.</div>
<div class="description-paragraph" id="p-0727" num="0726">In addition, in the present specification, the system indicates a set of a plurality of constituent elements (devices, modules (components), or the like), and it does not matter whether or not all constituent elements are located in the same casing. Therefore, a plurality of devices which are stored in separate casings and are connected to each other via a network, a single device in which a plurality of modules are stored in a single casing, are all a system.</div>
<div class="description-paragraph" id="p-0728" num="0727">The effects disclosed in the present specification are only an example and are not limited, and there may be other effects.</div>
<div class="description-paragraph" id="p-0729" num="0728">In addition, embodiments of the present disclosure are not limited to the above-described embodiments, and may have various modifications within the scope without departing from the spirit of the present disclosure.</div>
<div class="description-paragraph" id="p-0730" num="0729">For example, the present disclosure may have a cloud computing configuration in which a single function is distributed to a plurality of devices via a network and is processed in cooperation with each other.</div>
<div class="description-paragraph" id="p-0731" num="0730">Further, each step described in the above flowchart may be performed a single device, and may also be performed by a plurality of devices in a distribution manner.</div>
<div class="description-paragraph" id="p-0732" num="0731">Furthermore, in a case where a plurality of processes are included in a single step, the plurality of processes included in the single step may be performed by a single device, and may also be performed by a plurality of devices in a distribution manner.</div>
<div class="description-paragraph" id="p-0733" num="0732">The present disclosure may have the following configurations.</div>
<div class="description-paragraph" id="p-0734" num="0733">(1) A decoding device including; circuitry configured to receive coded data and conversion information, the coded data pertaining to an Image having luminance in a first dynamic range and the conversion information pertaining to a conversion of dynamic range of the luminance of the image from the first dynamic range into a second dynamic range; and decode the received coded data so as to generate the image, wherein the conversion uses a knee function.</div>
<div class="description-paragraph" id="p-0735" num="0734">(2) The decoding device according to the above (1), wherein the conversion uses a knee point.</div>
<div class="description-paragraph" id="p-0736" num="0735">(3) The decoding device according to the above (1) or (2), wherein the conversion uses the knee function to map the dynamic range of the luminance of the image from, the first dynamic range into the second dynamic range, and the knee function is defined by the knee point.</div>
<div class="description-paragraph" id="p-0737" num="0736">(4) The decoding device according to any of the above (1) to (3), wherein the conversion information includes pre-conversion information indicating a range of luminance which is a knee function target in the first dynamic range and post-conversion information indicating a range of luminance in the second dynamic range that corresponds to the range of luminance which is the knee function target in the first dynamic range.</div>
<div class="description-paragraph" id="p-0738" num="0737">(5) The decoding device according to any of the above (1) to (4), wherein the pre-conversion information indicates the range of luminance which is converted by knee function at a same conversion ratio as a conversion range of the first dynamic range.</div>
<div class="description-paragraph" id="p-0739" num="0738">(6) The decoding device according to any of the above (1) to (5), wherein the conversion uses the knee function which is defined by a plurality of knee points.</div>
<div class="description-paragraph" id="p-0740" num="0739">(7) The decoding device according to any of the above (1) to (6), wherein the conversion information includes a plurality of pairs of the pre-conversion information and the post-conversion information.</div>
<div class="description-paragraph" id="p-0741" num="0740">(8) The decoding device according to any of the above (1) to (7), wherein the conversion uses the knee function by mapping the dynamic range of the luminance of the image from the first, dynamic range into the second dynamic range, and a plurality of adjacent segments of the first dynamic range of the luminance are mapped to a corresponding plurality of adjacent segments of the second dynamic range of the luminance based on boundaries between adjacent segments defined by a plurality of knee points.</div>
<div class="description-paragraph" id="p-0742" num="0741">(9) The decoding device according to any of the above (1) to (8), wherein the conversion uses the knee function by mapping the dynamic range of the luminance of the image from the first dynamic range into the second dynamic range at a first conversion ratio to a point defined by the knee point and at a second conversion ratio from the point defined by the knee point.</div>
<div class="description-paragraph" id="p-0743" num="0742">(10) The decoding device according to any of the above (1) to (9), wherein the knee function is specified by an SEI message.</div>
<div class="description-paragraph" id="p-0744" num="0743">(11) The decoding device according to any of the above (1) to (10), wherein the SEI message includes a setting of a knee_functioned_id.</div>
<div class="description-paragraph" id="p-0745" num="0744">(12) A decoding method of causing a decoding device to perform: receiving coded data and conversion information, the coded data pertaining to an image having luminance in a first dynamic range and the conversion information pertaining to a conversion of dynamic range of the luminance of the image from the first dynamic range into a second dynamic range; and decoding the received coded, data so as to generate the image, wherein the conversion uses a knee function.</div>
<div class="description-paragraph" id="p-0746" num="0745">(13) The decoding method according to the above (12), wherein the conversion information includes pre-conversion information indicating a range of luminance which is a knee function target in the first dynamic range and post-conversion information indicating a range of luminance in the second dynamic range that corresponds to the range of luminance which is the knee function target in the first dynamic range.</div>
<div class="description-paragraph" id="p-0747" num="0746">(14) The decoding method according to the above (12) or (13), wherein the pre-conversion information indicates the range of luminance which is converted by knee function at a same conversion ratio as a conversion range of the first, dynamic range.</div>
<div class="description-paragraph" id="p-0748" num="0747">(15) The decoding method according to any of the above (12) to (14), wherein the conversion information includes a plurality of pairs of the pre-conversion information and the post-conversion information.</div>
<div class="description-paragraph" id="p-0749" num="0748">(16) The decoding method according to any of the above (12) to (15), wherein the conversion uses the knee function by mapping the dynamic range of the luminance of the image from the first dynamic range into the second dynamic range at a first conversion ratio to a point defined by the knee point and at a second conversion ratio from the point defined by the knee point.</div>
<div class="description-paragraph" id="p-0750" num="0749">(17) A coding device including: circuitry configured to set conversion information pertaining to a conversion of dynamic range of a luminance of an image from a first dynamic, range into a second dynamic range; and code the image having luminance in the first dynamic range so as to generate coded data, wherein the conversion uses a knee function.</div>
<div class="description-paragraph" id="p-0751" num="0750">(18) The coding device according to the above (17), wherein the conversion information includes pre-conversion information indicating a range of luminance which is a knee function target in the first dynamic range and post-conversion information indicating a range of luminance in the second dynamic range that corresponds to the range of luminance which is the knee function target in the first, dynamic range.</div>
<div class="description-paragraph" id="p-0752" num="0751">(19) The coding device according to the above (17) or (18), wherein the pre-conversion information indicates the range of luminance which is converted by knee function at a same conversion ratio as a conversion range of the first dynamic range.</div>
<div class="description-paragraph" id="p-0753" num="0752">(20) The coding device according to any of the above (17) to (19), wherein the conversion information includes a plurality of pairs of the pre-conversion information and the post-conversion information.</div>
<div class="description-paragraph" id="p-0754" num="0753">(21) The coding device according to any of the above (17) to (20), wherein the conversion uses the knee function by mapping the dynamic range of the luminance of the image from the first dynamic range into the second dynamic range at a first conversion ratio to a point defined by the knee point and at a second conversion ratio from the point defined by the knee point.</div>
<div class="description-paragraph" id="p-0755" num="0754">(22) A non-transitory computer-readable medium having stored thereon coded data and conversion information, the coded data pertaining to an image having luminance in a first dynamic range and the conversion information pertaining to a conversion of dynamic range of the luminance of the image from the first dynamic range into a second dynamic range, wherein a decoding device decodes coded data, generates the image based on the decoded data, and converts the dynamic range based, on the conversion information including a knee point.</div>
<div class="description-paragraph" id="p-0756" num="0755">(23) The non-transitory computer-readable medium according to the above (22), wherein the conversion information includes pre-conversion information indicating a range of luminance which is a knee function target in the first dynamic range and post-conversion information indicating a range of luminance in the second dynamic range that corresponds to the range of luminance which is the knee function target in the first dynamic range.</div>
<div class="description-paragraph" id="p-0757" num="0756">(24) The non-transitory computer-readable medium according to the above (22) or (23), wherein the pre-conversion information indicates the range of luminance which is converted by knee function at a same conversion ratio as a conversion range of the first dynamic range.</div>
<div class="description-paragraph" id="p-0758" num="0757">(25) The non-transitory computer-readable medium according to any of the above (22) to (24), wherein the conversion information includes a plurality of pairs of the pre-conversion information and the post-conversion information.</div>
<div class="description-paragraph" id="p-0759" num="0758">(26) The non-transitory computer-readable medium according to any of the above (22) to (25), wherein the conversion uses the knee function by mapping the dynamic range of the luminance of the image from the first dynamic range into the second dynamic range at a first conversion ratio to a point defined by the knee point and at a second conversion ratio from the point defined by the knee point.</div>
<div class="description-paragraph" id="p-0760" num="0759">(27) A decoding device including an extraction unit that extracts coded data, and conversion information from a coded stream including the coded data of a first image which is an image having luminance in a first dynamic range and the conversion information regarding conversion of a dynamic range of the luminance of the image from the first dynamic range into a second dynamic range; and a decoding unit that decodes the coded data extracted by the extraction unit so as to generate the first image.</div>
<div class="description-paragraph" id="p-0761" num="0760">(28) The decoding device according to the above (27), further including a conversion unit that converts the first image which is generated by the decoding unit into a second image which is the image having luminance in the second dynamic range on the basis of the conversion information extracted by the extraction unit.</div>
<div class="description-paragraph" id="p-0762" num="0761">(29) The decoding device according to the above (27) or (28), in which the conversion is performed by knee-converting the luminance of the first image.</div>
<div class="description-paragraph" id="p-0763" num="0762">(30) The decoding device according to the any one of the above (27) to (29), in which the conversion information includes pre-conversion information indicating a range of luminance which is a knee conversion target in the first dynamic range and post-conversion information indicating a range of luminance in the second dynamic range, corresponding to the range. (31) The decoding device according to the any one of the above (27) to (30), in which the pre-conversion information indicates a range of luminance which is knee-converted at the same conversion ratio as a conversion range of the first dynamic range, and in which the conversion information includes a plurality of pairs of the pre-conversion information and the post-conversion information.</div>
<div class="description-paragraph" id="p-0764" num="0763">(32) The decoding device according to the any one of the above (27) to (31), further including a selection unit that selects a predetermined number pairs from, among the plurality of pairs included in the conversion information which is extracted by the extraction unit, in an order in which the pairs are included in the conversion information.</div>
<div class="description-paragraph" id="p-0765" num="0764">(33) The decoding device according to the any one of the above (27) to (31), further including a selection unit that selects a predetermined number pairs from among the plurality of pairs included in the conversion information on the basis of priority information indicating an order in which a priority of the pair is higher, in which the extraction unit extracts the priority information included in the coded stream.</div>
<div class="description-paragraph" id="p-0766" num="0765">(34) The decoding device according to the any one of the above (27) to (33), further including a transmission unit that transmits the predetermined number of pairs selected by the selection unit.</div>
<div class="description-paragraph" id="p-0767" num="0766">(35) The decoding device according to any one of the above (27) to (34), in which the conversion information includes at least one of a maximum value of the luminance of the first image and a maximum value of the luminance of the second image.</div>
<div class="description-paragraph" id="p-0768" num="0767">(36) The decoding device according to any one of the above (27) to (35), in which the conversion information includes at least one of an expected value of brightness of a display unit which displays the first image and an expected value of brightness of a display unit which displays the second image.</div>
<div class="description-paragraph" id="p-0769" num="0768">(37) A decoding method of causing a decoding device to perform extracting coded data and conversion information from a coded stream including the coded data of a first image which is an image having luminance in a first dynamic range and the conversion information which is information regarding conversion of a dynamic range of the luminance of the image from the first dynamic range into a second dynamic range; and decoding the extracted coded data so as to generate the first image.</div>
<div class="description-paragraph" id="p-0770" num="0769">(38) A coding device including a setting unit that sets conversion information which is information regarding conversion of a dynamic range of luminance of an image from a first dynamic range into a second dynamic range; a coding unit that codes a first image which is the image having luminance in the first dynamic range so as to generate coded data; and a transmission unit that transmits a coded stream including the conversion information set by the setting unit and the coded data of the first image generated by the coding unit.</div>
<div class="description-paragraph" id="p-0771" num="0770">(39) The coding device according to the above (38), in which the conversion is performed by knee-converting the luminance of the first image.</div>
<div class="description-paragraph" id="p-0772" num="0771">(40) The coding device according to the above (38) or (39), in which the conversion information includes pre-conversion information indicating a range of luminance which is a knee conversion target in the first dynamic range and post-conversion information indicating a range of luminance in the second dynamic range, corresponding to the range.</div>
<div class="description-paragraph" id="p-0773" num="0772">(41) The coding device according to any one of the above (38) to (40), in which the pre-conversion information indicates a range of luminance which is knee-converted at the same conversion ratio as a conversion range of the first dynamic range, and in which the conversion information includes a plurality of pairs of the pre-conversion information and the post-conversion information.</div>
<div class="description-paragraph" id="p-0774" num="0773">(42) The coding device according to any one of the above (38) to (41), in which the conversion information includes the plurality of pairs of pre-conversion information and post-conversion information in an order in which a priority is higher.</div>
<div class="description-paragraph" id="p-0775" num="0774">(43) The coding device according to any one of the above (38) to (42), in which the transmission unit transmits priority information indicating an order in which a priority of the pair is higher.</div>
<div class="description-paragraph" id="p-0776" num="0775">(44) The coding device according to any one of the above (38) to (43), in which the conversion information includes at least one of a maximum value of the luminance of the first image and a maximum value of the luminance of the second image.</div>
<div class="description-paragraph" id="p-0777" num="0776">(45) The coding device according to any one of the above (38) to (44), in which the conversion information includes at least one of an expected value of brightness of a display unit which displays the first image and an expected value of brightness of a display unit which displays the second image.</div>
<div class="description-paragraph" id="p-0778" num="0777">(46) A coding method of causing a coding device to perform setting conversion information which is information regarding conversion of a dynamic range of luminance of an image from a first dynamic range into a second dynamic range; coding a first image which is the image having luminance in the first dynamic range so as to generate coded data; and transmitting a coded stream including the set conversion information and the generated coded data of the first image.</div>
<div class="description-paragraph" id="p-0779" num="0778">It should be understood by those skilled in the art that various modifications, combinations, sub-combinations and alterations may occur depending on design requirements and other factors insofar as they are within the scope of the appended claims or the equivalents thereof.</div>
<heading id="h-0024">REFERENCE SIGNS LIST</heading>
<div class="description-paragraph" id="p-0780" num="0779"> <b>10</b> Coding device</div>
<div class="description-paragraph" id="p-0781" num="0780"> <b>11</b> Setting unit</div>
<div class="description-paragraph" id="p-0782" num="0781"> <b>12</b> Coding unit</div>
<div class="description-paragraph" id="p-0783" num="0782"> <b>13</b> Transmission unit</div>
<div class="description-paragraph" id="p-0784" num="0783"> <b>14</b> Conversion unit</div>
<div class="description-paragraph" id="p-0785" num="0784"> <b>50</b> Decoding device</div>
<div class="description-paragraph" id="p-0786" num="0785"> <b>52</b> Extraction unit</div>
<div class="description-paragraph" id="p-0787" num="0786"> <b>53</b> Decoding unit</div>
<div class="description-paragraph" id="p-0788" num="0787"> <b>54</b> Conversion unit</div>
<div class="description-paragraph" id="p-0789" num="0788"> <b>70</b> Coding device</div>
<div class="description-paragraph" id="p-0790" num="0789"> <b>71</b> Setting unit</div>
<div class="description-paragraph" id="p-0791" num="0790"> <b>72</b> Coding unit</div>
<div class="description-paragraph" id="p-0792" num="0791"> <b>90</b> Decoding device</div>
<div class="description-paragraph" id="p-0793" num="0792"> <b>91</b> Extraction unit</div>
<div class="description-paragraph" id="p-0794" num="0793"> <b>92</b> Decoding unit</div>
<div class="description-paragraph" id="p-0795" num="0794"> <b>93</b> Conversion unit</div>
<div class="description-paragraph" id="p-0796" num="0795"> <b>110</b> Decoding system</div>
<div class="description-paragraph" id="p-0797" num="0796"> <b>111</b> Decoding device</div>
<div class="description-paragraph" id="p-0798" num="0797"> <b>112</b> Display device</div>
<div class="description-paragraph" id="p-0799" num="0798"> <b>121</b> Selection unit</div>
<div class="description-paragraph" id="p-0800" num="0799"> <b>122</b> Transmission unit</div>
</div>
</div>
</section><section itemprop="claims" itemscope="">
<h2>Claims (<span itemprop="count">12</span>)</h2>
<div html="" itemprop="content"><div class="claims" lang="EN" load-source="patent-office" mxw-id="PCLM243730953">
<claim-statement>The invention claimed is:</claim-statement>
<div class="claim"> <div class="claim" id="CLM-00001" num="00001">
<div class="claim-text">1. A decoding device comprising:
<div class="claim-text">circuitry configured to
<div class="claim-text">receive coded data and conversion information, the coded data pertaining to an image having luminance in a first dynamic range and the conversion information pertaining to a conversion of dynamic range of the luminance of the image from the first dynamic range into a second dynamic range; and</div>
<div class="claim-text">decode the received coded data so as to generate the image,</div>
</div>
<div class="claim-text">wherein the conversion uses a knee function that is defined by at least one knee point, and</div>
<div class="claim-text">wherein the conversion information includes
<div class="claim-text">unconverted luminance range information indicating a permillage of peak luminance level for the image prior to the conversion, relative to a normalized luminance level,</div>
<div class="claim-text">unconverted display luminance information indicating an expected display brightness of peak luminance level for the image prior to the conversion,</div>
<div class="claim-text">converted luminance range information indicating a permillage of peak luminance level for the image after the conversion relative to the normalized luminance level, and</div>
<div class="claim-text">converted display luminance information indicating an expected display brightness of peak luminance level for the image after the conversion.</div>
</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00002" num="00002">
<div class="claim-text">2. The decoding device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the conversion uses the knee function to map the dynamic range of the luminance of the image from the first dynamic range into the second dynamic range.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00003" num="00003">
<div class="claim-text">3. The decoding device according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the conversion information includes pre-conversion information and post-conversion information,
<div class="claim-text">wherein the pre-conversion information indicates a range of luminance which is a knee function target in the first dynamic range, and</div>
<div class="claim-text">wherein the post-conversion information indicates a range of luminance in the second dynamic range that corresponds to the range of luminance indicated, by the pre-conversion information.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00004" num="00004">
<div class="claim-text">4. The decoding device according to <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein the pre-conversion information indicates the range of luminance which is converted by knee function at a same conversion ratio as a conversion range of the first dynamic range.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00005" num="00005">
<div class="claim-text">5. The decoding device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the conversion uses the knee function which is defined by a plurality of knee points.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00006" num="00006">
<div class="claim-text">6. The decoding device according to <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the conversion information includes a plurality of pairs of the pre-conversion information and the post-conversion information.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00007" num="00007">
<div class="claim-text">7. The decoding device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the conversion uses the knee function by mapping the dynamic range of the luminance of the image from the first dynamic range into the second dynamic range, and a plurality of adjacent segments of the first dynamic range of the luminance are mapped to a corresponding plurality of adjacent segments of the second dynamic range of the luminance based on boundaries between adjacent segments defined by a plurality of knee points.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00008" num="00008">
<div class="claim-text">8. The decoding device according to <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the conversion uses the knee function by mapping the dynamic range of the luminance of the image from the first dynamic range into the second dynamic range at a first conversion ratio to a point defined by a first knee point of the at least one knee point and at a second, conversion ratio from the point defined by the first knee point.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00009" num="00009">
<div class="claim-text">9. The decoding device according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the knee function is specified by a Supplemental Enhancement Information (SEI) message.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00010" num="00010">
<div class="claim-text">10. The decoding device according to <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the SEI message includes a setting of a knee_function_id.</div>
</div>
</div> <div class="claim"> <div class="claim" id="CLM-00011" num="00011">
<div class="claim-text">11. A decoding method of causing a decoding device to perform:
<div class="claim-text">receiving coded data and conversion information, the coded data pertaining to an image having luminance in a first dynamic range and the conversion information pertaining to a conversion of dynamic range of the luminance of the image from the first dynamic range into a second dynamic range; and</div>
<div class="claim-text">decoding the received coded data so as to generate the image,</div>
<div class="claim-text">wherein the conversion uses a knee function that is defined by at least one knee point, and</div>
<div class="claim-text">wherein the conversion information includes
<div class="claim-text">unconverted luminance range information indicating a permillage of peak luminance level for the image prior to the conversion relative to a normalized luminance level,</div>
<div class="claim-text">unconverted display luminance information indicating an expected display brightness of peak luminance level for the image prior to the conversion,</div>
<div class="claim-text">converted luminance range information indicating a permillage of peak luminance level for the image after the conversion relative to the normalized luminance level, and</div>
<div class="claim-text">converted display luminance information indicating an expected display brightness of peak luminance level for the image after the conversion.</div>
</div>
</div>
</div>
</div> <div class="claim"> <div class="claim" id="CLM-00012" num="00012">
<div class="claim-text">12. A non-transitory computer-readable medium having stored thereon coded data and conversion information, the coded data pertaining to an image having luminance in a first dynamic range and the conversion information pertaining to a conversion of dynamic range of the luminance of the image from the first dynamic range into a second dynamic range, wherein
<div class="claim-text">when a decoding device decodes the coded data, the decoding device is caused to generate the image based on the decoded data, and also caused to convert, using a knee function that is defined by at least one knee point and based on the conversion information, the dynamic range of the luminance of the image from the first dynamic range into a second dynamic range, and</div>
<div class="claim-text">wherein the conversion information includes
<div class="claim-text">unconverted luminance range information indicating a permillage of peak luminance level for the image prior to the conversion relative to a normalized luminance level,</div>
<div class="claim-text">unconverted display luminance information indicating an expected display brightness of peak luminance level for the image prior to the conversion,</div>
<div class="claim-text">converted luminance range information indicating a permillage of peak luminance level for the image after the conversion relative to the normalized luminance level, and</div>
<div class="claim-text">converted display luminance information indicating an expected display brightness of peak luminance level for the image after the conversion.</div>
</div>
</div>
</div>
</div> </div>
</div>
</section>
                </article>
            </search-app>
        </body>
    </html>
    