
    <html>
        <body>
            <search-app>
                <article class="result" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
    <h1 itemprop="pageTitle">US10776127B2 - Reducing data hazards in pipelined processors to provide high processor utilization 
        - Google Patents</h1><section itemprop="abstract" itemscope="">
<h2>Abstract</h2>
<div html="" itemprop="content"><abstract lang="EN" load-source="patent-office" mxw-id="PA412931497">
<div class="abstract" id="p-0001" num="0000">A pipelined computer processor is presented that reduces data hazards such that high processor utilization is attained. The processor restructures a set of instructions to operate concurrently on multiple pieces of data in multiple passes. One subset of instructions operates on one piece of data while different subsets of instructions operate concurrently on different pieces of data. A validity pipeline tracks the priming and draining of the pipeline processor to ensure that only valid data is written to registers or memory. Pass-dependent addressing is provided to correctly address registers and memory for different pieces of data.</div>
</abstract>
</div>
</section><section itemprop="description" itemscope="">
<h2>Description</h2>
<div html="" itemprop="content"><div class="description" lang="EN" load-source="patent-office" mxw-id="PDES273726859">
<heading id="h-0001">CROSS REFERENCE TO RELATED APPLICATIONS</heading>
<div class="description-paragraph" id="p-0002" num="0001">This application is a divisional of U.S. patent application Ser. No. 14/101,902, filed Dec. 10, 2013, which is a divisional of U.S. patent application Ser. No. 13/205,552, filed Aug. 8, 2011, issued as U.S. Pat. No. 8,612,728 on Dec. 17, 2013, which is a divisional of U.S. patent application Ser. No. 12/782,474, filed May 18, 2010, issued as U.S. Pat. No. 8,006,072 on Aug. 23, 2011, which is a divisional of U.S. patent application Ser. No. 11/711,288, filed Feb. 26, 2007, issued as U.S. Pat. No. 7,734,899 on Jun. 8, 2010, which is a continuation of U.S. patent application Ser. No. 10/125,331, filed Apr. 18, 2002, issued as U.S. Pat. No. 7,200,738 on Apr. 3, 2007. These applications and patents are incorporated herein by reference, in their entirety, for any purpose.</div>
<heading id="h-0002">BACKGROUND OF THE INVENTION</heading>
<div class="description-paragraph" id="p-0003" num="0002">This invention relates to pipelined computer processors. More particularly, this invention relates to pipelined computer processors that reduce data hazards to provide high processor utilization.</div>
<div class="description-paragraph" id="p-0004" num="0003">A processor, also known as a central processing unit, processes a set of instructions from a stored program. The processing of an instruction is typically divided into multiple stages, where each stage generally requires one clock cycle to complete and typically requires different hardware within the processor.</div>
<div class="description-paragraph" id="p-0005" num="0004">For example, the processing of an instruction can be divided into the following stages: fetch, decode, execute, and write-back. At the fetch stage, the processor retrieves an instruction from memory. The instruction is typically encoded as a string of bits that represent input information (e.g., operands), an operation code (“opcode”), and output information (e.g., a destination address). An opcode represents an arithmetic or logic function associated with the operands. Once the instruction is retrieved from memory, a program counter is either incremented for linear program execution or updated to show a branch destination. The program counter contains a pointer to an address in memory from which a next instruction is fetched. At the decode stage, the processor decodes the instruction into an opcode, operands, and a destination. The opcode can include one of the following: add, subtract, multiply, divide, shift, load, store, loop, branch, etc. The operands, depending on the opcode, can be constants, values stored at one or more memory addresses, or the contents of one or more registers. The destination can be a register or a memory address where a result produced from execution of the opcode is stored. At the execute stage, the processor executes the decoded opcode using the operands. For instructions such as add and subtract, the execute stage typically requires one clock cycle. For more complicated instructions, such as multiply and divide, the execute stage typically requires more than one clock cycle. At the write-back stage, the processor stores the result from the execute stage at the specified destination.</div>
<div class="description-paragraph" id="p-0006" num="0005">Pipelining is a known technique that improves processor performance by overlapping the execution of instructions such that different instructions are in each stage of the pipeline during a same clock cycle. For example, while a first instruction is in the write-back stage, a second instruction can be in the execute stage, a third instruction can be in the decode stage, and a fourth instruction can be in the fetch stage. In an ideal situation, one instruction completes processing each clock cycle, and processor utilization is 100%. Processor utilization can be determined by dividing the number of program instructions that complete processing by the number of clock cycles in which those instructions complete processing.</div>
<div class="description-paragraph" id="p-0007" num="0006">Although pipelining can increase throughput (the number of instructions executed per unit time), it increases instruction latency (the time to completely process an instruction). Increases in throughput are restricted by data hazards. A data hazard is a dependence of one instruction on another instruction. An example is a load-use hazard, which occurs when the result of one instruction is needed as input for a subsequent instruction. Instructions (1) and (2) below illustrate a load-use hazard. R0, R1, R2, R3, and R4 represent register contents.
<br/>
<i>R</i>0<i>←R</i>1+<i>R</i>2  (1)
<br/>
<i>R</i>3<i>←R</i>0+<i>R</i>4  (2)
</div>
<div class="description-paragraph" id="p-0008" num="0007">In the four-stage pipeline described above, the result of instruction (1) is stored in register R0 and is available at the end of the write-back stage. Data dependent instruction (2) needs the contents of register R0 at the beginning of the decode stage. If instruction (2) is immediately subsequent to instruction (1) or is separated from instruction (1) by only one instruction, instruction (2) will retrieve an old value from register R0.</div>
<div class="description-paragraph" id="p-0009" num="0008">Software techniques that do not require hardware control for reducing such data hazards are known. One technique eliminates data hazards by exploiting instruction-level parallelism to reorder instructions. To eliminate a data hazard, an instruction and its associated data-dependent instruction are separated by sufficient independent instructions such that a result from the first instruction is available to the data-dependent instruction by the start of the data-dependent instruction's decode stage. However, there is a limit to the amount of instruction-level parallelism possible in a program and, therefore, a limit to the extent that data hazards can be eliminated by instruction reordering.</div>
<div class="description-paragraph" id="p-0010" num="0009">Data hazards that cannot be eliminated by instruction reordering can be eliminated by introducing one or more null (i.e., no-operation or nop) instructions immediately before the data-dependent instruction. Each nop instruction, which advances in the pipeline, simply delays the processing of the rest of the program by a clock cycle. The addition of nop instructions increases program size and total program execution time, which decreases utilization (since nop instructions do not process any data). For example, when each instruction is data-dependent on an immediately preceding instruction (such that the instructions cannot be reordered), two nop instructions should be inserted between each program instruction (e.g., A..B..C, where each letter represents a program instruction and each “.” represents a nop instruction). The utilization becomes less than 100% for a processor running in steady state (e.g., for instructions A, B, and C, the utilization is 3/7 or 43%; for nine similar instructions, the utilization is 9/25 or 36%), which does not take into account priming or draining. Priming is the initial entry of instructions into the pipeline and draining is the clearing of instructions from the pipeline.</div>
<div class="description-paragraph" id="p-0011" num="0010">In addition to software techniques, hardware techniques, such as “data forwarding,” are known. Without data forwarding, the result of an instruction, which is known at the end of the execute stage, is not available as input to another instruction until the end of the write-back stage. Data forwarding forwards that result one cycle earlier so that the result is available as input to another instruction at the end of the execute stage. With data forwarding, an instruction only needs to be separated from a data-dependent instruction by one independent instruction or one nop instruction. For example, in hardware, a state register R0 can hold a register value X. Without data forwarding, a new value Y can be written into R0 during a cycle n (e.g., a write-back stage) such that Y is available at a next cycle (n+1). Because the new value Y may be needed by an instruction in cycle n, control logic associated with data forwarding enables a multiplexer to output the new result Y, making Y available for another instruction one cycle earlier (cycle n). While data forwarding advantageously provides data one cycle earlier (which improves processor utilization), data forwarding hardware requires additional circuit area which increases cost. Data forwarding also increases hardware complexity, which increases design and verification time.</div>
<div class="description-paragraph" id="p-0012" num="0011">Furthermore, many hazards cannot be resolved by data forwarding (e.g., cases in which a new value cannot be forwarded). In these instances, stalling the pipeline is an alternative hardware method. Stalling allows instructions ahead of a data-dependent instruction to proceed while the processing of that data-dependent instruction is stalled. Once the hazard is resolved, the stalled section of the pipeline is restarted. Stalling the pipeline is analogous to the software technique of introducing nop instructions, except that the hardware stalling technique is automatic and avoids increasing program size. However, stalling also reduces performance and thus utilization.</div>
<div class="description-paragraph" id="p-0013" num="0012">In view of the foregoing, it would be desirable to provide a pipelined processor that reduces data hazards such that high processor utilization is attained.</div>
<description-of-drawings>
<heading id="h-0003">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<div class="description-paragraph" id="p-0014" num="0013">The above and other objects and advantages of the invention will be apparent upon consideration of the following detailed description, taken in conjunction with the accompanying drawings, in which like reference characters refer to like parts throughout, and in which:</div>
<div class="description-paragraph" id="p-0015" num="0014"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a diagram illustrating generally the processing of an instruction in multiple stages;</div>
<div class="description-paragraph" id="p-0016" num="0015"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a diagram illustrating a known pipelining of multiple instructions without data hazards;</div>
<div class="description-paragraph" id="p-0017" num="0016"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a diagram illustrating a known pipelining of multiple instructions with data hazards;</div>
<div class="description-paragraph" id="p-0018" num="0017"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a diagram illustrating the pipelining of subsets of instructions in multiple passes for a single piece of data in accordance with the invention;</div>
<div class="description-paragraph" id="p-0019" num="0018"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a diagram illustrating the pipelining of subsets of instructions in multiple passes for three pieces of data in accordance with the invention;</div>
<div class="description-paragraph" id="p-0020" num="0019"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a diagram illustrating alternatively the pipelining of <figref idrefs="DRAWINGS">FIG. 5</figref>;</div>
<div class="description-paragraph" id="p-0021" num="0020"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a diagram illustrating the pipelining of subsets of instructions in multiple passes for many pieces of data in accordance with the invention;</div>
<div class="description-paragraph" id="p-0022" num="0021"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a diagram illustrating alternatively the pipelining of <figref idrefs="DRAWINGS">FIG. 7</figref>:</div>
<div class="description-paragraph" id="p-0023" num="0022"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a table illustrating the priming and draining of a validity pipeline for multiple pipeline passes in accordance with the invention:</div>
<div class="description-paragraph" id="p-0024" num="0023"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a table illustrating a preferred arrangement of pass-dependent register file addressing in accordance with the invention;</div>
<div class="description-paragraph" id="p-0025" num="0024"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a table illustrating a more preferred arrangement of pass-dependent register file addressing in accordance with the invention;</div>
<div class="description-paragraph" id="p-0026" num="0025"> <figref idrefs="DRAWINGS">FIG. 12</figref> is a table illustrating register mapping in accordance with the invention;</div>
<div class="description-paragraph" id="p-0027" num="0026"> <figref idrefs="DRAWINGS">FIG. 13</figref> is a table illustrating frame pointers in a validity pipeline in accordance with the invention;</div>
<div class="description-paragraph" id="p-0028" num="0027"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a table illustrating address mapping in accordance with the invention; and</div>
<div class="description-paragraph" id="p-0029" num="0028"> <figref idrefs="DRAWINGS">FIG. 15</figref> is a block diagram of a pipelined processor in accordance with the invention.</div>
</description-of-drawings>
<heading id="h-0004">DETAILED DESCRIPTION OF THE INVENTION</heading>
<div class="description-paragraph" id="p-0030" num="0029"> <figref idrefs="DRAWINGS">FIG. 1</figref> illustrates the processing of an instruction in a fetch stage (F) <b>102</b>, a decode stage (D) <b>104</b>, an execute stage (E) <b>106</b>, and a write-back stage (WB) <b>108</b>. Although process <b>100</b> shows only four stages of instruction processing (for clarity), an instruction can be processed in other numbers and types of stages.</div>
<div class="description-paragraph" id="p-0031" num="0030">In a pipeline that processes multiple instructions with no data hazards (which can thus run at maximum utilization), an instruction enters the pipeline at each clock cycle and propagates through each stage with each subsequent clock cycle. Upon a first instruction completing the write-back stage, an instruction ideally completes processing every clock cycle thereafter. <figref idrefs="DRAWINGS">FIG. 2</figref> illustrates the pipelining of multiple instructions (which have a 1-cycle execute stage) with no data hazards. When the processor is in steady state (i.e., when the first instruction is being processed in a last stage of the pipeline; e.g., when instruction A is in cycle <b>4</b>), processor utilization is 100%. For more complicated instructions, such as multiply and divide, which require more than one clock cycle for the execute stage, an instruction may not be able to complete processing every cycle and, thus, maximum utilization may be less than 100%.</div>
<div class="description-paragraph" id="p-0032" num="0031">In a pipeline that processes multiple instructions with data hazards, the hazards can be avoided with software that inserts nop instructions between dependent instructions. However, this increases program execution time. <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates the pipelining of multiple instructions where each instruction is data-dependent on an immediately preceding instruction.</div>
<div class="description-paragraph" id="p-0033" num="0032">The invention provides a pipelined processor that reduces data hazards to improve processor utilization by executing a set of instructions in multiple passes concurrently, with subsets of the instructions operating on different pieces of data. The type of program preferably processed by the invention is one that is repeatedly executed (e.g., on different sets of input data) until a predefined condition occurs (e.g., a counter reaches a predefined number). A program's set of instructions is processed in multiple passes. In each pass, one or more subsets of those instructions are processed. For example, a program of nine instructions may be processed in three passes, with subsets of three instructions being processed in each pass. This technique, called “software pipelining,” is advantageous for processing many different sets of input data with a fixed algorithm. The more sets of input data, the more likely the processor is to run at maximum utilization, which may be less than 100% depending on the number of cycles required to process each instruction.</div>
<div class="description-paragraph" id="p-0034" num="0033">In accordance with the invention, a program is first restructured (e.g., by a specialized compiler) before being run on a software pipelined processor. The program's instructions are first preferably expressed as a single instruction sequence without data-dependent branches. Branches can be eliminated by providing an instruction set that allows predicated execution. Predicated execution is the conditional execution of instructions based on a boolean (e.g., true or false) value known as a predicate. These instructions may be executed depending on whether or not a branch would be taken. When the predicate is true, the instructions execute normally and the results, if any, are written to memory or to registers. However, when the predicate is false, the instructions are skipped (i.e., not executed). Second, data hazards are removed by reordering instructions and inserting nop instructions. At this point, the processor will operate at less than maximum utilization because of the nop instructions. Third, the sequence of instructions is divided into a number of subsets and interleaved so that all of the nop instructions are replaced by instructions from different subsets. A detailed example of this process is now described.</div>
<div class="description-paragraph" id="p-0035" num="0034">The instruction sequence A, B, C, D, E, F. G, H, and I (nine instructions) processes a single piece of input data, where each instruction requires two subsequent nop instructions to eliminate data hazards. (Note that the invention is not limited to regular sequences of this type, but is advantageously applicable to instruction sequences with arbitrary data hazards on arbitrary instructions within the sequence.) The execution sequence for this example is expressed as a single instruction sequence without data hazards in accordance with the invention as follows:
<br/>
<i>A..B..C..D..E..F..G..H..I</i>  (3)
<br/>
where each period represents a nop instruction. This sequence is then divided into three subsets of instructions in accordance with the invention as follows:
<br/>
Subset <i>I: A..B..C..</i>  (4)
<br/>
Subset <i>II: .D..E..F.</i>  (5)
<br/>
Subset <i>III: ..G..H..I</i>  (6)
<br/>
The subsets are arranged so that each subset contains a linear sequential fragment of the original sequence, and each of the subsets are of equal length. If necessary, the lengths of the subsets can be made equal by the addition of nop instructions. As shown, two additional nop instructions are introduced (one between instructions C and D, and one between instructions F and G). The optimum number of subsets required varies from program to program. For a given program, increasing the number of subsets allows processor utilization to increase until it reaches a maximum (which may be less than 100%). This maximum is reached when the number of nop instructions in the program reaches a minimum. Increasing the number of subsets beyond this point will require the addition of nop instructions and will therefore decrease the processor utilization.
</div>
<div class="description-paragraph" id="p-0036" num="0035"> <figref idrefs="DRAWINGS">FIG. 4</figref> illustrates the software pipelining of these three subsets of instructions operating on a single piece of data in three passes while avoiding data hazards. Note that only the first stage (e.g., the fetch stage) of the hardware pipeline for each instruction is represented in <figref idrefs="DRAWINGS">FIG. 4</figref> for clarity. Instruction A enters the fetch stage at a first cycle of pass 1. After instruction C enters the fetch stage, two additional nop instructions are processed in pass 1. Instruction D enters the fetch stage at a second cycle of pass 2. After instruction F enters the fetch stage, an additional nop instruction is processed in pass 2. Instruction G enters the fetch stage at a third cycle of pass 3. Instruction I is the final instruction that enters the pipeline in pass 3.</div>
<div class="description-paragraph" id="p-0037" num="0036">The processor preferably runs a set of instructions on multiple pieces of data concurrently, with each subset of instructions operating on different pieces of data during the same pass, in accordance with the invention. Using the example above with three pieces of data, in pass 1, subset I operates on a first piece of data. In pass 2, subset 11 operates on the first piece of data while subset I begins operating on a second piece of data. Subsets I and II are preferably interleaved in the hardware pipeline. This can be represented using the notation A(2)D(1)G(-)B(2)E(1)H(-)C(2)F(1)I(-) where the number in parentheses (n) represents the ordinal number of the piece of data being processed and (-) represents a subset that is not yet executing valid data and is therefore executing nop instructions. In passes 1 and 2, the software pipeline is primed as more subsets of instructions are processing valid data, reducing the number of nop instructions processed in the hardware pipeline. In pass 3, subset III operates on the first piece of data, while subset II operates on the second piece of data and subset I operates on a third piece of data. The instructions are again preferably interleaved in the hardware pipeline (e.g., A(3)D(2)G(1)B(3)E(2)H(1)C(3)F(2)I(1)). At this point, the software pipeline is fully primed and the processor is advantageously running at maximum utilization. One instruction completes processing each cycle. This continues until each piece of data has been processed through each subset of instructions. As subsets of instructions finish processing the final piece of data, the software pipeline drains as nop instructions enter the hardware pipeline.</div>
<div class="description-paragraph" id="p-0038" num="0037"> <figref idrefs="DRAWINGS">FIG. 5</figref> illustrates the above pipelining of three subsets of instructions operating on three pieces of data. In pass 1, the processor begins processing a first piece of data (designated as subscript “1” next to a corresponding instruction). In pass 2, the processor begins processing a second piece of data (designated as subscript “2”). In pass 3, the processor begins processing a third piece of data (designated as subscript “3”). By pass 4, the processor has finished processing the first piece of data through all subsets of instructions. By pass 5, the processor has finished processing the second piece of data through all subsets of instructions and is processing the third (final) piece of data through the last subset of instructions (Subset III). In passes 1 and 2, the nop instructions represent the priming of the software pipeline. In pass 3, the processor is running at maximum utilization, and in passes 4 and 5, the nop instructions represent the draining of the software pipeline. In both cases, the nop instructions are actually valid instructions that have been inhibited because there is no valid data to act upon.</div>
<div class="description-paragraph" id="p-0039" num="0038"> <figref idrefs="DRAWINGS">FIG. 6</figref> is another illustration of pipelining <b>500</b>. The instructions are processed from left (instruction A) to right (instruction I) and from top (pass 1) to bottom (pass 5). An instruction not operating on any data (i.e., an instruction that is behaving as a nop instruction) is designated by a “(-)” next to that instruction and preferably occurs only during priming and draining of the software pipeline.</div>
<div class="description-paragraph" id="p-0040" num="0039"> <figref idrefs="DRAWINGS">FIG. 7</figref> illustrates the pipelining of three subsets of instructions operating on several pieces of data in accordance with the invention. The more pieces of data that are processed in the pipeline, the more likely the overall performance of the processor is to approach maximum utilization.</div>
<div class="description-paragraph" id="p-0041" num="0040">The utilization attained when processing a sequence of instructions is dependent upon the following: the total number of instructions in a program, the number of subsets into which the program is divided, and the number of pieces of data processed. For the 3-subset example above, the utilization is given by equation (7):</div>
<div class="description-paragraph" id="p-0042" num="0041"> <maths id="MATH-US-00001" num="00001"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mrow> <mn>100</mn> <mo>*</mo> <mfrac> <mrow> <mo>(</mo> <mrow> <mrow> <mo>(</mo> <mrow> <mrow> <mo>(</mo> <mrow> <mrow> <mo>(</mo> <mrow> <mi>N</mi> <mo>+</mo> <mn>2</mn> </mrow> <mo>)</mo> </mrow> <mo>*</mo> <mi>I</mi> </mrow> <mo>)</mo> </mrow> <mo>-</mo> <mi>I</mi> </mrow> <mo>)</mo> </mrow> <mo>-</mo> <mi>I</mi> </mrow> <mo>)</mo> </mrow> <mrow> <mo>(</mo> <mrow> <mrow> <mo>(</mo> <mrow> <mi>N</mi> <mo>+</mo> <mn>2</mn> </mrow> <mo>)</mo> </mrow> <mo>*</mo> <mi>I</mi> </mrow> <mo>)</mo> </mrow> </mfrac> </mrow> <mo>=</mo> <mrow> <mn>100</mn> <mo>*</mo> <mfrac> <mi>N</mi> <mrow> <mi>N</mi> <mo>+</mo> <mn>2</mn> </mrow> </mfrac> </mrow> </mrow> </mtd> <mtd> <mrow> <mo>(</mo> <mn>7</mn> <mo>)</mo> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
where “I” is the number of instructions in the program and “N” is the number of pieces of data. In reduced form, utilization depends on only N. Because the value of the numerator (N) will always be less than the value of the denominator (N+2), utilization will be less than 100%. This occurs because of nop instructions during priming and draining of the software pipeline. However, as N increases, utilization approaches 100% (i.e., for very large N, the “+2” becomes negligible and (N+2) approximately equals N).
</div>
<div class="description-paragraph" id="p-0043" num="0042"> <figref idrefs="DRAWINGS">FIG. 8</figref> illustrates pipelining N pieces of data in accordance with the invention. To properly control the software pipeline, the number of subsets (NumberOfSubsets) is preferably programmed into a register before a program starts processing. To process N pieces of data, (N+NumberOfSubsets−1) passes are required, with the software pipeline being primed during a first (NumberOfSubsets−1) passes and being drained during a last (NumberOfSubsets−1) passes. For example, for the 3-subset example above, the number of passes needed to process 6 (N=6) pieces of data is 8 (i.e., 6+3−1). The software pipeline is primed during the first 2 (i.e., 3−1) passes and drained during the last 2 passes.</div>
<div class="description-paragraph" id="p-0044" num="0043">A “LOOP” mechanism in accordance with the invention causes a first program instruction of a subset to begin operating on a next piece of data at the start of a next pass. For example, as shown in <figref idrefs="DRAWINGS">FIG. 8</figref>, the loop mechanism causes instruction A to begin operating on a second piece of data at the start of pass 2. This mechanism can be implemented explicitly (e.g., by having a LOOP instruction encoded as one of the instructions in the program) or implicitly (e.g., by detecting when a program counter has reached an “end-of-program” value). The effect is the same in both cases: the program counter is typically reset to the address of the first instruction of the first subset, causing the first subset to begin executing on a new piece of data.</div>
<div class="description-paragraph" id="p-0045" num="0044">The LOOP instruction has several other functions. When the loop instruction is executed, a current pass counter can be incremented, modulo NumberOfSubsets. The modulo function divides the counter value by NumberOfSubsets and stores the integer remainder in the current pass counter. The current pass counter keeps track of a current piece of data through a given loop. In addition, a validity pipeline can be advanced.</div>
<div class="description-paragraph" id="p-0046" num="0045">The validity pipeline is a hardware pipeline that uses preferably one or more bits to keep track of valid data in the software pipeline. In particular, it is used to track the priming and draining of the software pipeline. The validity pipeline has a number of stages equal to NumberOfSubsets and a validity bit associated with each stage. Each piece of data can be associated with a validity bit (V) that propagates along the validity pipeline. When a program begins, the validity bit for each stage is initially cleared. When a first subset of instructions (in a first pass) begins processing a first piece of data, a validity bit associated with the first piece of data is set (e.g., to “I”) and enters a first stage of the validity pipeline. When a second subset of instructions (in a second pass) begins processing the first piece of data, the validity bit propagates to a second stage of the validity pipeline. Concurrently, when the first subset of instructions begins processing a second piece of data, a validity bit associated with the second piece of data is set (e.g., to “1”) and enters the first stage of the validity pipeline.</div>
<div class="description-paragraph" id="p-0047" num="0046">A data write that changes the state of a system (e.g., by writing to a destination register or to memory) is preferably only allowed if it is caused by an instruction associated with a valid bit (e.g., a bit of “1”). All other writes should be inhibited. This mechanism can cause normal instructions to behave like nop instructions at certain times, particularly during priming and draining of the software pipeline. While reads that have no effect on the state of the system do not need to be inhibited, system performance may be improved by eliminating unnecessary reads associated with invalid passes. When there is no new input data (i.e., the last piece of data has already entered the software pipeline), a cleared validity bit enters the first stage of the validity pipeline. The program stops processing when the validity bits in each stage are cleared.</div>
<div class="description-paragraph" id="p-0048" num="0047"> <figref idrefs="DRAWINGS">FIG. 9</figref> illustrates the priming and draining of a 3-stage (NumberOfSubsets=3) validity pipeline for the processing of three pieces of data (N=3). Five passes (i.e., N+NumberOfSubsets−1=5) are required to completely process the data (see, e.g., <figref idrefs="DRAWINGS">FIG. 5</figref>). Stage 1 is associated with a first pass for a given piece of data stage 2 is associated with a second pass, and stage 3 is associated with a third pass. At the start of a program, validity bits in each stage are cleared. A first subset of instructions begins processing a first piece of data in pass 1, a second subset of instructions in pass 2, and a third subset of instructions in pass 3. This causes a validity bit to be set (e.g., to “1”) in stage 1 during pass 1, which propagates to stage 2 in pass 2 and then to stage 3 in pass 3. By the start of pass 4, the validity bit for stage 1 is reset (e.g., to “0”), because a final piece of data had already entered the software pipeline in pass 3. This cleared validity bit propagates down the pipeline with each subsequent pass. When all the validity bits are cleared, the processor preferably prevents the start of another pass to save power. Program execution can then be stopped under hardware control.</div>
<div class="description-paragraph" id="p-0049" num="0048">Because a subset of instructions operating on a particular piece of data can be interleaved with other subsets of instructions operating on different pieces of data, new data-dependent addressing modes are preferably implemented in accordance with the invention for some processor and system resources (e.g., memory and general-purpose registers). Global resources (e.g., constants), however, can still be accessed in a data-independent way.</div>
<div class="description-paragraph" id="p-0050" num="0049">There is preferably a separate set of registers allocated for each piece of data processed by program instructions and an addressing mechanism to access those registers correctly. For example, for a three-subset program, there are preferably three sets of registers: one set associated with each of the first three pieces of data in the software pipeline. For a fourth piece of data to be processed in a fourth pass, the set of registers allocated for the first piece of data can be reused for the fourth piece of data (because the first piece of data has completely processed). This is known as pass-dependent register file addressing.</div>
<div class="description-paragraph" id="p-0051" num="0050">There are two ways of implementing pass-dependent register file addressing in accordance with the invention. One approach is to allocate a group of physical registers for each piece of data. Each group of physical registers is associated with a parallel set of temporary registers, which can be addressed by the program. The number of temporary registers (NumberOfTemporaries) is typically programmed at the start of program execution. This approach does not require that NumberOfSubsets be known. A more preferred second approach is to allocate a group of physical registers equal to NumberOfSubsets, with the same temporary register number assigned to each physical register in each group, but for a different pass of the program. In both approaches, the number of physical registers required is equal to (NumberOfSubsets*NumberOfTemporaries), and should not exceed the number of registers available.</div>
<div class="description-paragraph" id="p-0052" num="0051"> <figref idrefs="DRAWINGS">FIG. 10</figref> illustrates pass-dependent register mapping <b>1000</b> in which each group of physical registers (e.g., <b>1002</b>, <b>1004</b>, <b>1006</b>) is associated with a different piece of data. “Pass Used” indicates the pass in which a first subset of instructions for a given piece of data is processed (e.g., a fourth piece of data in a 3-subset program uses the group of physical registers associated with pass 1). “Register Name” indicates the temporary register name that can be addressed by the program.</div>
<div class="description-paragraph" id="p-0053" num="0052"> <figref idrefs="DRAWINGS">FIG. 11</figref> illustrates a more preferred pass-dependent register mapping <b>1100</b> in which each group of physical registers (e.g., <b>1102</b>, <b>1104</b>) contains a number of registers equal to NumberOfSubsets. Each register in groups <b>1102</b> and <b>1104</b> is assigned the same temporary register name but for different pieces of data. As before, “Register Name” indicates the temporary register name that can be addressed by the program. For a 3-subset program, register R0 is mapped to physical register numbers 0, 1, and 2 for passes 1, 2, and 3, respectively, at <b>1102</b>.</div>
<div class="description-paragraph" id="p-0054" num="0053">Instructions operating on a particular piece of data during different passes (subsets) may need to access the same physical register using pass-dependent register file addressing. Using the more preferred register mapping (<figref idrefs="DRAWINGS">FIG. 11</figref>), the physical register number can be calculated using equation (8) below. Calculation of the physical register number preferably occurs in the instruction decode stage of the hardware pipeline.
<br/>
Physical Register=(Register*NumberOfSubsets)+(CurrentPass−PassUsed) % NumberOfSubsets  (8)
<br/>
where “Register” is the temporary register number (e.g., 0 for R0, 1 for R1); “PassUsed” is the pass number for a particular subset of instructions for a given piece of data (e.g., a first subset of instructions has PassUsed=1, a second subset of instructions has PassUsed=2, a third subset of instructions has PassUsed=3); and symbol “%” represents the modulo operator. Register and PassUsed are typically invariant for a particular instruction and are preferably encoded within the operands of the instruction. The value of “NumberOfSubsets” is fixed for a given program. “CurrentPass” is the pass at which a piece of data begins processing (e.g., for a 3-subset program, a first piece of data has CurrentPass=1, a second piece of data has CurrentPass=2, a third piece of data has CurrentPass=3, a fourth piece of data has CurrentPass=1). As the processor processes successive passes, it maintains the value of CurrentPass by incrementing a counter. When the counter reaches NumberOfSubsets, the counter resets to 1. As a result, CurrentPass is a number between 1 and NumberOfSubsets (i.e., 1&lt;CurrentPass&lt;NumberOfSubsets).
</div>
<div class="description-paragraph" id="p-0055" num="0054"> <figref idrefs="DRAWINGS">FIG. 12</figref> illustrates physical register mapping <b>1200</b> for temporary register R1 using the 3-subset program of <figref idrefs="DRAWINGS">FIG. 7</figref> in accordance with the more preferred mapping arrangement of <figref idrefs="DRAWINGS">FIG. 11</figref>. For example, consider the processing of a first piece of data by instructions A, D, and G, and suppose that all three instructions require access to register R1. <figref idrefs="DRAWINGS">FIG. 7</figref> shows that this processing occurs in passes 1, 2, and 3, respectively. The operands for instructions A, D, and G all encode a register value of 1, and encode a PassUsed value of 1, 2, and 3, respectively. When instruction A processes the first piece of data in pass 1, equation <b>1202</b> shows that physical register <b>3</b> is addressed. Equation <b>1202</b> shows the different values used to calculate the physical register number using equation (8). When instruction A processes a second piece of data in pass 2, equation <b>1202</b> shows that physical register <b>4</b> is addressed. When instruction D processes the first piece of data in pass 2, equation <b>1202</b> shows that physical register <b>3</b> is addressed. Similarly, when instruction G processes the first piece of data in pass 3, equation <b>1202</b> shows that physical register <b>3</b> is addressed. Thus different passes in which the same piece of data is processed can share the same temporary registers. In equation <b>1202</b>, CurrentPass is the only invariant term for a given instruction. As CurrentPass changes for different passes, a given instruction accesses a same group of physical registers. Because each piece of data accesses a different physical register in the same group, different pieces of data can be independently processed.</div>
<div class="description-paragraph" id="p-0056" num="0055">In addition to pass-dependent register addressing, it may also be necessary for the program flow associated with a particular piece of data to perform memory reads and writes. A form of pass-dependent memory addressing is therefore provided in accordance with the invention. Because multiple subsets of instructions preferably operate concurrently on different pieces of data, memory locations corresponding to each piece of data are preferably known before a pass starts. For example, if each piece of input data causes the program to perform three writes, it may be necessary to be able to determine a base address for the three writes as a function of an ordinal number of a piece of data. The memory address can be calculated by summing at least two values: one a function of the ordinal number of a piece of data and the other a function of the particular write which is preferably encoded within the program instructions.</div>
<div class="description-paragraph" id="p-0057" num="0056">For example, if a piece of code generates three outputs for each piece of input data, these outputs can be stored sequentially in memory at offsets 0, 1, and 2 from a base address. Writing to offsets 0, 1, and 2 can occur in any order and the value of each offset (0, 1, 2) can be encoded within the stored instruction.</div>
<div class="description-paragraph" id="p-0058" num="0057">The address for storing the outputs generated by a piece of code can be calculated by adding a base address (which differs for each piece of input data) to an offset (e.g., the offset can be “0” for a first output. “1” for a second output, and “2” for a third output), which is preferably encoded within the operands of an instruction. Before a program starts, the base address is preferably set and the number of outputs for each input is preferably specified. Each piece of input data can have an associated base address for outputs as shown in (9) below.
<br/>
Data 0→base address(<i>x</i>)
<br/>
Data 1→base address(<i>x+</i>3)
<br/>
Data 2→base address(<i>x+</i>6)  (9)
</div>
<div class="description-paragraph" id="p-0059" num="0058">The base address for each subsequent piece of data is preferably incremented by three to allow storage space for the three outputs from each piece of input data. Alternatively, each piece of data may be assigned a unique base address independent of the base addresses for other pieces of data. The number of separate copies of the base address that are maintained equals NumberOfSubsets. These stored values are called “frame pointers” and are preferably stored in a field within the validity pipeline.</div>
<div class="description-paragraph" id="p-0060" num="0059">When a valid pass starts, the current value of the base address can be placed into the frame pointer field of stage 1 of the validity pipeline, with a corresponding validity bit set (e.g., to “1”). For invalid passes (V=0), particularly during the priming and draining of the software pipeline, the value of the frame pointer field is irrelevant, since a cleared validity bit (V=0) will inhibit any write instruction, forcing it to act as a nop. The value of the base address is only incremented after it has been assigned to a frame pointer field associated with a valid pass (V=1). Meanwhile, the previous base address is propagated down the frame pointer fields of the validity pipeline to a stage 2 associated with a second subset of instructions for the same piece of data. The size of the output data is preferably not determined during program execution time, but calculated during “compile” time when the program is restructured and the NumberOfSubsets is determined.</div>
<div class="description-paragraph" id="p-0061" num="0060"> <figref idrefs="DRAWINGS">FIG. 13</figref> illustrates frame pointers in a validity pipeline (as shown in <figref idrefs="DRAWINGS">FIG. 9</figref>) in accordance with the invention. Frame pointers (x), (x+3), and (x+6) are associated with valid bits in the validity pipeline. Frame pointers “D/C” (don't care) and (x+9) are associated with invalid bits pertaining to the priming and draining of the software pipeline. No data is stored at these addresses during these passes.</div>
<div class="description-paragraph" id="p-0062" num="0061">When an instruction performs a load or a store, it preferably specifies the pass in which the load or store is to be done and can also be used to select an associated frame pointer in the validity pipeline. For example, if instructions A. D, and G (in passes 1, 2, and 3, respectively) are to access memory at offsets 2, 0, and 1, respectively, the physical address can be calculated by selecting the appropriate frame pointer from the validity pipeline and adding the frame pointer value to the respective offsets.</div>
<div class="description-paragraph" id="p-0063" num="0062"> <figref idrefs="DRAWINGS">FIG. 14</figref> illustrates how the frame pointer values are extracted from the validity pipeline associated with <figref idrefs="DRAWINGS">FIG. 13</figref>. The offset indicates the location in memory from the base address, and the notation (Frame(n)=m) shows the current value m of the frame pointer field in the nth stage of the validity pipeline. The shaded regions indicate loads or stores that are inhibited because of invalid bits (e.g., V=0) for a given pass. <figref idrefs="DRAWINGS">FIG. 14</figref> shows how instructions A, D, and G are encoded to perform stores in their respective passes 1, 2, and 3. By accessing the 1st, 2nd, and 3rd entries in the validity pipeline, the instructions can access the region of memory associated with the same copy of the base address.</div>
<div class="description-paragraph" id="p-0064" num="0063">Invalid passes (e.g., when V=0) occur during priming and draining of the software pipeline, and may occur during processing, particularly when handling periodic gaps of input data. If input data is available for a new pass, the validity bit is set and the pass proceeds as normal. If input data is not available when the pass starts, the validity bit is cleared for that pass and the pass can still proceed. If input data is available for the next pass, there will be a one-pass “bubble” in the software pipeline, represented by the cleared validity bit. If input data is not available for a time equal to NumberOfSubsets (indicating that all instructions have completely processed the last piece of data), each stage of the validity pipeline will have their validity bits cleared, indicating that the software pipeline has completely drained.</div>
<div class="description-paragraph" id="p-0065" num="0064"> <figref idrefs="DRAWINGS">FIG. 15</figref> illustrates a pipelined processor <b>1500</b> in accordance with the invention. During an initial setup, a set of instructions from a program are loaded into a local program memory <b>1502</b>. Also, initial values are loaded into the following: a program counter <b>1504</b>, a base address register <b>1506</b>, a Number-Of-Outputs register <b>1508</b>, and a Number-Of-Subsets register <b>1510</b>. In addition, validity bits in a validity pipeline <b>1512</b> are cleared and a current pass counter <b>1514</b> is set to zero. Furthermore, validity pipeline <b>1512</b> is configured to behave as though it has a number of stages equal to the value loaded in Number-Of-Subsets register <b>1510</b>.</div>
<div class="description-paragraph" id="p-0066" num="0065">The address of a current instruction in local program memory <b>1502</b> is stored in program counter <b>1504</b>. After the current instruction is fetched, the value in program counter <b>1504</b> is updated to reference a next instruction. Control logic <b>1516</b> fetches and decodes the current instruction from local program memory <b>1502</b>. The current instruction is processed in an instruction pipeline <b>1518</b>, which preferably contains a number of (hardware pipeline) stages to process each instruction. Instruction pipeline <b>1518</b> can process input data and data reads from general-purpose registers <b>1520</b>.</div>
<div class="description-paragraph" id="p-0067" num="0066">Control logic <b>1516</b> controls instruction pipeline <b>1518</b> and validity pipeline <b>1512</b>. Instruction pipeline <b>1518</b>, validity pipeline <b>1512</b>, and control logic <b>1516</b> are preferably all coupled to a clock <b>1522</b>, which synchronizes their operation. Each time the program code in program memory <b>1502</b> executes a LOOP function, Current-Pass-Counter <b>1514</b> is incremented modulo the value in Number-Of-Subsets register <b>1510</b>, validity pipeline <b>1512</b> is advanced, and the current value of base address register <b>1506</b> is introduced into the frame pointer field of the first entry of validity pipeline <b>1512</b>. When the LOOP function is executed and new input data is available, the value introduced into the valid field of the validity pipeline is a “1” and the value in base address register <b>1506</b> is incremented by the value in Number-Of-Outputs register <b>1508</b>. When the LOOP function is executed and no new input data is available, the value introduced into the valid field of the validity pipeline is “0” and the value in base address register <b>1506</b> is not modified. Instruction pipeline <b>1518</b> reads/writes data from/to either general purpose registers <b>1520</b> using pass-dependent or pass-independent register file addressing, or a memory <b>1524</b> using pass-dependent or pass-independent memory addressing.</div>
<div class="description-paragraph" id="p-0068" num="0067">Thus it is seen that data hazards in pipelined processors can be reduced such that high processor utilization is attained. One skilled in the art will appreciate that the invention can be practiced by other than the described embodiments, which are presented for purposes of illustration and not of limitation, and the invention is limited only by the claims which follow.</div>
</div>
</div>
</section><section itemprop="claims" itemscope="">
<h2>Claims (<span itemprop="count">20</span>)</h2>
<div html="" itemprop="content"><div class="claims" lang="EN" load-source="patent-office" mxw-id="PCLM268870557">
<claim-statement>What is claimed is:</claim-statement>
<div class="claim"> <div class="claim" id="CLM-00001" num="00001">
<div class="claim-text">1. A method, comprising:
<div class="claim-text">in a first pass, operating on a first piece of data in accordance with an instruction of a first subset of instructions, wherein a first register of a group of registers of a processor is accessed responsive to a particular register value encoded in the instruction of the first subset;</div>
<div class="claim-text">in a second pass, operating on a second piece of data in accordance with the instruction of the first subset, wherein a second register of the group of registers is accessed responsive to the particular register value encoded in the instruction of the first subset; and</div>
<div class="claim-text">in the second pass, operating on the first piece of data in accordance with an instruction of a second subset of instructions, wherein the first register is accessed responsive to the particular register value encoded in the instruction of the second subset.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00002" num="00002">
<div class="claim-text">2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instruction of the first subset is executed responsive to a first cycle of the second pass and wherein the instruction of the second subset is executed responsive to a second cycle of the second pass.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00003" num="00003">
<div class="claim-text">3. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first and second subsets are of equal length.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00004" num="00004">
<div class="claim-text">4. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">in a third pass:</div>
<div class="claim-text">operating on a third piece of data in accordance with the instruction of the first subset, wherein a third register of the group of registers is accessed responsive to the particular register value encoded in the instruction of the first subset;</div>
<div class="claim-text">operating on the second piece of data in accordance with the instruction of the second subset of instructions, wherein the second register is accessed responsive to the particular register value encoded in the instruction of the second subset; and</div>
<div class="claim-text">operating on the first piece of data in accordance with an instruction of a third subset of instructions, wherein the first register is accessed responsive to the particular register value encoded in the instruction of the third subset.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00005" num="00005">
<div class="claim-text">5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the instruction of the first subset is executed responsive to a first cycle of the third pass, wherein the instruction of the second subset is executed responsive to a second cycle of the third pass, and wherein the instruction of the third subset is executed responsive to a third cycle of the third pass.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00006" num="00006">
<div class="claim-text">6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein operating on a third piece of data in accordance with the instruction of the first subset includes operating on the third piece of data in accordance with a first instruction of the first subset, wherein the method further includes operating on the third piece of data in accordance with a second instruction of the first subset, wherein the third register is accessed responsive to the particular register value encoded in the second instruction of the first subset, and wherein the second instruction of the first subset is executed responsive to a fourth cycle of the third pass.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00007" num="00007">
<div class="claim-text">7. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, further comprising:
<div class="claim-text">in a fourth pass:</div>
<div class="claim-text">operating on a fourth piece of data in accordance with the instruction of the first subset, wherein the first register is accessed responsive to the particular register value encoded in the instruction of the first subset;</div>
<div class="claim-text">operating on the third piece of data in accordance with the instruction of the second subset of instructions, wherein the third register is accessed responsive to the particular register value encoded in the instruction of the second subset; and</div>
<div class="claim-text">operating on the second piece of data in accordance with the instruction of the third subset of instructions, wherein the second register is accessed responsive to the particular register value encoded in the instruction of the third subset.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00008" num="00008">
<div class="claim-text">8. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising, in the first pass, inhibiting the instruction of the second subset of instructions.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00009" num="00009">
<div class="claim-text">9. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first and second subsets are interleaved in a hardware pipeline of the processor.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00010" num="00010">
<div class="claim-text">10. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein operating on a first piece of data in accordance with an instruction of a first subset of instructions includes setting a validity bit associated with the first piece of data.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00011" num="00011">
<div class="claim-text">11. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein operating on the first piece of data in accordance with an instruction of a second subset of instructions includes propagating the set validity bit from a first stage of a validity pipeline of the processor to a second stage of the validity pipeline; and
<div class="claim-text">wherein operating on a second piece of data in accordance with the instruction of the first subset includes setting a validity bit associated with the second piece of data when the first subset begins processing the second piece of data.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00012" num="00012">
<div class="claim-text">12. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:
<div class="claim-text">allowing a data write that changes a state of the apparatus if caused by an instruction associated with a set validity bit; and</div>
<div class="claim-text">inhibiting the data write that changes the state of the apparatus if caused by an instruction associated with a cleared validity bit.</div>
</div>
</div>
</div> <div class="claim"> <div class="claim" id="CLM-00013" num="00013">
<div class="claim-text">13. A system for operating a pipelined computer processor, said system comprising:
<div class="claim-text">an instruction pipeline that stores a set of instructions; and</div>
<div class="claim-text">a processor pipeline coupled to the instruction pipeline, the processor pipeline configured to:
<div class="claim-text">receive the set of instructions from the instruction pipeline;</div>
<div class="claim-text">divide the set of instructions into a first subset of instructions and a second subset of instructions;</div>
<div class="claim-text">retrieve an instruction of the first subset of instructions and an instruction of the second subset of instructions;</div>
<div class="claim-text">in a first pass, process the instruction of the first subset of instructions operating on a first piece of data;</div>
<div class="claim-text">in a second pass, process the instruction of the first subset operating on a second piece of data; and</div>
<div class="claim-text">in the second pass, process the instruction of the second subset operating on the first piece of data.</div>
</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00014" num="00014">
<div class="claim-text">14. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising a group of registers coupled to the processor pipeline:
<div class="claim-text">wherein a first register of the group of registers is accessed in the first pass responsive to a particular register value encoded in the instruction of the first subset; and</div>
<div class="claim-text">wherein the first register is accessed in the second pass responsive to the particular register value encoded in the instruction of the second subset.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00015" num="00015">
<div class="claim-text">15. The system of <claim-ref idref="CLM-00013">claim 13</claim-ref>, further comprising control logic operative to assign a different temporary register value to each physical register belonging to a corresponding one of the first and second subsets.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00016" num="00016">
<div class="claim-text">16. The system of <claim-ref idref="CLM-00015">claim 15</claim-ref>, wherein the temporary register value is assigned to a physical register belonging to the first subset in the first pass, and assigned to the physical register belonging to the second subset in the second pass.</div>
</div>
</div> <div class="claim"> <div class="claim" id="CLM-00017" num="00017">
<div class="claim-text">17. A method, comprising:
<div class="claim-text">in a first pass, operating on a first piece of data in accordance with an instruction of a first subset of instructions, wherein a first register of a group of registers is accessed responsive to a particular register value encoded in the instruction of the first subset;</div>
<div class="claim-text">in a second pass, operating on a second piece of data in accordance with the instruction of the first subset, wherein a second register of the group of registers is accessed responsive to the particular register value encoded in the instruction of the first subset; and</div>
<div class="claim-text">assigning a different temporary register value to each physical register belonging to a corresponding one of the first and second subsets.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00018" num="00018">
<div class="claim-text">18. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the first and second subsets of instructions are included in a set of instructions; and
<div class="claim-text">wherein each subset includes a number of instructions from the set of instructions.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00019" num="00019">
<div class="claim-text">19. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein each instruction of the set belongs to only one subset.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00020" num="00020">
<div class="claim-text">20. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, wherein the instruction of the first subset is executed responsive to a first cycle of the second pass;
<div class="claim-text">wherein the instruction of the second subset is executed responsive to a second cycle of the second pass; and</div>
<div class="claim-text">wherein the first and second subsets are of equal length.</div>
</div>
</div>
</div> </div>
</div>
</section>
                </article>
            </search-app>
        </body>
    </html>
    