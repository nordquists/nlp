
    <html>
        <body>
            <search-app>
                <article class="result" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
    <h1 itemprop="pageTitle">US11019408B2 - Methods, devices, and computer programs for streaming partitioned timed media data 
        - Google Patents</h1><section itemprop="abstract" itemscope="">
<h2>Abstract</h2>
<div html="" itemprop="content"><abstract lang="EN" load-source="patent-office" mxw-id="PA448036808">
<div class="abstract" id="p-0001" num="0000">Receiving, transmitting, and generating a manifest describing a plurality of versions of partitioned timed media data comprising timed samples that comprise subsamples. A portion of the data is transmitted as a media segment file comprising independently encapsulated components comprising partition components containing a subsample selected from among the plurality of subsamples of one of the timed samples and one corresponding subsample of the other timed samples and one reference component comprising at least one extractor identifying the partition component. The manifest comprises representations comprising a description of a version of a portion of the partitioned timed media data, one said representation comprising a description of components among which one component is required to reconstruct at least partially the partitioned timed media data and among which at least one component is an optional component that can be selected to reconstruct at least a portion of the partitioned timed media data.</div>
</abstract>
</div>
</section><section itemprop="description" itemscope="">
<h2>Description</h2>
<div html="" itemprop="content"><div class="description" lang="EN" load-source="patent-office" mxw-id="PDES293430391">
<heading id="h-0001">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<div class="description-paragraph" id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 14/784,555, filed on Oct. 14, 2015, that is the National Phase application of PCT Application No. PCT/EP2014/057123, filed on Apr. 9, 2014. This application claims the benefit under 35 U.S.C. § 119(a)-(d) of United Kingdom Patent Application No. 1306899.4, filed on Apr. 16, 2013. The above cited patent applications are incorporated herein by reference in their entirety.</div>
<heading id="h-0002">FIELD OF THE INVENTION</heading>
<div class="description-paragraph" id="p-0003" num="0002">The invention generally relates to the field of timed media data streaming over communication networks, for example communication networks conforming to Internet Protocol (IP) standard. More particularly, the invention concerns methods, devices, and computer programs for streaming partitioned timed media data, in particular for streaming tiled timed media data over IP networks using the HyperText Transfer Protocol (http).</div>
<heading id="h-0003">BACKGROUND OF THE INVENTION</heading>
<div class="description-paragraph" id="p-0004" num="0003">Video coding is a way of transforming a series of video images into a compact digitized bit-stream so that the video images can be transmitted or stored. An encoding device is used to code the video images, with an associated decoding device being available to reconstruct the bit-stream for display and viewing. A general aim is to form the bit-stream so as to be of smaller size than the original video information. This advantageously reduces the capacity required of a transfer network, or storage device, to transmit or store the bit-stream code. To be transmitted, a video bit-stream is generally encapsulated according to a transmission protocol that typically adds headers and check bits.</div>
<div class="description-paragraph" id="p-0005" num="0004">Streaming media data over a communication network typically means that the data representing a media presentation are provided by a host computer, referred to as a server, to a playback device, referred to as a client device, over the communication network. The client device is generally a media playback computer implemented as any of a variety of conventional computing devices, such as a desktop Personal Computer (PC), a tablet PC, a notebook or portable computer, a cellular telephone, a wireless handheld device, a personal digital assistant (PDA), a gaming console, etc. The client device typically renders a streamed content as it is received from the host (rather than waiting for an entire file to be delivered).</div>
<div class="description-paragraph" id="p-0006" num="0005">A media presentation generally comprises several media components such as audio, video, text, and/or subtitles that can be sent from a server to a client device for being jointly played by the client device. Those media components are downloaded by the client device from a server. A common practice aims at giving access to several versions of the same media component so that the client device can select one version as a function of its characteristics (e.g. resolution, computing power, and bandwidth).</div>
<div class="description-paragraph" id="p-0007" num="0006">Recently, the Moving Picture Experts Group (MPEG) published a new standard to unify and supersede existing streaming solutions over HTTP (HyperText Transfer Protocol). This new standard, called “Dynamic adaptive streaming over HTTP (DASH)”, is intended to support a media-streaming model over HTTP based on standard web servers, in which intelligence (i.e. selection of media data to stream and dynamic adaptation of the bit-streams to user choices, network conditions, and client capabilities) relies exclusively on client choices and devices.</div>
<div class="description-paragraph" id="p-0008" num="0007">In this model, a media presentation is organized in data segments and in a manifest called “Media Presentation Description (MPD)” that represents the organization of timed media data to be presented. In particular, a manifest comprises resource identifiers to use for downloading data segments and provides the context to select and combine those data segments to obtain a valid media presentation. Resource identifiers are typically HTTP-URLs (Uniform Resource Locator), possibly combined with byte ranges. Based on a manifest, a client device determines at any time which media segments are to be downloaded from a media data server according to its needs, its capabilities (e.g. supported codecs, display size, frame rate, level of quality, etc), and depending on network conditions (e.g. available bandwidth). In the context of DASH standard, this manifest conforms to the extensible markup language (XML) standard.</div>
<div class="description-paragraph" id="p-0009" num="0008">Before a client device requests media data, it receives a MPD file so as to obtain a description of each accessible media segment and thus, request only the required media segments. In other words, by analyzing a received MPD file, a client device can obtain items of information of the accessible media segments of a media presentation, comprising, in particular, the addresses (e.g. http addresses) of the segments. Therefore, it can decide which media segments are to be downloaded (via HTTP requests), obtain these media segments, and play them after reception and decoding.</div>
<div class="description-paragraph" id="p-0010" num="0009">In addition to this association, the DASH standard proposes to split each media component into media sub-components according to small periods of time. The time decomposition is added in the MPD file. Accordingly, the MPD file provides links between http addresses (or URLs) and compact descriptions of each media segment over small periods of time, allowing a client device to download desired media segments of the media presentation over desired periods of time.</div>
<div class="description-paragraph" id="p-0011" num="0010">Since video resolution continuously increases, going from standard definition (SD) to high definition (HD), and to ultra-high definition (e.g. 4K2K or 8K4K), since not all receiving and video decoding devices have resources (e.g. network access bandwidth or CPU (Central Processing Unit)) to access video in full resolution, and since not all users need to access such video, it is particularly advantageous to provide the ability of accessing only some Regions of Interest (ROIs) that is to say to access only some spatial sub-parts of a whole video sequence.</div>
<div class="description-paragraph" id="p-0012" num="0011">A known mechanism to access spatial sub-parts of frames belonging to a video consists in organizing each frame of the video as an arrangement of independently decodable spatial areas generally referred to as tiles. Some video formats such as SVC (Scalable Video Coding) or HEVC (High Efficiency Video Coding) provide support for tile definition. A user-defined ROI may cover one or several contiguous tiles.</div>
<div class="description-paragraph" id="p-0013" num="0012">Accordingly, for streaming user-selected ROIs according to HTTP protocol, it is important to provide encapsulation of timed media data of an encoded video bit-stream in a way that enables spatial access to one or more tiles and that enables combination of accessed tiles.</div>
<div class="description-paragraph" id="p-0014" num="0013">It is to be recalled that encoded video bit-streams are generally constructed as a set of contiguous temporal samples that correspond to complete frames, the temporal samples being organized as a function of the decoding order. File formats are used to encapsulate and describe such encoded bit-streams.</div>
<div class="description-paragraph" id="p-0015" num="0014">For the sake of illustration, the International Standard Organization Base Media File Format (ISO BMFF) is a well-known flexible and extensible format that describes encoded timed media data bit-streams either for local storage or transmission via a network or via another bit-stream delivery mechanism. This file format is object-oriented. It is composed of building blocks called boxes that are sequentially or hierarchically organized and that define parameters of the encoded timed media data bit-stream such as timing and structure parameters.</div>
<div class="description-paragraph" id="p-0016" num="0015">A solution for describing tiles in ISO BMFF standard consists in encapsulating each tile into a particular track and in using the track's transformation matrix to signal tile positions. A natural approach using DASH standard would consist in describing each track in the manifest as independent media content. However, since current MPD definition does not allow tiled timed media data to be described, there is no way to signal that each track is a sub-part of the same video in the MPD.</div>
<div class="description-paragraph" id="p-0017" num="0016">Therefore, in practice, a client device would have to download a first initialization segment (in addition to the manifest) in order to be in position of determining that each video component described in the MPD is a sub-part of a tiled video (via track and matrix definitions, e.g. in boxes known as moov/track/tkhd). Next, the client device would have to download, at the minimum, the beginning of each first media data segment of each video component to retrieve the association between tile locations and video component (e.g. via the boxes known as moof/traf/tfhd). The downloading of this initialization information leads to delays and additional http roundtrips.</div>
<div class="description-paragraph" id="p-0018" num="0017"> <figref idrefs="DRAWINGS">FIG. 1</figref> illustrates schematically the use of tiles for streaming regions of interest of video sequences.</div>
<div class="description-paragraph" id="p-0019" num="0018">As illustrated, multiple resolution layers are computed from a high spatial resolution input video <b>100</b> comprising a set of images <b>105</b>-<b>1</b> to <b>105</b>-n and each layer is divided into tiles, each tile being encoded independently. Similarly to a conventional video stream, a base layer tile shows the whole video scene. When a user wants to zoom into the video, tiles in the higher resolution layers are retrieved to provide higher quality details. Therefore, a client device needs to decode and synchronize multiple tiles for rendering a particular region of interest.</div>
<div class="description-paragraph" id="p-0020" num="0019">Alternatively, an overlapping tiling scheme can be used so that only one tile is needed to satisfy any region of interest. To handle different display sizes and network conditions, each tile is encoded at different spatial and quality resolutions.</div>
<div class="description-paragraph" id="p-0021" num="0020">An example of manifest file corresponding to input video <b>100</b> is given in the Appendix (Extract of code 1). According to this example, each image of high spatial resolution input video <b>100</b> comprises four segments arranged in a 2×2 matrix. The address of each segment and the position of the corresponding segment in the image are provided within the manifest.</div>
<div class="description-paragraph" id="p-0022" num="0021">US patent application US20100299630 discloses a system for visualizing regions of interest in panoramic images. However, only the case of pre-generated regions of interest (at the server end) and cropped images (at the client device end) are considered. It does not disclose any dynamic streaming of a user-selected region of interest.</div>
<div class="description-paragraph" id="p-0023" num="0022">«In the article entitled “An interactive region-of-interest video streaming system for online lecture viewing”, published in Packet Video Conference 2010, the authors mention the use of tiles for streaming regions of interest. A manifest is used to provide identifier and location items of information of the tiles (actually H.264 slices). However, even if the tiling configuration of each resolution layer is described in the manifest file, such a description does not provide a URL per tile. Furthermore, it requires some intelligence at the server end to interpret the specific http queries sent by the client to stream selected tiles. Indeed, from a base URL and tile items of information provided by the proprietary manifest (tile position and identifier), a client device can build a query of the HTTP GET query URL type, e.g. GET xxx?id=val, to access a particular tile, identified by the value of the identifier attribute read from the manifest. However, such a type of URL requires processing tasks at the server end to retrieve the file and byte-range in the file to be sent to the client device to fulfill its request. Moreover, it does not allow signaling tiles composition and/or exclusion items of information in the manifest.</div>
<div class="description-paragraph" id="p-0024" num="0023">According to patent application WO2012168365, a manifest file describes one or more spatial segment streams with their location information (URL) and a client device has the possibility to select one or more spatial areas. The manifest file also describes relationships between spatial segments, in particular to match a spatial area across resolution levels. However, a synchronization engine is required at the client end to provide the ability of streaming and displaying more than one tile at a time. Such a synchronization engine, when using DASH, requires timed segments in the manifest and reordering of the frames in the client device. The decoded spatial segment frames are stitched together for display as the selected region of interest.</div>
<div class="description-paragraph" id="p-0025" num="0024">To solve these issues, there is provided an efficient partition or tile description scheme for manifest, which ensures, whatever track combination is selected by a client application, that the result of the ISO BMFF parsing always leads to a valid video elementary bit-stream for the video decoder.</div>
<heading id="h-0004">SUMMARY OF THE INVENTION</heading>
<div class="description-paragraph" id="p-0026" num="0025">Faced with these constraints, the inventors provide a device for streaming partitioned timed media data.</div>
<div class="description-paragraph" id="p-0027" num="0026">It is a broad object of the invention to remedy the shortcomings of the prior art as described above.</div>
<div class="description-paragraph" id="p-0028" num="0027">According to a first aspect of the invention there is provided a method for receiving streamed timed media data organized into temporal media segments, the timed media data belonging to partitioned timed media data comprising timed samples, each timed sample comprising a plurality of subsamples, the timed media data being transmitted as at least one media segment file comprising independently encapsulated components comprising at least one partition component containing a subsample selected from among the plurality of subsamples of one of the timed samples and one corresponding subsample of each of the other timed samples and at least one reference component comprising at least one extractor identifying at least one partition component, the method comprising:</div>
<div class="description-paragraph" id="p-0029" num="0028">receiving a manifest describing a plurality of versions of the partitioned timed media data, the manifest comprising representations, each representation comprising at least a description of a version of a portion of the partitioned timed media data, at least one said representation comprising a description of a plurality of components among which at least one component is required to reconstruct at least partially the partitioned timed media data and among which at least one component is an optional component that can be selected to reconstruct at least a portion of the partitioned timed media data;</div>
<div class="description-paragraph" id="p-0030" num="0029">selecting at least one optional component that can be selected to reconstruct at least a portion of the partitioned timed media data;</div>
<div class="description-paragraph" id="p-0031" num="0030">requesting the at least one component that is required to reconstruct at least partially the partitioned timed media data and the at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data; and</div>
<div class="description-paragraph" id="p-0032" num="0031">on reception of the requested components, generating a playable media representation bit-stream from the received components.</div>
<div class="description-paragraph" id="p-0033" num="0032">Accordingly, the invention makes it possible for a client device to identify from a manifest file required data and optional data and to dynamically select a set of optional data to stream. Applied to tiles, this makes it possible to dynamically adapt the streaming to user-defined regions of interest. With the invention, a client device can be informed that videos from a media presentation offer spatial access. By using information from the manifest, a client device can decide to dynamically switch to a specific spatial area of a video and also dynamically switch back to the full-frame video.</div>
<div class="description-paragraph" id="p-0034" num="0033">In an embodiment, the method further comprises parsing and analyzing the manifest for establishing a dependency relation between the at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data and the at least one component that is required to reconstruct at least partially the partitioned timed media data.</div>
<div class="description-paragraph" id="p-0035" num="0034">In an embodiment, the dependency relation between the at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data and the at least one component that is required to reconstruct at least partially the partitioned timed media data is established as a function of non-conventional values of conventional parameters of a conventional data structure of the manifest. The data structures and the data structure parameters of the manifest may comply, for example, with DASH standard.</div>
<div class="description-paragraph" id="p-0036" num="0035">In an embodiment, the step of requesting the at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data comprises a step of requesting parameter values and a step of requesting, as a function of, in particular, the parameter values obtained in response to the step of requesting parameter values, the at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data.</div>
<div class="description-paragraph" id="p-0037" num="0036">In an embodiment, the dependency relation between the at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data and the at least one component that is required to reconstruct at least partially the partitioned timed media data is established as a function of values of non-conventional parameters of a conventional data structure of the manifest.</div>
<div class="description-paragraph" id="p-0038" num="0037">In an embodiment, the dependency relation between the at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data and the at least one component that is required to reconstruct at least partially the partitioned timed media data is established as a function of values of parameters of a non-conventional data structure of the manifest.</div>
<div class="description-paragraph" id="p-0039" num="0038">It is to be noted that when frames of a base layer are divided into tiles, such non-conventional parameters of a conventional or non-conventional data structure of the manifest can be used to describe dependencies between tiles of different layers such as tiles of a base layer and tiles of an enhancement layer.</div>
<div class="description-paragraph" id="p-0040" num="0039">In an embodiment, the method further comprises building an index table, the built index table associating a request address with an identifier of each optional component referred to in the at least one representation.</div>
<div class="description-paragraph" id="p-0041" num="0040">In an embodiment, the method further comprises associating a position with each optional component identifier in the index table, the position representing a position at which media data associated with the corresponding optional component are to be positioned in a reconstructed portion of the partitioned timed media data.</div>
<div class="description-paragraph" id="p-0042" num="0041">In an embodiment, the method further comprises parsing the at least one component that is required to reconstruct at least partially the partitioned timed media data, the playable media representation bit-stream being generated as a function of media data of the at least one selected optional component determined as a function of the parsed data of the at least one component that is required to reconstruct at least partially the partitioned timed media data.</div>
<div class="description-paragraph" id="p-0043" num="0042">A second aspect of the invention provides a method for receiving streamed timed media data organized into temporal media segments, the timed media data belonging to tiled timed media data comprising timed samples, each timed sample comprising a plurality of subsamples, the timed media data being transmitted as at least one media segment file comprising independently encapsulated tracks comprising at least one tile track containing a subsample selected from among the plurality of subsamples of one of the timed samples and one corresponding subsample of each of the other timed samples and at least one composite track comprising at least one extractor identifying at least one tile track, the method comprising:</div>
<div class="description-paragraph" id="p-0044" num="0043">receiving a manifest describing a plurality of versions of the tiled timed media data, the manifest comprising representations, each representation comprising at least a description of a version of a portion of the tiled timed media data, at least one said representation comprising a description of a plurality of tracks among which are at least one composite track and at least one tile track;</div>
<div class="description-paragraph" id="p-0045" num="0044">selecting at least one tile track;</div>
<div class="description-paragraph" id="p-0046" num="0045">requesting the at least one composite track and the at least one selected tile track; and</div>
<div class="description-paragraph" id="p-0047" num="0046">on reception of the requested tracks, generating a playable media representation bit-stream from the received tracks.</div>
<div class="description-paragraph" id="p-0048" num="0047">Accordingly, the invention makes it possible for a client device to identify from a manifest file required data and optional data and to dynamically select a set of optional data to stream. Applied to tiles, this makes it possible to dynamically adapt the streaming to user-defined regions of interest. With the invention, a client device can be informed that videos from a media presentation offer spatial access. By using information from the manifest, a client device can decide to dynamically switch to a specific spatial area of a video and also dynamically switch back to the full-frame video.</div>
<div class="description-paragraph" id="p-0049" num="0048">In an embodiment, the method further comprises parsing and analyzing the manifest for establishing a dependency relation between the at least one selected tile track and the at least one composite track.</div>
<div class="description-paragraph" id="p-0050" num="0049">In an embodiment, the dependency relation between the at least one selected tile track and the at least one composite track is established as a function of non-conventional values of conventional parameters of a conventional data structure of the manifest. The data structures and the data structure parameters of the manifest may comply, for example, with DASH standard.</div>
<div class="description-paragraph" id="p-0051" num="0050">In an embodiment, the step of requesting the at least one selected tile track comprises a step of requesting parameter values and a step of requesting, as a function of, in particular, the parameter values obtained in response to the step of requesting parameter values, the at least one selected tile track.</div>
<div class="description-paragraph" id="p-0052" num="0051">In an embodiment, the dependency relation between the at least one selected tile track and the at least one composite track is established as a function of values of non-conventional parameters of a conventional data structure of the manifest.</div>
<div class="description-paragraph" id="p-0053" num="0052">In an embodiment, the dependency relation between the at least one selected tile track and the at least one composite track is established as a function of values of parameters of a non-conventional data structure of the manifest.</div>
<div class="description-paragraph" id="p-0054" num="0053">It is to be noted that when frames of a base layer are divided into tiles, such non-conventional parameters of a conventional or non-conventional data structure of the manifest can be used to describe dependencies between tiles of different layers such as tiles of a base layer and tiles of an enhancement layer.</div>
<div class="description-paragraph" id="p-0055" num="0054">In an embodiment, the method further comprises comprising building an index table, the built index table associating a request address with an identifier of each tile track referred to in the at least one representation.</div>
<div class="description-paragraph" id="p-0056" num="0055">In an embodiment, the method further comprises associating a position with each tile track identifier in the index table, the position representing a position at which media data associated with the corresponding tile track are to be positioned in a reconstructed portion of the tiled timed media data.</div>
<div class="description-paragraph" id="p-0057" num="0056">In an embodiment, the method further comprises parsing the at least one composite track, the playable media representation bit-stream being generated as a function of media data of the at least one selected tile track determined as a function of the parsed data of the at least one composite track.</div>
<div class="description-paragraph" id="p-0058" num="0057">A third aspect of the invention provides a method for transmitting timed media data organized into temporal media segments, the timed media data belonging to partitioned timed media data comprising timed samples, each timed sample comprising a plurality of subsamples, the timed media data being transmitted as at least one media segment file comprising independently encapsulated components comprising at least one partition component containing a subsample selected from among the plurality of subsamples of one of the timed samples and one corresponding subsample of each of the other timed samples and at least one reference component comprising at least one extractor identifying at least one partition component, the method comprising:</div>
<div class="description-paragraph" id="p-0059" num="0058">transmitting a manifest describing a plurality of versions of the partitioned timed media data, the manifest comprising representations, each representation comprising at least a description of a version of a portion of the partitioned timed media data, at least one said representation comprising a description of a plurality of components among which at least one component is required to reconstruct at least partially the partitioned timed media data and among which at least one component is an optional component that can be selected to reconstruct at least a portion of the partitioned timed media data.</div>
<div class="description-paragraph" id="p-0060" num="0059">Accordingly, the invention makes it possible for a client device to identify from a manifest file required data and optional data and to dynamically select a set of optional data to stream. Applied to tiles, this makes it possible to dynamically adapt the streaming to user-defined regions of interest. With the invention, a client device can be informed that videos from a media presentation offer spatial access. By using information from the manifest, a client device can decide to dynamically switch to a specific spatial area of a video and also dynamically switch back to the full-frame video.</div>
<div class="description-paragraph" id="p-0061" num="0060">In an embodiment, the method further comprises:</div>
<div class="description-paragraph" id="p-0062" num="0061">receiving a request for transmitting the at least one component that is required to reconstruct at least partially the partitioned timed media data;</div>
<div class="description-paragraph" id="p-0063" num="0062">receiving at least one request for transmitting at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data; and</div>
<div class="description-paragraph" id="p-0064" num="0063">transmitting the at least one component that is required to reconstruct at least partially the partitioned timed media data and the at least one selected component.</div>
<div class="description-paragraph" id="p-0065" num="0064">In an embodiment, the method further comprises receiving a request for parameter values and transmitting the requested parameter values prior to receive at least one request for transmitting at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data, the at least one request for transmitting at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data being based, in particular, on the transmitted parameter values.</div>
<div class="description-paragraph" id="p-0066" num="0065">A fourth aspect of the invention provides a method for generating a media presentation description allowing the transmission of an item of partitioned timed media data comprising timed samples, each timed sample comprising a plurality of subsamples, the partitioned timed media data, organized into temporal media segments, being transmitted as at least one media segment file comprising independently encapsulated components comprising at least one partition component containing a subsample selected from among the plurality of subsamples of one of the timed samples and one corresponding subsample of each of the other timed samples and at least one reference component comprising at least one extractor identifying at least one partition component, the method comprising:</div>
<div class="description-paragraph" id="p-0067" num="0066">obtaining dependency relations between components of a plurality of components of the partitioned timed media data, at least one component of the plurality of component being required to reconstruct at least partially the partitioned timed media data and at least one component of the plurality of component being optional to reconstruct at least a portion of the partitioned timed media data;</div>
<div class="description-paragraph" id="p-0068" num="0067">generating a manifest describing a plurality of versions of the partitioned timed media data, the manifest comprising representations, each representation comprising at least a description of a version of a portion of the partitioned timed media data, at least one said representation comprising a description of the least one component that is required to reconstruct at least partially the partitioned timed media data and of the at least one component that is optional to reconstruct at least a portion of the partitioned timed media data.</div>
<div class="description-paragraph" id="p-0069" num="0068">Accordingly, the invention makes it possible for a client device to identify from a manifest file required data and optional data and to dynamically select a set of optional data to stream. Applied to tiles, this makes it possible to dynamically adapt the streaming to user-defined regions of interest. With the invention, a client device can be informed that videos from a media presentation offer spatial access. By using information from the manifest, a client device can decide to dynamically switch to a specific spatial area of a video and also dynamically switch back to the full-frame video.</div>
<div class="description-paragraph" id="p-0070" num="0069">In an embodiment, the dependency relations are characterized by using predetermined non-conventional values of conventional parameters of a conventional data structure of the manifest. The data structures and the data structure parameters of the manifest may comply, for example, with DASH standard.</div>
<div class="description-paragraph" id="p-0071" num="0070">In an embodiment, the dependency relations are characterized by using predetermined values of non-conventional parameters of a conventional data structure of the manifest.</div>
<div class="description-paragraph" id="p-0072" num="0071">In an embodiment, the dependency relations are characterized by using predetermined values of parameters of a non-conventional data structure of the manifest.</div>
<div class="description-paragraph" id="p-0073" num="0072">It is to be noted that when frames of a base layer are divided into tiles, such non-conventional parameters of a conventional or non-conventional data structure of the manifest can be used to describe dependencies between tiles of different layers such as tiles of a base layer and tiles of an enhancement layer.</div>
<div class="description-paragraph" id="p-0074" num="0073">A fifth aspect of the invention provides a device comprising means adapted for carrying out each step of the method described above.</div>
<div class="description-paragraph" id="p-0075" num="0074">Accordingly, the invention makes it possible for a client device to identify from a manifest file required data and optional data and to dynamically select a set of optional data to stream. Applied to tiles, this makes it possible to dynamically adapt the streaming to user-defined regions of interest. With the invention, a client device can be informed that videos from a media presentation offer spatial access. By using information from the manifest, a client device can decide to dynamically switch to a specific spatial area of a video and also dynamically switch back to the full-frame video.</div>
<div class="description-paragraph" id="p-0076" num="0075">A sixth aspect of the invention provides a device for receiving streamed timed media data organized into temporal media segments, the timed media data belonging to partitioned timed media data comprising timed samples, each timed sample comprising a plurality of subsamples, the timed media data being transmitted as at least one media segment file comprising independently encapsulated components comprising at least one partition component containing a subsample selected from among the plurality of subsamples of one of the timed samples and one corresponding subsample of each of the other timed samples and at least one reference component comprising at least one extractor identifying at least one partition component, the device comprising at least one microprocessor configured for carrying out the steps of:</div>
<div class="description-paragraph" id="p-0077" num="0076">receiving a manifest describing a plurality of versions of the partitioned timed media data, the manifest comprising representations, each representation comprising at least a description of a version of a portion of the partitioned timed media data, at least one said representation comprising a description of a plurality of components among which at least one component is required to reconstruct at least partially the partitioned timed media data and among which at least one component is an optional component that can be selected to reconstruct at least a portion of the partitioned timed media data;</div>
<div class="description-paragraph" id="p-0078" num="0077">selecting at least one optional component that can be selected to reconstruct at least a portion of the partitioned timed media data;</div>
<div class="description-paragraph" id="p-0079" num="0078">requesting the at least one component that is required to reconstruct at least partially the partitioned timed media data and the at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data; and</div>
<div class="description-paragraph" id="p-0080" num="0079">on reception of the requested components, generating a playable media representation bit-stream from the received components.</div>
<div class="description-paragraph" id="p-0081" num="0080">Accordingly, the invention makes it possible for a client device to identify from a manifest file required data and optional data and to dynamically select a set of optional data to stream. Applied to tiles, this makes it possible to dynamically adapt the streaming to user-defined regions of interest. With the invention, a client device can be informed that videos from a media presentation offer spatial access. By using information from the manifest, a client device can decide to dynamically switch to a specific spatial area of a video and also dynamically switch back to the full-frame video.</div>
<div class="description-paragraph" id="p-0082" num="0081">In an embodiment, the microprocessor is further configured for carrying out the step of parsing and analyzing the manifest for establishing a dependency relation between the at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data and the at least one component that is required to reconstruct at least partially the partitioned timed media data.</div>
<div class="description-paragraph" id="p-0083" num="0082">In an embodiment, the microprocessor is further configured so that the step of requesting the at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data comprises a step of requesting parameter values and a step of requesting, as a function of, in particular, the parameter values obtained in response to the step of requesting parameter values, the at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data.</div>
<div class="description-paragraph" id="p-0084" num="0083">In an embodiment, the microprocessor is further configured for carrying out the step of building an index table, the built index table associating a request address with an identifier of each optional component referred to in the at least one representation.</div>
<div class="description-paragraph" id="p-0085" num="0084">In an embodiment, the microprocessor is further configured for carrying out the step of associating a position with each optional component identifier in the index table, the position representing a position at which media data associated with the corresponding optional component are to be positioned in a reconstructed portion of the partitioned timed media data.</div>
<div class="description-paragraph" id="p-0086" num="0085">In an embodiment, the microprocessor is further configured for carrying out the step of parsing the at least one component that is required to reconstruct at least partially the partitioned timed media data, the playable media representation bit-stream being generated as a function of media data of the at least one selected optional component determined as a function of the parsed data of the at least one component that is required to reconstruct at least partially the partitioned timed media data.</div>
<div class="description-paragraph" id="p-0087" num="0086">A seventh aspect of the invention provides a device for receiving streamed timed media data organized into temporal media segments, the timed media data belonging to tiled timed media data comprising timed samples, each timed sample comprising a plurality of subsamples, the timed media data being transmitted as at least one media segment file comprising independently encapsulated tracks comprising at least one tile track containing a subsample selected from among the plurality of subsamples of one of the timed samples and one corresponding subsample of each of the other timed samples and at least one composite track comprising at least one extractor identifying at least one tile track, the device comprising at least one microprocessor configured for carrying out the steps of:</div>
<div class="description-paragraph" id="p-0088" num="0087">receiving a manifest describing a plurality of versions of the tiled timed media data, the manifest comprising representations, each representation comprising at least a description of a version of a portion of the tiled timed media data, at least one said representation comprising a description of a plurality of tracks among which are at least one composite track and at least one tile track;</div>
<div class="description-paragraph" id="p-0089" num="0088">selecting at least one tile track;</div>
<div class="description-paragraph" id="p-0090" num="0089">requesting the at least one composite track and the at least one selected tile track; and</div>
<div class="description-paragraph" id="p-0091" num="0090">on reception of the requested tracks, generating a playable media representation bit-stream from the received tracks.</div>
<div class="description-paragraph" id="p-0092" num="0091">Accordingly, the invention makes it possible for a client device to identify from a manifest file required data and optional data and to dynamically select a set of optional data to stream. Applied to tiles, this makes it possible to dynamically adapt the streaming to user-defined regions of interest. With the invention, a client device can be informed that videos from a media presentation offer spatial access. By using information from the manifest, a client device can decide to dynamically switch to a specific spatial area of a video and also dynamically switch back to the full-frame video.</div>
<div class="description-paragraph" id="p-0093" num="0092">In an embodiment, the microprocessor is further configured for carrying out the step of parsing and analyzing the manifest for establishing a dependency relation between the at least one selected tile track and the at least one composite track.</div>
<div class="description-paragraph" id="p-0094" num="0093">In an embodiment, the microprocessor is further so that the step of requesting the at least one selected tile track comprises a step of requesting parameter values and a step of requesting, as a function of, in particular, the parameter values obtained in response to the step of requesting parameter values, the at least one selected tile track.</div>
<div class="description-paragraph" id="p-0095" num="0094">In an embodiment, the microprocessor is further configured for carrying out the step of building an index table, the built index table associating a request address with an identifier of each tile track referred to in the at least one representation.</div>
<div class="description-paragraph" id="p-0096" num="0095">In an embodiment, the microprocessor is further configured for carrying out the step of associating a position with each tile track identifier in the index table, the position representing a position at which media data associated with the corresponding tile track are to be positioned in a reconstructed portion of the tiled timed media data.</div>
<div class="description-paragraph" id="p-0097" num="0096">In an embodiment, the microprocessor is further configured for carrying out the step of parsing the at least one composite track, the playable media representation bit-stream being generated as a function of media data of the at least one selected tile track determined as a function of the parsed data of the at least one composite track.</div>
<div class="description-paragraph" id="p-0098" num="0097">An eighth aspect of the invention provides a video decoder comprising the device described above.</div>
<div class="description-paragraph" id="p-0099" num="0098">Accordingly, the invention makes it possible for a client device to identify from a manifest file required data and optional data and to dynamically select a set of optional data to stream. Applied to tiles, this makes it possible to dynamically adapt the streaming to user-defined regions of interest. With the invention, a client device can be informed that videos from a media presentation offer spatial access. By using information from the manifest, a client device can decide to dynamically switch to a specific spatial area of a video and also dynamically switch back to the full-frame video.</div>
<div class="description-paragraph" id="p-0100" num="0099">A ninth aspect of the invention provides a device for transmitting timed media data organized into temporal media segments, the timed media data belonging to partitioned timed media data comprising timed samples, each timed sample comprising a plurality of subsamples, the timed media data being transmitted as at least one media segment file comprising independently encapsulated components comprising at least one partition component containing a subsample selected from among the plurality of subsamples of one of the timed samples and one corresponding subsample of each of the other timed samples and at least one reference component comprising at least one extractor identifying at least one partition component, the device comprising at least one microprocessor configured for carrying out the steps of:</div>
<div class="description-paragraph" id="p-0101" num="0100">transmitting a manifest describing a plurality of versions of the partitioned timed media data, the manifest comprising representations, each representation comprising at least a description of a version of a portion of the partitioned timed media data, at least one said representation comprising a description of a plurality of components among which at least one component is required to reconstruct at least partially the partitioned timed media data and among which at least one component is an optional component that can be selected to reconstruct at least a portion of the partitioned timed media data.</div>
<div class="description-paragraph" id="p-0102" num="0101">Accordingly, the invention makes it possible for a client device to identify from a manifest file required data and optional data and to dynamically select a set of optional data to stream. Applied to tiles, this makes it possible to dynamically adapt the streaming to user-defined regions of interest. With the invention, a client device can be informed that videos from a media presentation offer spatial access. By using information from the manifest, a client device can decide to dynamically switch to a specific spatial area of a video and also dynamically switch back to the full-frame video.</div>
<div class="description-paragraph" id="p-0103" num="0102">In an embodiment, the microprocessor is further configured for carrying out the step of:</div>
<div class="description-paragraph" id="p-0104" num="0103">receiving a request for transmitting the at least one component that is required to reconstruct at least partially the partitioned timed media data;</div>
<div class="description-paragraph" id="p-0105" num="0104">receiving at least one request for transmitting at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data; and</div>
<div class="description-paragraph" id="p-0106" num="0105">transmitting the at least one component that is required to reconstruct at least partially the partitioned timed media data and the at least one selected component.</div>
<div class="description-paragraph" id="p-0107" num="0106">In an embodiment, the microprocessor is further configured for carrying out the step of receiving a request for parameter values and transmitting the requested parameter values prior to receive at least one request for transmitting at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data, the at least one request for transmitting at least one selected optional component that can be selected to reconstruct at least a portion of the partitioned timed media data being based, in particular, on the transmitted parameter values.</div>
<div class="description-paragraph" id="p-0108" num="0107">A tenth aspect of the invention provides a device for generating a media presentation description allowing the transmission of an item of partitioned timed media data comprising timed samples, each timed sample comprising a plurality of subsamples, the partitioned timed media data, organized into temporal media segments, being transmitted as at least one media segment file comprising independently encapsulated components comprising at least one partition component containing a subsample selected from among the plurality of subsamples of one of the timed samples and one corresponding subsample of each of the other timed samples and at least one reference component comprising at least one extractor identifying at least one partition component, the device comprising at least one microprocessor configured for carrying out the steps of:</div>
<div class="description-paragraph" id="p-0109" num="0108">obtaining dependency relations between components of a plurality of components of the partitioned timed media data, at least one component of the plurality of component being required to reconstruct at least partially the partitioned timed media data and at least one component of the plurality of component being optional to reconstruct at least a portion of the partitioned timed media data;</div>
<div class="description-paragraph" id="p-0110" num="0109">generating a manifest describing a plurality of versions of the partitioned timed media data, the manifest comprising representations, each representation comprising at least a description of a version of a portion of the partitioned timed media data, at least one said representation comprising a description of the least one component that is required to reconstruct at least partially the partitioned timed media data and of the at least one component that is optional to reconstruct at least a portion of the partitioned timed media data.</div>
<div class="description-paragraph" id="p-0111" num="0110">Accordingly, the invention makes it possible for a client device to identify from a manifest file required data and optional data and to dynamically select a set of optional data to stream. Applied to tiles, this makes it possible to dynamically adapt the streaming to user-defined regions of interest. With the invention, a client device can be informed that videos from a media presentation offer spatial access. By using information from the manifest, a client device can decide to dynamically switch to a specific spatial area of a video and also dynamically switch back to the full-frame video.</div>
<div class="description-paragraph" id="p-0112" num="0111">An eleventh aspect of the invention provides a video encoder comprising the device described above.</div>
<div class="description-paragraph" id="p-0113" num="0112">Accordingly, the invention makes it possible for a client device to identify from a manifest file required data and optional data and to dynamically select a set of optional data to stream. Applied to tiles, this makes it possible to dynamically adapt the streaming to user-defined regions of interest. With the invention, a client device can be informed that videos from a media presentation offer spatial access. By using information from the manifest, a client device can decide to dynamically switch to a specific spatial area of a video and also dynamically switch back to the full-frame video.</div>
<div class="description-paragraph" id="p-0114" num="0113">Since the present invention can be implemented in software, the present invention can be embodied as computer readable code for provision to a programmable apparatus on any suitable carrier medium. A tangible carrier medium may comprise a storage medium such as a floppy disk, a CD-ROM, a hard disk drive, a magnetic tape device or a solid state memory device and the like. A transient carrier medium may include a signal such as an electrical signal, an electronic signal, an optical signal, an acoustic signal, a magnetic signal or an electromagnetic signal, e.g. a microwave or RF signal.</div>
<description-of-drawings>
<heading id="h-0005">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<div class="description-paragraph" id="p-0115" num="0114">Further advantages of the present invention will become apparent to those skilled in the art upon examination of the drawings and detailed description. It is intended that any additional advantages be incorporated herein.</div>
<div class="description-paragraph" id="p-0116" num="0115">Embodiments of the invention will now be described, by way of example only, and with reference to the following drawings in which:</div>
<div class="description-paragraph" id="p-0117" num="0116"> <figref idrefs="DRAWINGS">FIG. 1</figref> illustrates schematically the use of tiles for streaming regions of interest of video sequences;</div>
<div class="description-paragraph" id="p-0118" num="0117"> <figref idrefs="DRAWINGS">FIG. 2</figref> illustrates a general principle of adaptive media presentation streaming over a communication network according to HyperText Transfer Protocol;</div>
<div class="description-paragraph" id="p-0119" num="0118"> <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates steps for generating a media presentation and a corresponding manifest file;</div>
<div class="description-paragraph" id="p-0120" num="0119"> <figref idrefs="DRAWINGS">FIG. 4</figref> illustrates video tiling and how it applies to compressed video data;</div>
<div class="description-paragraph" id="p-0121" num="0120"> <figref idrefs="DRAWINGS">FIG. 5</figref>, comprising <figref idrefs="DRAWINGS">FIGS. 5<i>a</i>, 5<i>b</i>, and 5<i>c</i> </figref>, illustrates examples of tiles and slice segments;</div>
<div class="description-paragraph" id="p-0122" num="0121"> <figref idrefs="DRAWINGS">FIG. 6</figref> illustrates an example of concatenating media data segments to build a valid decodable timed media data bit-stream representing a spatial part of consecutive video frames for a given temporal period;</div>
<div class="description-paragraph" id="p-0123" num="0122"> <figref idrefs="DRAWINGS">FIG. 7</figref> illustrates an example of an mp4 organization that is suitable for using sub-representations for signaling tile tracks;</div>
<div class="description-paragraph" id="p-0124" num="0123"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a flow chart illustrating processing steps carried out in a client device for processing a manifest comprising tile description according to the previous embodiment;</div>
<div class="description-paragraph" id="p-0125" num="0124"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a flow chart illustrating processing steps carried out in a client device for processing a manifest comprising dependency description according to the previous embodiment;</div>
<div class="description-paragraph" id="p-0126" num="0125"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a schematic block diagram of a computing device that can be used for carrying each or some steps of each of the described embodiments of the invention;</div>
<div class="description-paragraph" id="p-0127" num="0126"> <figref idrefs="DRAWINGS">FIG. 11</figref>, comprising <figref idrefs="DRAWINGS">FIGS. 11<i>a </i>and 11<i>b</i> </figref>, illustrates examples of tiling configuration for spatially scalable videos; and</div>
<div class="description-paragraph" id="p-0128" num="0127"> <figref idrefs="DRAWINGS">FIG. 12</figref> illustrates an example of tiling configuration for SNR (Signal-to-noise ratio) scalable videos.</div>
</description-of-drawings>
<heading id="h-0006">DETAILED DESCRIPTION OF EMBODIMENTS OF THE INVENTION</heading>
<div class="description-paragraph" id="p-0129" num="0128">According to a particular embodiment, there is described a solution based on a compact description of spatial sub-parts of a video sequence in a manifest, that can be easily integrated, in particular, in file conforming to the DASH MPD standard. By using such a solution, a client device may obtain knowledge about the existence of spatial media components and obtain HyperText Transfer Protocol (http) addresses for downloading each of these media components. To that end, manifest files comprise information regarding optional dependencies between video representations.</div>
<div class="description-paragraph" id="p-0130" num="0129">According to a particular embodiment, video sequences are encoded into independent spatial partitions (e.g. tiles), each encoded partition being encapsulated in the file format as an independent track (partition track or tile track). An additional track, referred to as a reference track or a composite track, comprising references to data of partition tracks, is used to encapsulate any composition of more than one partition track. Such an encapsulation of the partition tracks and the reference track is signaled in a manifest to inform a client device on the availability of spatial access. The manifest also includes a description of each partition track as an optional addressable component of the composite track.</div>
<div class="description-paragraph" id="p-0131" num="0130">Various embodiments, resulting from a trade-off between importance of syntax modifications and completeness of the description, can be provided.</div>
<div class="description-paragraph" id="p-0132" num="0131">According to a particular embodiment, partitioned timed media data such as tiled timed media data (e.g. video data) comprising timed samples (e.g. images) are transmitted as a set of several timed media data tracks, typically a base layer track and several tile tracks, and a reference or composite track that comprises references to timed media data tracks. Each tile track comprises one spatial subsample (e.g. several Network Abstraction Layer (NAL) units) of several timed samples. An extended extractor type is defined for referencing timed media data tracks from a composite track. Timed media data tracks are labeled as not displayable and convey and describe timed media data for tiles. Such a set of timed media data tracks and a composite track allows the selecting, composing, and efficient streaming of spatial video tiles. Each track can be transmitted from a server to a client device as a set of media segment files. An initialization segment file can be used to transmit metadata required to decode media segment files.</div>
<div class="description-paragraph" id="p-0133" num="0132"> <figref idrefs="DRAWINGS">FIG. 2</figref> illustrates a general principle of adaptive media presentation streaming over a communication network according to http. Most of the protocols and standards for media streaming over http are based on this principle.</div>
<div class="description-paragraph" id="p-0134" num="0133">As illustrated, server <b>200</b> comprises media presentations among which, in particular, is media presentation <b>205</b> that contains interleaved video and audio components. <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates schematically how such a media presentation can be constructed.</div>
<div class="description-paragraph" id="p-0135" num="0134">During encoding, media presentations are temporally split into small independent and consecutive temporal components, for example components conforming to the MP4 standard (ISO/IEC 14496-14), that can be addressed and downloaded independently. Addresses (i.e., http addresses in the described embodiment) are set by server <b>200</b> for all the segments of each obtained temporal components and a manifest is created as described by reference to <figref idrefs="DRAWINGS">FIG. 4</figref>.</div>
<div class="description-paragraph" id="p-0136" num="0135">As described above, a manifest is a document, typically an XML file, that describes the content of all temporal components that can be accessed for a given media presentation. Such a description may comprise the types of the media components (for example audio, video, audio-video, or text), the time durations of the media segments, and the addresses (e.g. the URL) associated with the media segments, that is to say the addresses from which the media components can be obtained.</div>
<div class="description-paragraph" id="p-0137" num="0136">Typically, a MPD is based on a hierarchical data model. It consists of one or multiple periods, each period having a starting time and a duration and consists of one or multiple adaptation sets. An adaptation set provides the information about one or multiple media components and its various encoded alternatives, each encoded alternative of the same media component being referred to as a representation. In turn, each representation typically consists of one or multiple segments.</div>
<div class="description-paragraph" id="p-0138" num="0137">For the sake of illustration, the interleaved audio and video data of media presentation <b>205</b> is temporally split into consecutive temporal components, for example into three consecutive temporal components <b>210</b>-<b>1</b> to <b>210</b>-<b>3</b> corresponding to three consecutive periods. Each of these media components comprises at least one adaptation set (not represented) that comprises at least one representation (not represented) that contains several media segments (not represented). The addresses of these segments are set by server <b>200</b>. These addresses and other items of information relative to the temporal components <b>210</b>-<b>1</b> to <b>210</b>-<b>3</b> are accessible in manifest <b>215</b> corresponding to media presentation <b>205</b>.</div>
<div class="description-paragraph" id="p-0139" num="0138">This manifest file is sent to client device <b>220</b> (step <b>225</b>). After having been received, manifest file <b>215</b> is analyzed by client device <b>220</b> to determine accessible media segments of media components <b>210</b>-<b>1</b> to <b>210</b>-<b>3</b> of media presentation <b>205</b>, the http addresses of these media segments, and the relations between these media segments. Moreover, manifest file <b>215</b> gives items of information about the content of the media presentation (i.e. interleaved audio and video in the given example). These items of information may comprise a resolution, a bit-rate, and similar information.</div>
<div class="description-paragraph" id="p-0140" num="0139">In view of this information, client device <b>220</b> can therefore select media segments to receive and emit corresponding http requests (step <b>230</b>) for downloading these segments. In response, server <b>200</b> transmits the requested temporal segments (step <b>235</b>). These temporal segments can be decoded in decoder <b>240</b> and displayed on display <b>245</b>.</div>
<div class="description-paragraph" id="p-0141" num="0140"> <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates steps for generating a media presentation and a corresponding manifest file. Such steps are typically carried out by a server such as server <b>200</b> in <figref idrefs="DRAWINGS">FIG. 2</figref>.</div>
<div class="description-paragraph" id="p-0142" num="0141">As illustrated, audio and video data are obtained during steps <b>300</b> and <b>305</b>, respectively. Such data can be obtained, for example, from an external source, via a communication network, such as a data storage server connected to the server carrying out the steps illustrated in <figref idrefs="DRAWINGS">FIG. 3</figref>.</div>
<div class="description-paragraph" id="p-0143" num="0142">Audio data are compressed during step <b>310</b>. Such a compression can be based, for example, on the MP3 standard (MPEG-1/2 Audio Layer 3). In parallel, video data are also compressed during step <b>315</b>. To that end, video data compression algorithm like MPEG4, MPEG/AVC, SVC, HEVC, or scalable HEVC can be used.</div>
<div class="description-paragraph" id="p-0144" num="0143">The audio and video data are compressed as data elementary streams, as illustrated with references <b>320</b> and <b>325</b>, respectively. These elementary streams are encapsulated during step <b>330</b> to create a global media presentation <b>335</b>.</div>
<div class="description-paragraph" id="p-0145" num="0144">For example, the ISO BMFF standard (or, still for the sake of illustration, the extension of this ISO BMFF standard to AVC, SVC, or HEVC) can be used for describing the content of the encoded audio and video elementary streams as a global media presentation. Accordingly, the encapsulated media presentation is used as input for the generation (step <b>340</b>) of a manifest, for example XML manifest <b>345</b>.</div>
<div class="description-paragraph" id="p-0146" num="0145">As described above for the specific case of DASH, the manifest file (MPD) is hierarchically organized by components (associated with periods), adaptation sets, representations, and segments. In other words, a media presentation is split into temporal periods, the MPD containing all the data related to each period. By receiving corresponding items of information, a client device can determine the media presentation content for each period of time.</div>
<div class="description-paragraph" id="p-0147" num="0146">Again, this content is organized into adaptation sets, a possible organization being to have one or more adaptation sets per media type contained in the media presentation. An adaptation set relating to video data typically contains items of information about the different possible representations of the corresponding encoded video data component available from the server. For the sake of illustration, a first representation can be directed to video data encoded at a spatial resolution of 640×480 pixels and compressed at a bit-rate of 500 kbits/s. A second representation can be directed to a similar video content but compressed at a bit-rate of 250 kbits/s. Each representation can then be downloaded by a client device as segments using http requests under the condition that the client device knows the corresponding http addresses.</div>
<div class="description-paragraph" id="p-0148" num="0147">The association between video data of each representation and http addresses is made by using a specific level of description referred to as temporal segments. Accordingly, each video representation is split into temporal segments (having a duration of typically a few seconds). Therefore, each temporal segment is a portion of a video content stored in the server that is accessible through a particular http address (URL or URL with one byte range).</div>
<div class="description-paragraph" id="p-0149" num="0148">In addition, a specific segment known as the initialization segment is created and made accessible to a client device. This initialization segment may contain MP4 initialization items of information (if the video has been encapsulated by using the ISO BMFF or extensions) that describe the encapsulated video stream. For the sake of illustration, these items of information help a client device to instantiate the decoding algorithms relating to the accessed compressed video data. The http addresses of the initialization segment and of the media segments are given in the MPD file. An example of an MPD file is given in the Appendix (Extract of code 2).</div>
<div class="description-paragraph" id="p-0150" num="0149">Extract of code 2 given in the Appendix illustrates an example of a DASH manifest (MPD) for a given media presentation. The aim of this example is to present the main characteristics of an MPD. It is to be noted that for the sake of clarity, the representations given in this example are not split into temporal segments.</div>
<div class="description-paragraph" id="p-0151" num="0150">In this MPD example, two types of media data are described for one period. The first one is an English audio stream and the second one is a video stream.</div>
<div class="description-paragraph" id="p-0152" num="0151">The English audio stream is introduced through the AdaptationSet tag of the ‘audio/MP4’ type. The MPD describes two representations of this audio stream:
</div> <ul> <li id="ul0001-0001" num="0000"> <ul> <li id="ul0002-0001" num="0152">the first representation (having index one: &lt;Representation id=“1” . . . &gt;) is an MP4 encapsulated elementary audio stream having a bit-rate equal to 64,000 (bandwidth=“64000”) bytes per second. As indicated in this example, the codec to use for handling this elementary stream (after mp4 parsing) is defined in the standard by the attribute ‘mp4a.0x40’ (&lt;AdaptationSet codecs=“mp4a.0x40” . . . &gt;). According to this example, the representation is accessible on request at the address: &lt;BaseURL&gt;7657412348.mp4&lt;/BaseURL&gt;, the &lt;BaseURL&gt; being defined in the MPD by ‘http://cdntexample.com/’ or by ‘http://cdn2.example.com/’ (two servers are available for streaming the same content). Accordingly, a client device can request the English audio stream using a corresponding request to the address ‘http://cdn1.example.com/7657412348.mp4’ or to the address ‘http://cdn2.example.com/7657412348.mp4’; and</li> <li id="ul0002-0002" num="0153">the second representation (having index two: &lt;Representation id=“2” . . . &gt;) is an MP4 encapsulated elementary audio stream having a bit-rate equal to 32,000 bytes per second.</li> </ul> </li> </ul>
<div class="description-paragraph" id="p-0153" num="0154">The video stream is introduced through the ‘AdaptationSet’ tag of the ‘video/MP4’ type. The MPD describes six representations of this video stream. As indicated in the MPD, these representations contain videos at different spatial resolutions (320×240, 640×480, and 1280×720 pixels) and at different bit-rates (from 256000 to 2048000 bytes per second). For each of these representations, a different URL is associated. The client device can therefore choose one representation among these alternative representations of the same video data as a function of criteria such as an estimated bandwidth and a screen resolution.</div>
<div class="description-paragraph" id="p-0154" num="0155">From this example, one can understand the limitations of conventional MPD regarding the description of tile tracks for the streaming of regions of interest. Although tile tracks can be described as representation of full video frames, tile tracks may not be displayable, depending on the encapsulation, in particular if they contain only tile data. Initialization data for the decoder may be missing. Accordingly, by using conventional MPD and one representation per tile track, client devices cannot obtain items of information regarding the possibilities of tile combination or even incompatibilities. In other words, each tile would be seen as an alternative to another tile thus preventing multiple tile selection. The only combination that could be signaled is a combination of all tiles, using for example the attribute known as dependencyId in the Representation element of a composite track or no tile at all provided that the full-frame video has its own Representation in the manifest. Several embodiments are described herein below to solve this issue.</div>
<div class="description-paragraph" id="p-0155" num="0156">As described above, tiles are independently decodable spatial areas of video frames.</div>
<div class="description-paragraph" id="p-0156" num="0157"> <figref idrefs="DRAWINGS">FIG. 4</figref> illustrates video tiling and how it applies to compressed video data. As illustrated, video stream <b>400</b> comprises a set of consecutive temporal frames (for the sake of illustration, three consecutive temporal frames are represented). Each frame can be divided into rectangles, for example eight rectangles as illustrated with reference <b>405</b>, referred to as tiles Tn (with n varying from 1 to 8). Naturally the number and the shape of the tiles can be different. However, for the sake of illustration, it is considered that tiling is the same whatever the index of the considered video frame.</div>
<div class="description-paragraph" id="p-0157" num="0158">As a result of the tiling, independent sub-videos (eight in the illustrated example) are obtained. These sub-videos, referred to as <b>410</b>, are partitions of the whole video. Each independent sub-video can be encoded as an independent bit-stream conforming, for example, to AVC or HEVC standard, or it can be a part of a single video bit-stream such as a tile in a HEVC bit-stream or a slice in AVC.</div>
<div class="description-paragraph" id="p-0158" num="0159">This tiling organization of the video can be extended to other configurations, especially when considering scalable video encoding formats such as SVC or scalable HEVC.</div>
<div class="description-paragraph" id="p-0159" num="0160"> <figref idrefs="DRAWINGS">FIG. 11</figref>, comprising <figref idrefs="DRAWINGS">FIGS. 11<i>a </i>and 11<i>b</i> </figref>, illustrates examples of tiling configurations.</div>
<div class="description-paragraph" id="p-0160" num="0161"> <figref idrefs="DRAWINGS">FIG. 11<i>a </i> </figref>illustrates a particular tiling configuration. As illustrated, frame <b>1100</b> of a video sequence (not represented) is encoded as a scalable video with a base layer frame <b>1105</b> and a spatial enhancement layer frame <b>1110</b> that is divided into eight tile portions (T<b>1</b>, T<b>2</b>, . . . , T<b>8</b>). The base layer is not tiled. Accordingly, each tile of the enhancement layer (e.g., each tile portion of the enhancement layer frame <b>1110</b>) depends on the whole base layer. In such a frame organization, when a portion of an image such as portion <b>1115</b> is selected to stream a spatial part of the frames (e.g. the right bottom part of the frame <b>1100</b>), the selected tiles (e.g. tiles T<b>6</b> and T<b>8</b>) and the base layer are needed. As illustrated in <figref idrefs="DRAWINGS">FIG. 11<i>a</i> </figref>, selected portion <b>1115</b>, representing a region of interest, is encompassed by the two tiles T<b>6</b> and T<b>8</b> and the base layer <b>1105</b>.</div>
<div class="description-paragraph" id="p-0161" num="0162"> <figref idrefs="DRAWINGS">FIG. 11<i>b </i> </figref>illustrates another particular tiling configuration. As illustrated, a video sequence comprising frame <b>1150</b> is encoded as a tiled base layer (i.e. tile base layer frame <b>1155</b>) and a tiled spatial enhancement layer (i.e. tiled spatial enhancement layer frame <b>1160</b>) with spatial dependencies that are tiled-based: one tile of the enhancement layer depends only on the tile at the same position in the base layer. In such a configuration, when a user selects a region of interest such as ROI <b>1165</b>, he/she needs the two tiles T<b>6</b> and T<b>8</b> of the enhancement layer frame <b>1160</b> and the two reference tiles T<b>06</b> and T<b>08</b> of the base layer frame <b>1155</b>.</div>
<div class="description-paragraph" id="p-0162" num="0163"> <figref idrefs="DRAWINGS">FIG. 12</figref> illustrates an example of tiling configuration for scalability of the SNR (Signal-to-noise ratio) type. In such a configuration, tiles of an enhancement layer, for example tile portions T<b>1</b> to T<b>2</b> of enhancement layer frame <b>1210</b> of frame <b>1200</b>, depend on the same tiles of the base layer, for example on tile portions T<b>01</b> to T<b>08</b> of the base layer frame <b>1205</b>. Dependencies are tile-based. In such a case, when a user selects an image portion for streaming, for example area <b>1215</b> of frame <b>1200</b>, tiles of the enhancement layer are streamed with the corresponding dependent tiles of the base layer, for example tile portions T<b>6</b> and T<b>8</b> from enhancement layer frame <b>1210</b> are streamed with tile portions T<b>06</b> and T<b>08</b> of base layer frame <b>1205</b>.</div>
<div class="description-paragraph" id="p-0163" num="0164">A user-selected region of interest may correspond to one or several adjacent tiles (e.g., the combination of tiles T<b>6</b> and T<b>8</b> in the examples illustrated in <figref idrefs="DRAWINGS">FIGS. 11 and 12</figref> or T<b>6</b> and T<b>2</b> in the examples illustrated in <figref idrefs="DRAWINGS">FIG. 4</figref>).</div>
<div class="description-paragraph" id="p-0164" num="0165">As described above, an embodiment of the invention can apply, in particular, to the HEVC video format.</div>
<div class="description-paragraph" id="p-0165" num="0166">According to HEVC standard, images can be spatially divided into tiles, slices, and slice segments. In this standard, a tile corresponds to a rectangular region of an image that is defined by horizontal and vertical boundaries (i.e., rows and columns). It contains an integer number of Coding Tree Units (CTU). Therefore, tiles can be efficiently used to identify regions of interest by defining, for example, positions and sizes for regions of interest. However, the structure of an HEVC bit-stream as well as its encapsulation as Network Abstract Layer (NAL) units are not organized in terms of tiles but are based on slices.</div>
<div class="description-paragraph" id="p-0166" num="0167">In HEVC standard, slices are sets of slice segments, the first slice segment of a set of slice segments being an independent slice segment, that is to say a slice segment for which general information stored within a header does not refer to that of another slice segment. The other slice segments of the set of slice segments, if any, are dependent slice segments (i.e. slice segments for which general information stored within a header refers to that of an independent slice segment).</div>
<div class="description-paragraph" id="p-0167" num="0168">A slice segment contains an integer number of consecutive (in raster scan order) Coding Tree Units. Therefore, a slice segment can be of a rectangular shape or not and it is thus not suited to represent a region of interest. It is encoded in an HEVC bit-stream I, the form of a slice segment header followed by slice segment data. Independent and dependent slice segments differ by their header: since a dependent slice segment depends on an independent slice segment, the amount of information of its header is smaller than in the header of an independent slice segment. Both independent and dependent slice segments contain a list of entry points into the corresponding bit-stream that are used to define tiles or as entropy decoding synchronization points.</div>
<div class="description-paragraph" id="p-0168" num="0169"> <figref idrefs="DRAWINGS">FIG. 5</figref>, comprising <figref idrefs="DRAWINGS">FIGS. 5<i>a</i>, 5<i>b</i>, and 5<i>c</i> </figref>, illustrates examples of tiles and slice segments. More precisely, <figref idrefs="DRAWINGS">FIG. 5<i>a </i> </figref>illustrates an image (<b>500</b>) divided into nine portions by vertical boundaries <b>505</b>-<b>1</b> and <b>505</b>-<b>2</b> and horizontal boundaries <b>510</b>-<b>1</b> and <b>510</b>-<b>2</b>. Each of the nine portions referenced <b>515</b>-<b>1</b> to <b>515</b>-<b>9</b> represents a particular tile.</div>
<div class="description-paragraph" id="p-0169" num="0170"> <figref idrefs="DRAWINGS">FIG. 5<i>b </i> </figref>illustrates an image (<b>500</b>′) containing two vertical tiles delimited by vertical boundary <b>505</b>′. Image <b>500</b>′ comprises a single slice (not referenced) containing five slice segments, one independent slice segment <b>520</b>-<b>1</b> (represented with hatched lines) and four dependent slice segments <b>520</b>-<b>2</b> to <b>520</b>-<b>5</b>.</div>
<div class="description-paragraph" id="p-0170" num="0171"> <figref idrefs="DRAWINGS">FIG. 5<i>c </i> </figref>illustrates an image (<b>500</b>″) containing two vertical tiles delimited by vertical boundary <b>505</b>″. The left tile comprises two slices: a first slice containing one independent slice segment (<b>520</b>′-<b>1</b>) and one dependent slice segment (<b>520</b>′-<b>2</b>) and a second slice also containing one independent slice segment (<b>520</b>′-<b>3</b>) and one dependent slice segment (<b>520</b>′-<b>4</b>). The right tile comprises one slice containing one independent slice segment (<b>520</b>′-<b>5</b>) and one dependent slice segment (<b>520</b>′-<b>6</b>).</div>
<div class="description-paragraph" id="p-0171" num="0172">According to HEVC standard, slice segments are linked to tiles according to rules that may be summarized as follows (one or both conditions have to be met):
</div> <ul> <li id="ul0003-0001" num="0000"> <ul> <li id="ul0004-0001" num="0173">all CTUs in a slice segment belong to the same tile (i.e. a slice segment cannot belong to several tiles); and</li> <li id="ul0004-0002" num="0174">all CTUs in a tile belong to the same slice segment (i.e. a tile may be divided into several slice segments provided that each of these slice segments only belongs to that tile).</li> </ul> </li> </ul>
<div class="description-paragraph" id="p-0172" num="0175">For the sake of clarity, it is considered in the following that one tile contains one slice having only one independent slice segment. However, embodiments of the invention can be carried out with other configurations like the ones illustrated in <figref idrefs="DRAWINGS">FIGS. 9<i>b </i> </figref>and <b>9</b> <i>c. </i> </div>
<div class="description-paragraph" id="p-0173" num="0176">As mentioned above, while tiles can be considered as an appropriate support for regions of interest, slice segments are the entities that are actually put in NAL units for transport over a communication network and aggregated to form access units (i.e. coded picture or samples at file format level).</div>
<div class="description-paragraph" id="p-0174" num="0177">It is to be recalled that according to HEVC standard, the type of a NAL unit is encoded in two bytes of the NAL unit header that can be defined as follows:</div>
<div class="description-paragraph" id="p-0175" num="0178">
<tables id="TABLE-US-00001" num="00001">
<patent-tables colsep="0" frame="none" rowsep="0">
<table align="left" class="description-table" cols="3" colsep="0" rowsep="0" width="100%">
<thead>
<tr class="description-tr">
<td class="description-td"> </td>
<td align="center" class="description-td" colspan="3" nameend="2" namest="offset" rowsep="1"> </td>
</tr>
</thead>
<tbody><tr class="description-tr">
<td class="description-td"> </td>
<td class="description-td"> </td>
<td class="description-td">nal_unit_header ( ) {</td>
</tr>
<tr class="description-tr">
<td class="description-td"> </td>
<td class="description-td"> </td>
<td class="description-td"> forbidden_zero_bit</td>
</tr>
<tr class="description-tr">
<td class="description-td"> </td>
<td class="description-td"> </td>
<td class="description-td"> nal_unit_type</td>
</tr>
<tr class="description-tr">
<td class="description-td"> </td>
<td class="description-td"> </td>
<td class="description-td"> nuh_layer_id</td>
</tr>
<tr class="description-tr">
<td class="description-td"> </td>
<td class="description-td"> </td>
<td class="description-td"> nuh_temporal_id_plus1</td>
</tr>
<tr class="description-tr">
<td class="description-td"> </td>
<td class="description-td"> </td>
<td class="description-td">}</td>
</tr>
<tr class="description-tr">
<td class="description-td"> </td>
<td align="center" class="description-td" colspan="3" nameend="2" namest="offset" rowsep="1"> </td>
</tr>
</tbody></table>
</patent-tables>
</tables>
</div>
<div class="description-paragraph" id="p-0176" num="0179">NAL units used to code slice segments comprise slice segment headers indicating the address of the first CTU in the slice segment thanks to a slice segment address syntax element. Such slice segment headers can be defined as follows:</div>
<div class="description-paragraph" id="p-0177" num="0180">
<tables id="TABLE-US-00002" num="00002">
<patent-tables colsep="0" frame="none" rowsep="0">
<table align="left" class="description-table" cols="1" colsep="0" rowsep="0" width="100%">
<thead>
<tr class="description-tr">
<td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td>
</tr>
</thead>
<tbody><tr class="description-tr">
<td class="description-td">slice_segment_header ( ) {</td>
</tr>
<tr class="description-tr">
<td class="description-td"> first_slice_segment_in_pic_flag</td>
</tr>
<tr class="description-tr">
<td class="description-td"> if(nal_unit_type &gt;= BLA_W_LP &amp;&amp; nal_unit_type &lt;= RSV_IRAP_</td>
</tr>
<tr class="description-tr">
<td class="description-td"> VCL23)</td>
</tr>
<tr class="description-tr">
<td class="description-td">  no_output_of_prior_pics_flag</td>
</tr>
<tr class="description-tr">
<td class="description-td"> slice_pic_parameter_set_id</td>
</tr>
<tr class="description-tr">
<td class="description-td"> if(!first_slice_segment_in_pic_flag){</td>
</tr>
<tr class="description-tr">
<td class="description-td">  if(dependent_slice_segments_enabled_flag)</td>
</tr>
<tr class="description-tr">
<td class="description-td">   dependent_slice_segment_flag</td>
</tr>
<tr class="description-tr">
<td class="description-td">  slice_segment_address</td>
</tr>
<tr class="description-tr">
<td class="description-td"> }</td>
</tr>
<tr class="description-tr">
<td class="description-td"> If(!dependent_slice_segment_flag){</td>
</tr>
<tr class="description-tr">
<td class="description-td"> [...]</td>
</tr>
<tr class="description-tr">
<td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td>
</tr>
</tbody></table>
</patent-tables>
</tables>
</div>
<div class="description-paragraph" id="p-0178" num="0181">Tiling information is provided in a PPS (Picture Parameter Set) NAL unit. The relation between a slice segment and a tile can then be deduced from these parameters.</div>
<div class="description-paragraph" id="p-0179" num="0182">While spatial predictions are reset on tile borders (by definition), nothing prevents a tile from using temporal predictors from a different tile in the reference frame(s). Accordingly, to build independent tiles, motion vectors for the prediction units are advantageously constrained inside a tile, during encoding, to remain in the co-located tile in the reference frame(s). In addition, the in-loop filters (deblocking and sample adaptive offset (SAO) filters) are preferably deactivated on the tile borders so that no error drift is introduced when decoding only one tile. It is to be noted that such a control of the in-loop filters is available in HEVC standard. It is set in slice segment header with a flag known as loop_filter_across_files_enabled_flag. By explicitly setting this flag to zero, the pixels at the tile borders cannot depend on pixels that fall on the border of the neighbor tiles. When these two conditions relating to motion vectors and to in-loop filters are met, tiles can be considered as “independently decodable tiles” or “independent tiles”. This information on tile coding dependencies can be set in a dedicated SEI (Supplemental Enhancement Information) message of the HEVC bit-stream to signal ROI information.</div>
<div class="description-paragraph" id="p-0180" num="0183">When a video bit-stream is encoded as a set of independent tiles, it then enables tile-based decoding from one frame to another without any risk of missing reference data or propagation of reconstruction errors. This configuration then makes it possible to reconstruct only a spatial part of the original video that can correspond, for example, to a region of interest illustrated in <figref idrefs="DRAWINGS">FIG. 4</figref> (comprising tiles T<b>2</b> and T<b>6</b>) or in <figref idrefs="DRAWINGS">FIGS. 11 and 12</figref> (comprising tiles T<b>6</b> and T<b>8</b>). Such a configuration, independent tiles, and tile-based dependencies, can be indicated in SEI messages in the video bit-stream. This can be exploited in encapsulation and description level so as to indicate that tile-based decoding is reliable.</div>
<div class="description-paragraph" id="p-0181" num="0184">Before being described in a manifest, each tile must be processed for being encapsulated in a standard format. Such an encapsulation stage is described by reference to <figref idrefs="DRAWINGS">FIG. 6</figref>. For the sake of illustration, the encapsulation format complies with ISO BMFF standard (or is an extension of a media file conforming to this standard). This is one of the formats for which the MPEG/DASH standard specifies construction guidelines.</div>
<div class="description-paragraph" id="p-0182" num="0185">Independent tiles are provided as an input of an encapsulation module and each tile is considered as an independent track for encapsulation. For each encoded tile, a tile track is defined in the resulting ISO BMFF file. Each tile track then represents a spatial part of the whole (or full-frame) video. Additional tracks such as an audio track or a text track can be used and encapsulated in the same file.</div>
<div class="description-paragraph" id="p-0183" num="0186">A composite track is created and defined in the ISO BMFF file. It is used to handle any combination of tiles.</div>
<div class="description-paragraph" id="p-0184" num="0187">According to the organization of tile tracks and of the composite track, tile data are split into independent and addressable tracks so that any combination of tile tracks can easily be constructed from a composite track that references the tile tracks.</div>
<div class="description-paragraph" id="p-0185" num="0188">For each tile track, tile items of information such as tile position, tile size, and bandwidth are stored in track header, for example in track header boxes known as ‘moov’ box. For streaming, these items of information can be stored in an initialization segment defined in DASH standard.</div>
<div class="description-paragraph" id="p-0186" num="0189">In addition to the initialization segment, the encapsulation process generates segment files (media segments that may be accessed through an URL when the MPD is generated) that correspond to small periods of time. The segments typically correspond to movie fragments (e.g. boxes known as ‘moof’ and ‘mdat’). One mp4 segment file is generated per movie fragment and per tile track so that each spatio-temporal portion of the video becomes addressable.</div>
<div class="description-paragraph" id="p-0187" num="0190">The composite track follows the same temporal decomposition and can also be addressed temporally. It is mainly composed of extractors, typically mp4 extractors, each extractor referencing one tile track. It also contains specific extractors that, at parsing time, support the absence of data. Of course, the number of movie fragments and the corresponding mp4 segments as well as their granularity are not limited. The choice is done as a function of the application.</div>
<div class="description-paragraph" id="p-0188" num="0191">The encapsulation process is used by a manifest generator to describe in the manifest the video contained in the media presentation.</div>
<div class="description-paragraph" id="p-0189" num="0192"> <figref idrefs="DRAWINGS">FIG. 6</figref> illustrates an example of concatenating media data segments to build a valid decodable timed media data bit-stream representing a spatial part of consecutive video frames for a given temporal period. The same figure could be repeated for other temporal periods.</div>
<div class="description-paragraph" id="p-0190" num="0193">As described above, a tiled timed media data bit-stream is preferably transmitted as a set of data comprising one initialization segment file and a plurality of media segment files, the latter comprising several tile tracks and one composite track.</div>
<div class="description-paragraph" id="p-0191" num="0194">The initialization segment file comprises a movie box <b>600</b> (“moov”) that provides general information on each track, in particular the type of track (e.g. media track (audio or video) or tile track), a coding format, a frame resolution and the dependency among tracks (given in a track reference box “tref”). These data are used to process downloaded media segment files. The content of the movie box of the initialization segment file can comprise, in particular, the following:</div>
<div class="description-paragraph" id="p-0192" num="0195">MOOV
</div> <ul> <li id="ul0005-0001" num="0000"> <ul> <li id="ul0006-0001" num="0196">track 1: tile a</li> <li id="ul0006-0002" num="0197">track 2: tile b</li> <li id="ul0006-0003" num="0198">track 3: tile c</li> <li id="ul0006-0004" num="0199">track 4: tile d</li> <li id="ul0006-0005" num="0200">track 5: tile e</li> <li id="ul0006-0006" num="0201">track 6: composite track</li> </ul> </li> </ul>
<div class="description-paragraph" id="p-0193" num="0202"> <figref idrefs="DRAWINGS">FIG. 6</figref> roughly illustrates the file format obtained by concatenating media segments when only required media segment files (corresponding here to tiles a and c) are downloaded from a server. It is to be noted that not only does such a mechanism allow downloading of only the required media segment files but it also prevents downloading of duplicate data, especially in case of scalable video stream where each tile depends on the whole base layer (as described with reference to <figref idrefs="DRAWINGS">FIG. 11<i>a</i> </figref>).</div>
<div class="description-paragraph" id="p-0194" num="0203">As illustrated, composite track <b>605</b> allows the building of a valid decodable timed media data bit-stream <b>610</b> by referencing data from tile track <b>615</b> and <b>620</b> and by handling appropriately extractors referencing missing data (e.g. extractor referencing data from tile track associated with tile b).</div>
<div class="description-paragraph" id="p-0195" num="0204">The obtained file format is compliant with scalable file format definition. For example, a client device can decide to play a region of interest corresponding to tile a and c by selecting this region. The client device can also change the tiles to be displayed by downloading different “tile tracks” (i.e. media segment files) in a later temporal period while it continues to play the composite track.</div>
<div class="description-paragraph" id="p-0196" num="0205">Valid timed media data bit-stream <b>610</b> is generated from concatenated media segments received by a client device, more precisely from selected tiles when the composite track is played by the client device.</div>
<div class="description-paragraph" id="p-0197" num="0206">After having received the media segment files that have been previously requested, comprising composite track <b>600</b>, the latter is parsed to extract the first item of data (or the next item of data if at least one item of data of the received media segment has been processed, typically a NAL unit) from the media data box “mdat”.</div>
<div class="description-paragraph" id="p-0198" num="0207">Next, a test is performed to determine whether or not the extracted item of data (e.g. extracted NAL unit) corresponds to an extractor (EXT). If the extracted item of data does not correspond to an extractor, it is returned as is to be further decoded by a video decoder. On the contrary, if the extracted item of data is an extractor, it must be replaced by the item of data it is referencing. To that end, the values of the extractor's parameters are obtained from its structure (an extractor comprises all the parameter values required to extract data from another track (e.g., parameters known as track_ref_index, sample_offset, data_offset, and data_length)).</div>
<div class="description-paragraph" id="p-0199" num="0208">Once the identifier of the referenced track has been identified, a test is performed to determine whether or not the referenced track is available in the buffered set of media segment files. It is to be recalled that some tile tracks are missing since the client device downloads only the media segment files corresponding to the selected Region-of-Interest.</div>
<div class="description-paragraph" id="p-0200" num="0209">If the referenced track is available in the buffered set of media segment files, the extractor is replaced by the data it is referencing and the bit-stream is sent to a video decoder to be decoded.</div>
<div class="description-paragraph" id="p-0201" num="0210">If the referenced track is not available in the buffered set of media segment files, specific steps have to be performed since the absence of data referenced in an extractor leads to a fatal error according to the ISO BMFF standard. A test is performed to determine whether or not the referenced track is a tile track (the referenced track can correspond to a dependent scalability layer) and whether or not the extractor is of the tile type.</div>
<div class="description-paragraph" id="p-0202" num="0211">If the referenced track is not a tile track or if the extractor is not of the tile type, a standard fatal error is detected. On the contrary, if the referenced track is a tile track and if the extractor is of the tile type, the extractor is removed or the extractor is replaced by padding from an alternative “padding track” or “padding box” containing ‘skipped’ data for the missing tiles, depending on the coding format used to encode the timed media data bit-stream. Here, ‘skipped’ data represent pixel data missing from a current image that are replaced by other pixel data obtained from a previously decoded image either belonging to a same scalable layer or belonging to another scalable layer. Skipped data are generally represented by at least one flag. For example, when considering HEVC video compression format, the padding data can be one or more NALUs that exclusively contain coding units encoded with a skip flag set to 1.</div>
<div class="description-paragraph" id="p-0203" num="0212">Next, the bit-stream is sent to a video decoder to be decoded and displayed and the process loops to handle a following item of data.</div>
<div class="description-paragraph" id="p-0204" num="0213">As described above, current manifests, in particular MPDs, do not allow the description of a video stream as a set of optional and switchable components. Moreover, according to the encapsulation scheme used to stream data, the only video track that can be displayed is the one resulting from the mp4 parsing of the composite track (i.e. resolution of the extractors). The tile tracks are not intended to be displayable by themselves. Accordingly, a manifest aims at describing a composite track as an addressable video representation. However, a composite track does not contain any data (except header information common to several tile tracks) since it is built with extractors pointing to tile tracks. This means that tile tracks also have to be described in the manifest and depending on tile selections by a client device, some of these tiles also have to be downloaded.</div>
<div class="description-paragraph" id="p-0205" num="0214">A possible way to describe optional components such as tile tracks of a media presentation (e.g. components that can be selected by a user) is based on the use of the structure known as SubRepresentation, as defined in DASH/MPD standard. This structure describes the properties of one or several components that are embedded in a representation.</div>
<div class="description-paragraph" id="p-0206" num="0215">Extract of code 3 given in the Appendix illustrates an example of a DASH manifest describing tile tracks as components of a video. For the sake of illustration, only one period is represented (tags &lt;Period&gt; . . . &lt;/Period&gt;) but subsequent components would be similar. As represented, a first adaptation set (&lt;AdaptationSet id=‘1’ . . . &gt;) is used to describe a particular component consisting of a base layer track of the described scalable video that can be encoded according to SVC or HEVC scalable standard. The base layer is described as a single representation having identifier ‘R<b>1</b> (&lt;Representation id=‘R<b>1</b>’ . . . &gt;). A second adaptation set (&lt;AdaptationSet id=‘2’ . . . &gt;) is used to describe the highest resolution layer of the scalable video.</div>
<div class="description-paragraph" id="p-0207" num="0216">It is to be noted that the manifest of a non-scalable video would contain a single adaptation set similar to the second represented one, without any dependency on a base layer (i.e. without any dependency identifier attribute).</div>
<div class="description-paragraph" id="p-0208" num="0217">In the second adaptation set, another single representation is described (&lt;Representation id=‘R<b>2</b>’ . . . &gt;): this is the one that corresponds to the displayable video. It is described as a list of segments (&lt;segmentList&gt; . . . &lt;/SegmentList&gt;) with corresponding URL for client requests. As indicated with the parameter dependencyId, representation ‘R<b>2</b>’ depends on representation ‘R<b>1</b>’ (dependencyId=‘R<b>1</b>’), that is to say the base layer representation from the first adaptation set.</div>
<div class="description-paragraph" id="p-0209" num="0218">Such a dependency forces a client device to request first a current base layer segment before getting the corresponding current enhancement layer segment. This cannot be used to express dependencies with respect to tile tracks because the tracks that would be referenced this way would be automatically loaded by the client. This is something that is to be avoided since an object of embodiments of the invention is to let a user select tiles of interest (i.e. a region of interest) at any time during a media presentation.</div>
<div class="description-paragraph" id="p-0210" num="0219">Signaling dependencies between components, in particular between a composite track and tile tracks, is done through elements of the SubRepresentation type: a displayable video is represented as a list of sub-representations (&lt;SubRepresentation . . . &gt;. Each sub-representation represents a track in the encapsulated file (e.g. encapsulated mp4 file). Accordingly, one sub-representation is associated with each tile (four tiles Ta to Td in the example represented in extract of code 3 of the Appendix) and with the composite track (CT in the example represented in extract of code 3 of the Appendix).</div>
<div class="description-paragraph" id="p-0211" num="0220">Each sub-representation is described by a content component element (&lt;ContentComponent . . . &gt;) to indicate whether it corresponds to a tile track (&lt;Role schemeIdUri=‘tiling’&gt;) or to the composite track (&lt;Role schemeIdUri=‘role’&gt;). This is expressed using the Role descriptor type available in DASH/MPD standard with a specific scheme for tiling description. This role also indicates the position of the tile in the full-frame video (&lt;Role . . . value=‘x,y’&gt;). For the sake of illustration, the tile content component having identifier ‘Ta’ describes the tile located at the top left of the video (1:1 for 1st in row and 1st in column).</div>
<div class="description-paragraph" id="p-0212" num="0221">The tile dimensions (width and height) are specified as attributes of the sub-representation as it is allowed by MPD. It is to be noted that bandwidth values can also be indicated as sub-representation attributes to help a DASH client device in selecting alternate tiles versions according to a bandwidth criterion, for example when SNR scalability is available as described by reference to <figref idrefs="DRAWINGS">FIG. 12</figref>).</div>
<div class="description-paragraph" id="p-0213" num="0222">Composite tracks are signaled in a particular way so as to indicate that their downloading is mandatory (to be able to build a decodable video stream at the end of the download). To indicate such a feature, the descriptor in the related content component indicates that it is a main component among all the components (&lt;Role . . . value=‘main’/&gt;). Moreover, a new attribute ‘required’ is added in the corresponding sub-representation (&lt;SubRepresentation . . . contentComponent=‘CT’ required&gt;) to indicate that the associated data have to be requested by a client device.</div>
<div class="description-paragraph" id="p-0214" num="0223">All requests for a composite track or for one or more tile tracks are computed from URLs provided in the segment list (&lt;SegmentList&gt;), one per time interval. According to the illustrated example (&lt;SegmentURL media=«URL_X index_range=«0-43»»/&gt;), URL URL_X is combined with base URL BaseURL as defined at the beginning of the MPD to define a complete URL based on which a client device can generate a request of the HTTP GET type. However, by doing so, a client device obtains data for the composite track as well as all the data for all the tile tracks. Accordingly, to optimize transmissions over the used communication network, a first request is directed to segment index information (referred to as sidx and ssix and described by reference to <figref idrefs="DRAWINGS">FIG. 7</figref>), using an index_range attribute of URLs (e.g. index_range=«0-43»). Next, obtained segment index information is parsed in order to determine byte ranges for each of the components and to perform as many requests of the HTTP GET type with an appropriate byte range as there are selected tracks (including the required composite track).</div>
<div class="description-paragraph" id="p-0215" num="0224"> <figref idrefs="DRAWINGS">FIG. 7</figref> illustrates an example of an mp4 organization that is suitable for using sub-representations for signaling tile tracks.</div>
<div class="description-paragraph" id="p-0216" num="0225">As illustrated, the encapsulated data <b>700</b> stream comprises boxes known as ‘ftyp’, ‘moov’, and ‘mvex’ as well as ‘sidx’ and ssix’ boxes for storing initialization data.</div>
<div class="description-paragraph" id="p-0217" num="0226">‘moov’ box comprises, in particular, definition of the tracks.</div>
<div class="description-paragraph" id="p-0218" num="0227">Tile data are organized sequentially, one segment after another, each segment comprising data of each tile for the considered segment. Data are stored in ‘mdat’ boxes that are preceded by ‘moof’ boxes containing metadata specific initialization data.</div>
<div class="description-paragraph" id="p-0219" num="0228">As represented with references <b>705</b> and <b>710</b>, the items of information stored in ‘sidx’ box define the beginning and the length, in bytes, of each segment (for all the tiles) and the items of information stored in ‘ssix’ box defines the length of each tile segment, respectively. An anchor point (<b>715</b>) is defined as being the beginning of ‘ssix’ box. Accordingly, segment data (‘moof’ and ‘mdat’ boxes) begin at the address defined by the anchor point to which is added the length of ‘ssix’ box.</div>
<div class="description-paragraph" id="p-0220" num="0229">According to this embodiment, existing elements of manifests are reused. Therefore, it requires minimal modifications in manifests. However, it requires client devices to be able to parse specific mp4 segment indexes (e.g. ‘leva’ parameter in the ‘mvex’ box and parameters of the sidx and ssix boxes) to be able to determine the byte ranges to use in order to address tile data. Moreover, it induces delay for segment index requests and parsing before being in position to request video data.</div>
<div class="description-paragraph" id="p-0221" num="0230">According to another embodiment for describing optional components of a media representation, the components are explicitly described as what they are: actually spatial parts or spatial sub-representations of the full-frame video.</div>
<div class="description-paragraph" id="p-0222" num="0231">An example of a manifest based on the DASH standard and to this embodiment is represented in the Appendix (Extract of code 4). For the sake of illustration, only one period is represented (tags &lt;Period&gt; . . . &lt;/Period&gt;) but subsequent components would be similar.</div>
<div class="description-paragraph" id="p-0223" num="0232">According to the given example, the manifest comprises two representations for the given period, one for a particular component consisting of a base layer of a scalable video and another one for the enhancement layer of the same scalable video (components representing the spatial parts of the enhancement layer). This second representation depends on the first one due to scalable encoding (SVC, HEVC scalable, or any layered encoding). As represented, such a dependency is expressed through the dependencyId attribute (&lt;Representation . . . id=“EL<b>1</b>” dependencyId=“BL<b>1</b>” . . . &gt;).</div>
<div class="description-paragraph" id="p-0224" num="0233">In terms of dependency, the second representation also depends on its spatial parts which require a specific signalization. To that end, a new element is defined to characterize a “child” of a representation. Such a new element is referred to as a spatial sub-representation (&lt;SpatialSubRepresentation . . . dependencyId=“ ” . . . &gt;). One spatial sub-representation is used per tile track. Accordingly, since two tiles are considered in the described example, two spatial sub-representations are used.</div>
<div class="description-paragraph" id="p-0225" num="0234">Extract of code 6 given in the Appendix indicates the modification of the MPD XML schema to support this new element (&lt;xs:element name=“SubRepresentation” type=“SubRepresentationType” minOccurs=“0” maxOccurs=“unbounded”/&gt;) while extract of code 7 provides the XML schema for this new type of MPD element (&lt;xs:complexType name=“SpatialSubRepresentationType”&gt;).</div>
<div class="description-paragraph" id="p-0226" num="0235">Specifically, it contains two mandatory attributes (&lt;xs:attribute name=“posx” type=“xs:unsignedInt” use=“required”/&gt; and &lt;xs:attribute name=“posy” type=“xs:unsignedInt” use=“required”/&gt;) to describe the positions of the spatial area represented by the spatial sub representation. It is to be noted that an XML schema description is used because the manifest is based on XML standard however, any structure description language can be used.</div>
<div class="description-paragraph" id="p-0227" num="0236">Compared to the embodiment described above, this one allows a direct addressing per tile through the segment list (&lt;SegmentList . . . &gt;) inside each spatial sub-representation.</div>
<div class="description-paragraph" id="p-0228" num="0237">This avoids, in particular, a client device being configured for parsing mp4 boxes.</div>
<div class="description-paragraph" id="p-0229" num="0238">The last segment list of the example given in extract of code 4 in the Appendix (&lt;SegmentList duration=“10”&gt; &lt;SegmentURL media=“seg-EL<b>1</b>-<b>1</b>.mp4”/&gt; &lt;SegmentURL media=“seg-EL<b>1</b>-<b>2</b>.mp4”/&gt; &lt;/SegmentList&gt;) for the second representation (&lt;Representation mimeType=“video/hevc” codecs=“hvc1.4D401E” id=“EL<b>1</b>” dependencyId=“BL<b>1</b>” bandwidth=“1024000” width=“1920” height=“1080”&gt;) corresponds to the URL to stream data of the composite track.</div>
<div class="description-paragraph" id="p-0230" num="0239">When parsing a spatial sub-representation in a representation of the video type, a client device has to consider it as an optional component of this representation.</div>
<div class="description-paragraph" id="p-0231" num="0240">Conversely, the segment list (or segment template or any means to address temporal segments) provided directly under the representation is to be downloaded in order to obtain, at the client end, a displayable video. The bandwidth associated to the Representation indicates the requested bandwidth for downloading all the tiles. For a bandwidth adaptation based on spatial selection, the bandwidth parameter of each spatial sub-representation can be considered.</div>
<div class="description-paragraph" id="p-0232" num="0241">It is to be noted that this embodiment supports tile-based scalability as described by reference to <figref idrefs="DRAWINGS">FIG. 11<i>b </i> </figref>since spatial sub-representations can use the conventional dependency mechanism (dependencyId) to reference lower scalability layers. This can be useful, in particular, to handle scalable video streams where tiling is available at each layer (and not only on the highest resolution level as in the given example illustrated in <figref idrefs="DRAWINGS">FIG. 11</figref>). It also has the benefit of being easily understandable: all tile information is directly available after parsing of the manifest (through various attributes). This information can be put in the manifest by server <b>200</b> by reading SEI messages contained in HEVC that describe the tiling configuration, especially the inter layer tile dependencies.</div>
<div class="description-paragraph" id="p-0233" num="0242">Moreover, using this description, it is possible to describe, for each tile alternate spatial sub-representation, in terms of tile size or in terms of bandwidth to provide finer adaptation possibilities for a client device. This can be useful for a configuration as the one illustrated in <figref idrefs="DRAWINGS">FIG. 12</figref>. Indeed, in case of SNR scalability, a user would have spatial access to a video at different qualities and could decide to switch dynamically from one quality level to another while keeping on the same spatial area.</div>
<div class="description-paragraph" id="p-0234" num="0243">This is illustrated in extract of code 5 given in the Appendix where only one AdaptationSet is described with two representations: one for the base layer and one for the SNR enhancement layer. Each layer has a set of spatial sub-representations. It is to be noted that inter-tile dependencies can be expressed in a finer way removing the global dependency from the enhancement layer to the base layer and specifying tile-based dependencies. Accordingly, when a user selects a set of tiles, only the corresponding tiles of the base layer are streamed, saving bandwidth resources. Moreover, such description provides finer adaptation by combining tiles at different qualities, considering their respective bandwidths. These SNR tiles (as illustrated in <figref idrefs="DRAWINGS">FIG. 12</figref>) can be described in only one representation that contains, for each tile position, alternate spatial sub-representations in terms of quality and related bandwidth (not represented in the illustrated example). Finally, such a description does not break the dynamic adaptation of DASH since it remains segment and representation based.</div>
<div class="description-paragraph" id="p-0235" num="0244">According to another embodiment, the description of optional components is made at segment level with reference to descriptors as represented in extract of code 8 in the Appendix</div>
<div class="description-paragraph" id="p-0236" num="0245">Still for the sake of illustration, a scalable video having two layers is considered. Each layer is described in its own adaptation set: &lt;AdaptationSet id=‘1’ . . . &gt;) for the base layer and (&lt;AdaptationSet id=‘1’ . . . &gt;) for the enhancement layer, the latter corresponding to the video stream with spatial tiles. Only one representation is provided in this adaptation set, corresponding to a particular component consisting of the composite track. However, as described above, at least one tile track (optional component) has to be downloaded to allow the production of a displayable video.</div>
<div class="description-paragraph" id="p-0237" num="0246">As represented, the address (e.g. URLs) of the tile tracks are given in a list of URLs (&lt;SegmentList&gt; &lt;SegmentURL media=«URL_CT» related=«URL_Ta URL_Tb URL_Tc URL_Td» type=«Ta Tb Tc Td»/&gt; &lt;/SegmentList&gt;) at the same level as the main URL for the composite track. While description parameters are associated with the URL of the composite track, this is not the case for the list of optional URLs. To describe these optional URLs, the list is followed by a list of references to descriptors (&lt;ContentComponent id=‘Ta’ . . . &gt;, &lt;ContentComponent id=‘Tb’ . . . &gt;, &lt;ContentComponent id=‘Tc’ . . . &gt;, and &lt;ContentComponent id=‘Td’ . . . &gt;) that provide information about each URL. In the example represented in extract of code 8, the descriptor is an element of the role type that is put in a content component element. There is one content component per tile track. The elements of the role type, used to provide information on each tile, are similar to the one described above. In addition to tile position, they could also contain the tile sizes and bandwidth information.</div>
<div class="description-paragraph" id="p-0238" num="0247">Extract of code 9 in the Appendix illustrates an example of extension of the Segment URL element (in XML schema) with optional attributes (&lt;xs:attribute name=“related” type=“URLVectorType”/&gt;, &lt;xs:attribute name=“relatedRange” type=“StringVectorType”/&gt;, and &lt;xs:attribute name=“type” type=“StringVectorType”/&gt;) that are put at the same level as the URL segment. To that end, a new type of parameter is defined to describe list of URLs (&lt;xs:simpleType name=“URLVectorType”&gt; &lt;xs:list itemType=“xs:anyURI”/&gt; &lt;/xs:simpleType&gt;).</div>
<div class="description-paragraph" id="p-0239" num="0248"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a flow chart illustrating processing steps carried out in a client device for processing a manifest comprising tile description according to the previous embodiment.</div>
<div class="description-paragraph" id="p-0240" num="0249">First illustrated steps <b>800</b> to <b>820</b> are standard steps according to DASH standard that mainly consist in loading and parsing the manifest (MPD) when no tiling information is present.</div>
<div class="description-paragraph" id="p-0241" num="0250">If tiling is detected at step <b>815</b>, for example by detecting the presence of a role element comprising tiling schemeIdUri parameter value or by detecting the presence of spatial sub-representation elements in the manifest, a tile index table similar to the one illustrated with reference <b>830</b> is built (step <b>825</b>) by parsing either the tiling descriptors or the spatial sub-representations. The tiling organization can be displayed to the user, for example as a grid overlaid on a video of which display is beginning (step <b>835</b>).</div>
<div class="description-paragraph" id="p-0242" num="0251">Next, at any time during the streaming process, a user can select a set of one or several tiles he/she would like to focus on (step <b>840</b>). The selected tiles are marked as active in the tile index table (step <b>845</b>) so that the client device carrying out the algorithm knows that several requests have to be performed with corresponding URLs (stored in the third column of the index table <b>830</b>).</div>
<div class="description-paragraph" id="p-0243" num="0252">An iterative process is then launched on each temporal segment of the presentation (step <b>850</b>), that is to say on each period, during which the position of each active tile is read from the tile index table along with the associated URL (steps <b>855</b> and <b>860</b>). The obtained URLs are submitted to the streaming server in requests (step <b>865</b>) to receive the active tile tracks. Similarly, the URL of the composite track of the current temporal segment is submitted to the streaming server (step <b>870</b>). When all the active tile tracks and composite track are received, the client device is in a position to parse the composite track (reconstituted mp4 composite track) and to access data from tile tracks in order to build a standard decodable bit-stream (step <b>885</b>) that can be decoded (step <b>890</b>) and displayed (step <b>895</b>).</div>
<div class="description-paragraph" id="p-0244" num="0253">In case all segment data are not received, the client device waits for the tile tracks and composite track (steps <b>875</b> and <b>880</b>). This is to be sure to not miss an extractor resolution on a selected tile for which data would not have been received yet.</div>
<div class="description-paragraph" id="p-0245" num="0254">As illustrated in <figref idrefs="DRAWINGS">FIG. 9</figref>, such a process can be generalized for any descriptor (not specifically tile descriptor as described by reference to <figref idrefs="DRAWINGS">FIG. 8</figref>). As represented, one difference with the algorithm represented in <figref idrefs="DRAWINGS">FIG. 8</figref> lies in the index but the processing steps are similar to the one described by reference to that Figure.</div>
<div class="description-paragraph" id="p-0246" num="0255"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a flow chart illustrating processing steps carried out in a client device for processing a manifest comprising dependency description according to the previous embodiment.</div>
<div class="description-paragraph" id="p-0247" num="0256">Accordingly, first illustrated steps <b>900</b> to <b>910</b> are standard steps according to DASH standard that mainly consist in loading and parsing the manifest (MPD) when no dependency information is present.</div>
<div class="description-paragraph" id="p-0248" num="0257">If dependencies are detected at step <b>908</b>, for example by detecting the presence of a role element comprising dependency schemeIdUri parameter value or by detecting the presence of spatial sub-representation elements in the manifest, an index table similar to the one illustrated with reference <b>914</b> is built (step <b>912</b>) by parsing either the descriptors or the spatial sub-representations. The dependency organization is advantageously displayed to the user so that he/she can choose one or several dependencies to be displayed (step <b>916</b>).</div>
<div class="description-paragraph" id="p-0249" num="0258">Next, at any time during the streaming process, a user can select a set of one or several dependencies he/she would like to be used by the decoding process (step <b>918</b>). The selected dependencies are marked as active in the index table (step <b>920</b>) so that the client device carrying out the algorithm knows that several requests have to be performed with corresponding URLs (stored in the third column of the index table <b>914</b>).</div>
<div class="description-paragraph" id="p-0250" num="0259">An iterative process is then launched on each temporal segment of the presentation (step <b>922</b>), that is to say on each period, during which the list of active dependencies to be used by the decoding process is read from the index table along with the associated URL (steps <b>924</b> and <b>926</b>). The obtained URLs are submitted to the streaming server in requests (step <b>928</b>) to receive the active dependency tracks. Similarly, the URL of the main track of the current temporal segment is submitted to the streaming server (step <b>930</b>). When all the active dependency tracks and main track have been received, the client device is in a position to parse the main track and to access data from dependency tracks in order to build a standard decodable bit-stream (step <b>936</b>) that can be decoded (step <b>938</b>) and displayed (step <b>940</b>).</div>
<div class="description-paragraph" id="p-0251" num="0260">In case data has not been received from all segments, the client device waits for the dependency tracks and main track (steps <b>932</b> and <b>934</b>). This is to be sure to not miss an extractor resolution on a selected dependency for which data would not have been received yet.</div>
<div class="description-paragraph" id="p-0252" num="0261">Such an approach has the benefit of limiting syntax extension (no new element is introduced). Moreover, it provides a generic scheme for any optional content signaling at segment level, thus preserving segment based approach and switches for dynamic adaptation.</div>
<div class="description-paragraph" id="p-0253" num="0262">A variant of this embodiment would be to refer to descriptors in another adaptation set instead of content components inside the current adaptation set. This would be relevant in case of tile tracks encapsulated as displayable track while keeping on providing the combination of any tiles via a composite track referring to these displayable tile tracks.</div>
<div class="description-paragraph" id="p-0254" num="0263"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a schematic block diagram of a computing device <b>1000</b> that can be used for carrying each or some steps of each of the described embodiments of the invention. Computing device <b>1000</b> may be a device such as a micro-computer, a workstation, or a light portable device.</div>
<div class="description-paragraph" id="p-0255" num="0264">Computing device <b>1000</b> comprises a communication bus connected to:
</div> <ul> <li id="ul0007-0001" num="0000"> <ul> <li id="ul0008-0001" num="0265">a central processing unit <b>1005</b>, such as a microprocessor, denoted CPU;</li> <li id="ul0008-0002" num="0266">a random access memory <b>1010</b>, denoted RAM, for storing the executable code of the method of embodiments of the invention as well as registers adapted to record variables and parameters necessary for implementing the method for reading and writing the manifests and/or for encoding the video and/or for reading or generating data under a given file format, the memory capacity thereof can be expanded by an optional RAM connected to an expansion port for example;</li> <li id="ul0008-0003" num="0267">a read only memory <b>1015</b>, denoted ROM, for storing computer programs for implementing embodiments of the invention;</li> <li id="ul0008-0004" num="0268">a network interface <b>1020</b> is typically connected to a communication network over which digital data to be processed are transmitted or received. The network interface <b>1020</b> can be a single network interface, or composed of a set of different network interfaces (for instance wired and wireless interfaces, or different kinds of wired or wireless interfaces). Data are written to the network interface for transmission or are read from the network interface for reception under the control of the software application running in the CPU <b>1005</b>;</li> <li id="ul0008-0005" num="0269">a user interface <b>1025</b> for receiving inputs from a user or to display information to a user;</li> <li id="ul0008-0006" num="0270">a hard-disk <b>1030</b> denoted HD; and</li> <li id="ul0008-0007" num="0271">an I/O module <b>1035</b> for receiving/sending data from/to external devices such as a video source or display.</li> </ul> </li> </ul>
<div class="description-paragraph" id="p-0256" num="0272">The executable code may be stored either in read only memory <b>1015</b>, on the hard-disk <b>1030</b>, or on a removable digital medium such as for example a disk. According to a variant, the executable code of the programs can be received by means of a communication network, via the network interface <b>1020</b>, in order to be stored in one of the storage means of the communication device <b>1000</b>, such as the hard disk <b>1030</b>, before being executed.</div>
<div class="description-paragraph" id="p-0257" num="0273">The central processing unit <b>1005</b> is adapted to control and direct the execution of the instructions or portions of software code of the program or programs according to embodiments of the invention, which instructions are stored in one of the aforementioned storage means. After powering on, the CPU <b>1005</b> is capable of executing instructions from main RAM memory <b>1010</b> relating to a software application after those instructions have been loaded from the program ROM <b>1015</b> or the hard-disc <b>1030</b> for example. Such a software application, when executed by the CPU <b>1005</b>, causes steps of the algorithms described previously to be performed.</div>
<div class="description-paragraph" id="p-0258" num="0274">In this embodiment, the apparatus is a programmable apparatus which uses software to implement the invention. However, alternatively, embodiments of the present invention may be implemented in hardware (for example, in the form of an Application Specific Integrated Circuit or ASIC).</div>
<div class="description-paragraph" id="p-0259" num="0275">Embodiments of the invention may be embedded in a device like a camera, a smartphone, or a tablet that acts as a remote controller for a TV, for example to zoom into a particular region of interest. They can also be used from the same devices to have personalized browsing experience of a TV program by selecting specific areas of interest. Another usage of these devices by a user is to share selected sub-parts of his/her preferred videos with other connected devices. They can also be used in smartphone or tablet to monitor what happens in a specific area of a building put under surveillance provided that the surveillance camera supports the generation part of this invention.</div>
<div class="description-paragraph" id="p-0260" num="0276">Although the present invention has been described hereinabove with reference to specific embodiments, the present invention is not limited to the specific embodiments, and modifications will be apparent to a person skilled in the art which lie within the scope of the present invention.</div>
<div class="description-paragraph" id="p-0261" num="0277">Many further modifications and variations will suggest themselves to those versed in the art upon making reference to the foregoing illustrative embodiments, which are given by way of example only and which are not intended to limit the scope of the invention, that scope being determined solely by the appended claims. In particular the different features from different embodiments may be interchanged, where appropriate.</div>
<heading id="h-0007">APPENDIX</heading>
<div class="description-paragraph" id="p-0262" num="0000">
</div> <ul>
<li id="ul0009-0001" num="0278">File name=Movie_4.mf</li>
<li id="ul0009-0002" num="0279">Type of segmentation=spatially</li>
<li id="ul0009-0003" num="0280">Number of segments=4</li>
<li id="ul0009-0004" num="0281">Relationships between segments=2×2 matrix</li>
<li id="ul0009-0005" num="0282">Segment
    <ul> <li id="ul0010-0001" num="0283">Segment name=cache.source.com/res/Movie-4-1.seg</li> <li id="ul0010-0002" num="0284">Position in whole=(0, 0)</li> </ul>
</li>
<li id="ul0009-0006" num="0285">Segment
    <ul> <li id="ul0011-0001" num="0286">Segment name=cache.source.com/res/Movie-4-2.seg</li> <li id="ul0011-0002" num="0287">Position in whole=(0, 1)</li> </ul>
</li>
<li id="ul0009-0007" num="0288">Segment
    <ul> <li id="ul0012-0001" num="0289">Segment name=cache.source.com/res/Movie-4-3.seg</li> <li id="ul0012-0002" num="0290">Position in whole=(1, 0)</li> </ul>
</li>
<li id="ul0009-0008" num="0291">Segment
    <ul> <li id="ul0013-0001" num="0292">Segment name=cache.source.com/res/Movie-4-4.seg</li> <li id="ul0013-0002" num="0293">Position in whole=(1, 1)
<br/>
Extract of Code 1: Manifest File
</li> </ul>
</li>
</ul>
<div class="description-paragraph" id="p-0263" num="0294"> <tables id="TABLE-US-00003" num="00003"> <patent-tables colsep="0" frame="none" pgwide="1" rowsep="0"> <table align="left" class="description-table" cols="1" colsep="0" rowsep="0" width="100%"> <thead> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </thead> <tbody><tr class="description-tr"> <td class="description-td">&lt;?xml version=″1.0″?&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;MPD xmlns:xsi=″http://www.w3.org/2001/XMLSchema-instance″</td> </tr> <tr class="description-tr"> <td class="description-td"> xmlns=″urn:mpeg:DASH:schema:MPD:2011″</td> </tr> <tr class="description-tr"> <td class="description-td"> xsi:schemaLocation=″urn:mpeg:DASH:schema:MPD:2011 DASH-MPD.xsd″</td> </tr> <tr class="description-tr"> <td class="description-td"> type=″static″</td> </tr> <tr class="description-tr"> <td class="description-td"> mediaPresentationDuration=″PT3256S″</td> </tr> <tr class="description-tr"> <td class="description-td"> minBufferTime=″PT1.2S″</td> </tr> <tr class="description-tr"> <td class="description-td"> profiles=″urn:mpeg:dash:profile:isoff-on-demand:2011″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;BaseURL&gt;http://cdn1.example.com/&lt;/BaseURL&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;BaseURL&gt;http://cdn2.example.com/&lt;/BaseURL&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;Period&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;!-- English Audio --&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;AdaptationSet mimeType=″audio/mp4″ codecs=″mp4a.0x40″ lang=″en″</td> </tr> <tr class="description-tr"> <td class="description-td"> subsegmentAlignment=″true″ subsegmentStartsWithSAP=″1″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;ContentProtection schemeIdUri=″urn:uuid:706D6953-656C-5244-4D48-656164657221″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;Representation id=″1″ bandwidth=″64000″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;BaseURL&gt;7657412348.mp4&lt;/BaseURL&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;Representation id=″2″ bandwidth=″32000″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;BaseURL&gt;3463646346.mp4&lt;/BaseURL&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;!-- Video --&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;AdaptationSet mimeType=″video/mp4″ codecs=″avc1.4d0228″</td> </tr> <tr class="description-tr"> <td class="description-td">  subsegmentAlignment=″true″ subsegmentStartsWithSAP=″2″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;ContentProtection schemeIdUri=″urn:uuid:706D6953-656C-5244-4D48-56164657221″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;Representation id=″6″ bandwidth =″256000″ width =″320″ height=″240″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;BaseURL&gt;8563456473.mp4&lt;/BaseURL&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;Representation id=″7″ bandwidth=″512000″ width =″320″ height=″240″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;BaseURL&gt;56363634.mp4&lt;/BaseURL&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;Representation id=″8″ bandwidth =″1024000″ width =″640″ height=″480″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;BaseURL&gt;562465736.mp4&lt;/BaseURL&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;Representation id=″9″ bandwidth =″1384000″ width =″640″ height=″480″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;BaseURL&gt;41325645.mp4&lt;/BaseURL&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;Representation id=″A″ bandwidth=″1536000″ width-″1280″ height=″720″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;BaseURL&gt;89045625.mp4&lt;/BaseURL&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;Representation id=″B″ bandwidth=″2048000″ width-″1280″ height=″720″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;BaseURL&gt;23536745734.mp4&lt;/BaseURL&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/AdaptationSet&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;/Period&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;/MPD&gt;</td> </tr> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </tbody></table> </patent-tables> </tables> <br/>
Extract of Code 2: Manifest File
</div>
<div class="description-paragraph" id="p-0264" num="0295"> <tables id="TABLE-US-00004" num="00004"> <patent-tables colsep="0" frame="none" rowsep="0"> <table align="left" class="description-table" cols="1" colsep="0" rowsep="0" width="100%"> <thead> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </thead> <tbody><tr class="description-tr"> <td class="description-td">&lt;MPD ...&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;Period&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;BaseURL&gt;http://myserver.com/media&lt;/BaseURL&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;Initialization sourceURL= <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/91/8d/5d/a84e5f44f99fae/US11019408-20210525-P00001.png"><img alt="Figure US11019408-20210525-P00001" class="patent-full-image" file="US11019408-20210525-P00001.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00001" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/91/8d/5d/a84e5f44f99fae/US11019408-20210525-P00001.png" wi="1.78mm" width="7"/></a></div>   URL_SI  <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/da/2d/a9/96f33ce639df16/US11019408-20210525-P00002.png"><img alt="Figure US11019408-20210525-P00002" class="patent-full-image" file="US11019408-20210525-P00002.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00002" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/da/2d/a9/96f33ce639df16/US11019408-20210525-P00002.png" wi="1.78mm" width="7"/></a></div>  /&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;AdaptationSet id=′1′ contentType=′video′ framerate=′30′&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;!- Base layer description --&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;Representation id=′R1′ mimeType=′video/mp4′ width=′2000′ </td> </tr> <tr class="description-tr"> <td class="description-td">  height=′1000′ bandwidth=′512000′&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentList&gt; &lt;SegmentURL media= <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/91/8d/5d/a84e5f44f99fae/US11019408-20210525-P00001.png"><img alt="Figure US11019408-20210525-P00001" class="patent-full-image" file="US11019408-20210525-P00001.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00003" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/91/8d/5d/a84e5f44f99fae/US11019408-20210525-P00001.png" wi="1.78mm" width="7"/></a></div>   URL_BL  <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/da/2d/a9/96f33ce639df16/US11019408-20210525-P00002.png"><img alt="Figure US11019408-20210525-P00002" class="patent-full-image" file="US11019408-20210525-P00002.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00004" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/da/2d/a9/96f33ce639df16/US11019408-20210525-P00002.png" wi="1.78mm" width="7"/></a></div>  /&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/AdaptationSet&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;!- Enhancement layer description, composite track --&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;AdaptationSet id=′2′ contentType=video′ framerate=′30′&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;!- Tile a, b, c and d are described as components of composite </td> </tr> <tr class="description-tr"> <td class="description-td">   track --&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;ContentComponent id=′Ta′ /&gt;&lt;Role schemeIdUri=′tiling′</td> </tr> <tr class="description-tr"> <td class="description-td">   value=′1:1′/&gt;&lt;/ContentComponent&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;ContentComponent id=′Tb′/&gt;&lt;Role schemeIdUri=′tiling′</td> </tr> <tr class="description-tr"> <td class="description-td">   value=′1:2′/&gt;&lt;/ContentComponent&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;ContentComponent id=′Tc′/&gt; &lt;Role schemeIdUri=′tiling′</td> </tr> <tr class="description-tr"> <td class="description-td">   value=′2:1′/&gt;&lt;/ContentComponent&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;ContentComponent id=′Td′/&gt; &lt;Role schemeIdUri=′tiling′</td> </tr> <tr class="description-tr"> <td class="description-td">   value=′2:2′/&gt;&lt;/ContentComponent&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;ContentComponent id=′CT′/&gt; &lt;Role schemeIdUri=′...role′</td> </tr> <tr class="description-tr"> <td class="description-td">   value=′main′/&gt;&lt;/ContentComponent&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;Representation id=′R2′ mimeType=′video/mp4′ dependencyId=</td> </tr> <tr class="description-tr"> <td class="description-td">   ′R1′ width=′4000′ height=′2000′ bandwidth=′2048000′&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SubRepresentation level=′1′ contentComponent=′Ta′ </td> </tr> <tr class="description-tr"> <td class="description-td">    width=′2000′ height=′1000′/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SubRepresentation level=′2′ contentComponent=′Tb′ </td> </tr> <tr class="description-tr"> <td class="description-td">    width=′2000′ height=′1000′/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SubRepresentation level=′3′ contentComponent=′Tc′ </td> </tr> <tr class="description-tr"> <td class="description-td">    width=′2000′ height=′1000′/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SubRepresentation level=′4′ contentComponent=′Td′ </td> </tr> <tr class="description-tr"> <td class="description-td">    width=′2000′ height=′1000′/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SubRepresentation level=′5′ contentComponent=′CT′ </td> </tr> <tr class="description-tr"> <td class="description-td">    required/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     &lt;SegmentURL media= <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/91/8d/5d/a84e5f44f99fae/US11019408-20210525-P00001.png"><img alt="Figure US11019408-20210525-P00001" class="patent-full-image" file="US11019408-20210525-P00001.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00005" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/91/8d/5d/a84e5f44f99fae/US11019408-20210525-P00001.png" wi="1.78mm" width="7"/></a></div>   URL_X index _range=</td> </tr> <tr class="description-tr"> <td class="description-td">      <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/91/8d/5d/a84e5f44f99fae/US11019408-20210525-P00001.png"><img alt="Figure US11019408-20210525-P00001" class="patent-full-image" file="US11019408-20210525-P00001.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00006" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/91/8d/5d/a84e5f44f99fae/US11019408-20210525-P00001.png" wi="1.78mm" width="7"/></a></div>   0-43  <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/da/2d/a9/96f33ce639df16/US11019408-20210525-P00002.png"><img alt="Figure US11019408-20210525-P00002" class="patent-full-image" file="US11019408-20210525-P00002.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00007" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/da/2d/a9/96f33ce639df16/US11019408-20210525-P00002.png" wi="1.78mm" width="7"/></a></div>    <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/da/2d/a9/96f33ce639df16/US11019408-20210525-P00002.png"><img alt="Figure US11019408-20210525-P00002" class="patent-full-image" file="US11019408-20210525-P00002.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00008" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/da/2d/a9/96f33ce639df16/US11019408-20210525-P00002.png" wi="1.78mm" width="7"/></a></div>  /&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     ....</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/AdaptationSet&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;/Period&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;/MPD&gt;</td> </tr> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </tbody></table> </patent-tables> </tables> <br/>
Extract of Code 3: Manifest File Comprising Sub-representation Structures
</div>
<div class="description-paragraph" id="p-0265" num="0296"> <tables id="TABLE-US-00005" num="00005"> <patent-tables colsep="0" frame="none" rowsep="0"> <table align="left" class="description-table" cols="1" colsep="0" rowsep="0" width="100%"> <thead> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </thead> <tbody><tr class="description-tr"> <td class="description-td">&lt;Period&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;SegmentList&gt; &lt;Initialization sourceURL=″seg-m-init.mp4″/&gt; </td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;AdaptationSet subsegmentAlignment=″true″ </td> </tr> <tr class="description-tr"> <td class="description-td"> subsegmentStartsWithSAP=″2″ minBandwidth=″512000″ </td> </tr> <tr class="description-tr"> <td class="description-td"> maxBandwidth=″1024000″ frameRate=″30″ &gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;Representation mimeType=″video/hevc″ codecs=</td> </tr> <tr class="description-tr"> <td class="description-td">  ″hvc1.4D401E″ id=″BL1″ bandwidth=″512000″ </td> </tr> <tr class="description-tr"> <td class="description-td">  width=″640″ height=″480″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;SegmentList duration =″10″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentURL media=″seg-BL-1.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentURL media=″seg-BL-2.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;Representation mimeType=″video/hevc″ codecs=</td> </tr> <tr class="description-tr"> <td class="description-td">  ″hvc1.4D401E″ id=″EL1″ dependencyId = ″BL1″ </td> </tr> <tr class="description-tr"> <td class="description-td">  bandwidth=″1024000″ width =″1280″ height=″1080″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;SpatialSubRepresentation id=″tileA″ dependencyId=″ ″ </td> </tr> <tr class="description-tr"> <td class="description-td">   posx=″0″ posy=″0″ width=″640″ height=″480″ </td> </tr> <tr class="description-tr"> <td class="description-td">   bandwidth=″512000″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentList duration=″10″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     &lt;SegmentURL media=″seg-EL1-tileA-1.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     &lt;SegmentURL media=″seg-EL1-tileA-2.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/SpatialSubRepresentation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;SpatialSubRepresentation id=″tileB″ dependencyId=″ ″</td> </tr> <tr class="description-tr"> <td class="description-td">   posx=″640″ posy=″0″ width=″640″ height=″480″ </td> </tr> <tr class="description-tr"> <td class="description-td">   bandwidth=″512000″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentList duration=″10″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     &lt;SegmentURL media=″seg-EL1-tileB-1.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     &lt;SegmentURL media=″seg-EL1-tileB-2.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/SpatialSubRepresentation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;SegmentList duration=″10″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentURL media=″seg-EL1-1.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentURL media=″seg-EL1-2.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;/AdaptationSet&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;/Period&gt;</td> </tr> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </tbody></table> </patent-tables> </tables> <br/>
Extract of Code 4: Manifest File Comprising Specific Sub-representation Structures
</div>
<div class="description-paragraph" id="p-0266" num="0297"> <tables id="TABLE-US-00006" num="00006"> <patent-tables colsep="0" frame="none" pgwide="1" rowsep="0"> <table align="left" class="description-table" cols="1" colsep="0" rowsep="0" width="100%"> <thead> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </thead> <tbody><tr class="description-tr"> <td class="description-td">&lt;Period&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;SegmentList&gt; &lt;Initialization sourceURL=″seg-m-init.mp4″/&gt; &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;AdaptationSet subsegmentAlignment=″true″ subsegmentStartsWithSAP=″2″</td> </tr> <tr class="description-tr"> <td class="description-td"> minBandwidth=″512000″ maxBandwidth=″1024000″ frameRate=″30″ &gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;Representation mimeType=″video/hevc″ codecs=″hvc1.4D401E″ id=″BL1″</td> </tr> <tr class="description-tr"> <td class="description-td">  bandwidth=″512000″ width-″1280″ height=″1080″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;SpatialSubRepresentation id=″tileA_0″ posx=″0″ posy=″0″ width=″640″</td> </tr> <tr class="description-tr"> <td class="description-td">   height=″480″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentList duration=″10″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     &lt;SegmentURL media=″seg-EL1-tileA-01.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     &lt;SegmentURL media=″seg-EL1-tileA-02.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/SpatialSubRepresentation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;SpatialSubRepresentation id=″tileB_0″ posx=″640″ posy=″0″ width=″640″</td> </tr> <tr class="description-tr"> <td class="description-td">   height=″480″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentList duration=″10″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     &lt;SegmentURL media=″seg-EL1-tileB-01.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     &lt;SegmentURL media=″seg-EL1-tileB-02.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/SpatialSubRepresentation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;!-Composite track for base layer --&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;SegmentList duration=″10″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentURL media=″seg-BL-1.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentURL media=″seg-BL-2.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;Representation mimeType=″video/hevc″ codecs=″hvc1.4D401E″ id=″EL1″</td> </tr> <tr class="description-tr"> <td class="description-td">  bandwidth=″1024000″ width=″1280″ height=″1080″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;SpatialSubRepresentation id=″tileA_1″ dependencyId=″tileA_0″ posx=″0″ posy=″0″</td> </tr> <tr class="description-tr"> <td class="description-td">   width=″640″ height=″480″ bandwidth=″512000″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentList duration=″10″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     &lt;SegmentURL media=″seg-EL1-tileA-11.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     &lt;SegmentURL media=″seg-EL1-tileA-12.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/SpatialSubRepresentation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;SpatialSubRepresentation id=″tileB_1″ dependencyId=″tileB_0″ posx=″640″ posy=″0″</td> </tr> <tr class="description-tr"> <td class="description-td">   width=″640″ height=″480″ bandwidth=″512000″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentList duration=″10″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     &lt;SegmentURL media=″seg-EL1-tileB-11.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     &lt;SegmentURL media=″seg-EL1-tileB-12.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/SpatialSubRepresentation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;!-Composite track for SNR enhancement layer --&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;SegmentList duration =″10″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentURL media=″seg-EL1-1.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentURL media=″seg-EL1-2.mp4″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;/AdaptationSet&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;/Period&gt;</td> </tr> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </tbody></table> </patent-tables> </tables> <br/>
Extract of Code 5: Manifest File Comprising Specific Sub-representation Structures
</div>
<div class="description-paragraph" id="p-0267" num="0298"> <tables id="TABLE-US-00007" num="00007"> <patent-tables colsep="0" frame="none" rowsep="0"> <table align="left" class="description-table" cols="1" colsep="0" rowsep="0" width="100%"> <thead> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </thead> <tbody><tr class="description-tr"> <td class="description-td">&lt;!- Modification of the Representation type --&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;xs:complexType name=″RepresentationType″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;xs:complexContent&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;xs:extension base=″RepresentationBaseType″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;xs:sequence&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;xs:element name=″BaseURL″ type=″BaseURLType″ </td> </tr> <tr class="description-tr"> <td class="description-td">    minOccurs=″0″ maxOccurs=″unbounded″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;xs:element name=″SpatialSubRepresentation″</td> </tr> <tr class="description-tr"> <td class="description-td">    type=″SpatialSubRepresentationType″ minOccurs=″0″</td> </tr> <tr class="description-tr"> <td class="description-td">    maxOccurs=″unbounded″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;xs:element name=″SubRepresentation″ type=</td> </tr> <tr class="description-tr"> <td class="description-td">    ″SubRepresentationType″ minOccurs=″0″ maxOccurs=</td> </tr> <tr class="description-tr"> <td class="description-td">    ″unbounded″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;xs:element name=″SegmentBase″ type=″SegmentBaseType″ </td> </tr> <tr class="description-tr"> <td class="description-td">    minOccurs=″0″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;xs:element name=″SegmentList″ type=″SegmentListType″ </td> </tr> <tr class="description-tr"> <td class="description-td">    minOccurs=″0″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;xs:element name=″SegmentTemplate″ type=</td> </tr> <tr class="description-tr"> <td class="description-td">    ″SegmentTemplateType″ minOccurs=″0″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/xs:sequence&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;xs:attribute name=″id″ type=″StringNoWhitespaceType″ </td> </tr> <tr class="description-tr"> <td class="description-td">   use=″required″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;xs:attribute name=″bandwidth″ type=″xs:unsignedInt″ use=</td> </tr> <tr class="description-tr"> <td class="description-td">   ″required″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;xs:attribute name=″qualityRanking″ type=″xs:unsignedInt″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;xs:attribute name=″dependencyId″ type=″StringVectorType″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;xs:attribute name=″mediaStreamStructureId″ type=</td> </tr> <tr class="description-tr"> <td class="description-td">   ″StringVectorType″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/xs:extension&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;/xs:complexContent&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;/xs:complexType&gt;</td> </tr> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </tbody></table> </patent-tables> </tables> <br/>
Extract of Code 6: Modification of the MPD Representation Element
</div>
<div class="description-paragraph" id="p-0268" num="0299"> <tables id="TABLE-US-00008" num="00008"> <patent-tables colsep="0" frame="none" rowsep="0"> <table align="left" class="description-table" cols="1" colsep="0" rowsep="0" width="100%"> <thead> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </thead> <tbody><tr class="description-tr"> <td class="description-td">&lt;!- Definition of the SpatialSubRepresentation element --&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;xs:complexType name=″SpatialSubRepresentationType″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;xs:complexContent&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;xs:extension base=″RepresentationBaseType″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;xs:sequence&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;xs:element name=″BaseURL″ type=″BaseURLType″ </td> </tr> <tr class="description-tr"> <td class="description-td">    minOccurs=″0″ maxOccurs=″unbounded″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;xs:element name=″SegmentBase″ type=″SegmentBaseType″ </td> </tr> <tr class="description-tr"> <td class="description-td">    minOccurs=″0″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;xs:element name=″SegmentList″ type=″SegmentListType″ </td> </tr> <tr class="description-tr"> <td class="description-td">    minOccurs=″0″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;xs:element name=″SegmentTemplate″ type=</td> </tr> <tr class="description-tr"> <td class="description-td">    ″SegmentTemplateType″ minOccurs=″0″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/xs:sequence&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;xs:attribute name=″id″ type=″StringNoWhitespaceType″ /&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;xs:attribute name=″dependencyId″ type=″ StringVectorType ″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;xs:attribute name=″posx″ type=″xs:unsignedInt″ use=″required″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;xs:attribute name=″posy″ type=″xs:unsignedInt″ use=″required″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;xs:attribute name=″bandwidth″ type=″xs:unsignedInt″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;xs:attribute name=″contentComponent″ type=″StringVectorType″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/xs:extension&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;/xs:complexContent&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;/xs:complexType&gt;</td> </tr> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </tbody></table> </patent-tables> </tables> <br/>
Extract of Code 7: Definition of a Spatial Sub-representation for MPD
</div>
<div class="description-paragraph" id="p-0269" num="0300"> <tables id="TABLE-US-00009" num="00009"> <patent-tables colsep="0" frame="none" pgwide="1" rowsep="0"> <table align="left" class="description-table" cols="1" colsep="0" rowsep="0" width="100%"> <thead> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </thead> <tbody><tr class="description-tr"> <td class="description-td">&lt;MPD ...&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;Period&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;BaseURL&gt;http://myserver.com/media&lt;/BaseURL&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;Initialization sourceURL= <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/b3/f9/4a/c1b6c712e62b7b/US11019408-20210525-P00003.png"><img alt="Figure US11019408-20210525-P00003" class="patent-full-image" file="US11019408-20210525-P00003.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00009" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/b3/f9/4a/c1b6c712e62b7b/US11019408-20210525-P00003.png" wi="1.78mm" width="7"/></a></div>   URL_SI  <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/50/21/93/7fd895c5d868d7/US11019408-20210525-P00004.png"><img alt="Figure US11019408-20210525-P00004" class="patent-full-image" file="US11019408-20210525-P00004.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00010" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/50/21/93/7fd895c5d868d7/US11019408-20210525-P00004.png" wi="1.78mm" width="7"/></a></div>  /&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;AdaptationSet id=′1′ contentType=′video′ framerate=′30′&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;!- Base layer description --&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;Representation id=′R1′ mimeType=′video/mp4′ width=′2000′ height=′1000′</td> </tr> <tr class="description-tr"> <td class="description-td">   bandwidth=′512000′&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentList&gt; &lt;SegmentURL media= <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/b3/f9/4a/c1b6c712e62b7b/US11019408-20210525-P00003.png"><img alt="Figure US11019408-20210525-P00003" class="patent-full-image" file="US11019408-20210525-P00003.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00011" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/b3/f9/4a/c1b6c712e62b7b/US11019408-20210525-P00003.png" wi="1.78mm" width="7"/></a></div>   URL_BL  <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/50/21/93/7fd895c5d868d7/US11019408-20210525-P00004.png"><img alt="Figure US11019408-20210525-P00004" class="patent-full-image" file="US11019408-20210525-P00004.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00012" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/50/21/93/7fd895c5d868d7/US11019408-20210525-P00004.png" wi="1.78mm" width="7"/></a></div>  /&gt; &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/AdaptationSet&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;!- Enhancement layer description, composite track --&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;AdaptationSet id=′2′ contentType=′video′ framerate=′30′ width=′4000′</td> </tr> <tr class="description-tr"> <td class="description-td">  height=′2000′ &gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;!- Tile a, b, c and d appear as components of composite track --&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;ContentComponent id=′Ta′ /&gt;&lt; Role schemeIdUri=′tiling′ id=′1′</td> </tr> <tr class="description-tr"> <td class="description-td">   value=′1:1′/&gt;&lt;/ContentComponent&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;ContentComponent id=′Tb′ /&gt;&lt;Role schemeIdUri=′tiling′ id=′1′</td> </tr> <tr class="description-tr"> <td class="description-td">   value=′1:2′/&gt;&lt;/ContentComponent&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;ContentComponent id=′Tc′ /&gt;&lt;Role schemeIdUri=′tiling′ id=′1′</td> </tr> <tr class="description-tr"> <td class="description-td">   value=′2:1′/&gt;&lt;/Content Component&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;ContentComponent id=′Td ′/&gt;&lt;Role schemeIdUri=′tiling′ id=′1′</td> </tr> <tr class="description-tr"> <td class="description-td">   value=′2:2′/&gt;&lt;/ContentComponent&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;Representation id=′R2′ mimeType=′video/mp4′ dependencyId=′R1′</td> </tr> <tr class="description-tr"> <td class="description-td">   bandwidth=′2048000′ width =′4000′ height=′2000′&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">     &lt;SegmentURL media= <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/b3/f9/4a/c1b6c712e62b7b/US11019408-20210525-P00003.png"><img alt="Figure US11019408-20210525-P00003" class="patent-full-image" file="US11019408-20210525-P00003.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00013" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/b3/f9/4a/c1b6c712e62b7b/US11019408-20210525-P00003.png" wi="1.78mm" width="7"/></a></div>   URL_CT  <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/50/21/93/7fd895c5d868d7/US11019408-20210525-P00004.png"><img alt="Figure US11019408-20210525-P00004" class="patent-full-image" file="US11019408-20210525-P00004.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00014" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/50/21/93/7fd895c5d868d7/US11019408-20210525-P00004.png" wi="1.78mm" width="7"/></a></div>  </td> </tr> <tr class="description-tr"> <td class="description-td">     related= <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/b3/f9/4a/c1b6c712e62b7b/US11019408-20210525-P00003.png"><img alt="Figure US11019408-20210525-P00003" class="patent-full-image" file="US11019408-20210525-P00003.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00015" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/b3/f9/4a/c1b6c712e62b7b/US11019408-20210525-P00003.png" wi="1.78mm" width="7"/></a></div>   URL_Ta URL_Tb URL_Tc URL_Td <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/50/21/93/7fd895c5d868d7/US11019408-20210525-P00004.png"><img alt="Figure US11019408-20210525-P00004" class="patent-full-image" file="US11019408-20210525-P00004.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00016" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/50/21/93/7fd895c5d868d7/US11019408-20210525-P00004.png" wi="1.78mm" width="7"/></a></div>   type= <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/b3/f9/4a/c1b6c712e62b7b/US11019408-20210525-P00003.png"><img alt="Figure US11019408-20210525-P00003" class="patent-full-image" file="US11019408-20210525-P00003.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00017" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/b3/f9/4a/c1b6c712e62b7b/US11019408-20210525-P00003.png" wi="1.78mm" width="7"/></a></div>   Ta Tb Tc Td <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/50/21/93/7fd895c5d868d7/US11019408-20210525-P00004.png"><img alt="Figure US11019408-20210525-P00004" class="patent-full-image" file="US11019408-20210525-P00004.TIF" he="2.12mm" height="8" id="CUSTOM-CHARACTER-00018" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/50/21/93/7fd895c5d868d7/US11019408-20210525-P00004.png" wi="1.78mm" width="7"/></a></div>  /&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">    &lt;/SegmentList&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">   &lt;/Representation&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;/AdaptationSet&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;/Period&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;/MPD&gt;</td> </tr> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </tbody></table> </patent-tables> </tables> <br/>
Extract of Code 8: Segment-based Tile Signaling for MPD
</div>
<div class="description-paragraph" id="p-0270" num="0301"> <tables id="TABLE-US-00010" num="00010"> <patent-tables colsep="0" frame="none" rowsep="0"> <table align="left" class="description-table" cols="1" colsep="0" rowsep="0" width="100%"> <thead> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </thead> <tbody><tr class="description-tr"> <td class="description-td">&lt;!-- SegmentURL--&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;xs:complexType name=″SegmentURLType″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;xs:sequence&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">  &lt;xs:any namespace=″##other″ processContents=″lax″ minOccurs=″0″</td> </tr> <tr class="description-tr"> <td class="description-td">  maxOccurs=″unbounded″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;/xs:sequence&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;xs:attribute name=″media″ type=″xs:anyURI″ &gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;xs:attribute name=″mediaRange″ type=″xs:string″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;xs:attribute name=″index″ type=″xs:anyURI″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;xs:attribute name=″indexRange″ type=″xs:string″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;xs:attribute name=″related″ type=″URLVectorType″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;xs:attribute name=″relatedRange″ type=″StringVectorType″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;xs:attribute name=″type″ type=″StringVectorType″/&gt; </td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;!-- Actually descriptors IDs --&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;xs:anyAttribute namespace=″##other″ processContents=″lax″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;/xs:complexType&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;!- List of URLs (added) --&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;xs:simpleType name=″URLVectorType″&gt;</td> </tr> <tr class="description-tr"> <td class="description-td"> &lt;xs:list itemType=″xs:anyURI″/&gt;</td> </tr> <tr class="description-tr"> <td class="description-td">&lt;/xs:simpleType&gt;</td> </tr> <tr class="description-tr"> <td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td> </tr> </tbody></table> </patent-tables> </tables> <br/>
Extract of Code 9: Extension of the MPD SegmentURL Type
</div>
</div>
</div>
</section><section itemprop="claims" itemscope="">
<h2>Claims (<span itemprop="count">9</span>)</h2>
<div html="" itemprop="content"><div class="claims" lang="EN" load-source="patent-office" mxw-id="PCLM289574484">
<claim-statement>The invention claimed is:</claim-statement>
<div class="claim"> <div class="claim" id="CLM-00001" num="00001">
<div class="claim-text">1. A providing method of a Media Presentation Description used by a client to request one or more video segments which are obtained by temporal dividing of video data, the Media Presentation Description complying with the MPEG-DASH standard, the method comprising:
<div class="claim-text">identifying a first video segment and a plurality of second video segments which have a predetermined relationship,</div>
<div class="claim-text">generating the Media Presentation Description including:</div>
<div class="claim-text">i) a first representation including first request information used by the client to request the first video segment,</div>
<div class="claim-text">ii) a plurality of second representations including second request information used by the client to request each of the plurality of second video segments which has the predetermined relationship with the first video segment, and</div>
<div class="claim-text">iii) relationship information indicating that the first video segment and the plurality of second video segments have the predetermined relationship, the predetermined relationship indicating that the first video segment is required, that the plurality of second video segments are optional, and that at least one second video segment of the plurality of optional second video segments is required for the reconstruction of the required first video segment, and</div>
<div class="claim-text">providing the Media Presentation Description to the client in response to a request from the client.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00002" num="00002">
<div class="claim-text">2. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein both of the first request information and the second request information are represented by URL.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00003" num="00003">
<div class="claim-text">3. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the one or more video segments are obtained by spatially dividing the video data.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00004" num="00004">
<div class="claim-text">4. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first video segment is used by the client to decode at least one video segment which is selectively requested by the client among the video segments.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00005" num="00005">
<div class="claim-text">5. The method according to <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">receiving a request for the first and second video segments; and</div>
<div class="claim-text">providing the first and second video segments which are requested by the client.</div>
</div>
</div>
</div> <div class="claim"> <div class="claim" id="CLM-00006" num="00006">
<div class="claim-text">6. A device for providing a Media Presentation Description used by a client to request one or more video segments which are obtained by temporal dividing of video data, the Media Presentation Description complying with the MPEG-DASH standard, the device comprising:
<div class="claim-text">one or more processors, and</div>
<div class="claim-text">memory storing one or more programs configured to be executed by the one or more processors, the one or more programs including instructions for:</div>
<div class="claim-text">identifying a first video segment and a plurality of second video segments which have a predetermined relationship,</div>
<div class="claim-text">generating the Media Presentation Description including:</div>
<div class="claim-text">i) a first representation including first request information used by the client to request the first video segment,</div>
<div class="claim-text">ii) a plurality of second representations including second request information used by the client to request each of the plurality of second video segments which has the predetermined relationship with the first video segment, and</div>
<div class="claim-text">iii) relationship information indicating that the first video segment and the plurality of second video segments have the predetermined relationship, the predetermined relationship indicating that the first video segment is required, that the plurality of second video segments are optional, and that at least one second video segment of the plurality of optional second video segments is required for the reconstruction of the required first video segment, and</div>
<div class="claim-text">providing the Media Presentation Description to the client in response to a request from the client.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00007" num="00007">
<div class="claim-text">7. The device according to <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the first video segment is used by the client to decode at least one video segment which is selectively requested by the client among the video segments.</div>
</div>
</div> <div class="claim"> <div class="claim" id="CLM-00008" num="00008">
<div class="claim-text">8. A non-transitory computer-readable storage medium storing a program for causing a computer to execute a providing method of Media Presentation Description used by a client to request one or more video segments which are obtained by temporal dividing of video data, the Media Presentation Description complying with the MPEG-DASH standard, the method comprising:
<div class="claim-text">identifying a first video segment and a plurality of second video segments which have a predetermined relationship,</div>
<div class="claim-text">generating the Media Presentation Description including</div>
<div class="claim-text">i) a first representation including first request information used by the client to request the first video segment,</div>
<div class="claim-text">ii) a plurality of second representations including second request information used by the client to request each of the plurality of second video segments which has the predetermined relationship with the first video segment, and</div>
<div class="claim-text">iii) relationship information indicating that the first video segment and the plurality of second video segments have the predetermined relationship, the predetermined relationship indicating that the first video segment is required, that the plurality of second video segments are optional, and that at least one second video segment of the plurality of optional second video segments is required for the reconstruction of the required first video segment, and</div>
<div class="claim-text">providing the Media Presentation Description to the client in response to a request from the client.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00009" num="00009">
<div class="claim-text">9. The medium according to <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the first video segment is used by the client to decode at least one video segment which is selectively requested by the client among the video segments.</div>
</div>
</div> </div>
</div>
</section>
                </article>
            </search-app>
        </body>
    </html>
    