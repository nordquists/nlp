
    <html>
        <body>
            <search-app>
                <article class="result" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
    <h1 itemprop="pageTitle">US20190073296A1 - Systems and Methods for Persistent Address Space Management 
        - Google Patents</h1><section itemprop="abstract" itemscope="">
<h2>Abstract</h2>
<div html="" itemprop="content"><abstract lang="EN" load-source="patent-office" mxw-id="PA287726498">
<div class="abstract" id="p-0001" num="0000">Data is stored on a non-volatile storage media in a sequential, log-based format. The formatted data defines an ordered sequence of storage operations performed on the non-volatile storage media. A storage layer maintains volatile metadata, which may include a forward index associating logical identifiers with respective physical storage units on the non-volatile storage media. The volatile metadata may be reconstructed from the ordered sequence of storage operations. Persistent notes may be used to maintain consistency between the volatile metadata and the contents of the non-volatile storage media. Persistent notes may identify data that does not need to be retained on the non-volatile storage media and/or is no longer valid.</div>
</abstract>
</div>
</section><section itemprop="description" itemscope="">
<h2>Description</h2>
<div html="" itemprop="content"><ul class="description" lang="EN" load-source="patent-office" mxw-id="PDES186243713">
<heading id="h-0001">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<li> <para-num num="[0001]"> </para-num> <div class="description-line" id="p-0002" num="0001">This Application is a continuation of, and claims priority to, U.S. patent application Ser. No. 14/045,605, filed on Oct. 3, 2013, entitled “Systems and Methods for Persistent Address Space Management,” Now U.S. Pat. No. 10,133,663, issued Nov. 20, 2018, which is a continuation of, and claims priority to, U.S. patent application Ser. No. 13/330,554, entitled “Apparatus, System, and Method for Persistent Data Management on a Non-Volatile Storage Media,” filed on Dec. 19, 2011, and which claims priority to U.S. Provisional Patent Application No. No. 61/425,167, entitled “Apparatus, System and Method for Persistent Management of Data in a Cache Device,” filed on Dec. 20, 2010, and to U.S. Provisional Patent Application 61/424,585, entitled “Apparatus, System, and Method for Persistent Management of Data in a Cache Device,” filed on Dec. 17, 2010, each of which is hereby incorporated by reference in its entirety.</div>
</li> <heading id="h-0002">TECHNICAL FIELD</heading>
<li> <para-num num="[0002]"> </para-num> <div class="description-line" id="p-0003" num="0002">The present disclosure relates generally to caching data on a solid state storage device and, in particular, to maintaining information pertaining to the cache and the solid state storage device for use in managing the cache after an invalid device shutdown.</div>
</li> <heading id="h-0003">BACKGROUND</heading>
<li> <para-num num="[0003]"> </para-num> <div class="description-line" id="p-0004" num="0003">Cache devices are storage devices that allow quick data access in a system. Caches can significantly improve performance in systems by reducing the input/output (I/O) time for operations that use the data in the cache. Generally, the cache is implemented in front of another storage device which may have greater storage capacity, but slower I/O times, than the cache device. The benefits of caches are well understood and caches have been implemented advantageously in a variety of contexts and scales ranging from the caches in CPUs to caches in storage area networks (SANs).</div>
</li> <li> <para-num num="[0004]"> </para-num> <div class="description-line" id="p-0005" num="0004">Currently, invalid data stored on cache devices, and solid-state storage devices in general, after an improper shutdown (e.g., an abrupt loss of power or the like) may be improperly considered as valid data by a system. Similarly, storage systems may incorporate TRIM messages to identify data that may be removed from a non-volatile storage media. The effect of a TRIM message may be obviated due to loss of volatile metadata. Accordingly, systems and methods are needed to better manage data stored on a cache and/or solid-state storage device following improper device shutdowns.</div>
</li> <description-of-drawings>
<heading id="h-0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<li> <para-num num="[0005]"> </para-num> <div class="description-line" id="p-0006" num="0005">The written disclosure herein describes illustrative embodiments that are non-limiting and non-exhaustive. Reference is made to certain of such illustrative embodiments that are depicted in the figures, in which:</div>
</li> <li> <para-num num="[0006]"> </para-num> <div class="description-line" id="p-0007" num="0006"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a block diagram of a system comprising a non-volatile storage device;</div>
</li> <li> <para-num num="[0007]"> </para-num> <div class="description-line" id="p-0008" num="0007"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a block diagram of one embodiment of a non-volatile storage device;</div>
</li> <li> <para-num num="[0008]"> </para-num> <div class="description-line" id="p-0009" num="0008"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a block diagram of one embodiment of a storage controller comprising a write data pipeline and a read data pipeline;</div>
</li> <li> <para-num num="[0009]"> </para-num> <div class="description-line" id="p-0010" num="0009"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a block diagram of one embodiment of a system comprising a storage layer;</div>
</li> <li> <para-num num="[0010]"> </para-num> <div class="description-line" id="p-0011" num="0010"> <figref idrefs="DRAWINGS">FIG. 5</figref> depicts one embodiment of a forward index;</div>
</li> <li> <para-num num="[0011]"> </para-num> <div class="description-line" id="p-0012" num="0011"> <figref idrefs="DRAWINGS">FIG. 6A</figref> depicts one embodiment of a reverse index;</div>
</li> <li> <para-num num="[0012]"> </para-num> <div class="description-line" id="p-0013" num="0012"> <figref idrefs="DRAWINGS">FIG. 6B</figref> depicts one embodiment of a validity bitmap;</div>
</li> <li> <para-num num="[0013]"> </para-num> <div class="description-line" id="p-0014" num="0013"> <figref idrefs="DRAWINGS">FIG. 7</figref> depicts one embodiment of an append point within a physical storage space of a non-volatile storage device;</div>
</li> <li> <para-num num="[0014]"> </para-num> <div class="description-line" id="p-0015" num="0014"> <figref idrefs="DRAWINGS">FIG. 8A</figref> depicts one example of a sequence of storage operations performed on a non-volatile storage media;</div>
</li> <li> <para-num num="[0015]"> </para-num> <div class="description-line" id="p-0016" num="0015"> <figref idrefs="DRAWINGS">FIG. 8B</figref> depicts another example of a sequence of storage operations performed on a non-volatile storage media;</div>
</li> <li> <para-num num="[0016]"> </para-num> <div class="description-line" id="p-0017" num="0016"> <figref idrefs="DRAWINGS">FIG. 8C</figref> depicts another example of a sequence of storage operations performed on a non-volatile storage media;</div>
</li> <li> <para-num num="[0017]"> </para-num> <div class="description-line" id="p-0018" num="0017"> <figref idrefs="DRAWINGS">FIG. 8D</figref> depicts an example of a sequence of storage operations performed on a non-volatile storage media comprising a persistent note;</div>
</li> <li> <para-num num="[0018]"> </para-num> <div class="description-line" id="p-0019" num="0018"> <figref idrefs="DRAWINGS">FIG. 8E</figref> depicts an example of an ordered sequence of cache storage operations performed on a non-volatile storage media;</div>
</li> <li> <para-num num="[0019]"> </para-num> <div class="description-line" id="p-0020" num="0019"> <figref idrefs="DRAWINGS">FIG. 8F</figref> depicts an example of an ordered sequence of cache storage operations performed on a non-volatile storage media comprising a persistent note;</div>
</li> <li> <para-num num="[0020]"> </para-num> <div class="description-line" id="p-0021" num="0020"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a flow diagram of one embodiment of a method for managing a non-volatile storage media;</div>
</li> <li> <para-num num="[0021]"> </para-num> <div class="description-line" id="p-0022" num="0021"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a flow diagram of one embodiment of a method for managing persistent notes on a non-volatile storage media; and</div>
</li> <li> <para-num num="[0022]"> </para-num> <div class="description-line" id="p-0023" num="0022"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a flow diagram of one embodiment of a method for reconstructing volatile metadata.</div>
</li> </description-of-drawings>
<heading id="h-0005">DETAILED DESCRIPTION</heading>
<li> <para-num num="[0023]"> </para-num> <div class="description-line" id="p-0024" num="0023"> <figref idrefs="DRAWINGS">FIG. 1</figref> depicts one embodiment of a system <b>100</b> comprising a non-volatile storage device <b>102</b>. In the depicted embodiment, the system <b>100</b> includes a host computing system <b>114</b>, a throughput management apparatus <b>122</b>, and a storage device <b>102</b>. The host computing system <b>114</b> may be a computer such as a server, laptop, desktop, a mobile device, or other computing device known in the art. The host computing system <b>114</b> typically includes components such as memory, processors, buses, and other components as known to those of skill in the art.</div>
</li> <li> <para-num num="[0024]"> </para-num> <div class="description-line" id="p-0025" num="0024">The host computing system <b>114</b> stores data in the storage device <b>102</b> and communicates data with the storage device <b>102</b> via a communications connection. The storage device <b>102</b> may be internal to the host computing system <b>114</b> or external to the host computing system <b>114</b>. The communications connection may be a bus, a network, or other manner of connection allowing the transfer of data between the host computing system <b>114</b> and the storage device <b>102</b>. In one embodiment, the storage device <b>102</b> is connected to the host computing system <b>114</b> by a PCI connection such as PCI express (“PCI-e”). The storage device <b>102</b> may be a card that plugs into a PCI-e connection on the host computing system <b>114</b>.</div>
</li> <li> <para-num num="[0025]"> </para-num> <div class="description-line" id="p-0026" num="0025">The storage device <b>102</b>, in the depicted embodiment, performs data storage operations such as reads, writes, erases, etc. In certain embodiments, a power connection and the communications connection for the storage device <b>102</b> are part of the same physical connection between the host computing system <b>114</b> and the storage device <b>102</b>. For example, the storage device <b>102</b> may receive power over PCI, PCI-e, serial advanced technology attachment (“serial ATA” or “SATA”), parallel ATA (“PATA”), small computer system interface (“SCSI”), IEEE 1394 (“FireWire”), Fiber Channel, universal serial bus (“USB”), PCIe-AS, or another connection with the host computing system <b>114</b>.</div>
</li> <li> <para-num num="[0026]"> </para-num> <div class="description-line" id="p-0027" num="0026">The storage device <b>102</b> provides nonvolatile storage for the host computing system <b>114</b>. <figref idrefs="DRAWINGS">FIG. 1</figref> shows the storage device <b>102</b> as a nonvolatile non-volatile storage device <b>102</b> comprising a storage controller <b>104</b>, a write data pipeline <b>106</b>, a read data pipeline <b>108</b>, and nonvolatile non-volatile storage media <b>110</b>. The storage device <b>102</b> may contain additional components that are not shown in order to provide a simpler view of the storage device <b>102</b>.</div>
</li> <li> <para-num num="[0027]"> </para-num> <div class="description-line" id="p-0028" num="0027">The non-volatile storage media <b>110</b> stores data such that the data is retained even when the storage device <b>102</b> is not powered. In some embodiments, the non-volatile storage media <b>110</b> comprises a solid-state storage media, such as flash memory, nano random access memory (“NRAM”), magneto-resistive RAM (“MRAM”), dynamic RAM (“DRAM”), phase change RAM (“PRAM”), Racetrack memory, Memristor memory, nanocrystal wire-based memory, silicon-oxide based sub-10 nanometer process memory, graphene memory, Silicon-Oxide-Nitride-Oxide-Silicon (“SONOS”), Resistive random-access memory (“RRAM”), programmable metallization cell (“PMC”), conductive-bridging RAM (“CBRAM”), and the like. While, in the depicted embodiment, the storage device <b>102</b> includes non-volatile storage media <b>110</b>, in other embodiments, the storage device <b>102</b> may include magnetic media such as hard disks, tape, and the like, optical media, or other nonvolatile data storage media. The storage device <b>102</b> also includes a storage controller <b>104</b> that coordinates the storage and retrieval of data in the non-volatile storage media <b>110</b>. The storage controller <b>104</b> may use one or more indexes to locate and retrieve data, and perform other operations on data stored in the storage device <b>102</b>. For example, the storage controller <b>104</b> may include a groomer for performing data grooming operations such as garbage collection.</div>
</li> <li> <para-num num="[0028]"> </para-num> <div class="description-line" id="p-0029" num="0028">As shown, the storage device <b>102</b>, in certain embodiments, implements a write data pipeline <b>106</b> and a read data pipeline <b>108</b>, an example of which is described in greater detail below. The write data pipeline <b>106</b> may perform certain operations on data as the data is transferred from the host computing system <b>114</b> into the non-volatile storage media <b>110</b>. These operations may include, for example, error correction code (ECC) generation, encryption, compression, and others. The read data pipeline <b>108</b> may perform similar and potentially inverse operations on data that is being read out of non-volatile storage media <b>110</b> and sent to the host computing system <b>114</b>.</div>
</li> <li> <para-num num="[0029]"> </para-num> <div class="description-line" id="p-0030" num="0029">In one embodiment, the host computing system <b>114</b> includes one or more other components in addition to the storage device <b>102</b>, such as additional storage devices, graphics processors, network cards, and the like. Those of skill in the art, in view of this disclosure, will appreciate the different types of components that may be in a host computing system <b>114</b>. The components may be internal or external to the host computing system <b>114</b>. In one embodiment, some of the components may be PCI or PCI-e cards that connect to the host computing system <b>114</b> and receive power through the host computing system <b>114</b>.</div>
</li> <li> <para-num num="[0030]"> </para-num> <div class="description-line" id="p-0031" num="0030">In some embodiments, the driver <b>118</b>, or alternatively the storage interface <b>116</b>, is an application program interface (“API”) and acts to translate commands and other data to a form suitable to be sent to a storage controller <b>104</b>. In another embodiment, the driver <b>118</b> includes one or more functions of the storage controller <b>104</b>. For example, the driver <b>118</b> may include all or a portion of the modules described below and may include one or more indexes or maps for the storage devices <b>106</b>. The driver <b>118</b>, one or more storage controllers <b>104</b>, and one or more storage devices <b>106</b> comprising the storage system <b>102</b> have a storage interface <b>116</b> connection to a file system/file server and allocation traditionally done in a file system/file server is advantageously pushed down (i.e., offloaded) to the storage system <b>102</b>.</div>
</li> <li> <para-num num="[0031]"> </para-num> <div class="description-line" id="p-0032" num="0031">A logical identifier, as used in this application, is an identifier of a data unit that differs from a physical address where data of the data unit is stored. A data unit, as used in this application, is any set of data that is logically grouped together. A data unit may be a file, an object, a data segment of a redundant array of inexpensive/independent disks/drives (“RAID”) data stripe, or other data set used in data storage. The data unit may be executable code, data, metadata, directories, indexes, any other type of data that may be stored in a memory device, or a combination thereof. The data unit may be identified by a name, by a logical address, a physical address, an address range, or other convention for identifying data units. A logical identifier includes data unit identifiers, such as a file name, an object identifier, an inode, Universally Unique Identifier (“UUID”), Globally Unique Identifier (“GUID”), or other data unit label, and may also include a logical block address (“LBA”), cylinder/head/sector (“CHS”), or other lower level logical identifier. A logical identifier generally includes any logical label that can be mapped to a physical location.</div>
</li> <li> <para-num num="[0032]"> </para-num> <div class="description-line" id="p-0033" num="0032">In some embodiments, the storage device <b>106</b> stores data in a sequential log-based format on the non-volatile storage media <b>110</b>. For example, when a data unit is modified, data of the data unit is read from one physical storage unit, modified, and then written to a different physical storage unit. The order and sequence of writing data to the data storage device <b>106</b> may comprise an event log of the sequence of storage operations performed on the non-volatile storage device <b>102</b>. By traversing the event log (and/or replaying the sequence of storage operations), volatile storage metadata, such as a forward index can be constructed or reconstructed.</div>
</li> <li> <para-num num="[0033]"> </para-num> <div class="description-line" id="p-0034" num="0033">In a typical random access device, logical identifiers have almost a one-to-one correspondence to physical addresses of the random access device. This one-to-one mapping in a typical random access device (excluding a small number of physical addresses on the random access device reserved for bad block mapping) also correlates to a near one-to-one relationship between storage capacity associated with logical identifiers and physical capacity associated with physical addresses. For example, if a logical identifier is a logical block address (“LBA”), each logical block associated with an LBA has a fixed size. A corresponding physical block on the random access device is typically the same size as a logical block. This enables a typical file server <b>114</b>/file system to manage physical capacity on the random access device by managing logical identifiers, such as LBAs. This continuity of LBA to PBA mapping is generally depended upon and utilized by file systems to defragment the data stored on the data storage device. Similarly, some systems may use this continuity to locate the data on specific physical tracks to improve performance as is the case of a technique called “short stroking” the disk drive. The highly predictable LBA to PBA mapping is essential in certain applications to indirectly manage the storage of the data in the physical storage space through direct management of the logical address space.</div>
</li> <li> <para-num num="[0034]"> </para-num> <div class="description-line" id="p-0035" num="0034">However, the storage system <b>102</b> may be a log structured file system such that there is no “fixed” relationship or algorithm to determine the mapping of the LBA to the PBA, or in another embodiment, may be random access, but may be accessed by more than one client <b>110</b> or file server <b>114</b>/file system such that the logical identifiers allocated to each client <b>110</b> or file server <b>114</b>/file system represent a storage capacity much larger than the one-to-one relationship of logical to physical identifiers of typical systems. The storage system <b>102</b> may also be thinly provisioned such that one or more clients <b>110</b> each has an allocated logical address range that is much larger than the storage capacity of the storage devices <b>106</b> in the storage system <b>102</b>. In the system <b>100</b>, the storage system <b>102</b> manages and allocates logical identifiers such that there is no pre-determined one-to-one or near one-to-one relationship between logical identifiers and physical identifiers.</div>
</li> <li> <para-num num="[0035]"> </para-num> <div class="description-line" id="p-0036" num="0035">The system <b>100</b> is advantageous because it allows more efficient management of storage capacity than typical storage systems. For example, for typical random access devices accessible by a number of clients <b>110</b>, if each client is allocated a certain amount storage space, the storage space typically will exist and be tied up in the allocations even if the actual amount of storage space occupied is much less. The system <b>100</b> is also advantageous because the system <b>100</b> reduces complexity of standard thin provisioning systems connected to storage devices <b>106</b>. A standard thin provisioning system has a thin provisioning layer comprising a logical-to-logical mapping between logical identifiers in the space logical address space and physical storage (e.g., particular physical storage units). The system <b>100</b> is more efficient because multiple layers of mapping are eliminated and thin provisioning (logical-to-physical mapping) is done at the lowest level.</div>
</li> <li> <para-num num="[0036]"> </para-num> <div class="description-line" id="p-0037" num="0036"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a schematic block diagram illustrating one embodiment <b>200</b> of a non-volatile storage device controller <b>202</b> that includes a write data pipeline <b>106</b> and a read data pipeline <b>108</b> in a non-volatile storage device <b>102</b> in accordance with the present invention. The non-volatile storage device controller <b>202</b> may include a number of storage controllers <b>0</b>-N <b>104</b> <i>a</i>-<i>n, </i>each controlling non-volatile storage media <b>110</b>. In the depicted embodiment, two non-volatile controllers are shown: non-volatile controller <b>0</b> <b>104</b> <i>a </i>and storage controller N <b>104</b> <i>n, </i>and each controlling respective non-volatile storage media <b>110</b> <i>a</i>-<i>n. </i>In the depicted embodiment, storage controller <b>0</b> <b>104</b> <i>a </i>controls a data channel so that the attached non-volatile storage media <b>110</b> <i>a </i>stores data. Storage controller N <b>104</b> <i>n </i>controls an index metadata channel associated with the stored data and the associated non-volatile storage media <b>110</b> <i>n </i>stores index metadata. In an alternate embodiment, the non-volatile storage device controller <b>202</b> includes a single non-volatile controller <b>104</b> <i>a </i>with a single non-volatile storage media <b>110</b> <i>a. </i>In another embodiment, there are a plurality of storage controllers <b>104</b> <i>a</i>-<i>n </i>and associated non-volatile storage media <b>110</b> <i>a</i>-<i>n. </i>In one embodiment, one or more non-volatile controllers <b>104</b> <i>a</i>-<b>104</b> <i>n−</i>1, coupled to their associated non-volatile storage media <b>110</b> <i>a</i>-<b>110</b> <i>n−</i>1, control data while at least one storage controller <b>104</b> <i>n, </i>coupled to its associated non-volatile storage media <b>110</b> <i>n, </i>controls index metadata.</div>
</li> <li> <para-num num="[0037]"> </para-num> <div class="description-line" id="p-0038" num="0037">In one embodiment, at least one non-volatile controller <b>104</b> is a field-programmable gate array (“FPGA”) and controller functions are programmed into the FPGA. In a particular embodiment, the FPGA is a Xilinx® FPGA. In another embodiment, the storage controller <b>104</b> comprises components specifically designed as a storage controller <b>104</b>, such as an application-specific integrated circuit (“ASIC”) or custom logic solution. Each storage controller <b>104</b> typically includes a write data pipeline <b>106</b> and a read data pipeline <b>108</b>, which are describe further in relation to <figref idrefs="DRAWINGS">FIG. 3</figref>. In another embodiment, at least one storage controller <b>104</b> is made up of a combination FPGA, ASIC, and custom logic components.</div>
</li> <li> <para-num num="[0038]"> </para-num> <div class="description-line" id="p-0039" num="0038">The non-volatile storage media <b>110</b> is an array of non-volatile storage elements <b>216</b>, <b>218</b>, <b>220</b>, arranged in banks <b>214</b>, and accessed in parallel through a bi-directional storage input/output (“I/O”) bus <b>210</b>. The storage I/O bus <b>210</b>, in one embodiment, is capable of unidirectional communication at any one time. For example, when data is being written to the non-volatile storage media <b>110</b>, data cannot be read from the non-volatile storage media <b>110</b>. In another embodiment, data can flow both directions simultaneously. However bi-directional, as used herein with respect to a data bus, refers to a data pathway that can have data flowing in only one direction at a time, but when data flowing one direction on the bi-directional data bus is stopped, data can flow in the opposite direction on the bi-directional data bus.</div>
</li> <li> <para-num num="[0039]"> </para-num> <div class="description-line" id="p-0040" num="0039">A non-volatile storage element (e.g., SSS <b>0</b>.<b>0</b> <b>216</b> <i>a</i>) is typically configured as a chip (a package of one or more dies) or a die on a circuit board. As depicted, a non-volatile storage element (e.g., <b>216</b> <i>a</i>) operates independently or semi-independently of other non-volatile storage elements (e.g., <b>218</b> <i>a</i>) even if these several elements are packaged together in a chip package, a stack of chip packages, or some other package element. As depicted, a row of non-volatile storage elements <b>216</b> <i>a, </i> <b>216</b> <i>b, </i> <b>216</b> <i>m </i>is designated as a bank <b>214</b>. As depicted, there may be “n” banks <b>214</b> <i>a</i>-<i>n </i>and “m” non-volatile storage elements <b>216</b> <i>a</i>-<i>m, </i> <b>218</b> <i>a</i>-<i>m, </i> <b>220</b> <i>a</i>-<i>m </i>per bank in an array of N×m non-volatile storage elements <b>216</b>, <b>218</b>, <b>220</b> in a non-volatile storage media <b>110</b>. Of course, different embodiments may include different values for n and m. In one embodiment, a non-volatile storage media <b>110</b> <i>a </i>includes twenty non-volatile storage elements <b>216</b> <i>a</i>-<b>216</b> <i>m </i>per bank <b>214</b> with eight banks <b>214</b>. In one embodiment, the non-volatile storage media <b>110</b> <i>a </i>includes twenty-four non-volatile storage elements <b>216</b> <i>a</i>-<b>216</b> <i>m </i>per bank <b>214</b> with eight banks <b>214</b>. In addition to the n×m storage elements <b>216</b> <i>a</i>-<b>216</b> <i>m, </i> <b>218</b> <i>a</i>-<b>218</b> <i>m, </i> <b>220</b> <i>a</i>-<b>220</b> <i>m, </i>one or more additional columns (P) may also be addressed and operated in parallel with other non-volatile storage elements <b>216</b> <i>a, </i> <b>216</b> <i>b, </i> <b>216</b> <i>m </i>for one or more rows. The added P columns in one embodiment, store parity data for the portions of an ECC chunk (i.e., an ECC codeword) that span m storage elements for a particular bank. In one embodiment, each non-volatile storage element <b>216</b>, <b>218</b>, <b>220</b> is comprised of single-level cell (“SLC”) devices. In another embodiment, each non-volatile storage element <b>216</b>, <b>218</b>, <b>220</b> is comprised of multi-level cell (“MLC”) devices.</div>
</li> <li> <para-num num="[0040]"> </para-num> <div class="description-line" id="p-0041" num="0040">In one embodiment, non-volatile storage elements that share a common line <b>211</b> on the storage I/O bus <b>210</b> <i>a </i>(e.g., <b>216</b> <i>b, </i> <b>218</b> <i>b, </i> <b>220</b> <i>b</i>) are packaged together. In one embodiment, a non-volatile storage element <b>216</b>, <b>218</b>, <b>220</b> may have one or more dies per package with one or more packages stacked vertically and each die may be accessed independently. In another embodiment, a non-volatile storage element (e.g., SSS <b>0</b>.<b>0</b> <b>216</b> <i>a</i>) may have one or more virtual dies per die and one or more dies per package and one or more packages stacked vertically and each virtual die may be accessed independently. In another embodiment, a non-volatile storage element SSS <b>0</b>.<b>0</b> <b>216</b> <i>a </i>may have one or more virtual dies per die and one or more dies per package with some or all of the one or more dies stacked vertically and each virtual die may be accessed independently.</div>
</li> <li> <para-num num="[0041]"> </para-num> <div class="description-line" id="p-0042" num="0041">In one embodiment, two dies are stacked vertically with four stacks per group to form eight storage elements (e.g., SSS <b>0</b>.<b>0</b>-SSS <b>8</b>.<b>0</b>) <b>216</b> <i>a, </i> <b>218</b> <i>a </i>. . . <b>220</b> <i>a, </i>each in a separate bank <b>214</b> <i>a, </i> <b>214</b> <i>b </i>. . . <b>214</b> <i>n. </i>In another embodiment, 24 storage elements (e.g., SSS <b>0</b>.<b>0</b>-SSS <b>0</b>.<b>24</b>) <b>216</b> <i>a, </i> <b>216</b> <i>b, </i>. . . <b>216</b> <i>m </i>form a logical bank <b>214</b> <i>a </i>so that each of the eight logical banks has 24 storage elements (e.g., SSS <b>0</b>.<b>0</b>-SSS <b>8</b>.<b>24</b>) <b>216</b>, <b>218</b>, <b>220</b>. Data is sent to the non-volatile storage media <b>110</b> over the storage I/O bus <b>210</b> to all storage elements of a particular group of storage elements (SSS <b>0</b>.<b>0</b>-SSS <b>8</b>.<b>0</b>) <b>216</b> <i>a, </i> <b>218</b> <i>a, </i> <b>220</b> <i>a. </i>The storage control bus <b>212</b> <i>a </i>is used to select a particular bank (e.g., Bank <b>0</b> <b>214</b> <i>a</i>) so that the data received over the storage I/O bus <b>210</b> connected to all banks <b>214</b> is written just to the selected bank <b>214</b> <i>a. </i> </div>
</li> <li> <para-num num="[0042]"> </para-num> <div class="description-line" id="p-0043" num="0042">In one embodiment, the storage I/O bus <b>210</b> is comprised of one or more independent I/O buses (“IIOBa-m” comprising <b>210</b> <i>a.a</i>-<i>m </i>. . . <b>210</b> <i>n.a</i>-<i>m</i>) wherein the non-volatile storage elements within each column share one of the independent I/O buses that are connected to each non-volatile storage element <b>216</b>, <b>218</b>, <b>220</b> in parallel. For example, one independent I/O bus <b>210</b> <i>a.a </i>of the storage I/O bus <b>210</b> <i>a </i>may be physically connected to a first non-volatile storage element <b>216</b> <i>a, </i> <b>218</b> <i>a, </i> <b>220</b> <i>a </i>of each bank <b>214</b> <i>a</i>-<i>n. </i>A second independent I/O bus <b>210</b> <i>a.b </i>of the storage I/O bus <b>210</b> <i>b </i>may be physically connected to a second non-volatile storage element <b>216</b> <i>b, </i> <b>218</b> <i>b, </i> <b>220</b> <i>b </i>of each bank <b>214</b> <i>a</i>-<i>n. </i>Each non-volatile storage element <b>216</b> <i>a, </i> <b>216</b> <i>b, </i> <b>216</b> <i>m </i>in a bank <b>214</b> <i>a </i>(a row of non-volatile storage elements as illustrated in <figref idrefs="DRAWINGS">FIG. 2</figref>) may be accessed simultaneously and/or in parallel. In one embodiment, where non-volatile storage elements <b>216</b>, <b>218</b>, <b>220</b> comprise stacked packages of dies, all packages in a particular stack are physically connected to the same independent I/O bus. As used herein, “simultaneously” also includes near simultaneous access where devices are accessed at slightly different intervals to avoid switching noise. Simultaneously is used in this context to be distinguished from a sequential or serial access wherein commands and/or data are sent individually one after the other.</div>
</li> <li> <para-num num="[0043]"> </para-num> <div class="description-line" id="p-0044" num="0043">Typically, banks <b>214</b> <i>a</i>-<i>n </i>are independently selected using the storage control bus <b>212</b>. In one embodiment, a bank <b>214</b> is selected using a chip enable or chip select. Where both chip select and chip enable are available, the storage control bus <b>212</b> may select one package within a stack of packages. In other embodiments, other commands are used by the storage control bus <b>212</b> to individually select one package within a stack of packages. Non-volatile storage elements <b>216</b>, <b>218</b>, <b>220</b> may also be selected through a combination of control signals and address information transmitted on storage I/O bus <b>210</b> and the storage control bus <b>212</b>.</div>
</li> <li> <para-num num="[0044]"> </para-num> <div class="description-line" id="p-0045" num="0044">In one embodiment, each non-volatile storage element <b>216</b>, <b>218</b>, <b>220</b> is partitioned into erase blocks and each erase block is partitioned into pages. An erase block on a non-volatile storage element <b>216</b>, <b>218</b> <b>220</b> may be called a physical erase block or “PEB.” A typical page is 2048 bytes (“2 kB”). In one example, a non-volatile storage element (e.g., SSS <b>0</b>.<b>0</b>) includes two registers and can program two pages so that a two-register non-volatile storage element <b>216</b>, <b>218</b>, <b>220</b> has a capacity of 4 kB. A bank <b>214</b> of 20 non-volatile storage elements <b>216</b> <i>a, </i> <b>216</b> <i>b, </i> <b>216</b> <i>m </i>would then have an 80 kB capacity of pages accessed with the same address going out the independent I/O buses of the storage I/O bus <b>210</b>.</div>
</li> <li> <para-num num="[0045]"> </para-num> <div class="description-line" id="p-0046" num="0045">This group of pages in a bank <b>214</b> of non-volatile storage elements <b>216</b> <i>a, </i> <b>216</b> <i>b, </i>. . . <b>216</b> <i>m </i>of 80 kB may be called a logical page or virtual page. Similarly, an erase block of each storage element <b>216</b> <i>a, </i> <b>216</b> <i>b, </i>. . . <b>216</b> <i>m </i>of a bank <b>214</b> <i>a </i>may be grouped to form a logical erase block (which may also be called a virtual erase block). In one embodiment, an erase block of pages within a non-volatile storage element is erased when an erase command is received within the non-volatile storage element. Whereas the size and number of erase blocks, pages, planes, or other logical and physical divisions within a non-volatile storage element <b>216</b>, <b>218</b>, <b>220</b> are expected to change over time with advancements in technology, it is to be expected that many embodiments consistent with new configurations are possible and are consistent with the general description herein.</div>
</li> <li> <para-num num="[0046]"> </para-num> <div class="description-line" id="p-0047" num="0046">Typically, when a packet is written to a particular location within a non-volatile storage element <b>216</b>, wherein the packet is intended to be written to a location within a particular page which is specific to a particular physical erase block of a particular storage element of a particular bank, a physical address is sent on the storage I/O bus <b>210</b> and is followed by the packet. The physical address contains enough information for the non-volatile storage element <b>216</b> to direct the packet to the designated location within the page. Since all storage elements in a column of storage elements (e.g., SSS <b>0</b>.<b>0</b>-SSS N.<b>0</b> <b>216</b> <i>a, </i> <b>218</b> <i>a, </i>. . . <b>220</b> <i>a</i>) are connected to the same independent I/O bus (e.g., <b>210</b>.<i>a.a</i>) of the storage I/O bus <b>210</b> <i>a, </i>to reach the proper page and to avoid writing the data packet to similarly addressed pages in the column of storage elements (SSS <b>0</b>.<b>0</b>-SSS N.<b>0</b> <b>216</b> <i>a, </i> <b>218</b> <i>a, </i>. . . <b>220</b> <i>a</i>), the bank <b>214</b> <i>a </i>that includes the non-volatile storage element SSS <b>0</b>.<b>0</b> <b>216</b> <i>a </i>with the correct page where the data packet is to be written is selected by the storage control bus <b>212</b> <i>a </i>and other banks <b>214</b> <i>b </i>. . . <b>214</b> <i>n </i>of the non-volatile storage <b>110</b> <i>a </i>are deselected.</div>
</li> <li> <para-num num="[0047]"> </para-num> <div class="description-line" id="p-0048" num="0047">Similarly, satisfying a read command on the storage I/O bus <b>210</b> requires a signal on the storage control bus <b>212</b> to select a single bank <b>214</b> <i>a </i>and the appropriate page within that bank <b>214</b> <i>a. </i>In one embodiment, a read command reads an entire page, and because there are multiple non-volatile storage elements <b>216</b> <i>a, </i> <b>216</b> <i>b, </i>. . . <b>216</b> <i>m </i>in parallel in a bank <b>214</b> <i>a, </i>an entire logical page is read with a read command. However, the read command may be broken into subcommands, as will be explained below with respect to bank interleave. Similarly, an entire logical page may be written to the non-volatile storage elements <b>216</b> <i>a, </i> <b>216</b> <i>b, </i>. . . <b>216</b> <i>m </i>of a bank <b>214</b> <i>a </i>in a write operation.</div>
</li> <li> <para-num num="[0048]"> </para-num> <div class="description-line" id="p-0049" num="0048">An erase block erase command may be sent out to erase an erase block over the storage I/O bus <b>210</b> with a particular erase block address to erase a particular erase block. Typically, storage controller <b>104</b> <i>a </i>may send an erase block erase command over the parallel paths (independent I/O buses <b>210</b> <i>a</i>-<i>n.a</i>-<i>m</i>) of the storage I/O bus <b>210</b> to erase a logical erase block, each with a particular erase block address to erase a particular erase block. Simultaneously, a particular bank (e.g., Bank <b>0</b> <b>214</b> <i>a</i>) is selected over the storage control bus <b>212</b> to prevent erasure of similarly addressed erase blocks in non-selected banks (e.g., Banks <b>1</b>-N <b>214</b> <i>b</i>-<i>n</i>). Alternatively, no particular bank (e.g., Bank <b>0</b> <b>214</b> <i>a</i>) is selected over the storage control bus <b>212</b> (or all of the banks are selected) to enable erasure of similarly addressed erase blocks in all of the banks (Banks <b>1</b>-N <b>214</b> <i>b</i>-<i>n</i>) in parallel. Other commands may also be sent to a particular location using a combination of the storage I/O bus <b>210</b> and the storage control bus <b>212</b>. One of skill in the art will recognize other ways to select a particular storage unit using the bi-directional storage I/O bus <b>210</b> and the storage control bus <b>212</b>.</div>
</li> <li> <para-num num="[0049]"> </para-num> <div class="description-line" id="p-0050" num="0049">In one embodiment, packets are written sequentially to the non-volatile storage media <b>110</b>. For example, storage controller <b>104</b> <i>a </i>streams packets to storage write buffers of a bank <b>214</b> <i>a </i>of storage elements <b>216</b> and, when the buffers are full, the packets are programmed to a designated logical page. Storage controller <b>104</b> <i>a </i>then refills the storage write buffers with packets and, when full, the packets are written to the next logical page. The next logical page may be in the same bank <b>214</b> <i>a </i>or another bank (e.g., <b>214</b> <i>b</i>). This process continues, logical page after logical page, typically until a logical erase block is filled. In another embodiment, the streaming may continue across logical erase block boundaries with the process continuing, logical erase block after logical erase block.</div>
</li> <li> <para-num num="[0050]"> </para-num> <div class="description-line" id="p-0051" num="0050">In a read, modify, write operation, data packets associated with requested data are located and read in a read operation. Data segments of the modified requested data that have been modified are not written to the location from which they are read. Instead, the modified data segments are again converted to data packets and then written sequentially to the next available location in the logical page currently being written. The index entries for the respective data packets are modified to point to the packets that contain the modified data segments. The entry or entries in the index for data packets associated with the same requested data that have not been modified will include pointers to original location of the unmodified data packets. Thus, if the original requested data is maintained, for example to maintain a previous version of the requested data, the original requested data will have pointers in the index to all data packets as originally written. The new requested data will have pointers in the index to some of the original data packets and pointers to the modified data packets in the logical page that is currently being written.</div>
</li> <li> <para-num num="[0051]"> </para-num> <div class="description-line" id="p-0052" num="0051">In a copy operation, the index includes an entry for the original requested data mapped to a number of packets stored in the non-volatile storage media <b>110</b>. When a copy is made, a new copy of the requested data is created and a new entry is created in the index mapping the new copy of the requested data to the original packets. The new copy of the requested data is also written to the non-volatile storage media <b>110</b> with its location mapped to the new entry in the index. The new copy of the requested data packets may be used to identify the packets within the original requested data that are referenced in case changes have been made in the original requested data that have not been propagated to the copy of the requested data and the index is lost or corrupted.</div>
</li> <li> <para-num num="[0052]"> </para-num> <div class="description-line" id="p-0053" num="0052">Beneficially, sequentially writing packets facilitates a more even use of the non-volatile storage media <b>110</b> and allows the solid-storage device controller <b>202</b> to monitor storage hot spots and level usage of the various logical pages in the non-volatile storage media <b>110</b>. Sequentially writing packets also facilitates a powerful, efficient garbage collection system, which is described in detail below. One of skill in the art will recognize other benefits of sequential storage of data packets.</div>
</li> <li> <para-num num="[0053]"> </para-num> <div class="description-line" id="p-0054" num="0053">In various embodiments, the non-volatile storage device controller <b>202</b> also includes a data bus <b>204</b>, a local bus <b>206</b>, a buffer controller <b>208</b>, buffers <b>0</b>-N <b>222</b> <i>a</i>-n, a master controller <b>224</b>, a direct memory access (“DMA”) controller <b>226</b>, a memory controller <b>228</b>, a dynamic memory array <b>230</b>, a static random memory array <b>232</b>, a management controller <b>234</b>, a management bus <b>236</b>, a bridge <b>238</b> to a system bus <b>240</b>, and miscellaneous logic <b>242</b>, which are described below. In other embodiments, the system bus <b>240</b> is coupled to one or more network interface cards (“NICs”) <b>244</b>, some of which may include remote DMA (“RDMA”) controllers <b>246</b>, one or more central processing unit (“CPU”) <b>248</b>, one or more external memory controllers <b>250</b> and associated external memory arrays <b>252</b>, one or more storage controllers <b>254</b>, peer controllers <b>256</b>, and application specific processors <b>258</b>, which are described below. The components <b>244</b>-<b>258</b> connected to the system bus <b>240</b> may be located in the host computing system <b>114</b> or may be other devices.</div>
</li> <li> <para-num num="[0054]"> </para-num> <div class="description-line" id="p-0055" num="0054">Typically, the storage controller(s) <b>104</b> communicate data to the non-volatile storage media <b>110</b> over a storage I/O bus <b>210</b>. In a typical embodiment where the non-volatile storage is arranged in banks <b>214</b> and each bank <b>214</b> includes multiple storage elements <b>216</b> <i>a, </i> <b>216</b> <i>b, </i> <b>216</b> <i>m </i>accessed in parallel, the storage I/O bus <b>210</b> is an array of busses, one for each column of storage elements <b>216</b>, <b>218</b>, <b>220</b> spanning the banks <b>214</b>. As used herein, the term “storage I/O bus” may refer to one storage I/O bus <b>210</b> or an array of independent data busses wherein individual data busses of the array independently communicate different data relative to one another. In one embodiment, each storage I/O bus <b>210</b> accessing a column of storage elements (e.g., <b>216</b> <i>a, </i> <b>218</b> <i>a, </i> <b>220</b> <i>a</i>) may include a logical-to-physical mapping for storage divisions (e.g., erase blocks) accessed in a column of storage elements <b>216</b> <i>a, </i> <b>218</b> <i>a, </i> <b>220</b> <i>a. </i>This mapping (or bad block remapping) allows a logical address mapped to a physical address of a storage division to be remapped to a different storage division if the first storage division fails, partially fails, is inaccessible, or has some other problem.</div>
</li> <li> <para-num num="[0055]"> </para-num> <div class="description-line" id="p-0056" num="0055">Data may also be communicated to the storage controller(s) <b>104</b> from a requesting device <b>155</b> through the system bus <b>240</b>, bridge <b>238</b>, local bus <b>206</b>, buffer(s) <b>222</b>, and finally over a data bus <b>204</b>. The data bus <b>204</b> typically is connected to one or more buffers <b>222</b> <i>a</i>-<i>n </i>controlled with a buffer controller <b>208</b>. The buffer controller <b>208</b> typically controls transfer of data from the local bus <b>206</b> to the buffers <b>222</b> and through the data bus <b>204</b> to the pipeline input buffer <b>306</b> and output buffer <b>330</b>. The buffer controller <b>208</b> typically controls how data arriving from a requesting device can be temporarily stored in a buffer <b>222</b> and then transferred onto a data bus <b>204</b>, or vice versa, to account for different clock domains, to prevent data collisions, etc. The buffer controller <b>208</b> typically works in conjunction with the master controller <b>224</b> to coordinate data flow. As data arrives, the data will arrive on the system bus <b>240</b>, be transferred to the local bus <b>206</b> through a bridge <b>238</b>.</div>
</li> <li> <para-num num="[0056]"> </para-num> <div class="description-line" id="p-0057" num="0056">Typically, the data is transferred from the local bus <b>206</b> to one or more data buffers <b>222</b> as directed by the master controller <b>224</b> and the buffer controller <b>208</b>. The data then flows out of the buffer(s) <b>222</b> to the data bus <b>204</b>, through a non-volatile controller <b>104</b>, and on to the non-volatile storage media <b>110</b> such as NAND flash or other storage media. In one embodiment, data and associated out-of-band metadata (“metadata”) arriving with the data is communicated using one or more data channels comprising one or more storage controllers <b>104</b> <i>a</i>-<b>104</b> <i>n−</i>1 and associated non-volatile storage media <b>110</b> <i>a</i>-<b>110</b> <i>n−</i>1 while at least one channel (storage controller <b>104</b> <i>n, </i>non-volatile storage media <b>110</b> <i>n</i>) is dedicated to in-band metadata, such as index information and other metadata generated internally to the non-volatile storage device <b>102</b>.</div>
</li> <li> <para-num num="[0057]"> </para-num> <div class="description-line" id="p-0058" num="0057">The local bus <b>206</b> is typically a bidirectional bus or set of busses that allows for communication of data and commands between devices internal to the non-volatile storage device controller <b>202</b> and between devices internal to the non-volatile storage device <b>102</b> and devices <b>244</b>-<b>258</b> connected to the system bus <b>240</b>. The bridge <b>238</b> facilitates communication between the local bus <b>206</b> and system bus <b>240</b>. One of skill in the art will recognize other embodiments such as ring structures or switched star configurations and functions of buses <b>240</b>, <b>206</b>, <b>204</b>, <b>210</b> and bridges <b>238</b>.</div>
</li> <li> <para-num num="[0058]"> </para-num> <div class="description-line" id="p-0059" num="0058">The system bus <b>240</b> is typically a bus of a host computing system <b>114</b> or other device in which the non-volatile storage device <b>102</b> is installed or connected. In one embodiment, the system bus <b>240</b> may be a PCI-e bus, a Serial Advanced Technology Attachment (“serial ATA”) bus, parallel ATA, or the like. In another embodiment, the system bus <b>240</b> is an external bus such as small computer system interface (“SCSI”), FireWire, Fiber Channel, USB, PCIe-AS, or the like. The non-volatile storage device <b>102</b> may be packaged to fit internally to a device or as an externally connected device.</div>
</li> <li> <para-num num="[0059]"> </para-num> <div class="description-line" id="p-0060" num="0059">The non-volatile storage device controller <b>202</b> includes a master controller <b>224</b> that controls higher-level functions within the non-volatile storage device <b>102</b>. The master controller <b>224</b>, in various embodiments, controls data flow by interpreting object requests and other requests, directs creation of indexes to map object identifiers associated with data to physical locations of associated data, coordinating DMA requests, etc. Many of the functions described herein are controlled wholly or in part by the master controller <b>224</b>.</div>
</li> <li> <para-num num="[0060]"> </para-num> <div class="description-line" id="p-0061" num="0060">In one embodiment, the master controller <b>224</b> uses embedded controller(s). In another embodiment, the master controller <b>224</b> uses local memory such as a dynamic memory array <b>230</b> (dynamic random access memory “DRAM”), a static memory array <b>232</b> (static random access memory “SRAM”), etc. In one embodiment, the local memory is controlled using the master controller <b>224</b>. In another embodiment, the master controller <b>224</b> accesses the local memory via a memory controller <b>228</b>. In another embodiment, the master controller <b>224</b> runs a Linux server and may support various common server interfaces, such as the World Wide Web, hyper-text markup language (“HTML”), etc. In another embodiment, the master controller <b>224</b> uses a nano-processor. The master controller <b>224</b> may be constructed using programmable or standard logic, or any combination of controller types listed above. One skilled in the art will recognize many embodiments for the master controller <b>224</b>.</div>
</li> <li> <para-num num="[0061]"> </para-num> <div class="description-line" id="p-0062" num="0061">In one embodiment, where the storage device/non-volatile storage device controller <b>202</b> manages multiple data storage devices/non-volatile storage media <b>110</b> <i>a</i>-<i>n, </i>the master controller <b>224</b> divides the work load among internal controllers, such as the storage controllers <b>104</b> <i>a</i>-<i>n. </i>For example, the master controller <b>224</b> may divide an object to be written to the data storage devices (e.g., non-volatile storage media <b>110</b> <i>a</i>-<i>n</i>) so that a portion of the object is stored on each of the attached data storage devices. This feature is a performance enhancement allowing quicker storage and access to an object. In one embodiment, the master controller <b>224</b> is implemented using an FPGA. In another embodiment, the firmware within the master controller <b>224</b> may be updated through the management bus <b>236</b>, the system bus <b>240</b> over a network connected to a NIC <b>244</b> or other device connected to the system bus <b>240</b>.</div>
</li> <li> <para-num num="[0062]"> </para-num> <div class="description-line" id="p-0063" num="0062">In one embodiment, the master controller <b>224</b>, which manages objects, emulates block storage such that a host computing system <b>114</b> or other device connected to the storage device/non-volatile storage device <b>102</b> views the storage device/non-volatile storage device <b>102</b> as a block storage device and sends data to specific physical addresses in the storage device/non-volatile storage device <b>102</b>. The master controller <b>224</b> then divides up the blocks and stores the data blocks as it would objects. The master controller <b>224</b> then maps the blocks and physical address sent with the block to the actual locations determined by the master controller <b>224</b>. The mapping is stored in the object index. Typically, for block emulation, a block device application program interface (“API”) is provided in a driver in a computer such as the host computing system <b>114</b>, or other device wishing to use the storage device/non-volatile storage device <b>102</b> as a block storage device.</div>
</li> <li> <para-num num="[0063]"> </para-num> <div class="description-line" id="p-0064" num="0063">In another embodiment, the master controller <b>224</b> coordinates with NIC controllers <b>244</b> and embedded RDMA controllers <b>246</b> to deliver just-in-time RDMA transfers of data and command sets. NIC controller <b>244</b> may be hidden behind a non-transparent port to enable the use of custom drivers. Also, a driver on a host computing system <b>114</b> may have access to the computer network <b>116</b> through an I/O memory driver using a standard stack API and operating in conjunction with NICs <b>244</b>.</div>
</li> <li> <para-num num="[0064]"> </para-num> <div class="description-line" id="p-0065" num="0064">In one embodiment, the master controller <b>224</b> is also a redundant array of independent drive (“RAID”) controller. Where the data storage device/non-volatile storage device <b>102</b> is networked with one or more other data storage devices/non-volatile storage devices <b>102</b>, the master controller <b>224</b> may be a RAID controller for single tier RAID, multi-tier RAID, progressive RAID, etc. The master controller <b>224</b> also allows some objects to be stored in a RAID array and other objects to be stored without RAID. In another embodiment, the master controller <b>224</b> may be a distributed RAID controller element. In another embodiment, the master controller <b>224</b> may comprise many RAID, distributed RAID, and other functions as described elsewhere. In one embodiment, the master controller <b>224</b> controls storage of data in a RAID-like structure where parity information is stored in one or more storage elements <b>216</b>, <b>218</b>, <b>220</b> of a logical page where the parity information protects data stored in the other storage elements <b>216</b>, <b>218</b>, <b>220</b> of the same logical page.</div>
</li> <li> <para-num num="[0065]"> </para-num> <div class="description-line" id="p-0066" num="0065">In one embodiment, the master controller <b>224</b> coordinates with single or redundant network managers (e.g., switches) to establish routing, to balance bandwidth utilization, failover, etc. In another embodiment, the master controller <b>224</b> coordinates with integrated application specific logic (via local bus <b>206</b>) and associated driver software. In another embodiment, the master controller <b>224</b> coordinates with attached application specific processors <b>258</b> or logic (via the external system bus <b>240</b>) and associated driver software. In another embodiment, the master controller <b>224</b> coordinates with remote application specific logic (via the computer network <b>116</b>) and associated driver software. In another embodiment, the master controller <b>224</b> coordinates with the local bus <b>206</b> or external bus attached hard disk drive (“HDD”) storage controller.</div>
</li> <li> <para-num num="[0066]"> </para-num> <div class="description-line" id="p-0067" num="0066">In one embodiment, the master controller <b>224</b> communicates with one or more storage controllers <b>254</b> where the storage device/non-volatile storage device <b>102</b> may appear as a storage device connected through a SCSI bus, Internet SCSI (“iSCSI”), fiber channel, etc. Meanwhile the storage device/non-volatile storage device <b>102</b> may autonomously manage objects and may appear as an object file system or distributed object file system. The master controller <b>224</b> may also be accessed by peer controllers <b>256</b> and/or application specific processors <b>258</b>.</div>
</li> <li> <para-num num="[0067]"> </para-num> <div class="description-line" id="p-0068" num="0067">In another embodiment, the master controller <b>224</b> coordinates with an autonomous integrated management controller to periodically validate FPGA code and/or controller software, validate FPGA code while running (reset) and/or validate controller software during power on (reset), support external reset requests, support reset requests due to watchdog timeouts, and support voltage, current, power, temperature, and other environmental measurements and setting of threshold interrupts. In another embodiment, the master controller <b>224</b> manages garbage collection to free erase blocks for reuse. In another embodiment, the master controller <b>224</b> manages wear leveling. In another embodiment, the master controller <b>224</b> allows the data storage device/non-volatile storage device <b>102</b> to be partitioned into multiple logical devices and allows partition-based media encryption. In yet another embodiment, the master controller <b>224</b> supports a storage controller <b>104</b> with advanced, multi-bit ECC correction. One of skill in the art will recognize other features and functions of a master controller <b>224</b> in a storage controller <b>202</b>, or more specifically in a non-volatile storage device <b>102</b>.</div>
</li> <li> <para-num num="[0068]"> </para-num> <div class="description-line" id="p-0069" num="0068">In one embodiment, the non-volatile storage device controller <b>202</b> includes a memory controller <b>228</b>, which controls a dynamic random memory array <b>230</b> and/or a static random memory array <b>232</b>. As stated above, the memory controller <b>228</b> may be independent or integrated with the master controller <b>224</b>. The memory controller <b>228</b> typically controls volatile memory of some type, such as DRAM (dynamic random memory array <b>230</b>) and SRAM (static random memory array <b>232</b>). In other examples, the memory controller <b>228</b> also controls other memory types such as electrically erasable programmable read only memory (“EEPROM”), etc. In other embodiments, the memory controller <b>228</b> controls two or more memory types and the memory controller <b>228</b> may include more than one controller. Typically, the memory controller <b>228</b> controls as much SRAM <b>232</b> as is feasible and by DRAM <b>230</b> to supplement the SRAM <b>232</b>.</div>
</li> <li> <para-num num="[0069]"> </para-num> <div class="description-line" id="p-0070" num="0069">In one embodiment, the object index is stored in memory <b>230</b>, <b>232</b> and then periodically off-loaded to a channel of the non-volatile storage media <b>110</b> <i>n </i>or other non-volatile memory. One of skill in the art will recognize other uses and configurations of the memory controller <b>228</b>, dynamic memory array <b>230</b>, and static memory array <b>232</b>.</div>
</li> <li> <para-num num="[0070]"> </para-num> <div class="description-line" id="p-0071" num="0070">In one embodiment, the non-volatile storage device controller <b>202</b> includes a DMA controller <b>226</b> that controls DMA operations between the storage device/non-volatile storage device <b>102</b> and one or more external memory controllers <b>250</b> and associated external memory arrays <b>252</b> and CPUs <b>248</b>. Note that the external memory controllers <b>250</b> and external memory arrays <b>252</b> are called external because they are external to the storage device/non-volatile storage device <b>102</b>. In addition, the DMA controller <b>226</b> may also control RDMA operations with requesting devices through a NIC <b>244</b> and associated RDMA controller <b>246</b>.</div>
</li> <li> <para-num num="[0071]"> </para-num> <div class="description-line" id="p-0072" num="0071">In one embodiment, the non-volatile storage device controller <b>202</b> includes a management controller <b>234</b> connected to a management bus <b>236</b>. Typically, the management controller <b>234</b> manages environmental metrics and status of the storage device/non-volatile storage device <b>102</b>. The management controller <b>234</b> may monitor device temperature, fan speed, power supply settings, etc. over the management bus <b>236</b>. The management controller <b>234</b> may support the reading and programming of erasable programmable read only memory (“EEPROM”) for storage of FPGA code and controller software. Typically, the management bus <b>236</b> is connected to the various components within the storage device/non-volatile storage device <b>102</b>. The management controller <b>234</b> may communicate alerts, interrupts, etc. over the local bus <b>206</b> or may include a separate connection to a system bus <b>240</b> or other bus. In one embodiment, the management bus <b>236</b> is an Inter-Integrated Circuit (“I2C”) bus. One of skill in the art will recognize other related functions and uses of a management controller <b>234</b> connected to components of the storage device/non-volatile storage device <b>102</b> by a management bus <b>236</b>.</div>
</li> <li> <para-num num="[0072]"> </para-num> <div class="description-line" id="p-0073" num="0072">In one embodiment, the non-volatile storage device controller <b>202</b> includes miscellaneous logic <b>242</b> that may be customized for a specific application. Typically, where the non-volatile device controller <b>202</b> or master controller <b>224</b> is/are configured using a FPGA or other configurable controller, custom logic may be included based on a particular application, customer requirement, storage requirement, etc.</div>
</li> <li> <para-num num="[0073]"> </para-num> <div class="description-line" id="p-0074" num="0073"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a schematic block diagram illustrating one embodiment <b>300</b> of a storage controller <b>104</b> with a write data pipeline <b>106</b>, a read data pipeline <b>108</b> and a throughput management apparatus <b>122</b> in a non-volatile storage device <b>102</b> in accordance with the present invention. The embodiment <b>300</b> includes a data bus <b>204</b>, a local bus <b>206</b>, and buffer control <b>208</b>, which are substantially similar to those described in relation to the non-volatile storage device controller <b>202</b> of <figref idrefs="DRAWINGS">FIG. 2</figref>. The write data pipeline <b>106</b> includes a packetizer <b>302</b> and an error-correcting code (“ECC”) generator <b>304</b>. In other embodiments, the write data pipeline <b>106</b> includes an input buffer <b>306</b>, a write synchronization buffer <b>308</b>, a write program module <b>310</b>, a compression module <b>312</b>, an encryption module <b>314</b>, a garbage collector bypass <b>316</b> (with a portion within the read data pipeline <b>108</b>), a media encryption module <b>318</b>, and a write buffer <b>320</b>. The read data pipeline <b>108</b> includes a read synchronization buffer <b>328</b>, an ECC correction module <b>322</b>, a depacketizer <b>324</b>, an alignment module <b>326</b>, and an output buffer <b>330</b>. In other embodiments, the read data pipeline <b>108</b> may include a media decryption module <b>332</b>, a portion of the garbage collector bypass <b>316</b>, a decryption module <b>334</b>, a decompression module <b>336</b>, and a read program module <b>338</b>. The storage controller <b>104</b> may also include control and status registers <b>340</b> and control queues <b>342</b>, a bank interleave controller <b>344</b>, a synchronization buffer <b>346</b>, a storage bus controller <b>348</b>, and a multiplexer (“MUX”) <b>350</b>. The components of the non-volatile controller <b>104</b> and associated write data pipeline <b>106</b> and read data pipeline <b>108</b> are described below. In other embodiments, synchronous non-volatile storage media <b>110</b> may be used and synchronization buffers <b>308</b> <b>328</b> may be eliminated.</div>
</li> <li> <para-num num="[0074]"> </para-num> <div class="description-line" id="p-0075" num="0074">The write data pipeline <b>106</b> includes a packetizer <b>302</b> that receives a data or metadata segment to be written to the non-volatile storage, either directly or indirectly through another write data pipeline <b>106</b> stage, and creates one or more packets sized for the non-volatile storage media <b>110</b>. The data or metadata segment is typically part of a data structure such as an object, but may also include an entire data structure. In another embodiment, the data segment is part of a block of data, but may also include an entire block of data. Typically, a set of data such as a data structure is received from a computer such as the host computing system <b>114</b>, or other computer or device and is transmitted to the non-volatile storage device <b>102</b> in data segments streamed to the non-volatile storage device <b>102</b>. A data segment may also be known by another name, such as data parcel, but as referenced herein includes all or a portion of a data structure or data block.</div>
</li> <li> <para-num num="[0075]"> </para-num> <div class="description-line" id="p-0076" num="0075">Each data structure is stored as one or more packets. Each data structure may have one or more container packets. Each packet contains a header. The header may include a header type field. Type fields may include data, attribute, metadata, data segment delimiters (multi-packet), data structures, data linkages, and the like. The header may also include information regarding the size of the packet, such as the number of bytes of data included in the packet. The length of the packet may be established by the packet type. The header may include information that establishes the relationship of the packet to a data structure. An example might be the use of an offset in a data packet header to identify the location of the data segment within the data structure. One of skill in the art will recognize other information that may be included in a header added to data by a packetizer <b>302</b> and other information that may be added to a data packet.</div>
</li> <li> <para-num num="[0076]"> </para-num> <div class="description-line" id="p-0077" num="0076">Each packet includes a header and possibly data from the data or metadata segment. The header of each packet includes pertinent information to relate the packet to the data structure to which the packet belongs. For example, the header may include an object identifier or other data structure identifier and offset that indicate the data segment, object, data structure or data block from which the data packet was formed. The header may also include a logical address used by the storage bus controller <b>348</b> to store the packet. The header may also include information regarding the size of the packet, such as the number of bytes included in the packet. The header may also include a sequence number that identifies where the data segment belongs with respect to other packets within the data structure when reconstructing the data segment or data structure. The header may include a header type field. Type fields may include data, data structure attributes, metadata, data segment delimiters (multi-packet), data structure types, data structure linkages, and the like. One of skill in the art will recognize other information that may be included in a header added to data or metadata by a packetizer <b>302</b> and other information that may be added to a packet.</div>
</li> <li> <para-num num="[0077]"> </para-num> <div class="description-line" id="p-0078" num="0077">The write data pipeline <b>106</b> includes an ECC generator <b>304</b> that that generates one or more error-correcting codes (“ECC”) for the one or more packets received from the packetizer <b>302</b>. The ECC generator <b>304</b> typically uses an error-correcting algorithm to generate ECC check bits, which are stored with the one or more data packets. The ECC codes generated by the ECC generator <b>304</b> together with the one or more data packets associated with the ECC codes comprise an ECC chunk. The ECC data stored with the one or more data packets is used to detect and to correct errors introduced into the data through transmission and storage. In one embodiment, packets are streamed into the ECC generator <b>304</b> as un-encoded blocks of length N. A syndrome of length S is calculated, appended, and output as an encoded block of length N+S. The value of N and S are dependent upon the characteristics of the ECC algorithm, which is selected to achieve specific performance, efficiency, and robustness metrics. In one embodiment, there is no fixed relationship between the ECC blocks and the packets; the packet may comprise more than one ECC block; the ECC block may comprise more than one packet; and a first packet may end anywhere within the ECC block and a second packet may begin after the end of the first packet within the same ECC block. In one embodiment, ECC algorithms are not dynamically modified. In one embodiment, the ECC data stored with the data packets is robust enough to correct errors in more than two bits.</div>
</li> <li> <para-num num="[0078]"> </para-num> <div class="description-line" id="p-0079" num="0078">Beneficially, using a robust ECC algorithm allowing more than single bit correction or even double bit correction allows the life of the non-volatile storage media <b>110</b> to be extended. For example, if flash memory is used as the storage medium in the non-volatile storage media <b>110</b>, the flash memory may be written approximately 100,000 times without error per erase cycle. This usage limit may be extended using a robust ECC algorithm. Having the ECC generator <b>304</b> and corresponding ECC correction module <b>322</b> onboard the non-volatile storage device <b>102</b>, the non-volatile storage device <b>102</b> can internally correct errors and has a longer useful life than if a less robust ECC algorithm is used, such as single bit correction. However, in other embodiments the ECC generator <b>304</b> may use a less robust algorithm and may correct single-bit or double-bit errors. In another embodiment, the non-volatile storage device <b>110</b> may comprise less reliable storage such as multi-level cell (“MLC”) flash in order to increase capacity, which storage may not be sufficiently reliable without more robust ECC algorithms.</div>
</li> <li> <para-num num="[0079]"> </para-num> <div class="description-line" id="p-0080" num="0079">In one embodiment, the write pipeline <b>106</b> includes an input buffer <b>306</b> that receives a data segment to be written to the non-volatile storage media <b>110</b> and stores the incoming data segments until the next stage of the write data pipeline <b>106</b>, such as the packetizer <b>302</b> (or other stage for a more complex write data pipeline <b>106</b>) is ready to process the next data segment. The input buffer <b>306</b> typically allows for discrepancies between the rate data segments are received and processed by the write data pipeline <b>106</b> using an appropriately sized data buffer. The input buffer <b>306</b> also allows the data bus <b>204</b> to transfer data to the write data pipeline <b>106</b> at rates greater than can be sustained by the write data pipeline <b>106</b> in order to improve efficiency of operation of the data bus <b>204</b>. Typically, when the write data pipeline <b>106</b> does not include an input buffer <b>306</b>, a buffering function is performed elsewhere, such as in the non-volatile storage device <b>102</b> but outside the write data pipeline <b>106</b>, in the host computing system <b>114</b>, such as within a network interface card (“NIC”), or at another device, for example when using remote direct memory access (“RDMA”).</div>
</li> <li> <para-num num="[0080]"> </para-num> <div class="description-line" id="p-0081" num="0080">In another embodiment, the write data pipeline <b>106</b> also includes a write synchronization buffer <b>308</b> that buffers packets received from the ECC generator <b>304</b> prior to writing the packets to the non-volatile storage media <b>110</b>. The write synchronization buffer <b>308</b> is located at a boundary between a local clock domain and a non-volatile storage clock domain and provides buffering to account for the clock domain differences. In other embodiments, synchronous non-volatile storage media <b>110</b> may be used and synchronization buffers <b>308</b> <b>328</b> may be eliminated.</div>
</li> <li> <para-num num="[0081]"> </para-num> <div class="description-line" id="p-0082" num="0081">In one embodiment, the write data pipeline <b>106</b> also includes a media encryption module <b>318</b> that receives the one or more packets from the packetizer <b>302</b>, either directly or indirectly, and encrypts the one or more packets using an encryption key unique to the non-volatile storage device <b>102</b> prior to sending the packets to the ECC generator <b>304</b>. Typically, the entire packet is encrypted, including the headers. In another embodiment, headers are not encrypted. In this document, encryption key is understood to mean a secret encryption key that is managed externally from a storage controller <b>104</b>.</div>
</li> <li> <para-num num="[0082]"> </para-num> <div class="description-line" id="p-0083" num="0082">The media encryption module <b>318</b> and corresponding media decryption module <b>332</b> provide a level of security for data stored in the non-volatile storage media <b>110</b>. For example, where data is encrypted with the media encryption module <b>318</b>, if the non-volatile storage media <b>110</b> is connected to a different storage controller <b>104</b>, non-volatile storage device <b>102</b>, or server, the contents of the non-volatile storage media <b>110</b> typically could not be read without use of the same encryption key used during the write of the data to the non-volatile storage media <b>110</b> without significant effort.</div>
</li> <li> <para-num num="[0083]"> </para-num> <div class="description-line" id="p-0084" num="0083">In a typical embodiment, the non-volatile storage device <b>102</b> does not store the encryption key in non-volatile storage and allows no external access to the encryption key. The encryption key is provided to the storage controller <b>104</b> during initialization. The non-volatile storage device <b>102</b> may use and store a non-secret cryptographic nonce that is used in conjunction with an encryption key. A different nonce may be stored with every packet. Data segments may be split between multiple packets with unique nonces for the purpose of improving protection by the encryption algorithm.</div>
</li> <li> <para-num num="[0084]"> </para-num> <div class="description-line" id="p-0085" num="0084">The encryption key may be received from a host computing system <b>114</b>, a server, key manager, or other device that manages the encryption key to be used by the storage controller <b>104</b>. In another embodiment, the non-volatile storage media <b>110</b> may have two or more partitions and the storage controller <b>104</b> behaves as though it was two or more storage controllers <b>104</b>, each operating on a single partition within the non-volatile storage media <b>110</b>. In this embodiment, a unique media encryption key may be used with each partition.</div>
</li> <li> <para-num num="[0085]"> </para-num> <div class="description-line" id="p-0086" num="0085">In another embodiment, the write data pipeline <b>106</b> also includes an encryption module <b>314</b> that encrypts a data or metadata segment received from the input buffer <b>306</b>, either directly or indirectly, prior sending the data segment to the packetizer <b>302</b>, the data segment encrypted using an encryption key received in conjunction with the data segment. The encryption keys used by the encryption module <b>314</b> to encrypt data may not be common to all data stored within the non-volatile storage device <b>102</b> but may vary on an per data structure basis and received in conjunction with receiving data segments as described below. For example, an encryption key for a data segment to be encrypted by the encryption module <b>314</b> may be received with the data segment or may be received as part of a command to write a data structure to which the data segment belongs. The solid-sate storage device <b>102</b> may use and store a non-secret cryptographic nonce in each data structure packet that is used in conjunction with the encryption key. A different nonce may be stored with every packet. Data segments may be split between multiple packets with unique nonces for the purpose of improving protection by the encryption algorithm.</div>
</li> <li> <para-num num="[0086]"> </para-num> <div class="description-line" id="p-0087" num="0086">The encryption key may be received from a host computing system <b>114</b>, another computer, key manager, or other device that holds the encryption key to be used to encrypt the data segment. In one embodiment, encryption keys are transferred to the storage controller <b>104</b> from one of a non-volatile storage device <b>102</b>, host computing system <b>114</b>, computer, or other external agent, which has the ability to execute industry standard methods to securely transfer and protect private and public keys.</div>
</li> <li> <para-num num="[0087]"> </para-num> <div class="description-line" id="p-0088" num="0087">In one embodiment, the encryption module <b>314</b> encrypts a first packet with a first encryption key received in conjunction with the packet and encrypts a second packet with a second encryption key received in conjunction with the second packet. In another embodiment, the encryption module <b>314</b> encrypts a first packet with a first encryption key received in conjunction with the packet and passes a second data packet on to the next stage without encryption. Beneficially, the encryption module <b>314</b> included in the write data pipeline <b>106</b> of the non-volatile storage device <b>102</b> allows data structure-by-data structure or segment-by-segment data encryption without a single file system or other external system to keep track of the different encryption keys used to store corresponding data structures or data segments. Each requesting device <b>155</b> or related key manager independently manages encryption keys used to encrypt only the data structures or data segments sent by the requesting device <b>155</b>.</div>
</li> <li> <para-num num="[0088]"> </para-num> <div class="description-line" id="p-0089" num="0088">In one embodiment, the encryption module <b>314</b> may encrypt the one or more packets using an encryption key unique to the non-volatile storage device <b>102</b>. The encryption module <b>314</b> may perform this media encryption independently, or in addition to the encryption described above. Typically, the entire packet is encrypted, including the headers. In another embodiment, headers are not encrypted. The media encryption by the encryption module <b>314</b> provides a level of security for data stored in the non-volatile storage media <b>110</b>. For example, where data is encrypted with media encryption unique to the specific non-volatile storage device <b>102</b>, if the non-volatile storage media <b>110</b> is connected to a different storage controller <b>104</b>, non-volatile storage device <b>102</b>, or host computing system <b>114</b>, the contents of the non-volatile storage media <b>110</b> typically could not be read without use of the same encryption key used during the write of the data to the non-volatile storage media <b>110</b> without significant effort.</div>
</li> <li> <para-num num="[0089]"> </para-num> <div class="description-line" id="p-0090" num="0089">In another embodiment, the write data pipeline <b>106</b> includes a compression module <b>312</b> that compresses the data for metadata segment prior to sending the data segment to the packetizer <b>302</b>. The compression module <b>312</b> typically compresses a data or metadata segment using a compression routine known to those of skill in the art to reduce the storage size of the segment. For example, if a data segment includes a string of <b>512</b> zeros, the compression module <b>312</b> may replace the <b>512</b> zeros with code or token indicating the <b>512</b> zeros where the code is much more compact than the space taken by the <b>512</b> zeros.</div>
</li> <li> <para-num num="[0090]"> </para-num> <div class="description-line" id="p-0091" num="0090">In one embodiment, the compression module <b>312</b> compresses a first segment with a first compression routine and passes along a second segment without compression. In another embodiment, the compression module <b>312</b> compresses a first segment with a first compression routine and compresses the second segment with a second compression routine. Having this flexibility within the non-volatile storage device <b>102</b> is beneficial so that computing systems <b>114</b> or other devices writing data to the non-volatile storage device <b>102</b> may each specify a compression routine or so that one can specify a compression routine while another specifies no compression. Selection of compression routines may also be selected according to default settings on a per data structure type or data structure class basis. For example, a first data structure of a specific data structure may be able to override default compression routine settings and a second data structure of the same data structure class and data structure type may use the default compression routine and a third data structure of the same data structure class and data structure type may use no compression.</div>
</li> <li> <para-num num="[0091]"> </para-num> <div class="description-line" id="p-0092" num="0091">In one embodiment, the write data pipeline <b>106</b> includes a garbage collector bypass <b>316</b> that receives data segments from the read data pipeline <b>108</b> as part of a data bypass in a garbage collection system. A garbage collection system (also referred to as a “groomer” or grooming operation) typically marks packets that are no longer valid, typically because the packet is marked for deletion or has been modified and the modified data is stored in a different location. At some point, the garbage collection system determines that a particular section (e.g., an erase block) of storage may be recovered. This determination may be due to a lack of available storage capacity, the percentage of data marked as invalid reaching a threshold, a consolidation of valid data, an error detection rate for that section of storage reaching a threshold, or improving performance based on data distribution, etc. Numerous factors may be considered by a garbage collection algorithm to determine when a section of storage is to be recovered.</div>
</li> <li> <para-num num="[0092]"> </para-num> <div class="description-line" id="p-0093" num="0092">Once a section of storage has been marked for recovery, valid packets in the section typically must be relocated. The garbage collector bypass <b>316</b> allows packets to be read into the read data pipeline <b>108</b> and then transferred directly to the write data pipeline <b>106</b> without being routed out of the storage controller <b>104</b>. In one embodiment, the garbage collector bypass <b>316</b> is part of an autonomous garbage collector system that operates within the non-volatile storage device <b>102</b>. This allows the non-volatile storage device <b>102</b> to manage data so that data is systematically spread throughout the non-volatile storage media <b>110</b> to improve performance, data reliability and to avoid overuse and underuse of any one location or area of the non-volatile storage media <b>110</b> and to lengthen the useful life of the non-volatile storage media <b>110</b>.</div>
</li> <li> <para-num num="[0093]"> </para-num> <div class="description-line" id="p-0094" num="0093">The garbage collector bypass <b>316</b> coordinates insertion of segments into the write data pipeline <b>106</b> with other segments being written by computing systems <b>114</b> or other devices. In the depicted embodiment, the garbage collector bypass <b>316</b> is before the packetizer <b>302</b> in the write data pipeline <b>106</b> and after the depacketizer <b>324</b> in the read data pipeline <b>108</b>, but may also be located elsewhere in the read and write data pipelines <b>106</b>, <b>108</b>. The garbage collector bypass <b>316</b> may be used during a flush of the write pipeline <b>108</b> to fill the remainder of the logical page in order to improve the efficiency of storage within the non-volatile storage media <b>110</b> and thereby reduce the frequency of garbage collection.</div>
</li> <li> <para-num num="[0094]"> </para-num> <div class="description-line" id="p-0095" num="0094">Grooming may comprise refreshing data stored on the non-volatile storage media <b>110</b>. Data stored on the non-volatile storage media <b>110</b> may degrade over time. The storage controller <b>104</b> may comprise a groomer that identifies “stale” data on the non-volatile storage device <b>102</b> (data that has not been modified and/or moved for a pre-determined time), and refreshes the stale data by re-writing the data to a different storage unit.</div>
</li> <li> <para-num num="[0095]"> </para-num> <div class="description-line" id="p-0096" num="0095">In some embodiments, the garbage collection system, groomer, and/or garbage collection bypass <b>316</b> may be temporarily disabled to allow data to be stored contiguously on physical storage units of the non-volatile storage device <b>102</b>. Disabling the garbage collection system and/or bypass <b>316</b> may ensure that data in the write data pipeline <b>106</b> is not interleaved with other data.</div>
</li> <li> <para-num num="[0096]"> </para-num> <div class="description-line" id="p-0097" num="0096">In some embodiments, the garbage collection and/or groomer may be restricted to a certain portion of the physical storage space of the non-volatile storage device. For example, metadata, such as the reverse index described below, may be periodically persisted to non-volatile storage. The garbage collection and/or grooming may be restricted to operating on portions of the non-volatile storage media that correspond to the persisted metadata.</div>
</li> <li> <para-num num="[0097]"> </para-num> <div class="description-line" id="p-0098" num="0097">In one embodiment, the write data pipeline <b>106</b> includes a write buffer <b>320</b> that buffers data for efficient write operations. Typically, the write buffer <b>320</b> includes enough capacity for packets to fill at least one logical page in the non-volatile storage media <b>110</b>. This allows a write operation to send an entire logical page of data to the non-volatile storage media <b>110</b> without interruption. By sizing the write buffer <b>320</b> of the write data pipeline <b>106</b> and buffers within the read data pipeline <b>108</b> to be the same capacity or larger than a storage write buffer within the non-volatile storage media <b>110</b>, writing and reading data is more efficient since a single write command may be crafted to send a full logical page of data to the non-volatile storage media <b>110</b> instead of multiple commands.</div>
</li> <li> <para-num num="[0098]"> </para-num> <div class="description-line" id="p-0099" num="0098">While the write buffer <b>320</b> is being filled, the non-volatile storage media <b>110</b> may be used for other read operations. This is advantageous because other non-volatile devices with a smaller write buffer or no write buffer may tie up the non-volatile storage when data is written to a storage write buffer and data flowing into the storage write buffer stalls. Read operations will be blocked until the entire storage write buffer is filled and programmed. Another approach for systems without a write buffer or a small write buffer is to flush the storage write buffer that is not full in order to enable reads. Again, this is inefficient because multiple write/program cycles are required to fill a page.</div>
</li> <li> <para-num num="[0099]"> </para-num> <div class="description-line" id="p-0100" num="0099">For depicted embodiment with a write buffer <b>320</b> sized larger than a logical page, a single write command, which includes numerous subcommands, can then be followed by a single program command to transfer the page of data from the storage write buffer in each non-volatile storage element <b>216</b>, <b>218</b>, <b>220</b> to the designated page within each non-volatile storage element <b>216</b>, <b>218</b>, <b>220</b>. This technique has the benefits of eliminating partial page programming, which is known to reduce data reliability and durability and freeing up the destination bank for reads and other commands while the buffer fills.</div>
</li> <li> <para-num num="[0100]"> </para-num> <div class="description-line" id="p-0101" num="0100">In one embodiment, the write buffer <b>320</b> is a ping-pong buffer where one side of the buffer is filled and then designated for transfer at an appropriate time while the other side of the ping-pong buffer is being filled. In another embodiment, the write buffer <b>320</b> includes a first-in first-out (“FIFO”) register with a capacity of more than a logical page of data segments. One of skill in the art will recognize other write buffer <b>320</b> configurations that allow a logical page of data to be stored prior to writing the data to the non-volatile storage media <b>110</b>.</div>
</li> <li> <para-num num="[0101]"> </para-num> <div class="description-line" id="p-0102" num="0101">In another embodiment, the write buffer <b>320</b> is sized smaller than a logical page so that less than a page of information could be written to a storage write buffer in the non-volatile storage media <b>110</b>. In the embodiment, to prevent a stall in the write data pipeline <b>106</b> from holding up read operations, data is queued using the garbage collection system that needs to be moved from one location to another as part of the garbage collection process. In case of a data stall in the write data pipeline <b>106</b>, the data can be fed through the garbage collector bypass <b>316</b> to the write buffer <b>320</b> and then on to the storage write buffer in the non-volatile storage media <b>110</b> to fill the pages of a logical page prior to programming the data. In this way, a data stall in the write data pipeline <b>106</b> would not stall reading from the non-volatile storage device <b>102</b>.</div>
</li> <li> <para-num num="[0102]"> </para-num> <div class="description-line" id="p-0103" num="0102">In another embodiment, the write data pipeline <b>106</b> includes a write program module <b>310</b> with one or more user-definable functions within the write data pipeline <b>106</b>. The write program module <b>310</b> allows a user to customize the write data pipeline <b>106</b>. A user may customize the write data pipeline <b>106</b> based on a particular data requirement or application. Where the storage controller <b>104</b> is an FPGA, the user may program the write data pipeline <b>106</b> with custom commands and functions relatively easily. A user may also use the write program module <b>310</b> to include custom functions with an ASIC, however, customizing an ASIC may be more difficult than with an FPGA. The write program module <b>310</b> may include buffers and bypass mechanisms to allow a first data segment to execute in the write program module <b>310</b> while a second data segment may continue through the write data pipeline <b>106</b>. In another embodiment, the write program module <b>310</b> may include a processor core that can be programmed through software.</div>
</li> <li> <para-num num="[0103]"> </para-num> <div class="description-line" id="p-0104" num="0103">Note that the write program module <b>310</b> is shown between the input buffer <b>306</b> and the compression module <b>312</b>, however, the write program module <b>310</b> could be anywhere in the write data pipeline <b>106</b> and may be distributed among the various stages <b>302</b>-<b>320</b>. In addition, there may be multiple write program modules <b>310</b> distributed among the various states <b>302</b>-<b>320</b> that are programmed and operate independently. In addition, the order of the stages <b>302</b>-<b>320</b> may be altered. One of skill in the art will recognize workable alterations to the order of the stages <b>302</b>-<b>320</b> based on particular user requirements.</div>
</li> <li> <para-num num="[0104]"> </para-num> <div class="description-line" id="p-0105" num="0104">The read data pipeline <b>108</b> includes an ECC correction module <b>322</b> that determines if a data error exists in ECC blocks a requested packet received from the non-volatile storage media <b>110</b> by using ECC stored with each ECC block of the requested packet. The ECC correction module <b>322</b> then corrects any errors in the requested packet if any error exists and the errors are correctable using the ECC. For example, if the ECC can detect an error in six bits but can only correct three bit errors, the ECC correction module <b>322</b> corrects ECC blocks of the requested packet with up to three bits in error. The ECC correction module <b>322</b> corrects the bits in error by changing the bits in error to the correct one or zero state so that the requested data packet is identical to when it was written to the non-volatile storage media <b>110</b> and the ECC was generated for the packet.</div>
</li> <li> <para-num num="[0105]"> </para-num> <div class="description-line" id="p-0106" num="0105">If the ECC correction module <b>322</b> determines that the requested packets contains more bits in error than the ECC can correct, the ECC correction module <b>322</b> cannot correct the errors in the corrupted ECC blocks of the requested packet and sends an interrupt. In one embodiment, the ECC correction module <b>322</b> sends an interrupt with a message indicating that the requested packet is in error. The message may include information that the ECC correction module <b>322</b> cannot correct the errors or the inability of the ECC correction module <b>322</b> to correct the errors may be implied. In another embodiment, the ECC correction module <b>322</b> sends the corrupted ECC blocks of the requested packet with the interrupt and/or the message.</div>
</li> <li> <para-num num="[0106]"> </para-num> <div class="description-line" id="p-0107" num="0106">In one embodiment, a corrupted ECC block or portion of a corrupted ECC block of the requested packet that cannot be corrected by the ECC correction module <b>322</b> is read by the master controller <b>224</b>, corrected, and returned to the ECC correction module <b>322</b> for further processing by the read data pipeline <b>108</b>. In one embodiment, a corrupted ECC block or portion of a corrupted ECC block of the requested packet is sent to the device requesting the data. The requesting device <b>155</b> may correct the ECC block or replace the data using another copy, such as a backup or mirror copy, and then may use the replacement data of the requested data packet or return it to the read data pipeline <b>108</b>. The requesting device <b>155</b> may use header information in the requested packet in error to identify data required to replace the corrupted requested packet or to replace the data structure to which the packet belongs. In another embodiment, the storage controller <b>104</b> stores data using some type of RAID and is able to recover the corrupted data. In another embodiment, the ECC correction module <b>322</b> sends an interrupt and/or message and the receiving device fails the read operation associated with the requested data packet. One of skill in the art will recognize other options and actions to be taken as a result of the ECC correction module <b>322</b> determining that one or more ECC blocks of the requested packet are corrupted and that the ECC correction module <b>322</b> cannot correct the errors.</div>
</li> <li> <para-num num="[0107]"> </para-num> <div class="description-line" id="p-0108" num="0107">The read data pipeline <b>108</b> includes a depacketizer <b>324</b> that receives ECC blocks of the requested packet from the ECC correction module <b>322</b>, directly or indirectly, and checks and removes one or more packet headers. The depacketizer <b>324</b> may validate the packet headers by checking packet identifiers, data length, data location, etc. within the headers. In one embodiment, the header includes a hash code that can be used to validate that the packet delivered to the read data pipeline <b>108</b> is the requested packet. The depacketizer <b>324</b> also removes the headers from the requested packet added by the packetizer <b>302</b>. The depacketizer <b>324</b> may directed to not operate on certain packets but pass these forward without modification. An example might be a container label that is requested during the course of a rebuild process where the header information is required for index reconstruction. Further examples include the transfer of packets of various types destined for use within the non-volatile storage device <b>102</b>. In another embodiment, the depacketizer <b>324</b> operation may be packet type dependent.</div>
</li> <li> <para-num num="[0108]"> </para-num> <div class="description-line" id="p-0109" num="0108">The read data pipeline <b>108</b> includes an alignment module <b>326</b> that receives data from the depacketizer <b>324</b> and removes unwanted data. In one embodiment, a read command sent to the non-volatile storage media <b>110</b> retrieves a packet of data. A device requesting the data may not require all data within the retrieved packet and the alignment module <b>326</b> removes the unwanted data. If all data within a retrieved page is requested data, the alignment module <b>326</b> does not remove any data.</div>
</li> <li> <para-num num="[0109]"> </para-num> <div class="description-line" id="p-0110" num="0109">The alignment module <b>326</b> re-formats the data as data segments of a data structure in a form compatible with a device requesting the data segment prior to forwarding the data segment to the next stage. Typically, as data is processed by the read data pipeline <b>108</b>, the size of data segments or packets changes at various stages. The alignment module <b>326</b> uses received data to format the data into data segments suitable to be sent to the requesting device <b>155</b> and joined to form a response. For example, data from a portion of a first data packet may be combined with data from a portion of a second data packet. If a data segment is larger than a data requested by the requesting device <b>155</b>, the alignment module <b>326</b> may discard the unwanted data.</div>
</li> <li> <para-num num="[0110]"> </para-num> <div class="description-line" id="p-0111" num="0110">In one embodiment, the read data pipeline <b>108</b> includes a read synchronization buffer <b>328</b> that buffers one or more requested packets read from the non-volatile storage media <b>110</b> prior to processing by the read data pipeline <b>108</b>. The read synchronization buffer <b>328</b> is at the boundary between the non-volatile storage clock domain and the local bus clock domain and provides buffering to account for the clock domain differences.</div>
</li> <li> <para-num num="[0111]"> </para-num> <div class="description-line" id="p-0112" num="0111">In another embodiment, the read data pipeline <b>108</b> includes an output buffer <b>330</b> that receives requested packets from the alignment module <b>326</b> and stores the packets prior to transmission to the requesting device <b>155</b>. The output buffer <b>330</b> accounts for differences between when data segments are received from stages of the read data pipeline <b>108</b> and when the data segments are transmitted to other parts of the storage controller <b>104</b> or to the requesting device <b>155</b>. The output buffer <b>330</b> also allows the data bus <b>204</b> to receive data from the read data pipeline <b>108</b> at rates greater than can be sustained by the read data pipeline <b>108</b> in order to improve efficiency of operation of the data bus <b>204</b>.</div>
</li> <li> <para-num num="[0112]"> </para-num> <div class="description-line" id="p-0113" num="0112">In one embodiment, the read data pipeline <b>108</b> includes a media decryption module <b>332</b> that receives one or more encrypted requested packets from the ECC correction module <b>322</b> and decrypts the one or more requested packets using the encryption key unique to the non-volatile storage device <b>102</b> prior to sending the one or more requested packets to the depacketizer <b>324</b>. Typically, the encryption key used to decrypt data by the media decryption module <b>332</b> is identical to the encryption key used by the media encryption module <b>318</b>. In another embodiment, the non-volatile storage media <b>110</b> may have two or more partitions and the storage controller <b>104</b> behaves as though it was two or more storage controllers <b>104</b> each operating on a single partition within the non-volatile storage media <b>110</b>. In this embodiment, a unique media encryption key may be used with each partition.</div>
</li> <li> <para-num num="[0113]"> </para-num> <div class="description-line" id="p-0114" num="0113">In another embodiment, the read data pipeline <b>108</b> includes a decryption module <b>334</b> that decrypts a data segment formatted by the depacketizer <b>324</b> prior to sending the data segment to the output buffer <b>330</b>. The data segment may be decrypted using an encryption key received in conjunction with the read request that initiates retrieval of the requested packet received by the read synchronization buffer <b>328</b>. The decryption module <b>334</b> may decrypt a first packet with an encryption key received in conjunction with the read request for the first packet and then may decrypt a second packet with a different encryption key or may pass the second packet on to the next stage of the read data pipeline <b>108</b> without decryption. When the packet was stored with a non-secret cryptographic nonce, the nonce is used in conjunction with an encryption key to decrypt the data packet. The encryption key may be received from a host computing system <b>114</b>, a client, key manager, or other device that manages the encryption key to be used by the storage controller <b>104</b>.</div>
</li> <li> <para-num num="[0114]"> </para-num> <div class="description-line" id="p-0115" num="0114">In another embodiment, the read data pipeline <b>108</b> includes a decompression module <b>336</b> that decompresses a data segment formatted by the depacketizer <b>324</b>. In one embodiment, the decompression module <b>336</b> uses compression information stored in one or both of the packet header and the container label to select a complementary routine to that used to compress the data by the compression module <b>312</b>. In another embodiment, the decompression routine used by the decompression module <b>336</b> is dictated by the device requesting the data segment being decompressed. In another embodiment, the decompression module <b>336</b> selects a decompression routine according to default settings on a per data structure type or data structure class basis. A first packet of a first object may be able to override a default decompression routine and a second packet of a second data structure of the same data structure class and data structure type may use the default decompression routine and a third packet of a third data structure of the same data structure class and data structure type may use no decompression.</div>
</li> <li> <para-num num="[0115]"> </para-num> <div class="description-line" id="p-0116" num="0115">In another embodiment, the read data pipeline <b>108</b> includes a read program module <b>338</b> that includes one or more user-definable functions within the read data pipeline <b>108</b>. The read program module <b>338</b> has similar characteristics to the write program module <b>310</b> and allows a user to provide custom functions to the read data pipeline <b>108</b>. The read program module <b>338</b> may be located as shown in <figref idrefs="DRAWINGS">FIG. 3</figref>, may be located in another position within the read data pipeline <b>108</b>, or may include multiple parts in multiple locations within the read data pipeline <b>108</b>. Additionally, there may be multiple read program modules <b>338</b> within multiple locations within the read data pipeline <b>108</b> that operate independently. One of skill in the art will recognize other forms of a read program module <b>338</b> within a read data pipeline <b>108</b>. As with the write data pipeline <b>106</b>, the stages of the read data pipeline <b>108</b> may be rearranged and one of skill in the art will recognize other orders of stages within the read data pipeline <b>108</b>.</div>
</li> <li> <para-num num="[0116]"> </para-num> <div class="description-line" id="p-0117" num="0116">The storage controller <b>104</b> includes control and status registers <b>340</b> and corresponding control queues <b>342</b>. The control and status registers <b>340</b> and control queues <b>342</b> facilitate control and sequencing commands and subcommands associated with data processed in the write and read data pipelines <b>106</b>, <b>108</b>. For example, a data segment in the packetizer <b>302</b> may have one or more corresponding control commands or instructions in a control queue <b>342</b> associated with the ECC generator <b>304</b>. As the data segment is packetized, some of the instructions or commands may be executed within the packetizer <b>302</b>. Other commands or instructions may be passed to the next control queue <b>342</b> through the control and status registers <b>340</b> as the newly formed data packet created from the data segment is passed to the next stage.</div>
</li> <li> <para-num num="[0117]"> </para-num> <div class="description-line" id="p-0118" num="0117">Commands or instructions may be simultaneously loaded into the control queues <b>342</b> for a packet being forwarded to the write data pipeline <b>106</b> with each pipeline stage pulling the appropriate command or instruction as the respective packet is executed by that stage. Similarly, commands or instructions may be simultaneously loaded into the control queues <b>342</b> for a packet being requested from the read data pipeline <b>108</b> with each pipeline stage pulling the appropriate command or instruction as the respective packet is executed by that stage. One of skill in the art will recognize other features and functions of control and status registers <b>340</b> and control queues <b>342</b>.</div>
</li> <li> <para-num num="[0118]"> </para-num> <div class="description-line" id="p-0119" num="0118">The storage controller <b>104</b> and or non-volatile storage device <b>102</b> may also include a bank interleave controller <b>344</b>, a synchronization buffer <b>346</b>, a storage bus controller <b>348</b>, and a multiplexer (“MUX”) <b>350</b>.</div>
</li> <li> <para-num num="[0119]"> </para-num> <div class="description-line" id="p-0120" num="0119">In some embodiments, a storage layer provides an interface through which storage clients perform persistent operations. The storage layer may simplify data storage operations for storage clients and expose enhanced storage features, such as atomicity, transactional support, recovery, and so on. <figref idrefs="DRAWINGS">FIG. 4</figref> depicts one embodiment of a system <b>400</b> comprising a storage layer <b>430</b> that presents a logical address space <b>432</b> of the non-volatile storage device <b>402</b> to storage client applications <b>412</b> operating on a computing device <b>401</b>. The computing device <b>401</b> may comprise a processor, non-volatile storage, memory, human-machine interface (HMI) components, communication interfaces (for communication via the network <b>420</b>), and so on.</div>
</li> <li> <para-num num="[0120]"> </para-num> <div class="description-line" id="p-0121" num="0120">The non-volatile storage device <b>402</b> may comprise a single non-volatile storage device, may comprise a plurality of non-volatile storage devices, a cluster of storage devices, or other suitable configuration. The storage layer <b>430</b> may comprise a driver, kernel-level module, hypervisor, user-space application, or the like. In some embodiments, the storage layer <b>430</b> is implemented in conjunction with the driver <b>118</b> described above. The storage layer <b>430</b> and/or the storage clients <b>412</b> may be embodied as instructions stored on a non-volatile storage device.</div>
</li> <li> <para-num num="[0121]"> </para-num> <div class="description-line" id="p-0122" num="0121">The storage layer <b>430</b> may maintain and present a logical address space <b>432</b> to the clients <b>412</b> via one or more interfaces and/or APIs provided by the storage layer <b>430</b> (storage layer interface <b>436</b>). As used herein, a logical address space refers to a logical representation of storage resources, such as physical storage units on the non-volatile storage media <b>410</b>, storage on a backing store <b>460</b>), or the like. The physical storage units may comprise pages, logical pages, storage divisions, logical storage divisions, sectors, blocks, or other units of storage. The logical address space <b>432</b> may comprise a plurality of logical identifiers (LIDs), each corresponding to a respective storage unit. A logical identifier may comprise any identifier capable of being mapped to a storage resource including, but not limited to: a logical block address (“LBA”), cylinder/head/sector (“CHS”) address, a file name, an object identifier, an inode, Universally Unique Identifier (“UUID”), Globally Unique Identifier (“GUID”), or other suitable identifier. In some embodiments, the logical identifiers of the logical address space <b>432</b> correspond to physical storage units of a particular a storage device, such as the non-volatile storage device <b>102</b>, backing store <b>460</b>, or the like. Alternatively, or in addition, the logical identifiers may correspond to storage units of arbitrary size, which may map to one or more physical storage units of a storage device.</div>
</li> <li> <para-num num="[0122]"> </para-num> <div class="description-line" id="p-0123" num="0122">The storage layer <b>430</b> may provide storage services to the host <b>114</b>, clients <b>112</b>, the cache layer <b>440</b>, through the storage layer interface <b>436</b>. The clients <b>412</b> may include, but are not limited to: operating systems, virtual operating systems (e.g., guest operating systems, hypervisors, etc.), file systems, database applications, server applications, general-purpose applications, and the like. In some embodiments, one or more clients <b>452</b> operating on a remote computing device <b>450</b> may access the storage layer <b>430</b> via a network <b>420</b>. The storage layer interface <b>436</b> may comprise a block device interface and/or one or more extended interfaces.</div>
</li> <li> <para-num num="[0123]"> </para-num> <div class="description-line" id="p-0124" num="0123">The storage layer <b>430</b> is configured to perform persistent storage operations on the non-volatile storage device <b>402</b>, which may comprise a non-volatile storage device as described above. The storage layer <b>430</b> communicates with the non-volatile storage device <b>402</b> via a communication link <b>421</b>, which may include, but is not limited to: a PCE-e bus, a network connection (e.g., Infiniband), a storage network, Fibre Channel Protocol (FCP) network, HyperSCSI, Universal Serial Bus (USB), IEEE 1394, or other suitable communication link. The storage operations may be configured according to the capabilities and/or configuration of the non-volatile storage device <b>402</b>. For example, if the non-volatile storage device <b>402</b> comprises a write-once, block-erasable device, the storage layer <b>430</b> may be configured to perform storage operations accordingly (e.g., store data on initialized or erased storage divisions, etc.).</div>
</li> <li> <para-num num="[0124]"> </para-num> <div class="description-line" id="p-0125" num="0124">In some embodiments, the storage layer <b>430</b> maintains metadata <b>434</b> comprising associations between logical identifiers of the logical address space <b>432</b> and physical storage units on the non-volatile storage device <b>402</b>. The storage layer <b>430</b> may maintain “any-to-any” assignments between logical identifiers and physical storage units. Accordingly, there may be no pre-defined mapping between logical identifiers and physical storage units. The storage layer <b>430</b> may cause data to be written and/or updated “out-of-place” on the non-volatile storage media <b>410</b>. In some embodiments, data is stored on the non-volatile storage media <b>410</b> in a sequential, log-based format. Storing data sequentially, “out-of-place” provides wear-leveling benefits and addresses “erase-and-program-once” properties of many types of non-volatile storage media <b>410</b>. Moreover, out-of-place writing (and writing data in logical storage units as opposed to individual pages) addresses asymmetric properties of the non-volatile storage device <b>402</b>. Asymmetric properties refers to the idea that different storage operations (read, write, erase) take very different amounts of time. For example, it may take ten times as long to program data on a non-volatile storage media <b>410</b> as it takes to read data from the non-volatile storage element media <b>410</b>. Moreover, in some cases, data may only be programmed to physical storage units that have first been initialized (e.g., erased). An erase operation may take ten times as long as a program operation (and by extension one hundred times as long as a read operation). Associations between logical identifiers in the logical address space <b>432</b> and physical storage units on the non-volatile storage device <b>402</b> are maintained in the volatile metadata <b>434</b>.</div>
</li> <li> <para-num num="[0125]"> </para-num> <div class="description-line" id="p-0126" num="0125">The logical address space <b>432</b> may be “sparse” meaning the logical address space <b>432</b> is large enough that allocated/assigned logical identifiers are non-contiguous and separated by sections of one or more unallocated/unassigned addresses, and, as such, may comprise a logical capacity that exceeds the physical storage capacity of the non-volatile storage device <b>402</b>. Accordingly, the logical address space <b>432</b> may be defined independent of the non-volatile storage device <b>402</b>; the logical address space <b>432</b> may present a larger address space than the physical storage capacity of the non-volatile storage device <b>402</b>, may present different storage unit partitions and/or block sizes than provided by the non-volatile storage device <b>402</b>, and so on. Associations between the logical address space <b>432</b> and the non-volatile storage <b>402</b> are managed by the storage layer <b>430</b> (using the volatile metadata <b>434</b>). Storage clients <b>412</b> may leverage the storage layer interface <b>436</b>, as opposed to a more limited block-storage layer and/or the other storage interface provided by a particular non-volatile storage device <b>402</b>.</div>
</li> <li> <para-num num="[0126]"> </para-num> <div class="description-line" id="p-0127" num="0126">In some embodiments, the logical address space <b>432</b> may be very large, comprising a 64-bit address space referenced by 64-bit logical identifiers (LIDs). Each 64-bit logical identifier in the logical address space <b>432</b> (e.g., 64-bit address) references a respective virtual storage unit. As used herein, a virtual storage unit refers to a block of logical storage capacity (e.g., an allocation block). The storage layer <b>430</b> may be configured to implement arbitrarily sized virtual storage units; typical sizes range from 512 to 4086 bytes (or even 8 kb to 16 kb depending on the needs of the storage clients <b>412</b>); the disclosure, however, is not limited in this regard. Since the logical address space <b>432</b> (and the virtual storage units therein) is independent of the physical storage capacity and/or storage partitioning of the non-volatile storage device <b>402</b>, the logical address space <b>432</b> may be tailored to the requirements of the storage clients <b>412</b>.</div>
</li> <li> <para-num num="[0127]"> </para-num> <div class="description-line" id="p-0128" num="0127">The storage layer <b>430</b> may manage allocations within the logical address space using volatile metadata <b>434</b>. In some embodiments, the storage layer <b>430</b> maintains volatile, storage metadata <b>434</b> that tracks allocations of the logical address space <b>432</b> using a forward index. The storage layer <b>430</b> may allocate ranges within the logical address space <b>432</b> for use by particular storage clients <b>412</b>. Logical identifiers may be allocated for a particular client <b>412</b> to persist a storage entity. As used herein, a storage entity refers to any data or data structure in the logical address space <b>412</b> that is capable of being persisted to the non-volatile storage device <b>402</b>; accordingly, a storage entity may include, but is not limited to: file system objects (e.g., files, streams, I-nodes, etc.), a database primitive (e.g., database table, extent, or the like), streams, persistent memory space, memory mapped files, or the like. A storage entity may also be referred to as a Virtual Storage Unit (VSU). A file system object refers to any data structure used by a file system including, but not limited to: a file, a stream, file attributes, file index, volume index, node table, or the like.</div>
</li> <li> <para-num num="[0128]"> </para-num> <div class="description-line" id="p-0129" num="0128">As described above, allocating a logical identifier refers to reserving a logical identifier for a particular use or storage client. A logical identifier may refer to a set or range of the logical address space <b>432</b> (e.g., a set or range of virtual storage units). The logical capacity of an allocated logical identifier may be determined by the size of the virtual storage units of the logical address space <b>432</b>. As described above, the logical address space <b>432</b> may be configured to present virtual storage units of any pre-determined size. The size of the virtual storage units may be configured by one or more storage clients <b>412</b>, the storage layer <b>430</b>, or the like.</div>
</li> <li> <para-num num="[0129]"> </para-num> <div class="description-line" id="p-0130" num="0129">An allocated logical identifier, however, may not necessarily be associated with and/or assigned to physical storage units on the non-volatile storage device <b>402</b> until required. In some embodiments, the storage layer <b>430</b> allocates logical identifiers comprising large, contiguous ranges in the logical address space <b>432</b>. The availability of large, contiguous ranges in the logical address space <b>432</b> is enabled by the large address space (e.g., 64-bit address space) presented by the storage layer <b>430</b>. For example, a logical identifier allocated for a file may be associated by the storage layer <b>430</b> with an address range of 2̂32 contiguous virtual storage units in the logical address space <b>432</b> for data of the file. If the virtual storage units (e.g., allocation blocks) are 512 bytes each, the allocated logical identifier may represent a logical capacity of two (2) terabytes. The physical storage capacity of the non-volatile storage device <b>402</b> may be smaller than two (2) terabytes and/or may be sufficient to store only a small number of such files, such that if logical identifier allocations were to cause equivalent assignments in physical storage space, the storage layer <b>430</b> would quickly exhaust the capacity of the non-volatile storage device <b>402</b>. Advantageously, however, the storage layer <b>430</b> is configured to allocate large, contiguous ranges within the logical address space <b>432</b> and to defer assigning physical storage units on the non-volatile storage device <b>402</b> to the logical identifiers until necessary. Similarly, the storage layer <b>430</b> may support the use of “sparse” allocated logical ranges. For example, a client <b>412</b> may request that a first data segment be persisted at the “head” of an allocated logical identifier and a second data segment be persisted at the “tail” of an allocated logical identifier. The storage layer <b>430</b> may assign only those physical storage units on the non-volatile storage device <b>402</b> that are needed to persist the first and second data segments. The storage layer <b>430</b> may not assign or reserve physical storage units on the non-volatile storage device <b>402</b> for allocated logical identifiers that are not being used to store data.</div>
</li> <li> <para-num num="[0130]"> </para-num> <div class="description-line" id="p-0131" num="0130">As discussed above, the storage layer <b>430</b> may maintain volatile metadata <b>434</b> to track allocations in the logical address space <b>432</b> space and to track assignments between logical identifiers in the logical address space <b>432</b> and physical storage units on the non-volatile storage media <b>410</b>. In some embodiments, the storage layer <b>430</b> may track both logical allocations and physical storage unit assignments using a single datastructure in the volatile metadata <b>434</b>. Alternatively, or in addition, the storage layer <b>430</b> may be configured to track logical allocations in logical allocation metadata and to track assigned physical storage units on the non-volatile storage media <b>410</b> using separate, physical reservation metadata.</div>
</li> <li> <para-num num="[0131]"> </para-num> <div class="description-line" id="p-0132" num="0131">Storage clients <b>412</b> may access the storage layer <b>430</b> via the storage layer interface <b>436</b>. In some embodiments, storage clients <b>412</b> may delegate certain functions to the storage layer <b>430</b>. For example, and as described above, storage clients <b>412</b> may leverage the sequential, log-based data format of the storage layer <b>430</b> to delegate crash recovery and/or data integrity functions to the storage layer <b>430</b>. In some embodiments, storage clients may also delegate allocations in the logical address space <b>432</b> and/or physical storage reservations to the storage layer <b>430</b>.</div>
</li> <li> <para-num num="[0132]"> </para-num> <div class="description-line" id="p-0133" num="0132">Typically, a client <b>412</b>, such as a file system, tracks the logical addresses and/or physical storage units that are available for use. The logical storage units available to the client <b>412</b> may be limited to the physical storage capacity of the underlying non-volatile storage device (or partition thereof). Accordingly, the client <b>412</b> may maintain a set of logical addresses that “mirrors” the physical storage units of the non-volatile storage device <b>402</b>. For example, and as shown in <figref idrefs="DRAWINGS">FIG. 4</figref>, a client <b>412</b> may identify one or more available logical block addresses (LBAs) for a new file. Since the LBAs map directly to physical storage units in conventional implementations, the LBAs are unlikely to be contiguous; the availability of contiguous LBAs may depend upon the capacity of the underlying block storage device and/or whether the device is “fragmented.” The client <b>412</b> then performs block-level operations to store the file through, inter alia, a block storage layer (e.g., a block-deice interface). If the underlying storage device provides a one-to-one mapping between logical block address and physical storage units, as with conventional storage devices, the block storage layer performs appropriate LBA-to-physical address translations and implements the requested storage operations. If, however, the underlying non-volatile storage device <b>402</b> does not support one-to-one mappings (e.g., the underlying storage device is a sequential, or write-out-of-place device, such as a non-volatile storage device, in accordance with embodiments of this disclosure), another redundant set of translations is needed (e.g., a Flash Translation Layer, or other mapping). The redundant set of translations and the requirement that the client <b>412</b> maintain logical address allocations may represent a significant overhead for storage operations performed by the client <b>412</b> and may make allocating contiguous LBA ranges difficult or impossible without time-consuming “defragmentation” operations.</div>
</li> <li> <para-num num="[0133]"> </para-num> <div class="description-line" id="p-0134" num="0133">In some embodiments, storage clients <b>412</b> delegate allocation functionality to the storage layer <b>430</b>. Storage clients <b>412</b> may access the storage layer interface <b>436</b> to request logical ranges in the logical address space <b>432</b>. The storage layer <b>430</b> tracks the allocation status of the logical address space <b>432</b> using the volatile metadata <b>434</b>. If the storage layer <b>430</b> determines that the requested logical address range is unallocated, the storage layer <b>430</b> allocates the requested logical address range for the client <b>412</b>. If the requested range is allocated (or only a portion of the range is unallocated), the storage layer <b>430</b> may return an alternative range in the logical address space <b>432</b> and/or may return a failure. In some embodiments, the storage layer <b>430</b> may return an alternative range in the logical address space <b>430</b> that includes contiguous range of logical addresses. Having a contiguous range of logical addresses often simplifies the management of the storage entity associated with this range of logical addresses. Since the storage layer <b>430</b> uses the volatile metadata <b>434</b> to maintain associations between the logical address space <b>432</b> and physical storage units on the non-volatile storage device <b>402</b>, no redundant set of address translations is needed. Moreover, the storage layer <b>430</b> uses the volatile metadata <b>434</b> to identify unallocated logical identifiers, which frees the client <b>412</b> from this overhead.</div>
</li> <li> <para-num num="[0134]"> </para-num> <div class="description-line" id="p-0135" num="0134">In some embodiments, the storage layer <b>430</b> makes allocations within the logical address space <b>432</b> as described above. The storage layer <b>430</b> may access an index comprising allocated logical address ranges (e.g., forward index of <figref idrefs="DRAWINGS">FIG. 5</figref>) to identify unallocated logical identifiers, which are allocated to storage clients <b>412</b> upon request. For example, the storage layer <b>430</b> may maintain volatile metadata <b>434</b> comprising a range-encoded tree datastructure, as described above; entries in the tree may represent allocated logical identifiers in the logical address space <b>432</b>, and “holes” in the tree represent unallocated logical identifiers. Alternatively, or in addition, the storage layer <b>430</b> maintains an index of unallocated logical identifiers that can be allocated to storage clients (e.g., without searching a forward index).</div>
</li> <li> <para-num num="[0135]"> </para-num> <div class="description-line" id="p-0136" num="0135"> <figref idrefs="DRAWINGS">FIG. 5</figref> depicts one example of volatile metadata <b>434</b> and, in particular, a forward index <b>504</b> that maintains allocations of the logical address space of one or more non-volatile storage devices (e.g., storage devices <b>106</b> described above). The forward index <b>504</b> may be further configured to maintain assignments between allocated logical identifiers and physical storage units on a non-volatile storage device. The forward index <b>504</b> may be maintained by the storage layer <b>430</b>, a storage controller (e.g., storage controller <b>404</b>, described above), and/or a driver (e.g., driver <b>118</b> described above), or the like.</div>
</li> <li> <para-num num="[0136]"> </para-num> <div class="description-line" id="p-0137" num="0136">In the <figref idrefs="DRAWINGS">FIG. 5</figref> example, the datastructure <b>504</b> is implemented as a range-encoded B-tree. The disclosure is not limited in this regard, however; the forward index <b>504</b> may be implemented using and suitable data structure including, but not limited to: a tree, a B-tree, a range-encoded B-tree, a radix tree, a map, a content addressable map (CAM), a table, a hash table, or other suitable data structure (or combination of data structures).</div>
</li> <li> <para-num num="[0137]"> </para-num> <div class="description-line" id="p-0138" num="0137">The forward index <b>504</b> comprises a plurality of entries <b>505</b> (entries <b>505</b>A-G), each representing one or more logical identifiers in the logical address space. For example, the entry <b>505</b>B references logical identifiers <b>515</b> (LIDs <b>072</b>-<b>083</b>). Data may be stored sequentially or “out-of-place” on the non-volatile storage device and, as such, there may be no correspondence between logical identifiers and the physical storage units. The forward index <b>504</b> maintains assignments between allocated logical identifiers and physical storage units (e.g., using physical storage unit references <b>517</b>). For example, the reference <b>517</b>B assigns the logical identifiers <b>515</b> (LIDs <b>072</b>-<b>083</b>) to one or more physical storage units of the non-volatile storage device. In some embodiments, the references <b>517</b> comprise a physical address on the non-volatile storage device. Alternatively, or in addition, the references <b>517</b> may correspond to a secondary datastructure (e.g., a reverse index), or the like. The references <b>517</b> may be updated in response to changes to the physical storage unit of data (e.g., due to grooming operations, data refresh, modification, overwrite, or the like).</div>
</li> <li> <para-num num="[0138]"> </para-num> <div class="description-line" id="p-0139" num="0138">In some embodiments, one or more of the entries <b>505</b> may represent logical identifiers that have been allocated to a storage client, but have not been assigned to any particular physical storage units (e.g., the storage client has not caused data to be written to the logical identifiers). The physical storage unit reference <b>517</b> of an unassigned entry <b>505</b> may be marked as “null” or not assigned.</div>
</li> <li> <para-num num="[0139]"> </para-num> <div class="description-line" id="p-0140" num="0139">The entries <b>505</b> are arranged into a tree data structure by the edges <b>507</b>. In some embodiments, the entries <b>505</b> are indexed by logical identifier, which provides for fast and efficient entry <b>505</b> lookup. In the <figref idrefs="DRAWINGS">FIG. 5</figref> example, the entries <b>505</b> are arranged in logical identifier order such that the entry <b>505</b>C references the “lowest” logical identifiers and <b>505</b>G references the “largest” logical identifiers. Particular entries <b>505</b> are accessed by traversing the edges <b>507</b> of the forward index <b>504</b>. In some embodiments, the forward index <b>504</b> is balanced, such that all leaf entries <b>505</b> are of a similar depth within the tree.</div>
</li> <li> <para-num num="[0140]"> </para-num> <div class="description-line" id="p-0141" num="0140">For clarity, the <figref idrefs="DRAWINGS">FIG. 5</figref> example depicts entries <b>505</b> comprising numeric logical identifiers, however, the disclosure is not limited in this regard, and one of skill in the art will recognize that the entries <b>505</b> could comprise any suitable logical identifier representation, including, but not limited to: alpha-numerical characters, hexadecimal characters, binary values, text identifiers, hash codes, or the like.</div>
</li> <li> <para-num num="[0141]"> </para-num> <div class="description-line" id="p-0142" num="0141">The entries <b>505</b> of the index <b>504</b> may reference logical identifiers of variable size and/or length; a single entry <b>505</b> may reference a plurality of logical identifiers (e.g., a set of logical identifiers, a logical identifier range, a noncontiguous set of logical identifiers, or the like). For example, the entry <b>505</b>B represents a contiguous range of logical identifiers <b>072</b>-<b>083</b>. Other entries of the forward index <b>504</b> may represent a noncontiguous set of logical identifiers; entry <b>505</b>G represents logical identifiers <b>454</b>-<b>477</b> and <b>535</b>-<b>598</b>, each assigned to respective physical storage units by respective references <b>517</b>G and <b>527</b>G. The forward index <b>504</b> may represent logical identifiers using any suitable technique; for example, the entry <b>505</b>D references logical identifier <b>178</b> and length <b>15</b>, which corresponds to a range of logical identifiers <b>178</b>-<b>192</b>.</div>
</li> <li> <para-num num="[0142]"> </para-num> <div class="description-line" id="p-0143" num="0142">In some embodiments, the entries <b>505</b> comprise and/or reference metadata <b>519</b>, which may comprise metadata pertaining to the entries <b>505</b>, such as age, size, logical identifier attributes (e.g., client identifier, data identifier, file name, group identifier), the underlying physical storage unit(s), or the like. The metadata <b>519</b> may be indexed by logical identifier (through association with the respective entries <b>505</b>) and, as such, the metadata <b>519</b> may remain associated with entry <b>505</b> regardless of changes to the location of the underlying physical storage units of the data.</div>
</li> <li> <para-num num="[0143]"> </para-num> <div class="description-line" id="p-0144" num="0143">The forward index <b>504</b> may be used to efficiently determine whether the non-volatile storage device comprises a particular logical identifier. In one example, a storage client may request allocation of a particular logical identifier. If the forward index <b>504</b> comprises and entry <b>505</b> that includes the requested logical identifiers, the logical identifier(s) associated with the request may be identified as being already allocated. If the logical identifiers are not in the index, they may be allocated to the requester by creating a new entry <b>505</b> in the forward index <b>504</b>. In another example, a storage client requests data of a particular logical identifier. The physical storage unit of the data is determined by accessing the reference <b>517</b> to the physical storage unit of the entry <b>505</b> comprising the logical identifier. In another example, a client modifies data pertaining to a logical identifier. In another example, a storage client modifies existing data of a particular logical identifier. The modified data is written sequentially to a new physical storage unit on the non-volatile storage device, and the physical storage unit reference <b>517</b> of the entry <b>505</b> in the forward index <b>504</b> is updated to reference the physical storage unit of the new data. The obsolete data may be marked as invalid for reclamation in a grooming operation.</div>
</li> <li> <para-num num="[0144]"> </para-num> <div class="description-line" id="p-0145" num="0144">The forward index <b>504</b> of <figref idrefs="DRAWINGS">FIG. 5</figref> maintains a logical address space and, as such, is indexed by logical identifier. As discussed above, entries <b>505</b> in forward index <b>504</b> may comprise references <b>517</b> to physical storage units on a non-volatile storage device. In some embodiments, the references <b>517</b> may comprise physical addresses (or address ranges) of the physical storage units. Alternatively, or in addition, the references <b>517</b> may be indirect (e.g., reference a secondary datastructure, such as a reverse index).</div>
</li> <li> <para-num num="[0145]"> </para-num> <div class="description-line" id="p-0146" num="0145"> <figref idrefs="DRAWINGS">FIG. 6A</figref> depicts one example of a reverse index <b>622</b> for maintaining metadata pertaining to physical storage units of a non-volatile storage device. In the <figref idrefs="DRAWINGS">FIG. 6A</figref> example, the reverse index <b>622</b> is implemented as a table data structure. The disclosure is not limited in this regard, however, and could implement the reverse index <b>622</b> using any suitable datastructure. For example, in some embodiments, the reverse index <b>622</b> is implemented in the same data structure with the forward index <b>504</b> described above (e.g., portions and/or entries of the reverse index <b>622</b> may be included as leaf entries of the forward index <b>504</b>). The reverse index <b>622</b> comprises a plurality of entries <b>620</b> (depicted as rows in the table datastructure <b>622</b>), each of which may comprise an entry ID <b>624</b>, a physical address <b>626</b>, a data length <b>628</b> associated with the data stored at the physical address <b>626</b> on the non-volatile storage media <b>410</b> (in this case the data is compressed), a valid tag <b>630</b>, a logical address <b>632</b> associated with the data, a data length <b>634</b> associated with the logical address <b>632</b>, and other miscellaneous data <b>636</b>. In a further embodiment, the reverse index <b>622</b> may include an indicator of whether the physical address <b>626</b> stores dirty or clean data, or the like.</div>
</li> <li> <para-num num="[0146]"> </para-num> <div class="description-line" id="p-0147" num="0146">The reverse index <b>622</b> may be organized according to the configuration and/or layout of a particular non-volatile storage device. Accordingly, the reverse index <b>622</b> may be arranged by storage divisions (e.g., erase blocks), physical storage units (e.g., pages), logical storage units, or the like. In the <figref idrefs="DRAWINGS">FIG. 6A</figref> example, the reverse index <b>622</b> is arranged into a plurality of erase blocks (<b>640</b>, <b>638</b>, and <b>642</b>), each comprising a plurality of physical storage units (e.g., pages, logical pages, or the like).</div>
</li> <li> <para-num num="[0147]"> </para-num> <div class="description-line" id="p-0148" num="0147">The entry <b>620</b> comprises metadata pertaining to the physical storage unit(s) comprising data of the entry <b>505</b>F of <figref idrefs="DRAWINGS">FIG. 5</figref>. The entry <b>620</b> indicates that the physical storage unit is within erase block n <b>638</b>. Erase block n <b>638</b> is preceded by erase block n−1 <b>640</b> and followed by erase block n+1 <b>642</b>. (The contents of erase blocks n−1 and n+1 are not shown).</div>
</li> <li> <para-num num="[0148]"> </para-num> <div class="description-line" id="p-0149" num="0148">The entry ID <b>624</b> may be an address, a virtual link, or other data to associate entries in the reverse index <b>622</b> with entries in the forward index <b>504</b> (or other volatile, storage metadata). The physical address <b>626</b> indicates a physical address on the non-volatile storage device (e.g., non-volatile storage media <b>410</b>). The data length <b>628</b> associated with the physical address <b>626</b> identifies a length of the data stored at the physical address <b>626</b>. Together the physical address <b>626</b> and data length <b>628</b> may be referred to as destination parameters <b>644</b>.</div>
</li> <li> <para-num num="[0149]"> </para-num> <div class="description-line" id="p-0150" num="0149">The logical identifier <b>632</b> and data length <b>634</b> may be referred to as source parameters <b>646</b>. The logical identifier <b>632</b> associates the entry with a logical identifier of the logical address space. The logical identifier <b>632</b> may be used to associate an entry in the reverse index <b>622</b> with an entry <b>505</b> of the forward index <b>504</b>. The data length <b>624</b> refers to the length of the data in the logical address space (e.g., from the perspective of the storage client). The source parameter <b>646</b> data length <b>634</b> may be different from the destination parameter <b>644</b> data length <b>634</b> due to, inter alia, data compression, header overhead, encryption overhead, or the like. In the <figref idrefs="DRAWINGS">FIG. 6A</figref> example, the data associated with the entry <b>620</b> is highly compressible and was compressed from <b>64</b> blocks in the logical address space to <b>1</b> block on the non-volatile storage device.</div>
</li> <li> <para-num num="[0150]"> </para-num> <div class="description-line" id="p-0151" num="0150">The valid tag <b>630</b> indicates whether the data mapped to the entry <b>620</b> is valid. In this case, the data associated with the entry <b>620</b> is valid and is depicted in <figref idrefs="DRAWINGS">FIG. 6A</figref> as a “Y” in the row of the entry <b>620</b>. As used herein, valid data refers to data that is up-to-date and has not been deleted and/or made obsolete (overwritten or modified). The reverse index <b>622</b> may track the validity status of each physical storage unit of the non-volatile storage device. The forward index <b>504</b> may comprise entries corresponding to valid data only. In the <figref idrefs="DRAWINGS">FIG. 6A</figref> example, entry “Q” <b>648</b> indicates that data associated with the entry <b>648</b> is invalid. Note that the forward index <b>504</b> does not include logical addresses associated with entry Q <b>648</b>. The entry Q <b>648</b> may correspond to an obsolete version of the data of entry <b>505</b>C (overwritten by data now stored at entry “C”).</div>
</li> <li> <para-num num="[0151]"> </para-num> <div class="description-line" id="p-0152" num="0151">The reverse index <b>622</b> may maintain entries for invalid data so that valid and invalid data can be quickly distinguished for storage recovery (e.g., grooming). In some embodiments, the forward index <b>504</b> and/or the reverse index <b>622</b> may track dirty and clean data in a similar manner to distinguish dirty data from clean data when operating as a cache.</div>
</li> <li> <para-num num="[0152]"> </para-num> <div class="description-line" id="p-0153" num="0152">In some embodiments, the reverse index <b>622</b> may omit the source parameters <b>646</b>. For example, if the source parameters <b>646</b> are stored with the data, possibly in a header of the stored data, the reverse index <b>622</b> may identify a logical address indirectly by including a physical address <b>626</b> associated with the data and the source parameters <b>646</b> could be identified from the stored data.</div>
</li> <li> <para-num num="[0153]"> </para-num> <div class="description-line" id="p-0154" num="0153">The reverse index <b>622</b> may also include other miscellaneous data <b>636</b>, such as a file name, object name, source data, storage client, security flags, atomicity flag, transaction identifier, or the like. One of skill in the art will recognize other information useful in a reverse index <b>622</b>. While physical addresses <b>626</b> are depicted in the reverse index <b>622</b>, in other embodiments, physical addresses <b>626</b>, or other destination parameters <b>644</b>, may be included in other locations, such as in the forward index <b>504</b>, an intermediate table or data structure, or the like.</div>
</li> <li> <para-num num="[0154]"> </para-num> <div class="description-line" id="p-0155" num="0154">The reverse index <b>622</b> may be arranged by erase block or erase region (or other storage division) so that traversing a section of the index allows a groomer to identify valid data in a particular storage division (e.g., erase block <b>638</b>) and to quantify an amount of valid data, or conversely invalid data, therein. The groomer may select storage divisions for recovery based, in part, on the amount of valid and/or invalid data in each division.</div>
</li> <li> <para-num num="[0155]"> </para-num> <div class="description-line" id="p-0156" num="0155"> <figref idrefs="DRAWINGS">FIG. 6B</figref> depicts a validity bitmap which may be in place of (or in addition to) the reverse index <b>622</b> described above. The validity bitmap <b>631</b> may comprise a plurality of entries for one or more erase blocks <b>638</b>, <b>640</b>, <b>642</b>, of the non-volatile storage media <b>410</b>. The entries may comprise a single bit, each bit representing the validity status of a storage unit (e.g., valid or invalid). The validity bitmap <b>631</b> of each erase block may be stored in a pre-determined portion of the erase block (and/or within another erase block).</div>
</li> <li> <para-num num="[0156]"> </para-num> <div class="description-line" id="p-0157" num="0156">Referring back to <figref idrefs="DRAWINGS">FIG. 4</figref>, in some embodiments, the storage layer interface <b>436</b> may be configured to receive TRIM messages from clients <b>412</b>. As used herein, a TRIM message refers to a message (e.g., “hint” or “directive”) that one or more logical identifiers are no longer in use to reference data on the non-volatile storage media <b>410</b> (e.g., that data of the specified logical identifiers can be (or shall be for TRIM directives) erased from the non-volatile storage media <b>410</b>). A TRIM message may not require that the data be removed immediately; rather, the data may remain on the non-volatile storage media until the storage division upon which the data is stored is erased (e.g., in a subsequent grooming operation). Data of the TRIM message may be “logically invalidated,” however. As used herein, “logically invalidating,” data of a logical identifier refers to removing one or more references to the data in the volatile metadata <b>434</b>, such as the forward index <b>504</b> and/or reverse index <b>622</b>, described above. As described below, since the data is invalidated logically (e.g., in the volatile metadata <b>434</b>), the TRIM message may provide inconsistent results if/when the volatile metadata <b>434</b> is lost due to inter alia an invalid shutdown, software fault, memory fault, or the like.</div>
</li> <li> <para-num num="[0157]"> </para-num> <div class="description-line" id="p-0158" num="0157">Accordingly, in some embodiments, the storage layer <b>430</b> may be configured to store a persistent indicator of a TRIM message (e.g., a persistent note) on the non-volatile storage media <b>410</b>. The persistent note may ensure that the TRIM message is implemented even if the volatile metadata <b>434</b> is lost. Accordingly, the persistent note may be used to exclude logically invalidated data from reconstructed volatile metadata <b>434</b>. In some embodiments, the storage layer interface <b>436</b> provides one or more different TRIM APIs, including a TRIM message (or hint), which does not comprise storing a persistent note, and a TRIM directive that includes storing a persistent note to ensure that the TRIM directive is effective.</div>
</li> <li> <para-num num="[0158]"> </para-num> <div class="description-line" id="p-0159" num="0158">As discussed above, the non-volatile storage device <b>402</b> may be configured to store data on the non-volatile storage media <b>410</b> in a sequential, log-based format. The contents of the non-volatile storage device may, therefore, comprise an ordered “event log” of storage operations on the non-volatile storage media <b>410</b>. The sequential ordering of storage operations may be maintained by appending data at an append point within the physical storage space of the non-volatile storage device <b>402</b>. Alternatively, or in addition, sequence information may be maintained through persistent data stored on the non-volatile storage media <b>410</b>. For example, each storage division (e.g., erase block) on the non-volatile storage media <b>410</b> may comprise a respective indicator (e.g., timestamp, sequence number, or other indicator), to indicate an order or sequence of the storage division within the event log.</div>
</li> <li> <para-num num="[0159]"> </para-num> <div class="description-line" id="p-0160" num="0159">Persisting data in a sequential, log-based format may comprise persisting metadata on the non-volatile storage device <b>402</b> that describes the data. The persistent metadata may be stored with the data itself (e.g., in the same program and/or storage operation and/or in the smallest write unit supported by the non-volatile storage device <b>402</b>); the persistent metadata may, therefore, be guaranteed to be stored with the data it describes. In some embodiments, data is stored in a container format (e.g., a packet, ECC codeword, etc.). Persistent metadata may be included as part of the packet format of the data (e.g., as a header, footer, or other field within the packet). Alternatively, or in addition, portions of the persistent metadata may be stored separately from the data it describes. In this case, the persistent metadata may be linked to (or otherwise reference) the data it describes (or vice versa). For example, a sequence indicator may be included on a storage division with data.</div>
</li> <li> <para-num num="[0160]"> </para-num> <div class="description-line" id="p-0161" num="0160">The persistent metadata describes the data and may include, but is not limited to: a logical identifier (or other identifier) of the data, security or access tracking parameters, sequence information (e.g., a sequence indicator), a persistent metadata flag (e.g., indicating inclusion in an atomic storage operation), a transaction identifier, or the like. The persistent metadata may comprise sufficient information to reconstruct all, or portions, of the metadata <b>434</b> and/or replay the sequence of storage operations performed on the non-volatile storage device <b>402</b>.</div>
</li> <li> <para-num num="[0161]"> </para-num> <div class="description-line" id="p-0162" num="0161">As described above, data stored in the sequential, log-based format may comprise an ordered sequence of storage operations (e.g., “event log”) performed on the non-volatile storage device <b>402</b>. Accordingly, the storage layer <b>430</b> may be capable of replaying a sequence of storage operations performed on the non-volatile storage device <b>402</b> by accessing the data stored on the non-volatile storage media <b>410</b> in a particular order that matches the order of the event log. Similarly, the storage layer <b>430</b> may be capable of determining the relative ordering data on the non-volatile storage media <b>410</b>.</div>
</li> <li> <para-num num="[0162]"> </para-num> <div class="description-line" id="p-0163" num="0162"> <figref idrefs="DRAWINGS">FIG. 7</figref> depicts one example of a sequential, log-based data format (packet format <b>710</b>). A data packet <b>710</b> includes data (e.g., a data segment <b>712</b>) that is associated with one or more logical identifiers. In some embodiments, the data segment <b>712</b> comprises compressed, encrypted, and/or whitened data. Furthermore, the data segment <b>712</b> may be encoded in one or more error-correcting code datastructures and/or symbols (e.g., ECC codewords, ECC symbols, or the like). The data segment <b>712</b> may be a predetermined size (e.g., a fixed “block” or “segment” size). Alternatively, the data segment <b>712</b> may be a variable size.</div>
</li> <li> <para-num num="[0163]"> </para-num> <div class="description-line" id="p-0164" num="0163">The packet <b>710</b> includes persistent metadata <b>714</b> that is stored on the non-volatile storage device. In some embodiments, the persistent metadata <b>714</b> is stored with the data segment <b>712</b> (e.g., as a packet header, footer, or the like). The persistent metadata <b>714</b> may include a logical identifier indicator <b>715</b> that identifies the logical identifier(s) to which the data segment <b>712</b> pertains. The logical identifier indicator <b>715</b> may be used to reconstruct the volatile metadata <b>434</b>, such as the forward index (e.g., forward index <b>504</b>) and/or reverse index (e.g., reverse index <b>622</b>). The persistent metadata <b>714</b> may further comprise one or more metadata flags <b>717</b>, which may be used to support atomic storage operations, transactions, or the like.</div>
</li> <li> <para-num num="[0164]"> </para-num> <div class="description-line" id="p-0165" num="0164">In some embodiments, the packet <b>710</b> is associated with a sequence indicator <b>718</b>. The sequence indicator <b>718</b> may be persisted on the non-volatile storage media (e.g., page) with the data packet <b>710</b> and/or on the storage division (e.g., erase block) with the data packet <b>710</b>. Alternatively, the sequence indicator <b>718</b> may be persisted in a separate storage unit. In some embodiments, a sequence indicator <b>718</b> is applied when a storage division is made available for use (e.g., when erased, when the first or last storage unit is programmed, or the like). The sequence indicator <b>718</b> may be used to determine the temporal sequential ordering of storage operations on the non-volatile storage device.</div>
</li> <li> <para-num num="[0165]"> </para-num> <div class="description-line" id="p-0166" num="0165">Referring back to <figref idrefs="DRAWINGS">FIG. 4</figref>, the sequential, log-based data format enables the storage layer <b>430</b> to reconstruct the volatile metadata <b>434</b>, as well as other data, in the event of an invalid shutdown (or other failure condition). Examples of apparatus, systems, and methods for crash recovery and/or data integrity despite invalid shutdown conditions are described in U.S. Provisional Patent Application No. 61/424,585, entitled, “Apparatus, System, and Method for Persistent Management of Data in a Cache Device,” filed Dec. 17, 2010, and in U.S. Provisional Patent Application No. 61/425,167, entitled, “Apparatus, System, and Method for Persistent Management of Data in a Cache Device,” filed Dec. 20, 2010, which are hereby incorporated by reference in their entirety. In some embodiments, the non-volatile storage device <b>402</b> comprises a secondary power source (e.g., battery, capacitor, etc.) to power the storage controller <b>404</b> and/or non-volatile storage media <b>410</b> in the event of an invalid shutdown. The non-volatile storage device <b>402</b> (or controller <b>404</b>) may, therefore, comprise a “protection domain” or “powercut safe domain” (defined by the secondary power source <b>407</b>). Once data is transferred to within the protection domain, of the non-volatile storage device, it may be guaranteed to be persisted on the non-volatile storage media <b>410</b>. Alternatively, or in addition, the storage controller <b>404</b> may be capable of performing storage operations independent of the host computing device <b>401</b>.</div>
</li> <li> <para-num num="[0166]"> </para-num> <div class="description-line" id="p-0167" num="0166">The sequential, log-based storage format implemented by the storage layer <b>430</b> provides crash-recovery and/or data integrity for the data stored on the non-volatile storage device <b>402</b> as well as the storage metadata <b>434</b>. After an invalid shutdown and reconstruction operation, the storage layer <b>430</b> may expose the reconstructed storage metadata <b>434</b> to storage clients <b>412</b>. The storage clients <b>412</b> may, therefore, delegate crash-recovery and/or data integrity to the storage layer <b>430</b>, which may significantly simplify the storage clients <b>412</b> and/or allow the storage clients <b>412</b> to operate more efficiently. For example, a file system client <b>412</b> may require crash-recovery and/or data integrity services for some of its metadata, such as I-node tables, file allocation tables, and so on. The client <b>412</b> may have to implement these services itself, which may impose significant overhead and/or complexity on the client <b>412</b>. The client <b>412</b> may be relieved from this overhead by delegating crash recovery and/or data integrity to the storage layer <b>430</b>. As described above, the storage layer <b>430</b> stores data in a sequential, log-based format. As such, in the event of an invalid shutdown, the storage layer <b>430</b> is capable of reconstructing the storage metadata <b>434</b> and/or identifying the “current” version of data using the sequential, log-based formatted data on the non-volatile storage device <b>402</b>. The storage layer <b>430</b> provides access to the reconstructed storage metadata <b>434</b> and/or data via the storage layer interface <b>436</b>. Accordingly, after an invalid shutdown, a file system client <b>412</b> may access crash-recovered file system metadata and/or may ensure the integrity of file data accessed through the storage layer <b>430</b>.</div>
</li> <li> <para-num num="[0167]"> </para-num> <div class="description-line" id="p-0168" num="0167"> <figref idrefs="DRAWINGS">FIG. 8A</figref> depicts a physical storage space <b>800</b> of a non-volatile storage device. The physical storage space <b>800</b> is arranged into storage divisions (e.g., erase blocks <b>812</b>, <b>813</b>, <b>814</b>, and <b>815</b>), each of which can be initialized (e.g., erased) in a single operation. Each storage division comprises a plurality of physical storage units (e.g., pages or logical pages) capable of storing data.</div>
</li> <li> <para-num num="[0168]"> </para-num> <div class="description-line" id="p-0169" num="0168">Each physical storage unit may be assigned a respective physical address ranging from zero (0) to N. Data is stored sequentially at an append point <b>820</b>. The append point <b>820</b> moves sequentially through the physical storage space <b>800</b>. After storing data at the append point <b>820</b>, the append point advances sequentially <b>821</b> to the next available physical storage unit. Storage resources may be recovered by a groomer (or other process) anywhere along the length of the event log, for example at a tail at the “opposite end” of the ordered sequence of storage operations.</div>
</li> <li> <para-num num="[0169]"> </para-num> <div class="description-line" id="p-0170" num="0169">As used herein, an available physical storage unit refers to a physical storage unit that has been initialized and is ready to store data (e.g., has been erased). Some non-volatile storage media, such as non-volatile storage media <b>410</b>, can only be reliably programmed once after erasure. Accordingly, as used herein, an available physical storage unit may refer to a storage unit that is in an initialized (or erased) state. In one embodiment, a storage division comprises a plurality of storage units. If the next storage division in the sequence is unavailable (e.g., comprises valid data, has not been erased or initialized, is out of service, etc.), the append point <b>820</b> selects the next available physical storage unit. In the <figref idrefs="DRAWINGS">FIG. 8A</figref> example, after storing data on the physical storage unit <b>816</b>, the append point <b>820</b> may skip the unavailable storage division <b>813</b>, and continue at the next available location (e.g., physical storage unit <b>817</b> of storage division <b>818</b>).</div>
</li> <li> <para-num num="[0170]"> </para-num> <div class="description-line" id="p-0171" num="0170">After storing data on the “last” storage unit (e.g., storage unit N <b>818</b> of storage division <b>815</b>), the append point <b>820</b> wraps back to the first division <b>812</b> (or the next available storage division, if storage division <b>812</b> is unavailable). Accordingly, the append point <b>820</b> may treat the physical address space <b>801</b> as a loop or cycle. As depicted in <figref idrefs="DRAWINGS">FIG. 8B</figref>, the append point <b>820</b> sequentially cycles through the storage units <b>801</b> of the non-volatile storage device (e.g., in the sequence <b>821</b>).</div>
</li> <li> <para-num num="[0171]"> </para-num> <div class="description-line" id="p-0172" num="0171">As discussed above, storing data in a sequential, log-based format may comprise persisting metadata on the non-volatile storage device <b>402</b> that describes the data stored thereon. The persistent metadata may comprise the logical identifier associated with the data and/or provide sequence information pertaining to the sequential ordering of storage operations performed on the non-volatile storage device. Accordingly, the sequential, log-based data may represent an “event log” that tracks the sequence of storage operations performed on the non-volatile storage device <b>402</b>.</div>
</li> <li> <para-num num="[0172]"> </para-num> <div class="description-line" id="p-0173" num="0172"> <figref idrefs="DRAWINGS">FIG. 8B</figref> depicts an example of a sequential, log-based data format. In the <figref idrefs="DRAWINGS">FIG. 8B</figref> example, the letters A-L represent data stored on physical storage units of a non-volatile storage device. Data A is initially stored at physical storage unit <b>850</b>. When the data A is persisted at location <b>850</b>, the physical storage unit reference <b>817</b> of the corresponding forward index entry <b>805</b> is updated to reference the physical storage unit <b>850</b>. In addition, a reverse index entry <b>822</b> may be updated to indicate that the physical storage unit <b>80</b> comprises valid data and/or to associate the physical storage unit <b>850</b> with logical identifiers <b>205</b>-<b>212</b> (not shown). (For clarity, other portions of the forward index and/or reverse index are omitted from <figref idrefs="DRAWINGS">FIG. 8B</figref>.) The data A may be stored on the physical storage unit <b>850</b> in a sequential, log-based format, as described above. Accordingly, data A may be stored in a packet format <b>810</b>A comprising the data segment A <b>812</b>A, which may be encrypted, compressed, and/or whitened as described above. The packet <b>810</b>A may further comprise indications <b>815</b>A of the logical identifiers <b>205</b>-<b>212</b> associated with data A (in a header or the like). As shown in <figref idrefs="DRAWINGS">FIG. 8B</figref>, the logical identifiers may be stored together with the data A in the packet format <b>810</b>A. The data A may also be associated with a sequence identifier <b>818</b>A, which determines a position of the data packet <b>810</b>A in the ordered sequence of storage operations performed on the non-volatile storage media <b>410</b>.</div>
</li> <li> <para-num num="[0173]"> </para-num> <div class="description-line" id="p-0174" num="0173">When the data A is modified and/or overwritten, the updated data may not be stored in the original physical storage unit <b>850</b>. Instead, at <b>830</b>, the updated data A′ is stored sequentially (out-of-place) at storage unit <b>851</b> (at the current position of the append point <b>820</b>). Although not shown in <figref idrefs="DRAWINGS">FIG. 8B</figref>, the data A′ may be stored in a sequential, log-based format, as described above. The volatile metadata <b>434</b> may be updated accordingly. The forward index entry <b>805</b> is updated to associate the logical identifiers <b>205</b>-<b>212</b> with the physical storage unit <b>851</b> comprising A′. The entry <b>822</b> of the reverse index may be updated to mark physical storage unit <b>850</b> as invalid, and an entry <b>823</b> may be updated to indicate that the physical storage unit <b>851</b> comprises valid data. Marking the physical storage unit <b>850</b> as invalid may allow the storage unit <b>850</b> to be reclaimed in a grooming and/or garbage collection operation, as described above.</div>
</li> <li> <para-num num="[0174]"> </para-num> <div class="description-line" id="p-0175" num="0174">At <b>832</b>, the data A′ is further modified and/or overwritten with data A″ (e.g., a client may overwrite and/or modify data at the logical identifiers <b>215</b>-<b>212</b>). The updated data A″ is stored at the current append point <b>820</b> (physical storage unit <b>852</b>) on the non-volatile storage media <b>410</b>. The volatile metadata <b>434</b> is updated, as described above: the forward index entry <b>805</b> is updated to associate the entry with the physical storage unit <b>852</b>, and a reverse index entry <b>824</b> is updated to indicate that the physical storage address <b>852</b> comprises valid data (and that the physical address <b>851</b> comprises invalid data). The “obsolete” versions A and A′ may be retained on the non-volatile storage device until the corresponding physical storage units <b>850</b> and/or <b>851</b> are reclaimed (e.g., erased) in a grooming and/or recovery operation. The Data A″ may be stored in the sequential, log-based format <b>810</b>A″, comprising logical identifiers <b>815</b>A″, data A″, and a sequence identifier <b>818</b>A″, as described above.</div>
</li> <li> <para-num num="[0175]"> </para-num> <div class="description-line" id="p-0176" num="0175">The volatile metadata <b>434</b> may be subject to loss due to inter alia invalid shutdown conditions. The volatile metadata <b>434</b> may be reconstructed from data stored in the sequential, log-based format on the non-volatile storage media <b>410</b>, as described above. As described above, the volatile metadata <b>434</b> may be reconstructed by sequentially accessing the ordered sequence of storage operations on the non-volatile storage device (e.g., the data stored in the sequential log-based format, described above).</div>
</li> <li> <para-num num="[0176]"> </para-num> <div class="description-line" id="p-0177" num="0176">At step <b>834</b>, the volatile metadata <b>434</b> is reconstructed, and the physical storage unit <b>850</b> is accessed. The sequential, log-based format <b>810</b>A at physical storage unit <b>850</b> comprises an indication <b>815</b>A that the data corresponds to logical identifiers <b>205</b>-<b>212</b>. Accordingly, the entry <b>805</b> of the forward index may be reconstructed to indicate that data of logical identifiers <b>205</b>-<b>212</b> is stored at physical storage unit <b>850</b>. In addition, the reverse index may be updated to indicate that storage unit <b>850</b> comprises valid data. The volatile metadata <b>434</b> may be updated in response to accessing other entries in the log (e.g., other physical storage units on the non-volatile storage media <b>410</b>). The data A″ may be identified as the current, up-to-date version of the data by comparing the position of the data packet <b>810</b>A″ to the position of the data at <b>850</b> and <b>851</b> in the ordered sequence of storage operations (e.g., comparing the sequence identifiers of the data packets <b>810</b>A and <b>810</b>A″). Accordingly, at <b>836</b>, in response to accessing physical storage unit <b>852</b>, the volatile metadata <b>434</b> is updated to associate logical identifiers <b>205</b>-<b>212</b> with data A″ at physical storage unit <b>852</b>, and to invalidate the data A and A′ at physical storage units <b>850</b> and <b>851</b>.</div>
</li> <li> <para-num num="[0177]"> </para-num> <div class="description-line" id="p-0178" num="0177">As illustrated in <figref idrefs="DRAWINGS">FIG. 8B</figref>, the volatile metadata <b>434</b>, such as the forward index <b>500</b> and/or reverse index <b>600</b>, may be reconstructed from a sequence of storage operations preserved in the event log on the non-volatile storage media <b>410</b>. In some cases, however, loss of volatile metadata <b>434</b> may cause inconsistent results. As described above, the storage layer interface <b>436</b> may be configured to receive TRIM messages (which may comprise a TRIM directive) from clients <b>412</b>. In response to a TRIM message, the storage layer <b>430</b> may “logically invalidate” the data specified therein. As described above, “logically invalidate,” refers to invalidating data of one or more logical identifiers in the volatile metadata <b>434</b>, which may include, but is not limited to: removing references to the logical identifiers in the forward index <b>500</b>, invalidating the data in the reverse index <b>600</b> (e.g., marking storage units comprising the data may be marked as “invalid”), and so on. A TRIM message may not require that data of the specified logical identifiers be immediately removed from the non-volatile storage media <b>410</b>. Rather the TRIM message may be a “hint” that the data need not be retained on the non-volatile storage media <b>410</b>; the data may remain on the non-volatile storage media <b>410</b> until the storage division (e.g., erase block) upon which the data is stored is recovered in a subsequent grooming operation. As discussed above, data that has been logically invalidated may remain on the non-volatile storage media <b>410</b> until it is removed in subsequent grooming operation(s). If the volatile metadata <b>434</b> is lost before the data is removed from the non-volatile storage media <b>410</b>, the TRIM message may not be properly completed or complied with (e.g., the data may be considered to be valid after the volatile metadata <b>434</b> is reconstructed).</div>
</li> <li> <para-num num="[0178]"> </para-num> <div class="description-line" id="p-0179" num="0178">By contrast, a TRIM directive may require that the data be made inaccessible despite losses to the volatile metadata <b>434</b>. Accordingly, a TRIM directive may comprise storing an indicator of the TRIM operation on the non-volatile storage media <b>410</b> (e.g., storing a persistent note on the non-volatile storage media <b>410</b>). Accordingly, the storage layer <b>430</b> may not acknowledge completion of a TRIM directive until data of the logical identifiers subject to the TRIM directive are guaranteed to be inaccessible to a subsequent access request (e.g., read request). In some embodiments, the storage layer <b>430</b> may not acknowledge a TRIM message or directive until a corresponding persistent note has been stored on the non-volatile storage media <b>410</b>.</div>
</li> <li> <para-num num="[0179]"> </para-num> <div class="description-line" id="p-0180" num="0179"> <figref idrefs="DRAWINGS">FIG. 8C</figref> depicts another example of a physical storage space <b>802</b> of a non-volatile storage media <b>410</b>. At <b>870</b>, data B of logical identifiers <b>305</b>-<b>312</b> is stored at physical storage unit <b>855</b> of the non-volatile storage media <b>410</b>. The data B may be stored in a sequential, log-based format (packet format <b>710</b>). Accordingly, the data B may be stored as a data segment <b>812</b> together with the logical identifier <b>815</b> (logical identifiers <b>305</b>-<b>312</b>) of the data B. The data B may be stored in association with a sequence identifier <b>818</b>, which indicates a position of the data B in the ordered sequence of storage operations performed on the non-volatile storage media <b>410</b>.</div>
</li> <li> <para-num num="[0180]"> </para-num> <div class="description-line" id="p-0181" num="0180">Storing the data B may further comprise updating volatile metadata <b>434</b>; an entry <b>865</b> of a forward index may be updated to associate the logical identifiers <b>305</b>-<b>312</b> with the physical storage unit <b>855</b>, and an entry <b>866</b> in a validity bitmap (or reverse index) may be updated to indicate that the physical storage unit <b>855</b> comprises valid data.</div>
</li> <li> <para-num num="[0181]"> </para-num> <div class="description-line" id="p-0182" num="0181">At step <b>872</b>, a TRIM message is received. As discussed above, in certain embodiments, the TRIM message may comprise a TRIM directive, which may require that data of one or more specified logical identifiers (e.g., logical identifiers <b>305</b>-<b>312</b>) be made inaccessible and/or removed from the non-volatile storage media <b>410</b>, as described above.</div>
</li> <li> <para-num num="[0182]"> </para-num> <div class="description-line" id="p-0183" num="0182">In response to the TRIM directive of step <b>872</b>, data of the logical identifiers <b>305</b>-<b>312</b> may be “logically invalidated,” which may comprise updating the volatile metadata <b>434</b> to remove the entry <b>865</b> that associates the logical identifiers <b>305</b>-<b>312</b> with the data B stored on physical storage unit <b>855</b>. The logical invalidation may further comprise invalidating the physical storage unit <b>855</b> in a reverse index and/or validity bitmap entry <b>866</b>.</div>
</li> <li> <para-num num="[0183]"> </para-num> <div class="description-line" id="p-0184" num="0183">Before the physical storage unit <b>855</b> is recovered (and the data B is removed from the non-volatile storage media <b>410</b>), the volatile metadata <b>434</b> may be lost. The loss may occur due to an invalid shutdown, loss of power, software fault, or the like. The volatile metadata <b>434</b> may be reconstructed by sequentially reading data stored on the non-volatile storage media <b>410</b> in the sequential, log-based format, starting at a first predetermined physical location on the media and sequentially advancing through storage divisions, as described above. As the data is read, a logical identifier of the data may be determined (e.g., by examining a logical identifier indicator <b>815</b> stored with the data). Data that is “later” in the ordered sequence of storage operations for a given logical identifier over-writes previous versions of the data. For example, the data T at storage unit <b>857</b> may be “overwritten” by the data T′ stored at storage unit <b>858</b> since T′ is later in the ordered sequence of storage operations (e.g., closer to the append point <b>820</b> and/or is later as indicated by sequence identifiers of T and T′).</div>
</li> <li> <para-num num="[0184]"> </para-num> <div class="description-line" id="p-0185" num="0184">The reconstruction, however, may fail to account for the TRIM of B, through a TRIM message for the logical identifier of data B. Since data B remains on the non-volatile storage media <b>410</b>, data B may be included in the reconstructed non-volatile storage media. At step <b>874</b>, and in response to reading the storage unit <b>855</b> comprising data B, entries <b>865</b> and/or <b>866</b> may be reconstructed. These entries <b>865</b> and <b>866</b> may indicate that B is valid data, which must be retained on the non-volatile storage media <b>410</b>. Moreover, the data B may be readable by other clients (e.g., a request to access data of logical identifiers <b>305</b>-<b>312</b> may return data B). Accordingly, the effect of the TRIM message of <b>872</b> received prior to the loss of the volatile metadata <b>434</b> may be obviated.</div>
</li> <li> <para-num num="[0185]"> </para-num> <div class="description-line" id="p-0186" num="0185">In some embodiments, a TRIM message may be persisted on the non-volatile storage media, using a persistent note. This “persistent note” may be used to give effect to a TRIM message in the absence of volatile metadata <b>434</b> (e.g., even when the volatile metadata <b>434</b> is lost).</div>
</li> <li> <para-num num="[0186]"> </para-num> <div class="description-line" id="p-0187" num="0186"> <figref idrefs="DRAWINGS">FIG. 8D</figref> depicts an exemplary persistent note <b>880</b> that may be used to implement a “persistent TRIM” message, hint, or directive. As discussed above, the volatile metadata <b>434</b> may be updated in response to the TRIM message at <b>872</b> (e.g., logically invalidated logical identifiers <b>305</b>-<b>312</b>), which may comprise removing the entry <b>865</b> from a forward index and/or invalidating the data B in a reverse index entry <b>866</b>. In addition, a persistent note <b>880</b> may be stored on the non-volatile storage media (e.g., at storage unit <b>859</b>, as depicted in <figref idrefs="DRAWINGS">FIG. 8D</figref>). The persistent note <b>880</b> may specify the logical identifiers that are no longer in use to reference data on the non-volatile storage media <b>410</b> (e.g., logical identifiers <b>305</b>-<b>312</b>). In some embodiments, the persistent note may comprise a header <b>883</b>, which may be used to distinguish the persistent note <b>880</b> from other types of data on the non-volatile storage media <b>410</b> (e.g., data packets, such as data packet <b>810</b>B comprising the B data <b>812</b>B, logical identifier indicators <b>815</b>B, and/or sequence identifier <b>818</b>B). The persistent note <b>880</b> may also include an “original” sequence identifier <b>888</b>, which may be used to order the persistent note <b>880</b> with respect to the ordered sequence of storage operations performed on the non-volatile storage media <b>410</b>. The original sequence identifier <b>888</b> may be used to determine how long to retain the persistent note <b>880</b> on the non-volatile storage media <b>410</b>. Accordingly, the persistent note <b>880</b> may retain the original sequence identifier <b>888</b> if/when the persistent note <b>880</b> is moved to a different physical storage unit on the non-volatile storage media <b>410</b> (e.g., in a grooming operation).</div>
</li> <li> <para-num num="[0187]"> </para-num> <div class="description-line" id="p-0188" num="0187">At step <b>874</b>, the volatile metadata <b>434</b> is lost before data B is removed from the non-volatile storage media <b>410</b>, as described above. During reconstruction of the volatile metadata <b>434</b>, the storage unit <b>855</b> comprising data B is accessed and the volatile metadata <b>434</b> is updated to include an entry <b>865</b> associating logical identifiers <b>305</b>-<b>312</b> with physical storage unit <b>855</b>, as described above. At step <b>876</b>, the storage unit <b>859</b> comprising the persistent note <b>880</b> is accessed. The persistent note <b>880</b> indicates that the logical identifiers <b>305</b>-<b>312</b> are no longer in use to reference data on the non-volatile storage media <b>410</b> (e.g., the data B may be erased from the non-volatile storage media <b>410</b>). In response to the persistent note <b>880</b>, the volatile metadata <b>434</b> is updated to remove the entry <b>865</b> and/or to invalidate B (e.g., invalidate the data at physical storage unit <b>855</b>). Accordingly, the persistent note <b>880</b> may be used to exclude the logical identifiers <b>882</b> from the volatile metadata <b>434</b>, and preserve the effect of the TRIM message received at step <b>872</b>. Although the logical identifiers of <b>882</b> comprise a contiguous range, the disclosure is not limited in this regard; a persistent note <b>880</b> could reference any set of contiguous and/or discontiguous logical identifiers in the logical address space <b>432</b>.</div>
</li> <li> <para-num num="[0188]"> </para-num> <div class="description-line" id="p-0189" num="0188">Referring back to <figref idrefs="DRAWINGS">FIG. 4</figref>, the system <b>400</b> may comprise a cache layer <b>440</b> that is configured to cache data of a backing store <b>460</b> using the non-volatile storage device <b>402</b>. The backing store <b>460</b> may comprise one or more hard disks, network attached storage (NAS), a storage area network (SAN), or other persistent store. The backing store <b>460</b> may comprise a plurality of physical storage units <b>461</b> capable of storing data of the storage clients <b>412</b>. The backing store <b>460</b> may be communicatively coupled to the communication link <b>421</b>. Alternatively, or in addition, the backing store <b>460</b> may be communicatively coupled to the host <b>401</b> (and storage layer <b>430</b>) via a network <b>420</b>.</div>
</li> <li> <para-num num="[0189]"> </para-num> <div class="description-line" id="p-0190" num="0189">The cache layer <b>440</b> may leverage the storage layer <b>430</b> to cache data of the backing store <b>460</b> on the non-volatile storage media <b>410</b>. In some embodiments, the storage layer <b>430</b> is configured to provide a logical address space <b>432</b> corresponding to an address space of the backing store <b>460</b>. The logical address space <b>432</b> may, therefore, correspond to the physical storage units <b>461</b> of the backing store <b>460</b>. As discussed above, the storage layer <b>430</b> may maintain volatile, storage metadata <b>434</b> to associate logical identifiers of the backing store <b>460</b> with storage units of cache data on the non-volatile storage media <b>410</b> (e.g., physical storage units on the non-volatile storage device <b>402</b>), which may include a forward index <b>500</b> and/or reverse index <b>600</b>. The logical address space <b>432</b> may have a logical capacity that is equivalent to a physical storage capacity of the backing store <b>460</b>. Alternatively, the logical address space <b>432</b> may exceed the physical storage capacity of the backing store <b>460</b>. The logical capacity of the logical address space <b>432</b> (as well as the physical capacity of the backing store <b>460</b>) may exceed the physical storage capacity of the non-volatile storage device <b>402</b>. The storage layer <b>430</b> may manage allocations of the logical address space <b>432</b> and the physical storage capacity of the non-volatile storage media <b>402</b>, as described above. In some embodiments, the storage layer <b>430</b> may provide a plurality of logical address spaces <b>432</b>, each corresponding to a different backing store <b>460</b> and/or different client <b>412</b>. The storage layer <b>430</b> may maintain separate volatile, storage metadata <b>434</b> for each logical address space <b>432</b>.</div>
</li> <li> <para-num num="[0190]"> </para-num> <div class="description-line" id="p-0191" num="0190">The cache layer <b>440</b> may leverage the logical address space <b>432</b> and volatile, storage metadata <b>434</b> maintained by the storage layer <b>430</b> to cache data of the backing store <b>460</b>. The cache layer <b>440</b> may reference cache data on the non-volatile storage media <b>410</b> using logical identifiers of the backing store <b>460</b> (through the logical address space <b>432</b> of the storage layer <b>430</b>). Accordingly, the cache layer <b>440</b> may not have to maintain its own storage metadata; the cache layer may not maintain a separate index to associate logical identifiers of the backing store <b>460</b> with cache storage units on the non-volatile storage media <b>410</b>. By leveraging the logical address space <b>432</b> and volatile, storage metadata <b>434</b> of the storage layer <b>430</b>, the overhead of the cache layer <b>440</b> may be significantly reduced.</div>
</li> <li> <para-num num="[0191]"> </para-num> <div class="description-line" id="p-0192" num="0191">The cache layer <b>440</b> may comprise a cache controller <b>441</b> that is configured to coordinate the exchange of data between storage clients <b>412</b>, backing store <b>460</b>, and the non-volatile storage device <b>402</b>. The cache controller <b>441</b> may manage cache admission, eviction, and the like. The cache controller <b>441</b> may implement a cache eviction policy based, inter alia, on cache metadata <b>442</b>, such as cache access patterns (e.g., access frequency, whether the data is “hot,” “warm,” or “cold,” and so on). The cache eviction policy may depend upon a last access time (e.g., least recently used), access frequency, ration of cache entry size to access time, or the like. The cache metadata <b>411</b> may comprise discardability indicators to identify cache data that can be evicted or removed from the non-volatile storage media <b>410</b>. Discardable data may be cache data that has been copied (e.g., de-staged) to the backing store <b>460</b> and no longer needs to be stored on the cache.</div>
</li> <li> <para-num num="[0192]"> </para-num> <div class="description-line" id="p-0193" num="0192">Although the cache layer <b>440</b> is depicted as a separate component (separate from the storage layer <b>430</b>), the disclosure is not limited in this regard. In some embodiments, the cache layer <b>440</b> may be implemented by and/or within the storage layer <b>430</b>. Similarly, in some embodiments, the storage layer <b>430</b> and the cache layer <b>440</b> may share a common set of metadata (e.g., the metadata <b>434</b> may be combined with the cache metadata <b>442</b>). For example, the cache layer <b>440</b> may leverage the forward index <b>500</b> of the metadata <b>434</b> to maintain information regarding data access, eviction candidates, discardability, and so on.</div>
</li> <li> <para-num num="[0193]"> </para-num> <div class="description-line" id="p-0194" num="0193">Persistent notes may be used to maintain cache consistency despite losses of the volatile metadata <b>434</b> and/or <b>442</b>. In the <figref idrefs="DRAWINGS">FIG. 8E</figref> example, the non-volatile storage device <b>402</b> may be used to cache data of the backing store <b>460</b>. At step <b>890</b>, data X may be admitted into the cache (by the cache management module <b>441</b>). Admitting data X into the cache may comprise storing data X on the non-volatile storage media <b>410</b> in association with one or more logical identifiers of the backing store <b>460</b> (e.g., logical identifiers <b>905</b>-<b>912</b>). The data X may be stored on the storage unit <b>861</b> within the storage division <b>871</b>.</div>
</li> <li> <para-num num="[0194]"> </para-num> <div class="description-line" id="p-0195" num="0194">In response to admitting data X into the cache, the storage layer <b>430</b> and/or cache layer <b>440</b> may update the volatile metadata <b>434</b> and/or <b>442</b>, as described above. An entry <b>867</b> in the forward index associates the logical identifiers <b>905</b>-<b>912</b> with the physical storage unit <b>861</b>, and an entry <b>868</b> may be made in a reverse index (or bit in a validity bitmap) to indicate that the physical storage unit <b>860</b> comprises valid data.</div>
</li> <li> <para-num num="[0195]"> </para-num> <div class="description-line" id="p-0196" num="0195">At step <b>892</b>, a client <b>412</b> may modify or replace data X with X′. In response, a new copy of X′ is cached at storage unit <b>863</b> within storage division <b>873</b>, the forward index metadata <b>867</b> is updated to associate the logical identifiers <b>905</b>-<b>912</b> with the new storage unit <b>863</b>, and the reverse index metadata <b>868</b> is updated to indicate that the data of storage unit <b>861</b> is invalid and that the data of storage unit <b>863</b> is valid.</div>
</li> <li> <para-num num="[0196]"> </para-num> <div class="description-line" id="p-0197" num="0196">At step <b>894</b>, the cache layer <b>440</b> and/or cache manager <b>441</b> may de-stage data X′ to the backing store <b>460</b> and evict the data X′ from the cache. If data X′ has already been stored on the backing store <b>460</b> (e.g., in a write-through cache configuration) no de-staging may be needed. The eviction may operate similarly to a TRIM message and/or directive. The eviction may be implemented by way of a TRIM hint or a TRIM directive. The eviction may comprise logically invalidating the logical identifiers <b>905</b>-<b>912</b>, which may comprise removing the entry <b>867</b> from the forward index and invalidating entry <b>868</b> in the reverse index (and/or validity bitmap).</div>
</li> <li> <para-num num="[0197]"> </para-num> <div class="description-line" id="p-0198" num="0197">At step <b>896</b>, a storage recovery and/or grooming operation may erase the data of storage division <b>873</b> (and storage unit <b>863</b> which includes the data X′) from the non-volatile storage media <b>410</b>. The physical storage unit <b>861</b>, however, may be stored within a different storage division <b>871</b> and, as such, may remain on the non-volatile storage media <b>410</b>.</div>
</li> <li> <para-num num="[0198]"> </para-num> <div class="description-line" id="p-0199" num="0198">At step <b>898</b>, the volatile metadata is lost and is reconstructed from the sequential, log-based data on the non-volatile storage media <b>410</b>, as described above. In response to accessing storage unit <b>861</b>, the entries <b>867</b> and <b>868</b> are reconstructed. Since X′ is not on the non-volatile storage media <b>410</b>, the obsolete version of X is deemed to be the up-to-date version of the data, resulting in an inconsistency between the cache and the backing store <b>460</b>, because data X has been destaged to the backing store <b>460</b>.</div>
</li> <li> <para-num num="[0199]"> </para-num> <div class="description-line" id="p-0200" num="0199"> <figref idrefs="DRAWINGS">FIG. 8F</figref> illustrates one embodiment of a persistent note <b>879</b> used to maintain cache consistency. At step <b>891</b>, data X is admitted into the cache, as described above. At step <b>893</b>, a client <b>412</b> modifies and/or overwrites data X with X′, which is stored at storage unit <b>863</b> within storage division <b>873</b>. The entries <b>867</b> and <b>868</b> of the volatile metadata <b>434</b> are updated accordingly. At step <b>895</b>, the data X′ is destaged and evicted from the cache. At step <b>895</b>, the storage layer <b>430</b> and/or cache layer <b>440</b> may be configured to store a persistent note <b>879</b>, identifying the logical identifier(s) of the evicted data (e.g., logical identifiers <b>905</b>-<b>912</b>). In some embodiments, a persistent note may be stored in response to determining that an obsolete version of the evicted data (e.g., data X′) remains on the non-volatile storage media <b>410</b> (e.g., by scanning the volatile metadata <b>434</b> and/or the non-volatile storage media <b>410</b> itself). Alternatively, a persistent note may be stored in response to all cache eviction operations.</div>
</li> <li> <para-num num="[0200]"> </para-num> <div class="description-line" id="p-0201" num="0200">At step <b>897</b>, a grooming operation removes data X′ from the non-volatile storage media <b>410</b>, as described above. In some embodiments, the persistent note <b>879</b> may be stored in response to the grooming operation (as opposed to storing the persistent note <b>879</b> when the data X′ is evicted from the cache). The obsolete version of data X at storage unit <b>861</b> remains on the non-volatile storage media <b>410</b>, as described above.</div>
</li> <li> <para-num num="[0201]"> </para-num> <div class="description-line" id="p-0202" num="0201">At step <b>899</b>, the volatile metadata <b>434</b> is lost and is reconstructed. During reconstruction, the entries <b>867</b> and <b>868</b> are created in response to accessing storage unit <b>861</b>. In response accessing the persistent note, the logical identifiers of the obsolete version of data X may be excluded from the volatile metadata <b>434</b>, which, as discussed above, may comprise removing the entry <b>867</b> corresponding to the data from forward index and/or marking the data as invalid a reverse index entry <b>868</b>.</div>
</li> <li> <para-num num="[0202]"> </para-num> <div class="description-line" id="p-0203" num="0202">In some embodiments, each time a storage division is recovered, the persistent notes thereof (if any) are evaluated to determine whether the persistent note should remain on the non-volatile storage media <b>410</b>. Persistent notes remain on the non-volatile storage media <b>410</b> until the data referenced thereby is removed or updated. Referring back to <figref idrefs="DRAWINGS">FIG. 8D</figref>, the persistent note <b>880</b> may be removed once data B (at storage unit <b>855</b>) is removed from the non-volatile storage media (e.g., removal of data D will be indicated by the reverse index, forward index or the like).</div>
</li> <li> <para-num num="[0203]"> </para-num> <div class="description-line" id="p-0204" num="0203">Alternatively, or in addition, the persistent note <b>880</b> may be removed once data B has been overwritten and/or modified subsequent to receiving the TRIM message at step <b>872</b> (e.g., following the TRIM of data B at step <b>872</b> in the ordered sequence of storage operations on the non-volatile storage media <b>410</b>). For example, after the TRIM of data B at step <b>872</b>, a client <b>412</b> may store new, updated data in association with the logical identifiers <b>305</b>-<b>312</b>. This new data will be stored at the append point and will “overwrite” the data B associated with the logical identifiers <b>305</b>-<b>312</b> (due to being more recent (data B is at the head of the event log) in the ordered sequence of storage operations on the non-volatile storage media <b>410</b>) and, as such, the persistent note <b>880</b> is no longer needed.</div>
</li> <li> <para-num num="[0204]"> </para-num> <div class="description-line" id="p-0205" num="0204">In another example, a persistent note may be removed when the persistent note has a position in the ordered sequence earlier in log event “time”/“sequence” than a tail <b>825</b> of the ordered sequence of storage operations. In some embodiments, a groomer is configured to recover storage resources at the “tail” portion <b>825</b> of the sequence of ordered storage operations. When the tail portion <b>825</b> of the log “wraps” around and moves past the persistent note <b>880</b>, any data referenced thereby will have been removed from the non-volatile storage media <b>410</b>. Therefore, the persistent note <b>880</b> may be removed in response to determining that the persistent note <b>880</b> has a position in the ordered sequence of storage operations on the non-volatile storage media <b>410</b> that is later in the sequence than the position of the tail <b>825</b>. In some embodiments, the groomer may be configured to recover storage resources anywhere within the log (e.g., not just at the tail <b>825</b>). In this case, persistent notes may be removed when a sequence identifier of recovered data exceeds a sequence identifier of a persistent note by a pre-determined threshold.</div>
</li> <li> <para-num num="[0205]"> </para-num> <div class="description-line" id="p-0206" num="0205">As discussed above, the persistent note <b>880</b> may comprise an indication <b>888</b> of its original “log-time” (e.g., original order within the ordered sequence of storage operations performed on the non-volatile storage media <b>410</b>). When a persistent note <b>880</b> is moved to a new storage division in a grooming operation, the persistent note <b>880</b> may retain its original log-time (e.g., original sequence identifier), to allow the persistent note <b>880</b> to be removed from the non-volatile storage media <b>410</b>, as described above. The original log-time of the persistent note may be used to determine a position of the persistent note within the ordered sequence of storage operations (despite being stored at another storage division having a later sequence position in the log). Accordingly, the original log-time is used to maintain the position of the persistent note despite changes to the storage location of the persistent note.</div>
</li> <li> <para-num num="[0206]"> </para-num> <div class="description-line" id="p-0207" num="0206">In some embodiments, the storage layer <b>430</b> may maintain metadata pertaining to persistent notes on the non-volatile storage media <b>410</b> (e.g., in volatile metadata <b>434</b>). The metadata may facilitate persistent note management and/or allow the storage layer <b>430</b> to efficiently determine whether a persistent note should be retained. The persistent note metadata may include an invalidation list, comprising information pertaining to logical identifiers (and/or physical storage units) of data affected by a persistent note and/or a FIFO datastructure comprising the log-time of one or more persistent notes on the non-volatile storage media. When the data invalidated by a persistent note is removed from the invalidation list due to inter alia grooming operation and/or overwrite, the corresponding persistent note may be removed from the FIFO. The persistent note may be flagged for removal (e.g., marked as invalid in a reverse map and/or validity bitmap), in response to removal from the FIFO.</div>
</li> <li> <para-num num="[0207]"> </para-num> <div class="description-line" id="p-0208" num="0207">In some embodiments, one or more persistent notes may be consolidated into a single, composite persistent note. For example, in response to a storage division (e.g., erase block) and/or logical storage division being recovered in a grooming operation, a plurality of persistent notes that are to be retained on the non-volatile storage media <b>410</b> may be identified. The persistent notes may be small in comparison to a minimum data storage size on the non-volatile storage media <b>410</b> (e.g., a minimum packet size). Accordingly, the plurality of persistent notes for a given storage division may be consolidated into a single “summary” persistent note that indicates that data of each of a plurality of different logical identifiers (e.g., different, noncontiguous ranges within the logical address space <b>432</b>) no longer need to be retained on the non-volatile storage media <b>410</b>. The summary persistent note may further comprise respective sequence identifying information to determine a position of each persistent note within the sequence of storage operations, as described above. The summary persistent note may be stored on the non-volatile storage media <b>410</b> and/or used to reconstruct the volatile metadata <b>434</b> as described herein.</div>
</li> <li> <para-num num="[0208]"> </para-num> <div class="description-line" id="p-0209" num="0208">In some embodiments, metadata pertaining to persistent notes (e.g., data subject to a TRIM message or directive) may comprise an “anti-index.” During reconstruction of the volatile metadata <b>434</b>, the anti-index may be constructed first (before reading other data). The anti-index may then be used to selectively exclude logical identifiers from the volatile metadata <b>434</b> (e.g., selectively ignore data invalidated by one or more persistent notes). In some embodiments, the anti-index is maintained in the volatile metadata <b>434</b> during normal operations (e.g., outside of the reconstruction context). The anti-index may be periodically persisted to the non-volatile storage media <b>410</b> (along with other portions of the volatile metadata <b>434</b>), to prevent inconsistencies and/or to speed up reconstruction of the volatile metadata <b>434</b>. Alternatively, or in addition, persistent notes may be appended to predetermined storage location(s) on the non-volatile storage media (e.g., using a different append point than the append point <b>820</b>). The dedicated persistent note storage area may allow the anti-index described above to be reconstructed more quickly; the anti-index may be reconstructed by accessing the predetermined, persistent note storage location as opposed to accessing the non-volatile storage media <b>410</b> as a whole.</div>
</li> <li> <para-num num="[0209]"> </para-num> <div class="description-line" id="p-0210" num="0209"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a flow diagram of one embodiment of a method for managing storage operations on a non-volatile storage media. At step <b>910</b>, the method <b>900</b> starts and is initialized. Step <b>910</b> may comprise initializing and/or allocating resources to manage the non-volatile storage device <b>402</b>, which may include, but is not limited to: storage layers, such as the storage layer <b>430</b>, communications interfaces (e.g., bus <b>421</b>, network <b>420</b>, and so on), allocating volatile memory, and so on. Step <b>910</b> may further comprise presenting a logical address space <b>432</b>, storing data of logical identifiers on the non-volatile storage media, and maintaining volatile metadata <b>434</b> comprising associations between logical identifiers and respective physical storage units.</div>
</li> <li> <para-num num="[0210]"> </para-num> <div class="description-line" id="p-0211" num="0210">Step <b>920</b> comprises updating the volatile metadata to indicate that a logical identifier is no longer in use to reference data on the non-volatile storage device. The update may occur in response to a TRIM message, a TRIM directive, a cache eviction, or the like, as described above.</div>
</li> <li> <para-num num="[0211]"> </para-num> <div class="description-line" id="p-0212" num="0211">Step <b>930</b> comprises storing a persistent note on the non-volatile storage media to indicate that data of the logical identifier does not need to be retained on the non-volatile storage media. Step <b>930</b> may further comprise logically invalidating the logical identifier in the volatile metadata, which may include removing the logical identifier from a forward index and/or invalidating the data in a reverse index.</div>
</li> <li> <para-num num="[0212]"> </para-num> <div class="description-line" id="p-0213" num="0212">In some embodiments, step <b>930</b> comprises acknowledging a TRIM directive (or other message). The TRIM directive may be acknowledged in response to storing the persistent note on the non-volatile storage media. The method <b>900</b> ends at step <b>940</b>.</div>
</li> <li> <para-num num="[0213]"> </para-num> <div class="description-line" id="p-0214" num="0213"> <figref idrefs="DRAWINGS">FIG. 1000</figref> is a flow diagram of one embodiment of a method <b>1000</b> for managing persistent notes on a non-volatile storage media. Step <b>1010</b> comprises starting and/or initializing the method <b>1000</b> as described above. Step <b>1020</b> may comprise grooming a storage division of the non-volatile storage media <b>410</b> that comprises a persistent note.</div>
</li> <li> <para-num num="[0214]"> </para-num> <div class="description-line" id="p-0215" num="0214">Step <b>1030</b> comprises determining whether the persistent note needs to be retained on the non-volatile storage media. As discussed above, data may be stored on the non-volatile storage media in a sequential, log-based format, which defines an ordered sequence of storage operations performed on the non-volatile storage media. In some embodiments, the persistent note may be retained when data referenced by the persistent note remains on the non-volatile storage media (e.g., as indicated by the reverse index and/or other metadata, such as the persistent trim metadata, described above). Alternatively, or in addition, a persistent note may be removed in response to determining that data referenced by the persistent note has been overwritten in one or more storage operations that occurred after the persistent note in the ordered sequence of storage operations. Step <b>1030</b> may further comprise comparing a position of the persistent note in the ordered sequence of storage operations to a position of the tail <b>855</b> (e.g., the position of the groomer). The persistent note may be removed in response to determining that the position of the persistent note is earlier than the position of the tail <b>855</b>.</div>
</li> <li> <para-num num="[0215]"> </para-num> <div class="description-line" id="p-0216" num="0215">In response to determining that the persistent note is to be retained, the persistent note is copied to a new storage division (physical storage unit) at step <b>1040</b>. Step <b>1040</b> may comprise storing an original position of the persistent note in the ordered sequence of storage operations (e.g., the original sequence identifier of the persistent note). In some embodiments, step <b>1040</b> comprises consolidating two or more persistent notes into a summary persistent note, as described above. The summary persistent note may identify two or more logical identifiers (e.g., a plurality of contiguous or discontiguous ranges within the logical address space <b>432</b>) that are no longer in use to reference data on the non-volatile storage media. The summary persistent note may retain the original sequence information of each constituent persistent note, such that a position of each persistent note within the sequence of storage operations can be determined. The summary persistent note may be stored on the non-volatile storage media <b>410</b> and/or used to reconstruct the volatile metadata <b>434</b> as described above.</div>
</li> <li> <para-num num="[0216]"> </para-num> <div class="description-line" id="p-0217" num="0216">In response to determining that the persistent note does not need to be retained, the persistent note may be removed from the non-volatile storage media at step <b>1050</b>. The method <b>1000</b> ends at step <b>1060</b>.</div>
</li> <li> <para-num num="[0217]"> </para-num> <div class="description-line" id="p-0218" num="0217"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a flow diagram of one embodiment of a method for reconstructing volatile metadata from data stored in a sequential, log-based format. Step <b>1110</b> comprising starting and initializing the method <b>1100</b> as described above.</div>
</li> <li> <para-num num="[0218]"> </para-num> <div class="description-line" id="p-0219" num="0218">Step <b>1120</b> comprises accessing data on a non-volatile storage media <b>410</b>. The data may be accessed sequentially from a tail <b>825</b> to an append point <b>820</b> (e.g., according to the sequential access pattern <b>821</b>, described above). The data may be stored in the sequential, log-based format described above. Step <b>1130</b> comprises determining a logical identifier of data accessed at step <b>1120</b> using the sequential, log-based format of the data. As described above, data may be stored together with a logical identifier thereof (e.g., in a header of a data packet <b>710</b>). Step <b>1130</b> may comprise accessing the packet format of the data, and extracting the logical identifier of the data therefrom.</div>
</li> <li> <para-num num="[0219]"> </para-num> <div class="description-line" id="p-0220" num="0219">Step <b>1140</b> comprises reconstructing volatile metadata <b>434</b> using the logical identifier(s) and/or physical storage unit locations determined at step <b>1120</b>. The volatile metadata <b>434</b> may comprise a forward index of associations between logical identifiers of a logical address space <b>432</b> and physical storage units. The metadata <b>434</b> may further comprise a reverse index comprising indications of physical storage units that comprise valid and/or invalid data.</div>
</li> <li> <para-num num="[0220]"> </para-num> <div class="description-line" id="p-0221" num="0220">Step <b>1150</b> may comprise accessing a persistent note that references a specified logical identifier. Step <b>1150</b> may comprise excluding the specified logical identifier from the volatile metadata <b>1140</b>, which may comprise logically invalidating the specified logical identifier (e.g., removing the logical identifier from a forward index and/or invalidating data of the logical identifier in a reverse index), as described above. In some embodiments, step <b>1150</b> may comprise constructing and/or accessing an anti-index identifying logical identifiers that are no longer in use to reference data on the non-volatile storage media <b>410</b>, as described above. Accordingly, step <b>1150</b> may comprise scanning the non-volatile storage media <b>410</b> (and/or scanning a pre-determined portion of the non-volatile storage media <b>410</b>) to access persistent notes thereon (and construct the anti-index). Accordingly, step <b>1150</b> may comprise skipping data corresponding to logical identifier(s) identified within the anti-index.</div>
</li> <li> <para-num num="[0221]"> </para-num> <div class="description-line" id="p-0222" num="0221">Alternatively, step <b>1150</b> may comprise adding references to logical identifiers as data in accessed at step <b>1140</b>, and removing references to the data (e.g., logically invalidating the data), in response to accessing a persistent note at step <b>1150</b>. The method <b>1100</b> ends at step <b>1160</b>.</div>
</li> <li> <para-num num="[0222]"> </para-num> <div class="description-line" id="p-0223" num="0222">The above description provides numerous specific details for a thorough understanding of the embodiments described herein. However, those of skill in the art will recognize that one or more of the specific details may be omitted, or other methods, components, or materials may be used. In some cases, operations are not shown or described in detail.</div>
</li> <li> <para-num num="[0223]"> </para-num> <div class="description-line" id="p-0224" num="0223">Furthermore, the described features, operations, or characteristics may be combined in any suitable manner in one or more embodiments. It will also be readily understood that the order of the steps or actions of the methods described in connection with the embodiments disclosed may be changed as would be apparent to those skilled in the art. Thus, any order in the drawings or Detailed Description is for illustrative purposes only and is not meant to imply a required order, unless specified to require an order.</div>
</li> <li> <para-num num="[0224]"> </para-num> <div class="description-line" id="p-0225" num="0224">Embodiments may include various steps, which may be embodied in machine-executable instructions to be executed by a general-purpose or special-purpose computer (or other electronic device). Alternatively, the steps may be performed by hardware components that include specific logic for performing the steps, or by a combination of hardware, software, and/or firmware.</div>
</li> <li> <para-num num="[0225]"> </para-num> <div class="description-line" id="p-0226" num="0225">Embodiments may also be provided as a computer program product including a computer-readable storage medium having stored instructions thereon that may be used to program a computer (or other electronic device) to perform processes described herein. The computer-readable storage medium may include, but is not limited to: hard drives, floppy diskettes, optical disks, CD-ROMs, DVD-ROMs, ROMs, RAMs, EPROMs, EEPROMs, magnetic or optical cards, solid-state memory devices, or other types of medium/machine-readable medium suitable for storing electronic instructions.</div>
</li> <li> <para-num num="[0226]"> </para-num> <div class="description-line" id="p-0227" num="0226">As used herein, a software module or component may include any type of computer instruction or computer executable code located within a memory device and/or computer-readable storage medium. A software module may, for instance, comprise one or more physical or logical blocks of computer instructions, which may be organized as a routine, program, object, component, data structure, etc., that perform one or more tasks or implements particular abstract data types.</div>
</li> <li> <para-num num="[0227]"> </para-num> <div class="description-line" id="p-0228" num="0227">In certain embodiments, a particular software module may comprise disparate instructions stored in different locations of a memory device, which together implement the described functionality of the module. Indeed, a module may comprise a single instruction or many instructions, and may be distributed over several different code segments, among different programs, and across several memory devices. Some embodiments may be practiced in a distributed computing environment where tasks are performed by a remote processing device linked through a communications network. In a distributed computing environment, software modules may be located in local and/or remote memory storage devices. In addition, data being tied or rendered together in a database record may be resident in the same memory device, or across several memory devices, and may be linked together in fields of a record in a database across a network.</div>
</li> <li> <para-num num="[0228]"> </para-num> <div class="description-line" id="p-0229" num="0228">It will be understood by those having skill in the art that many changes may be made to the details of the above-described embodiments without departing from the underlying principles of the disclosure.</div>
</li> </ul>
</div>
</section><section itemprop="claims" itemscope="">
<h2>Claims (<span itemprop="count">1</span>)</h2>
<div html="" itemprop="content"><div class="claims" lang="EN" load-source="patent-office" mxw-id="PCLM180076161">
<claim-statement>We claim:</claim-statement>
<div class="claim"> <div class="claim" id="CLM-00001" num="00001">
<div class="claim-text"> <b>1</b>. A method of operating a storage layer, comprising:
<div class="claim-text">receiving a message at the storage layer which specifies a logical identifier that is no longer in use by a storage client to reference data stored on a non-volatile storage medium;</div> <div class="claim-text">storing, at the non-volatile storage medium, a persistent note configured to invalidate data stored at a storage location of the non-volatile storage medium that is assigned to the logical identifier;</div> <div class="claim-text">receiving, from the storage client, a request comprising a first logical identifier; and</div> <div class="claim-text">determining whether the first logical identifier corresponds to valid data stored on the non-volatile storage medium based on whether an entry corresponding to the first logical identifier exists in an index comprising entries corresponding to assignments between logical identifiers and physical storage locations of the non-volatile storage medium.</div> </div>
</div>
</div> </div>
</div>
</section>
                </article>
            </search-app>
        </body>
    </html>
    