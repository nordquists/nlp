
    <html>
        <body>
            <search-app>
                <article class="result" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
    <h1 itemprop="pageTitle">US20200033431A1 - Deep learning techniques for magnetic resonance image reconstruction 
      - Google Patents</h1><section itemprop="abstract" itemscope="">
<h2>Abstract</h2>
<div html="" itemprop="content"><abstract lang="EN" load-source="patent-office" mxw-id="PA363049560">
<div class="abstract" id="p-0001" num="0000">A magnetic resonance imaging (MRI) system, comprising: a magnetics system comprising: a B<sub>0 </sub>magnet configured to provide a B<sub>0 </sub>field for the MRI system; gradient coils configured to provide gradient fields for the MRI system; and at least one RF coil configured to detect magnetic resonance (MR) signals; and a controller configured to: control the magnetics system to acquire MR spatial frequency data using non-Cartesian sampling; and generate an MR image from the acquired MR spatial frequency data using a neural network model comprising one or more neural network blocks including a first neural network block, wherein the first neural network block is configured to perform data consistency processing using a non-uniform Fourier transformation.</div>
</abstract>
</div>
</section><section itemprop="description" itemscope="">
<h2>Description</h2>
<div html="" itemprop="content"><ul class="description" lang="EN" load-source="patent-office" mxw-id="PDES237970261">
<heading id="h-0001">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<li> <para-num num="[0001]"> </para-num> <div class="description-line" id="p-0002" num="0001">This application claims priority under 35 U.S.C. § 119(e) to U.S. Provisional Application Ser. No. 62/711,895, Attorney Docket No. 00354.70028US00, filed Jul. 30, 2018, and titled “DEEP LEARNING TECHNIQUES FOR MAGNETIC RESONANCE IMAGE RECONSTRUCTION”, U.S. Provisional Application Ser. No. 62/737,524, Attorney Docket No. 00354.70028US01, filed Sep. 27, 2018, and titled “DEEP LEARNING TECHNIQUES FOR MAGNETIC RESONANCE IMAGE RECONSTRUCTION”, U.S. Provisional Application Ser. No. 62/744,529, Attorney Docket No. 00354.70028US02, filed Oct. 11, 2018, and titled “DEEP LEARNING TECHNIQUES FOR MAGNETIC RESONANCE IMAGE RECONSTRUCTION”, and U.S. Provisional Application Ser. No. 62/820,119, Attorney Docket No. “00354.70039U500”, filed Mar. 18, 2019, and titled “END-TO-END LEARNABLE MR IMAGE RECONSTRUCTION”, each of which is incorporated by reference in its entirety.</div>
</li> <heading id="h-0002">BACKGROUND</heading>
<li> <para-num num="[0002]"> </para-num> <div class="description-line" id="p-0003" num="0002">Magnetic resonance imaging (MRI) provides an important imaging modality for numerous applications and is widely utilized in clinical and research settings to produce images of the inside of the human body. MRI is based on detecting magnetic resonance (MR) signals, which are electromagnetic waves emitted by atoms in response to state changes resulting from applied electromagnetic fields. For example, nuclear magnetic resonance (NMR) techniques involve detecting MR signals emitted from the nuclei of excited atoms upon the re-alignment or relaxation of the nuclear spin of atoms in an object being imaged (e.g., atoms in the tissue of the human body). Detected MR signals may be processed to produce images, which in the context of medical applications, allows for the investigation of internal structures and/or biological processes within the body for diagnostic, therapeutic and/or research purposes.</div>
</li> <li> <para-num num="[0003]"> </para-num> <div class="description-line" id="p-0004" num="0003">MRI provides an attractive imaging modality for biological imaging due to its ability to produce non-invasive images having relatively high resolution and contrast without the safety concerns of other modalities (e.g., without needing to expose the subject to ionizing radiation, such as x-rays, or introducing radioactive material into the body). Additionally, MRI is particularly well suited to provide soft tissue contrast, which can be exploited to image subject matter that other imaging modalities are incapable of satisfactorily imaging. Moreover, MR techniques are capable of capturing information about structures and/or biological processes that other modalities are incapable of acquiring. However, there are a number of drawbacks to conventional MRI techniques that, for a given imaging application, may include the relatively high cost of the equipment, limited availability (e.g., difficulty and expense in gaining access to clinical MRI scanners), and the length of the image acquisition process.</div>
</li> <li> <para-num num="[0004]"> </para-num> <div class="description-line" id="p-0005" num="0004">To increase imaging quality, the trend in clinical and research MRI has been to increase the field strength of MRI scanners to improve one or more specifications of scan time, image resolution, and image contrast, which in turn drives up costs of MRI imaging. The vast majority of installed MRI scanners operate using at least at 1.5 or 3 tesla (T), which refers to the field strength of the main magnetic field B0 of the scanner. A rough cost estimate for a clinical MRI scanner is on the order of one million dollars per tesla, which does not even factor in the substantial operation, service, and maintenance costs involved in operating such MRI scanners. Additionally, conventional high-field MRI systems typically require large superconducting magnets and associated electronics to generate a strong uniform static magnetic field (B0) in which a subject (e.g., a patient) is imaged. Superconducting magnets further require cryogenic equipment to keep the conductors in a superconducting state. The size of such systems is considerable with a typical MRI installment including multiple rooms for the magnetic components, electronics, thermal management system, and control console areas, including a specially shielded room to isolate the magnetic components of the MRI system. The size and expense of MRI systems generally limits their usage to facilities, such as hospitals and academic research centers, which have sufficient space and resources to purchase and maintain them. The high cost and substantial space requirements of high-field MRI systems results in limited availability of MRI scanners. As such, there are frequently clinical situations in which an MRI scan would be beneficial, but is impractical or impossible due to the above-described limitations and as described in further detail below.</div>
</li> <heading id="h-0003">SUMMARY</heading>
<li> <para-num num="[0005]"> </para-num> <div class="description-line" id="p-0006" num="0005">Some embodiments are directed to a method comprising: generating a magnetic resonance (MR) image from input MR spatial frequency data using a neural network model that comprises: a first neural network sub-model configured to process spatial frequency domain data; and a second neural network sub-model configured to process image domain data.</div>
</li> <li> <para-num num="[0006]"> </para-num> <div class="description-line" id="p-0007" num="0006">Some embodiments are directly to a system, comprising at least one computer hardware processor; and at least one non-transitory computer-readable storage medium storing processor-executable instructions that, when executed by the at least one computer hardware processor, cause the at least one computer hardware processor to perform: generating a magnetic resonance (MR) image from MR spatial frequency data using a neural network model. The neural network includes that comprises: a first neural network portion configured to process data in a spatial frequency domain; and a second neural network portion configured to process data in an image domain.</div>
</li> <li> <para-num num="[0007]"> </para-num> <div class="description-line" id="p-0008" num="0007">Some embodiments are directed to at least one non-transitory computer-readable storage medium storing processor-executable instructions that, when executed by at least one computer hardware processor, cause the at least one computer hardware processor to perform: generating a magnetic resonance (MR) image from MR spatial frequency data using a neural network model. The neural network model comprises a first neural network portion configured to process data in a spatial frequency domain; and a second neural network portion configured to process data in an image domain.</div>
</li> <li> <para-num num="[0008]"> </para-num> <div class="description-line" id="p-0009" num="0008">Some embodiments are directed to a method, comprising: generating a magnetic resonance (MR) image from input MR spatial frequency data using a neural network model that comprises a neural network sub-model configured to process spatial frequency domain data and having a locally connected neural network layer.</div>
</li> <li> <para-num num="[0009]"> </para-num> <div class="description-line" id="p-0010" num="0009">Some embodiments are directed to a system comprising: at least one processor; at least one non-transitory computer-readable storage medium storing processor-executable instructions that, when executed, cause the at least one processor to perform: generating a magnetic resonance (MR) image from input MR spatial frequency data using a neural network model that comprises a neural network sub-model configured to process spatial frequency domain data and having a locally connected neural network layer.</div>
</li> <li> <para-num num="[0010]"> </para-num> <div class="description-line" id="p-0011" num="0010">At least one non-transitory computer-readable storage medium storing processor-executable instructions that, when executed, cause the at least one processor to perform: generating a magnetic resonance (MR) image from input MR spatial frequency data using a neural network model that comprises a neural network sub-model configured to process spatial frequency domain data and having a locally connected neural network layer.</div>
</li> <li> <para-num num="[0011]"> </para-num> <div class="description-line" id="p-0012" num="0011">Some embodiments provide for at least one non-transitory computer-readable storage medium storing processor-executable instructions that, when executed by at least one computer hardware processor, cause the at least one computer hardware processor to perform a method comprising: generating a magnetic resonance (MR) image from input MR spatial frequency data using a neural network model comprising one or more neural network blocks including a first neural network block, wherein the first neural network block is configured to perform data consistency processing using a non-uniform Fourier transformation for transforming image domain data to spatial frequency domain data.</div>
</li> <li> <para-num num="[0012]"> </para-num> <div class="description-line" id="p-0013" num="0012">Some embodiments provide for a magnetic resonance imaging (MRI) system, comprising: a magnetics system comprising: a B<sub>0 </sub>magnet configured to provide a B<sub>0 </sub>field for the MRI system; gradient coils configured to provide gradient fields for the MRI system; and at least one RF coil configured to detect magnetic resonance (MR) signals; a controller configured to: control the magnetics system to acquire MR spatial frequency data; generate an MR image from MR spatial frequency data using a neural network model that comprises: a first neural network portion configured to process data in a spatial frequency domain; and a second neural network portion configured to process data in an image domain.</div>
</li> <li> <para-num num="[0013]"> </para-num> <div class="description-line" id="p-0014" num="0013">Some embodiments a magnetic resonance imaging (MRI) system, comprising: a magnetics system comprising: a B<sub>0 </sub>magnet configured to provide a B<sub>0 </sub>field for the MRI system; gradient coils configured to provide gradient fields for the MRI system; and at least one RF coil configured to detect magnetic resonance (MR) signals; a controller configured to: control the magnetics system to acquire MR spatial frequency data; generate an MR image from input MR spatial frequency data using a neural network model that comprises a neural network sub-model configured to process spatial frequency domain data and having a locally connected neural network layer.</div>
</li> <li> <para-num num="[0014]"> </para-num> <div class="description-line" id="p-0015" num="0014">Some embodiments provide for a method, comprising: generating a magnetic resonance (MR) image from input MR spatial frequency data using a neural network model comprising one or more neural network blocks including a first neural network block, wherein the first neural network block is configured to perform data consistency processing using a non-uniform Fourier transformation for transforming image domain data to spatial frequency domain data.</div>
</li> <li> <para-num num="[0015]"> </para-num> <div class="description-line" id="p-0016" num="0015">Some embodiments provide for a system, comprising: at least one computer hardware processor; and at least one non-transitory computer-readable storage medium storing processor-executable instructions that, when executed by the at least one computer hardware processor, cause the at least one computer hardware processor to perform a method comprising: generating a magnetic resonance (MR) image from input MR spatial frequency data using a neural network model comprising one or more neural network blocks including a first neural network block, wherein the first neural network block is configured to perform data consistency processing using a non-uniform Fourier transformation for transforming image domain data to spatial frequency domain data.</div>
</li> <li> <para-num num="[0016]"> </para-num> <div class="description-line" id="p-0017" num="0016">Some embodiments provide for a magnetic resonance imaging (MRI) system, comprising: a magnetics system comprising: a B<sub>0 </sub>magnet configured to provide a B<sub>0 </sub>field for the MRI system; gradient coils configured to provide gradient fields for the MRI system; and at least one RF coil configured to detect magnetic resonance (MR) signals; a controller configured to: control the magnetics system to acquire MR spatial frequency data using a non-Cartesian sampling trajectory; and generate an MR image from the acquired MR spatial frequency data using a neural network model comprising one or more neural network blocks including a first neural network block, wherein the first neural network block is configured to perform data consistency processing using a non-uniform Fourier transformation.</div>
</li> <li> <para-num num="[0017]"> </para-num> <div class="description-line" id="p-0018" num="0017">The foregoing is a non-limiting summary of the invention, which is defined by the attached claims.</div>
</li> <description-of-drawings>
<heading id="h-0004">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<li> <para-num num="[0018]"> </para-num> <div class="description-line" id="p-0019" num="0018">Various aspects and embodiments of the disclosed technology will be described with reference to the following figures. It should be appreciated that the figures are not necessarily drawn to scale.</div>
</li> <li> <para-num num="[0019]"> </para-num> <div class="description-line" id="p-0020" num="0019"> <figref idrefs="DRAWINGS">FIG. 1A</figref> illustrates the architecture of an example neural network model for generating a magnetic resonance (MR) image from input MR spatial frequency data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0020]"> </para-num> <div class="description-line" id="p-0021" num="0020"> <figref idrefs="DRAWINGS">FIG. 1B</figref> illustrates the architecture of another example neural network model for generating an MR image from input MR spatial frequency data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0021]"> </para-num> <div class="description-line" id="p-0022" num="0021"> <figref idrefs="DRAWINGS">FIG. 1C</figref> illustrates the architecture of yet another example neural network model for generating an MR image from input MR spatial frequency data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0022]"> </para-num> <div class="description-line" id="p-0023" num="0022"> <figref idrefs="DRAWINGS">FIG. 2A</figref> is a flowchart of an illustrative process <b>200</b> for generating an MR image from input MR spatial frequency data using a neural network model, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0023]"> </para-num> <div class="description-line" id="p-0024" num="0023"> <figref idrefs="DRAWINGS">FIG. 2B</figref> is a flowchart of an illustrative process for processing MR spatial frequency data in the spatial frequency domain, which may be part of the illustrative process <b>200</b>, to obtain output spatial frequency data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0024]"> </para-num> <div class="description-line" id="p-0025" num="0024"> <figref idrefs="DRAWINGS">FIG. 2C</figref> is a flowchart of an illustrative process for processing spatial frequency domain data, which may be part of the illustrative process <b>200</b>, to generate an MR image, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0025]"> </para-num> <div class="description-line" id="p-0026" num="0025"> <figref idrefs="DRAWINGS">FIG. 2D</figref> is a flowchart of another illustrative process for processing image domain data, which may be part of the illustrative process <b>200</b>, to generate an MR image, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0026]"> </para-num> <div class="description-line" id="p-0027" num="0026"> <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates the performance of the techniques described herein for generating an MR image from input MR spatial frequency data using a neural network model having a locally-connected layer for operating on data in the spatial frequency domain, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0027]"> </para-num> <div class="description-line" id="p-0028" num="0027"> <figref idrefs="DRAWINGS">FIG. 4</figref> illustrates the performance of the techniques described herein for generating an MR image from input MR spatial frequency data using different embodiments of the neural network model described herein.</div>
</li> <li> <para-num num="[0028]"> </para-num> <div class="description-line" id="p-0029" num="0028"> <figref idrefs="DRAWINGS">FIG. 5A</figref> illustrates the architecture of another example neural network model for generating a magnetic resonance (MR) image from input MR spatial frequency data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0029]"> </para-num> <div class="description-line" id="p-0030" num="0029"> <figref idrefs="DRAWINGS">FIG. 5B</figref> illustrates the architecture of another example neural network model for generating a magnetic resonance (MR) image from input MR spatial frequency data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0030]"> </para-num> <div class="description-line" id="p-0031" num="0030"> <figref idrefs="DRAWINGS">FIG. 5C</figref> illustrates the architecture of another example neural network model for generating a magnetic resonance (MR) image from input MR spatial frequency data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0031]"> </para-num> <div class="description-line" id="p-0032" num="0031"> <figref idrefs="DRAWINGS">FIGS. 6A-6C</figref> illustrate the distribution of weights of a fully-connected network layer in a neural network sub-model configured to process spatial frequency domain data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0032]"> </para-num> <div class="description-line" id="p-0033" num="0032"> <figref idrefs="DRAWINGS">FIG. 7</figref> illustrates results of generating MR images, from under-sampled spatial frequency domain data sampled using a non-Cartesian sampling trajectory, using the techniques described herein and a zero-padded inverse Fourier transform, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0033]"> </para-num> <div class="description-line" id="p-0034" num="0033"> <figref idrefs="DRAWINGS">FIG. 8</figref> illustrates aspects of training a neural network model for generating MR images from under-sampled spatial frequency domain data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0034]"> </para-num> <div class="description-line" id="p-0035" num="0034"> <figref idrefs="DRAWINGS">FIG. 9A</figref> illustrates aspects of generating synthetic complex-valued images for training a neural network model for generating MR images from under-sampled spatial frequency domain data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0035]"> </para-num> <div class="description-line" id="p-0036" num="0035"> <figref idrefs="DRAWINGS">FIG. 9B</figref> illustrates a loss function, having spatial frequency and image domain components, which may be used for training a neural network model for generating MR images from under-sampled spatial frequency domain data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0036]"> </para-num> <div class="description-line" id="p-0037" num="0036"> <figref idrefs="DRAWINGS">FIGS. 10A-10H</figref> illustrate reconstructed MR images using a zero-padded inverse discrete Fourier transform (DFT) and using neural network models, trained with and without transfer learning, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0037]"> </para-num> <div class="description-line" id="p-0038" num="0037"> <figref idrefs="DRAWINGS">FIG. 11</figref> illustrates performance of some of the neural network models for generating MR images from under-sampled spatial frequency domain data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0038]"> </para-num> <div class="description-line" id="p-0039" num="0038"> <figref idrefs="DRAWINGS">FIG. 12</figref> further illustrates performance of some of the neural network models for generating MR images from under-sampled spatial frequency domain data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0039]"> </para-num> <div class="description-line" id="p-0040" num="0039"> <figref idrefs="DRAWINGS">FIG. 13A</figref> is a diagram of an illustrative architecture of an example neural network model for generating MR images from input MR spatial frequency data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0040]"> </para-num> <div class="description-line" id="p-0041" num="0040"> <figref idrefs="DRAWINGS">FIG. 13B</figref> is a diagram of one type of architecture of a block of the neural network model of <figref idrefs="DRAWINGS">FIG. 13A</figref>, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0041]"> </para-num> <div class="description-line" id="p-0042" num="0041"> <figref idrefs="DRAWINGS">FIG. 13C</figref> is a diagram of an illustrative architecture of a data consistency block, which may be part of the block shown in <figref idrefs="DRAWINGS">FIG. 13B</figref>, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0042]"> </para-num> <div class="description-line" id="p-0043" num="0042"> <figref idrefs="DRAWINGS">FIG. 13D</figref> is a diagram of an illustrative architecture of a convolutional neural network block, which may be part of the block shown in <figref idrefs="DRAWINGS">FIG. 13B</figref>, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0043]"> </para-num> <div class="description-line" id="p-0044" num="0043"> <figref idrefs="DRAWINGS">FIG. 13E</figref> is a diagram of another type of architecture of a block of the neural network model of <figref idrefs="DRAWINGS">FIG. 13A</figref>, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0044]"> </para-num> <div class="description-line" id="p-0045" num="0044"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a flowchart of an illustrative process <b>1400</b> for using a neural network model to generate an MR image from input MR spatial frequency data obtained using non-Cartesian sampling, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0045]"> </para-num> <div class="description-line" id="p-0046" num="0045"> <figref idrefs="DRAWINGS">FIG. 15A</figref> illustrates T1-weighted MR images reconstructed by using conventional neural network models and neural network models, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0046]"> </para-num> <div class="description-line" id="p-0047" num="0046"> <figref idrefs="DRAWINGS">FIG. 15B</figref> illustrates T2-weighted MR images reconstructed by using conventional neural network models and neural network models, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0047]"> </para-num> <div class="description-line" id="p-0048" num="0047"> <figref idrefs="DRAWINGS">FIG. 15C</figref> illustrates reconstructed MR images at different stages of processing by neural network models, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0048]"> </para-num> <div class="description-line" id="p-0049" num="0048"> <figref idrefs="DRAWINGS">FIG. 16</figref> is a schematic illustration of a low-field MRI system, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0049]"> </para-num> <div class="description-line" id="p-0050" num="0049"> <figref idrefs="DRAWINGS">FIGS. 17A and 17B</figref> illustrate bi-planar permanent magnet configurations for a B<sub>0 </sub>magnet, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0050]"> </para-num> <div class="description-line" id="p-0051" num="0050"> <figref idrefs="DRAWINGS">FIGS. 18A and 18B</figref> illustrate views of a portable MRI system, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0051]"> </para-num> <div class="description-line" id="p-0052" num="0051"> <figref idrefs="DRAWINGS">FIG. 18C</figref> illustrates a portable MRI system performing a scan of the head, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0052]"> </para-num> <div class="description-line" id="p-0053" num="0052"> <figref idrefs="DRAWINGS">FIG. 18D</figref> illustrates a portable MRI system performing a scan of the knee, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0053]"> </para-num> <div class="description-line" id="p-0054" num="0053"> <figref idrefs="DRAWINGS">FIG. 19</figref> is a diagram of an illustrative computer system on which embodiments described herein may be implemented.</div>
</li> </description-of-drawings>
<heading id="h-0005">DETAILED DESCRIPTION</heading>
<li> <para-num num="[0054]"> </para-num> <div class="description-line" id="p-0055" num="0054">Conventional magnetic resonance imaging techniques require a time-consuming MRI scan for a patient in a tight chamber in order to obtain high-resolution cross-sectional images of the patient's anatomy. Long scan duration limits the number of patients that can be scanned with MR scanners, causes patient discomfort, and increases the cost of scanning. The inventors have developed techniques for generating medically-relevant, clinically-accepted MRI images from shorter-duration MRI scans, thereby improving conventional MRI technology.</div>
</li> <li> <para-num num="[0055]"> </para-num> <div class="description-line" id="p-0056" num="0055">The duration of an MRI scan is proportional to the number of data points acquired in the spatial frequency domain (sometimes termed “k-space”). Accordingly, one way of reducing the duration of the scan is to acquire fewer data points. For example, fewer samples may be acquired in the frequency encoding direction, the phase encoding direction, or both the frequency and phase encoding directions. However, when fewer data points are obtained than what is required by the spatial Nyquist criteria (this is often termed “under-sampling” k-space), the MR image generated from the collected data points by an inverse Fourier transform contains artifacts due to aliasing. As a result, although scanning time is reduced by under-sampling in the spatial frequency domain, the resulting MRI images have poor quality and may be unusable, as the introduced artifacts may severely degrade image quality, fidelity, and interpretability.</div>
</li> <li> <para-num num="[0056]"> </para-num> <div class="description-line" id="p-0057" num="0056">Conventional techniques for reconstructing MR images from under-sampled k-space data also suffer from drawbacks. For example, compressed sensing techniques have been applied to the problem of generating an MR image from under-sampled spatial frequency data by using a randomized k-space under-sampling trajectory that creates incoherent aliasing, which in turn is eliminated using an iterative image reconstruction process. However, the iterative reconstruction techniques require a large amount of computational resources, do not work well without extensive empirical parameter tuning, and often result in a lower-resolution MR image with lost details.</div>
</li> <li> <para-num num="[0057]"> </para-num> <div class="description-line" id="p-0058" num="0057">Deep learning techniques have also been used for reconstructing MR images from under-sampled k-space data. The neural network parameters underlying such techniques may be estimated using fully-sampled data (data collected by sampling spatial frequency space so that the Nyquist criterion is not violated) and, although training such models may be time-consuming, the trained models may be applied in real-time during acquisition because the neural network-based approach to image reconstruction is significantly more computationally efficient than the iterative reconstruction techniques utilized in the compressive sensing context.</div>
</li> <li> <para-num num="[0058]"> </para-num> <div class="description-line" id="p-0059" num="0058">The inventors have recognized that conventional deep learning MR image reconstruction techniques may be improved upon. For example, conventional deep learning MR image reconstruction techniques operate either purely in the image domain or in the spatial frequency domain and, as such, fail to take into account correlation structure both in the spatial frequency domain and in the image domain. As another example, none of the conventional deep learning MR image reconstruction techniques (nor the compressed sensing techniques described above) work with non-Cartesian (e.g., radial, spiral, rosette, variable density, Lissajou, etc.) sampling trajectories, which are commonly used to accelerate MRI acquisition and are also robust to motion by the subject. By contrast, the inventors have developed novel deep learning techniques for generating high-quality MR images from under-sampled spatial frequency data that: (1) operate both in the spatial frequency domain and in the image domain; and (2) enable reconstruction of MR images from non-Cartesian sampling trajectories. As described herein, the deep learning techniques developed by the inventors improve upon conventional MR image reconstruction techniques (including both compressed sensing and deep learning techniques) and improve MR scanning technology by reducing the duration of scans while generating high quality MR images.</div>
</li> <li> <para-num num="[0059]"> </para-num> <div class="description-line" id="p-0060" num="0059">Some embodiments described herein address all of the above-described issues that the inventors have recognized with conventional techniques for generating MR images from under-sampled spatial frequency domain data. However, not every embodiment described below addresses every one of these issues, and some embodiments may not address any of them. As such, it should be appreciated that embodiments of the technology provided herein are not limited to addressing all or any of the above-described issues of conventional techniques for generating MR images from under-sampled spatial frequency domain data.</div>
</li> <li> <para-num num="[0060]"> </para-num> <div class="description-line" id="p-0061" num="0060">Accordingly, some embodiments provide for a method of generating an MR image from under-sampled spatial frequency domain data, the method comprising generating a magnetic resonance (MR) image from input MR spatial frequency data using a neural network model that comprises: (1) a first neural network sub-model configured to process spatial frequency domain data; and (2) a second neural network sub-model configured to process image domain data. In this way, the techniques described herein operate both in the spatial-frequency and image domains.</div>
</li> <li> <para-num num="[0061]"> </para-num> <div class="description-line" id="p-0062" num="0061">In some embodiments, the first neural network sub-model is applied prior to the second neural network sub-model. In this way, a neural network is applied to spatial-frequency domain data, prior to transforming the spatial-frequency domain data to the image domain, to take advantage of the correlation structure in the spatial frequency domain data. Accordingly, in some embodiments, generating the MR image may include: (1) processing the input MR spatial frequency data using the first neural network sub-model to obtain output MR spatial frequency data; (2) transforming the output MR spatial frequency data to the image domain to obtain input image-domain data; and (3) processing the input image-domain data using the second neural network sub-model to obtain the MR image.</div>
</li> <li> <para-num num="[0062]"> </para-num> <div class="description-line" id="p-0063" num="0062">In some embodiments, the first neural network sub-model may include one or more convolutional layers. In some embodiments, one or more (e.g., all) of the convolutional layers may have a stride greater than one, which may provide for down-sampling of the spatial-frequency data. In some embodiments, the first neural network sub-model may include one or more transposed convolutional layers, which may provide for up-sampling of the spatial frequency data. Additionally or alternatively, the first neural network sub-model may include at least one locally-connected layer, at least one data consistency layer, and/or at least one complex-conjugate symmetry layer. In some embodiments, the locally-connected layer may include a respective set of parameter values for each data point in the MR spatial frequency data.</div>
</li> <li> <para-num num="[0063]"> </para-num> <div class="description-line" id="p-0064" num="0063">In some embodiments, the first neural network sub-model includes at least one convolutional layer, a locally-connected layer, and at least one transposed convolutional layer, and processing the input MR spatial frequency data using the first neural network sub-model may include: (1) applying the at least one convolutional layer to the input MR spatial frequency data; (2) applying the locally-connected layer to data obtained using output of the at least one convolutional layer; and (3) applying the at least one transposed convolutional layer to data obtained using output of the locally-connected layer. In such embodiments, the first neural network sub-model may be thought of as having a “U” structure consisting of a down-sampling path (the left arm of the “U”—implemented using a series of convolutional layers one or more of which have a stride greater than one), a locally-connected layer (the bottom of the “U”), and an up-sampling path (the right arm of the “U”—implemented using a series of transposed convolutional layers).</div>
</li> <li> <para-num num="[0064]"> </para-num> <div class="description-line" id="p-0065" num="0064">In some embodiments, using a transposed convolutional layer (which is sometimes termed a fractionally sliding convolutional layer or a deconvolutional layer) may lead to checkerboard artifacts in the upsampled output. To address this issue, in some embodiments, upsampling may be performed by a convolutional layer in which the kernel size is divisible by the stride length, which may be thought of a “sub-pixel” convolutional layer. Alternatively, in other embodiments, upsampling to a higher resolution may be performed without relying purely on a convolutional layer to do so. For example, the upsampling may be performed by resizing the input image (e.g., using interpolation such as bilinear interpolation or nearest-neighbor interpolation) and following this operation by a convolutional layer. It should be appreciated that such an approach may be used in any of the embodiments described herein instead of and/or in conjunction with a transposed convolutional layer.</div>
</li> <li> <para-num num="[0065]"> </para-num> <div class="description-line" id="p-0066" num="0065">In some embodiments, the first neural network sub-model further takes into account the complex-conjugate symmetry of the spatial frequency data by including a complex-conjugate symmetry layer. In some such embodiments, the complex-conjugate symmetry layer may be applied at the output of the transposed convolutional layers so that processing the input MR spatial frequency data using the first neural network sub-model includes applying the complex-conjugate symmetry layer to data obtained using output of the at least one transposed convolutional layer.</div>
</li> <li> <para-num num="[0066]"> </para-num> <div class="description-line" id="p-0067" num="0066">In some embodiments, the first neural network sub-model further includes a data consistency layer to ensure that the application of first neural network sub-model to the spatial frequency data does not alter the values of the spatial frequency data obtained by the MR scanner. In this way, the data consistency layer forces the first neural network sub-model to interpolate missing data from the under-sampled spatial frequency data without perturbing the under-sampled spatial frequency data itself. In some embodiments, the data consistency layer may be applied to the output of the complex-conjugate symmetry layer.</div>
</li> <li> <para-num num="[0067]"> </para-num> <div class="description-line" id="p-0068" num="0067">In some embodiments, the first neural network sub-model includes a residual connection. In some embodiments, the first neural network sub-model includes one or more non-linear activation layers. In some embodiments, the first neural network sub-model includes a rectified linear unit activation layer. In some embodiments, the first neural network sub-model includes a leaky rectified linear unit activation layer.</div>
</li> <li> <para-num num="[0068]"> </para-num> <div class="description-line" id="p-0069" num="0068">The inventors have also recognized that improved MR image reconstruction may be achieved by generating MR images directly from spatial frequency data samples, without gridding the spatial frequency data, as is often done in conventional MR image reconstruction techniques. In gridding, the obtained spatial frequency data points are mapped to a two-dimensional (2D) Cartesian grid (e.g., the value at each grid point is interpolated from data points within a threshold distance) and a 2D discrete Fourier transform (DFT) is used to reconstruct the image from the grid values. However, such local interpolation introduces reconstruction errors.</div>
</li> <li> <para-num num="[0069]"> </para-num> <div class="description-line" id="p-0070" num="0069">The inventors have developed multiple deep-learning techniques for reconstructing MR images from data obtained using non-Cartesian sampling trajectories. Some of the techniques involve using a non-uniform Fourier transformation (e.g., a non-uniform fast Fourier transformation—NuFFT) at each of multiple blocks part of a neural network model in order to promote data consistency with the (ungridded) spatial frequency data obtained by an MRI system. Such data consistency processing may be performed in a number of different ways, though each may make use of the non-uniform Fourier transformation (e.g., as represented by the forward operator A described herein), and the input MR spatial frequency data y. For example, in some embodiments, a non-uniform Fourier transformation may be used in a neural network model block to transform image domain data, which represents the MR reconstruction in the block, to spatial frequency data so that the MR reconstruction in the block may be compared with the spatial frequency data obtained by the MRI system. A neural network model implementing this approach may be termed the non-uniform variational network (NVN) and is described herein including with reference to <figref idrefs="DRAWINGS">FIGS. 13A-13D</figref>.</div>
</li> <li> <para-num num="[0070]"> </para-num> <div class="description-line" id="p-0071" num="0070">As another example, in some embodiments, the non-uniform Fourier transformation may be applied to the spatial frequency data, and the result may be provided as input to each of one or more neural network blocks of a neural network model for reconstructing MR images from spatial frequency data. These innovations provide for a state-of-the art deep learning technique for reconstructing MR images from spatial frequency data obtained using a non-Cartesian sampling trajectory. A neural network model implementing this approach may be termed the generalized non-uniform variational network (GNVN) and is described herein including with reference to <figref idrefs="DRAWINGS">FIGS. 13A, 13D, and 13E</figref>.</div>
</li> <li> <para-num num="[0071]"> </para-num> <div class="description-line" id="p-0072" num="0071">Accordingly, some embodiments provide a method for generating a magnetic resonance (MR) image from input MR spatial frequency data using a neural network model comprising one or more neural network blocks including a first neural network block, wherein the first neural network block is configured to perform data consistency processing using a non-uniform Fourier transformation (e.g., a non-uniform fast Fourier transform—NuFFT) for transforming image domain data to spatial frequency domain data. The MR spatial frequency data may have been obtained using a non-Cartesian sampling trajectory, examples of which are provided herein. In some embodiments, the neural network model may include multiple blocks each of which is configured to perform data consistency processing using the non-uniform Fourier transformation.</div>
</li> <li> <para-num num="[0072]"> </para-num> <div class="description-line" id="p-0073" num="0072">In some embodiments, the method for generating the MR image from input MR spatial frequency data includes: obtaining the input MR spatial frequency data; generating an initial image from the input MR spatial frequency data using the non-uniform Fourier transformation; and applying the neural network model to the initial image at least in part by using the first neural network block to perform data consistency processing using the non-uniform Fourier transformation.</div>
</li> <li> <para-num num="[0073]"> </para-num> <div class="description-line" id="p-0074" num="0073">In some embodiments, the data consistency processing may involve applying a data consistency block to the data, which may apply a non-uniform Fourier transformation to the data to transform it from the image domain to the spatial frequency domain where it may be compared against the input MR spatial frequency data. In other embodiments, the data consistency processing may involve applying an adjoint non-uniform Fourier transformation to the input MR spatial frequency data and providing the result as the input to each of one or more neural network blocks (e.g., as input to each of one or more convolutional neural network blocks part of the overall neural network model).</div>
</li> <li> <para-num num="[0074]"> </para-num> <div class="description-line" id="p-0075" num="0074">In some embodiments, the first neural network block is configured to perform data consistency processing using the non-uniform Fourier transformation at least in part by performing the non-uniform Fourier transformation on data by applying a gridding interpolation transformation, a fast Fourier transformation, and a de-apodization transformation to the data. In this way, the non-uniform Fourier transformation A is represented as a composition of three transformations—a gridding interpolation transformation G, a fast Fourier transformation F<sub>s</sub>, and a de-apodization transformation D such that A=G F<sub>s </sub>D, and applying A to the data may be performed by applying the transformation D, F<sub>s</sub>, and G, to the data in that order (e.g., as shown in <figref idrefs="DRAWINGS">FIG. 13C</figref>). The gridding interpolation transformation may be determined based on the non-Cartesian sampling trajectory used to obtain the initial MR input data. In some embodiments, applying the gridding interpolation transformation to the data may be performed using sparse graphical processing unit (GPU) matrix multiplication. Example realizations of these constituent transformations are described herein.</div>
</li> <li> <para-num num="[0075]"> </para-num> <div class="description-line" id="p-0076" num="0075">In some embodiments, the neural network model to reconstruct MR images from spatial frequency data may include multiple neural network blocks each of which includes: (1) a data consistency block configured to perform the data consistency processing; and (2) a convolutional neural network block comprising one or more convolutional layers (e.g., having one or more convolutional and/or transpose convolutional layers, having a U-net structure, etc.). Such a neural network model may be termed herein as a non-uniform variational network (NVN).</div>
</li> <li> <para-num num="[0076]"> </para-num> <div class="description-line" id="p-0077" num="0076">In some embodiments, the data consistency block is configured to apply the non-uniform Fourier transformation to a first image, provided as input to the data consistency block, to obtain first MR spatial frequency data; and apply an adjoint non-uniform Fourier transformation to a difference between the first MR spatial frequency data and the input MR spatial frequency data. In some embodiments, applying the non-uniform Fourier transformation to the first image domain data comprises: applying, to the first image domain data, a de-apodization transformation followed by a Fourier transformation, and followed by a gridding interpolation transformation.</div>
</li> <li> <para-num num="[0077]"> </para-num> <div class="description-line" id="p-0078" num="0077">In some embodiments, applying the first neural network block to image domain data, the applying comprising: applying the data consistency block to image domain data to obtain first output; applying the plurality of convolutional layers to the image domain data to obtain second output; and determining a linear combination of the first and second output.</div>
</li> <li> <para-num num="[0078]"> </para-num> <div class="description-line" id="p-0079" num="0078">In some embodiments, the neural network model to reconstruct MR images from spatial frequency data may include multiple neural network blocks each of which includes a plurality of convolutional layers configured to receive as input: (1) image domain data (e.g., representing the networks current reconstruction of the MR data); and (2) output obtained by applying an adjoint non-uniform Fourier transformation to the input MR spatial frequency data. Such a neural network model may be termed herein as a non-uniform variational network (GNVN). In some embodiments, the plurality of convolutional layers is further configured to receive as input: output obtained by applying the non-uniform Fourier transformation and the adjoint non-uniform Fourier transformation to the image domain data.</div>
</li> <li> <para-num num="[0079]"> </para-num> <div class="description-line" id="p-0080" num="0079">Another approach developed by the inventors for reconstructing an MR image from input MR spatial frequency data, but without the use of gridding, is to use at least one fully connected layer in the spatial frequency domain. Accordingly, in some embodiments, the first neural network sub-model may include at least one fully connected layer that is to be applied directly to the spatial frequency data points obtained by the scanner. The data points are not mapped to a grid (through gridding and/or any other type of local interpolation) prior to the application of the at least one fully connected layer. In some embodiments, the data points may be irregularly spaced prior to application of the at least one fully connected layer.</div>
</li> <li> <para-num num="[0080]"> </para-num> <div class="description-line" id="p-0081" num="0080">In some of the embodiments in which the first neural network sub-model includes a fully-connected layer, the fully connected layer is applied to the real part of the spatial frequency domain data, and the same fully-connected layer is applied to the imaginary part of the spatial frequency domain data. In other words, the data is channelized and the same fully connected layer is applied to both the real and imaginary data channels.</div>
</li> <li> <para-num num="[0081]"> </para-num> <div class="description-line" id="p-0082" num="0081">Alternatively, in some of the embodiments in which the first neural network sub-model includes a fully connected layer, the first neural network sub-model includes a first fully-connected layer for applying to the real part of the spatial frequency domain data and a second fully-connected layer for applying to the imaginary part of the spatial frequency domain data. In some embodiments, the first and second fully-connected layers share at least some parameter values (e.g., weights). In some embodiments, the output of the first and second fully-connected layers is transformed using a Fourier transformation (e.g., a two-dimensional inverse discrete Fourier transformation) to obtain image-domain data. In turn, the image-domain data may be provided as input to the second neural network sub-model.</div>
</li> <li> <para-num num="[0082]"> </para-num> <div class="description-line" id="p-0083" num="0082">The mention of a 2D Fourier transformation in the preceding paragraph should not be taken to imply that the techniques described herein are limited to operating on two-dimensional data (e.g., on spatial frequency domain and/or image domain data corresponding to a 2D MR image of a brain “slice”). In some embodiments, the techniques described herein may be applied to 3D data (e.g., spatial frequency domain and/or image domain data corresponding to a stack of 2D MR images of different respective brain slices).</div>
</li> <li> <para-num num="[0083]"> </para-num> <div class="description-line" id="p-0084" num="0083">In some embodiments, batch normalization may be applied to the output of fully-connected layer(s) prior to using the Fourier transformation to obtain image-domain data.</div>
</li> <li> <para-num num="[0084]"> </para-num> <div class="description-line" id="p-0085" num="0084">In some embodiments, the second neural network sub-model comprises at least one convolutional layer and at least one transposed convolutional layer. In some embodiments, the second neural network sub-model comprises a series of blocks comprising respective sets of neural network layers, each of the plurality of blocks comprising at least one convolutional layer and at least one transposed convolutional layer. In some embodiments, each of the plurality of blocks further comprises: a Fourier transformation layer, a data consistency layer, and an inverse Fourier transformation layer.</div>
</li> <li> <para-num num="[0085]"> </para-num> <div class="description-line" id="p-0086" num="0085">In some embodiments, the neural network model used for generating MR images from under-sampled spatial frequency data may be trained using a loss function comprising a spatial frequency domain loss function and an image domain loss function. In some embodiments, the loss function is a weighted sum of the spatial frequency domain loss function and the image domain loss function. In some embodiments, the spatial frequency domain loss function includes mean-squared error.</div>
</li> <li> <para-num num="[0086]"> </para-num> <div class="description-line" id="p-0087" num="0086">In some embodiments, the techniques described herein may be used for generating MR images from under-sampled spatial frequency data may be adapted for application to spatial frequency data collected using a low-field MRI system, including, by way of example and not limitation, any of the low-field MR systems described herein and in U.S. Patent Application Publication No. “2018/0164390”, titled “ELECTROMAGNETIC SHIELDING FOR MAGNETIC RESONANCE IMAGING METHODS AND APPARATUS,” which is incorporated by reference herein in its entirety.</div>
</li> <li> <para-num num="[0087]"> </para-num> <div class="description-line" id="p-0088" num="0087">As used herein, “high-field” refers generally to MRI systems presently in use in a clinical setting and, more particularly, to MRI systems operating with a main magnetic field (i.e., a B<sub>0 </sub>field) at or above 1.5 T, though clinical systems operating between 0.5 T and 1.5 T are often also characterized as “high-field.” Field strengths between approximately 0.2 T and 0.5 T have been characterized as “mid-field” and, as field strengths in the high-field regime have continued to increase, field strengths in the range between 0.5 T and 1 T have also been characterized as mid-field. By contrast, “low-field” refers generally to MRI systems operating with a B<sub>0 </sub>field of less than or equal to approximately 0.2 T, though systems having a B<sub>0 </sub>field of between 0.2 T and approximately 0.3 T have sometimes been characterized as low-field as a consequence of increased field strengths at the high end of the high-field regime. Within the low-field regime, low-field MRI systems operating with a B<sub>0 </sub>field of less than 0.1 T are referred to herein as “very low-field” and low-field MRI systems operating with a B<sub>0 </sub>field of less than 10 mT are referred to herein as “ultra-low field.”</div>
</li> <li> <para-num num="[0088]"> </para-num> <div class="description-line" id="p-0089" num="0088">In order to train the neural network models described herein to generate MR images from (e.g., under-sampled) spatial frequency data obtained by a low-field MRI system, training data obtained using the low-field MRI system is needed. However, there are few low-field MRI scanners on the market and little low-field MRI data available for training such neural network models. To address this limitation, the inventors have developed a novel two-stage training technique for training a neural network model for generating MR images from spatial frequency data obtained by a low-field MRI system. In the first stage, the neural network model (e.g., any of the neural network models described herein having a first and a second neural network sub-model) is trained using a set of images obtained using a “high-field” or a “mid-field” MR system and, subsequently, be adapted by using a set of images obtained using a low-field MRI system.</div>
</li> <li> <para-num num="[0089]"> </para-num> <div class="description-line" id="p-0090" num="0089">Following below are more detailed descriptions of various concepts related to, and embodiments of, methods and apparatus for generating MR images from spatial frequency domain data. It should be appreciated that various aspects described herein may be implemented in any of numerous ways. Examples of specific implementations are provided herein for illustrative purposes only. In addition, the various aspects described in the embodiments below may be used alone or in any combination, and are not limited to the combinations explicitly described herein.</div>
</li> <li> <para-num num="[0090]"> </para-num> <div class="description-line" id="p-0091" num="0090"> <figref idrefs="DRAWINGS">FIG. 1A</figref> illustrates the architecture of an example neural network model for generating a magnetic resonance (MR) image from input MR spatial frequency data, in accordance with some embodiments of the technology described herein. As shown in <figref idrefs="DRAWINGS">FIG. 1A</figref>, the neural network model <b>100</b> comprises first neural network sub-model <b>102</b> configured to process spatial frequency domain data, inverse fast Fourier transform (IFFT) layer <b>112</b> configured to transform spatial frequency domain data to image domain data, and second neural network sub-model <b>120</b> configured to process image domain data. After initial spatial frequency MR data is obtained using an MR scanner (e.g., using any of the low-field MR scanners described herein or any other suitable type of MR scanner), the initial spatial frequency MR data may be processed using the first neural network sub-model <b>102</b> to obtain output MR spatial frequency data <b>111</b>. The MR spatial frequency data <b>111</b> is then transformed by IFFT layer <b>112</b> to obtain input image-domain data <b>113</b>, which is processed by second neural network sub-model <b>120</b> to obtain an MR image <b>127</b>.</div>
</li> <li> <para-num num="[0091]"> </para-num> <div class="description-line" id="p-0092" num="0091">As shown in <figref idrefs="DRAWINGS">FIG. 1A</figref>, the first neural network sub-model <b>102</b> includes one or more convolutional layers <b>104</b>, a locally-connected layer <b>106</b>, one or more transposed convolutional layers <b>108</b>, a residual connection <b>109</b>, complex-conjugate symmetry layer <b>105</b> and a data consistency layer <b>110</b>.</div>
</li> <li> <para-num num="[0092]"> </para-num> <div class="description-line" id="p-0093" num="0092">When the first neural network sub-model <b>102</b> is applied to initial MR spatial frequency data, the initial MR spatial frequency data is first processed by one or more convolutional layers <b>104</b>, then by locally-connected layer <b>106</b>, then by transposed convolutional layers <b>108</b>. In some embodiments the convolutional layer(s) <b>104</b> may be used to downsample the data and the transposed convolutional layers may be used to upsample the data. In such embodiments, these three processing steps may be considered as providing a “U” shaped neural network architecture, with the convolutional layer(s) <b>104</b> providing a down-sampling path (left arm of the “U”), the locally-connected layer <b>106</b> being at the bottom of the “U”, and the transposed convolutional layers <b>108</b> providing an up-sampling path (right arm of the “U”).</div>
</li> <li> <para-num num="[0093]"> </para-num> <div class="description-line" id="p-0094" num="0093">In the illustrated embodiment of <figref idrefs="DRAWINGS">FIG. 1A</figref>, the convolutional layer(s) <b>104</b> include m<sub>0 </sub>convolutional layers. In some embodiments, m0 may be 1, 2, 3, 4, 5, or any number of layers between 1 and 20 layers. In some embodiments, one or more of the m0 convolutional layers may have a stride greater than or equal to one. In some embodiments, one or more of the m0 convolutional layers has a stride greater than one, which provides for down-sampling or pooling the data through processing by such layers.</div>
</li> <li> <para-num num="[0094]"> </para-num> <div class="description-line" id="p-0095" num="0094">In the illustrated embodiment of <figref idrefs="DRAWINGS">FIG. 1A</figref>, the transposed convolutional layer(s) <b>108</b> include m<sub>0 </sub>transposed convolutional layers. In the illustrated embodiment of <figref idrefs="DRAWINGS">FIG. 1A</figref>, the number of convolutional layer(s) <b>104</b> and the number of transposed convolutional layer(s) <b>108</b> is the same, but the number of convolutional and transposed convolutional layers may be different in other embodiments.</div>
</li> <li> <para-num num="[0095]"> </para-num> <div class="description-line" id="p-0096" num="0095">In some embodiments, the locally-connected layer <b>106</b> is provided to exploit local correlation with K-space. In some embodiments, the locally-connected layer <b>106</b> is not a convolutional layer (where the same set of weights is applied across different portions of the data), but instead has a respective set of weights for each data point in the spatial frequency domain data. In the illustrated embodiment of <figref idrefs="DRAWINGS">FIG. 1A</figref>, the locally-connected layer is placed between the down-sampling and up-samplings paths at the bottom of the “U” structure so that it would have fewer parameters (since the resolution of the data is the lowest at this point), which reduces the number of parameters that have to be learned during training.</div>
</li> <li> <para-num num="[0096]"> </para-num> <div class="description-line" id="p-0097" num="0096">In some embodiments, the locally-connected layer may account for energy density variations in the spatial frequency domain (e.g., the center region in the spatial frequency domain has a higher energy density than the peripheral region). In the illustrative embodiment of <figref idrefs="DRAWINGS">FIG. 1A</figref>, the locally-connected layer <b>106</b> operates in the spatial frequency domain and works to interpolate the missing data (due to under-sampling) directly in the spatial frequency domain. In practice, the locally-connected layer, which has far fewer parameters than a fully-connected layer, but more parameters than convolutional layer, provides a good balance between training time and capability to interpolate the missing data points using the local contextual correlation of the spatial frequency domain data.</div>
</li> <li> <para-num num="[0097]"> </para-num> <div class="description-line" id="p-0098" num="0097">It should be appreciated that using a locally-connected layer to account for energy density variations in the spatial frequency domain is a novel approach developed by the inventors. Previous approaches split the spatial-frequency domain into three square regions, and the data in each of the three regions was input into a separate model consisting of a stack of convolutional layers (so three separate models for three different square regions). By contrast, using a locally-connected layer does not involve partitioning k space into three square regions, and instead involves assigning independent weights for each sign pixel, which accounts for the various energy density in a more general and flexible manner than previous approaches, resulting in a performance improvement.</div>
</li> <li> <para-num num="[0098]"> </para-num> <div class="description-line" id="p-0099" num="0098"> <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates the performance improvement obtained by generating an MR image from input MR spatial frequency data using a neural network model having a locally-connected layer. As can be seen in middle column of <figref idrefs="DRAWINGS">FIG. 3</figref>, the MR image generated from a convolutional layer model without a locally-connected layer generates artifacts (artificial streaks) that deteriorate the image quality. By contrast, as shown in the right column of <figref idrefs="DRAWINGS">FIG. 3</figref>, using a neural network model having a sub-model with a locally-connected layer (e.g., locally connected layer <b>106</b>) eliminates such artifacts and produces an image closer to the original image (left column of <figref idrefs="DRAWINGS">FIG. 3</figref>) in terms of mean-squared error.</div>
</li> <li> <para-num num="[0099]"> </para-num> <div class="description-line" id="p-0100" num="0099">Returning back to <figref idrefs="DRAWINGS">FIG. 1A</figref>, after data is processed by the layers <b>104</b>, <b>106</b>, and <b>108</b>, the data is provided to a complex-conjugate symmetry layer <b>105</b>, also termed the k-space symmetry layer, whose output is provided as input to data consistency layer <b>110</b>. The output of the data consistency layer <b>110</b>, which is also the output of the first neural network sub-model, is then provided as input to IFFT layer <b>112</b>.</div>
</li> <li> <para-num num="[0100]"> </para-num> <div class="description-line" id="p-0101" num="0100">In some embodiments, the complex-conjugate symmetry layer <b>105</b> performs interpolation based on the complex-conjugate symmetry in the spatial frequency domain (whereby S(x, y)=S′(−x, −y) with (x,y) being coordinates of a data point and S′ representing the complex conjugation of S). In some embodiments, applying the complex-conjugate symmetry layer <b>105</b> to spatial frequency domain data involves symmetrically mapping any missing points from existing samples. For example, if a value were obtained for point (x,y), but no corresponding value were obtained for point (−x,−y), the complex-conjugate symmetry layer may be used to provide the value for point (−x,−y) as the complex-conjugate of the obtained value for the point (x,y). Using the complex-conjugate symmetry layer <b>105</b> accelerates the convergence of training the neural network model and improves the quality of images produces by the neural network model, as illustrated in the right panel of <figref idrefs="DRAWINGS">FIG. 4</figref>. Indeed, as shown in the right panel of <figref idrefs="DRAWINGS">FIG. 4</figref>, using the complex-conjugate symmetry layer allows fewer training epochs to be used when training the neural network model while obtaining improved model performance, which is measured in this illustrative example by relative pixel intensity variation in the center region of the images between the model reconstructed image and the fully-sampled image.</div>
</li> <li> <para-num num="[0101]"> </para-num> <div class="description-line" id="p-0102" num="0101">In some embodiments, the data consistency layer <b>110</b> may be used to ensure that the application of first neural network sub-model to the spatial frequency data does not alter the values of the spatial frequency data obtained by the MR scanner. To the extent any such value was modified by other layers in the first neural network sub-model (e.g., by convolutional layer(s) <b>104</b>, locally connected layer <b>106</b>, and transposed convolutional layer(s) <b>108</b>), the modified values are replaced by the original values. In this way, the data consistency layer forces the first neural network sub-model to interpolate missing data from the under-sampled spatial frequency data without perturbing the under-sampled spatial frequency data itself.</div>
</li> <li> <para-num num="[0102]"> </para-num> <div class="description-line" id="p-0103" num="0102">In some embodiments, any of the neural network layers may include an activation function, which may be non-linear. In some embodiments, the activation function may be a rectified linear unit (ReLU) activation function, a leaky ReLU activation function, a hyperbolic tangent, a sigmoid, or any other suitable activation function, as aspects of the technology described herein are not limited in this respect. For example, one or more of the convolutional layer(s) <b>104</b> may include an activation function.</div>
</li> <li> <para-num num="[0103]"> </para-num> <div class="description-line" id="p-0104" num="0103">After the spatial frequency data is processed by the data consistency layer <b>110</b>, the data is provided as input to the IFFT layer <b>112</b>, which transforms the spatial frequency data to the image domain—the output is initial image domain data <b>113</b>. The transformation may be performed using a discrete Fourier transform, which may be implemented using a fast Fourier transformation, in some embodiments. The initial image domain data <b>113</b>, output by the IFFT layer <b>112</b>, is provided as input to the second neural sub-model <b>120</b>.</div>
</li> <li> <para-num num="[0104]"> </para-num> <div class="description-line" id="p-0105" num="0104">As shown in <figref idrefs="DRAWINGS">FIG. 1A</figref> the second neural network sub-model <b>120</b> includes multiple convolutional blocks <b>122</b>, <b>124</b>, and <b>126</b>. Convolutional block <b>122</b> may include one or more convolutional layers <b>128</b>, an FFT layer <b>130</b>, a complex-conjugate symmetry layer <b>105</b>, a data consistency layer, an IFFT layer <b>134</b> and a residual connection. Each of the blocks <b>122</b>, <b>124</b>, and <b>126</b> may have the same neural network architecture (e.g., these blocks may have the same types of layers arranged in the same sequence), though the various parameter values for the layers may vary (e.g., the weights of the convolutional layers in block <b>122</b> may be different from that of block <b>124</b>). Although in the illustrative embodiment of <figref idrefs="DRAWINGS">FIG. 1A</figref>, the second neural network sub-model <b>120</b> includes three convolutional blocks, this is by way of example, as in other embodiments the second neural network sub-model <b>120</b> may include any suitable number of convolutional blocks (e.g., 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, or 15), as aspects of the technology described herein are not limited in this respect.</div>
</li> <li> <para-num num="[0105]"> </para-num> <div class="description-line" id="p-0106" num="0105">When the second neural network sub-model <b>120</b> is applied to initial image domain data <b>113</b> obtained at the output of the IFFT block <b>112</b>, the convolutional blocks <b>122</b>, <b>124</b>, and <b>126</b> are applied to initial image domain data <b>113</b> in that order. The application of convolutional block <b>122</b> is described next, and it should be appreciated that the convolutional blocks <b>124</b> and <b>126</b> may be applied in a similar way to the image domain data provided as input to them.</div>
</li> <li> <para-num num="[0106]"> </para-num> <div class="description-line" id="p-0107" num="0106">As shown in <figref idrefs="DRAWINGS">FIG. 1A</figref>, convolutional block <b>122</b> includes at least one convolutional layer <b>128</b>, followed by an FFT layer <b>130</b>, a complex-conjugate symmetry layer <b>105</b>, data consistency layer <b>132</b>, and IFFT layer <b>134</b>.</div>
</li> <li> <para-num num="[0107]"> </para-num> <div class="description-line" id="p-0108" num="0107">In some embodiments, convolutional block <b>128</b> includes one or more convolutional layers with stride greater than 1 (e.g., 2 or greater) to downsample the image, followed by one or more transposed convolutional layers with stride greater than 1 (e.g., 2 or greater), which upsample the image to its original size. This structure of down-sampling followed by up-sampling allows operations to be performed at different resolutions, which helps the neural network model to capture both local and global features. In turn, this helps to eliminate image artifacts that may result from under-sampling in the spatial frequency domain. In this illustrative embodiment, the convolutional layers do not include skip connections, which may consume a substantial amount of memory. For example, in some embodiments, convolutional block <b>128</b> has five layers with the number of filters being 16, 32, 64, 32, and 2, respectively. In some embodiments, each of the filters may be a 3×3 filter with a Leaky ReLU activation, though in other embodiments different size filters and/or different activation functions may be used.</div>
</li> <li> <para-num num="[0108]"> </para-num> <div class="description-line" id="p-0109" num="0108">The impact of variable resolution layers is shown in <figref idrefs="DRAWINGS">FIG. 4</figref>, left panel. Indeed, as shown in the left panel of <figref idrefs="DRAWINGS">FIG. 4</figref>, using the variable resolution layers allows fewer training epochs to be used when training the neural network model while obtaining improved model performance, which is measured in this illustrative example by relative pixel intensity variation in the center region of the images between the model reconstructed image and the fully-sampled image.</div>
</li> <li> <para-num num="[0109]"> </para-num> <div class="description-line" id="p-0110" num="0109">As shown in the illustrative embodiment of <figref idrefs="DRAWINGS">FIG. 1A</figref>, after the convolutional layers of convolutional block <b>122</b> are applied, the data may be transformed into the spatial frequency domain so that the complex-conjugate symmetry and the data consistency blocks may be applied, after which the data is transformed back into the image domain, and one or more other convolutional blocks may be applied.</div>
</li> <li> <para-num num="[0110]"> </para-num> <div class="description-line" id="p-0111" num="0110">In the embodiment illustrated in <figref idrefs="DRAWINGS">FIG. 1A</figref>, each of the convolutional blocks <b>122</b>, <b>124</b>, and <b>126</b> includes complex-conjugate symmetry and data consistency blocks. However, in other embodiments, one or more (or all) of the convolutional blocks part of second neural network sub-model <b>120</b> may not have either one or both of these blocks, as aspects of the technology described herein are not limited in this respect.</div>
</li> <li> <para-num num="[0111]"> </para-num> <div class="description-line" id="p-0112" num="0111"> <figref idrefs="DRAWINGS">FIG. 1B</figref> illustrates the architecture of another example neural network model <b>140</b> for generating MR images from input MR spatial frequency data, in accordance with some embodiments of the technology described herein. Neural network model <b>140</b> has a first neural network sub-model <b>142</b> with a convolutional layer <b>146</b> instead of a locally-connected layer (e.g., in contrast with first neural network sub-model <b>102</b> of model <b>100</b> that has a locally connected layer <b>106</b>). Such an embodiment may be advantageous as the convolutional layer <b>142</b> has fewer parameters to learn during training than the locally-connected layer <b>106</b>. In other respects, neural network models <b>140</b> and <b>100</b> are the same.</div>
</li> <li> <para-num num="[0112]"> </para-num> <div class="description-line" id="p-0113" num="0112"> <figref idrefs="DRAWINGS">FIG. 1C</figref> illustrates the architecture of yet another example neural network model <b>150</b> for generating MR images from input MR spatial frequency data, in accordance with some embodiments of the technology described herein. Neural network model <b>150</b> has a first neural network sub-model <b>152</b>, with convolutional block <b>154</b> and transposed convolutional block <b>158</b>. However, unlike corresponding convolutional block <b>104</b> and transposed convolutional block <b>108</b> of neural network model <b>100</b>, the convolutional blocks <b>154</b> and <b>158</b> contain convolutional (and transposed convolutional) layers using a stride of 1. As a result, the first neural network sub-model <b>152</b> does not perform up-sampling or down-sampling. Such an architecture may be advantageous when there is a large volume of training data available.</div>
</li> <li> <para-num num="[0113]"> </para-num> <div class="description-line" id="p-0114" num="0113"> <figref idrefs="DRAWINGS">FIG. 2A</figref> is a flowchart of an illustrative process <b>200</b> for generating an MR image from input MR spatial frequency data using a neural network model, in accordance with some embodiments of the technology described herein. Process <b>200</b> may be implemented using any suitable neural network architecture described herein including any of the neural network architectures described with reference to <figref idrefs="DRAWINGS">FIGS. 1A-1C and 5A-5C</figref>. Process <b>200</b> may be executed using any suitable computing device(s), as aspects of the technology described herein are not limited in this respect. For example, in some embodiments, process <b>200</b> may be executed by a computing device communicatively coupled to or part of an MR imaging system.</div>
</li> <li> <para-num num="[0114]"> </para-num> <div class="description-line" id="p-0115" num="0114">Process <b>200</b> begins at act <b>202</b>, where spatial frequency domain data is obtained. In some embodiments, the spatial frequency domain data may be obtained by using an MR scanner including any of the MR scanners described herein. In other embodiments, the spatial frequency domain data may have been obtained by an MR scanner prior to the execution of process <b>200</b>, stored, and the stored data may be accessed during act <b>202</b>.</div>
</li> <li> <para-num num="[0115]"> </para-num> <div class="description-line" id="p-0116" num="0115">In some embodiments, the spatial frequency domain data may be under-sampled relative to the Nyquist sampling criterion. For example, in some embodiments, the spatial frequency domain data may include less than 90% (or less than 80%, or less than 75%, or less than 70%, or less than 65%, or less than 60%, or less than 55%, or less than 50%, or less than 40%, or less than 35%, or any percentage between 25 and 100) of the number of data samples required by the Nyquist criterion.</div>
</li> <li> <para-num num="[0116]"> </para-num> <div class="description-line" id="p-0117" num="0116">The spatial frequency domain data obtained at act <b>202</b> may be (or may have been) obtained by an MR scanner using any suitable pulse sequence and sampling scheme. For example, in some embodiments, the spatial frequency domain data may be gathered using a Cartesian sampling scheme. In other embodiments, the spatial frequency domain data may be gathered using a non-Cartesian sampling scheme (e.g., radial, spiral, rosette, Lissajou, etc.).</div>
</li> <li> <para-num num="[0117]"> </para-num> <div class="description-line" id="p-0118" num="0117">Next, process <b>200</b> proceeds to act <b>204</b>, where the MR spatial frequency data obtained at act <b>202</b> is processed using a first neural network sub-model (e.g., sub-model <b>102</b> described with reference to <figref idrefs="DRAWINGS">FIG. 1A</figref>, sub-model <b>142</b> described with reference to <figref idrefs="DRAWINGS">FIG. 1B</figref>, sub-model <b>152</b> described with reference to <figref idrefs="DRAWINGS">FIG. 1C</figref>, sub-model <b>502</b> described with reference to <figref idrefs="DRAWINGS">FIG. 5A</figref>, sub-model <b>522</b> described with reference to <figref idrefs="DRAWINGS">FIG. 5B</figref>, and sub-model <b>532</b> described with reference to <figref idrefs="DRAWINGS">FIG. 5C</figref>). Illustrative examples of how act <b>204</b> may be implemented are described with reference to <figref idrefs="DRAWINGS">FIGS. 2B and 2C</figref>.</div>
</li> <li> <para-num num="[0118]"> </para-num> <div class="description-line" id="p-0119" num="0118">Next, process <b>200</b> proceeds to act <b>206</b>, where the spatial frequency domain data obtained at the completion of act <b>204</b> is transformed to obtain initial image domain data (e.g., using a Fourier transformation).</div>
</li> <li> <para-num num="[0119]"> </para-num> <div class="description-line" id="p-0120" num="0119">Next, process <b>200</b> proceeds to act <b>208</b>, where initial the image domain data obtained at the completion of act <b>206</b> is processed a second neural network sub-model (e.g., sub-model <b>120</b> described with reference to <figref idrefs="DRAWINGS">FIG. 1A</figref>, sub-model <b>510</b> described with reference to <figref idrefs="DRAWINGS">FIG. 5A</figref>) to generate an MR image. An illustrative example of how act <b>208</b> may be implemented is described with reference to <figref idrefs="DRAWINGS">FIG. 2D</figref>.</div>
</li> <li> <para-num num="[0120]"> </para-num> <div class="description-line" id="p-0121" num="0120"> <figref idrefs="DRAWINGS">FIG. 2B</figref> is a flowchart of an illustrative process for processing MR spatial frequency data in the spatial frequency domain, which may be part of the illustrative process <b>200</b>, to obtain output spatial frequency data, in accordance with some embodiments of the technology described herein. In particular, <figref idrefs="DRAWINGS">FIG. 2B</figref> shows an illustrative embodiment for implementing act <b>204</b> of process <b>200</b>.</div>
</li> <li> <para-num num="[0121]"> </para-num> <div class="description-line" id="p-0122" num="0121">As shown in <figref idrefs="DRAWINGS">FIG. 2B</figref>, act <b>204</b> may be implemented using acts <b>212</b>-<b>218</b>. At act <b>212</b>, one or more convolutional layers may be applied to the spatial frequency domain data obtained at act <b>202</b>. In some embodiments, the convolutional layer(s) applied at act <b>212</b> may be part of block <b>104</b> described with reference to <figref idrefs="DRAWINGS">FIG. 1A</figref> or block <b>154</b> described with reference to <figref idrefs="DRAWINGS">FIG. 1C</figref>. In some embodiments, the convolutional layer(s) may include any suitable number of layers including any number of layers in the range of 1-20 layers. In some embodiments, the convolutional layer(s) may be implemented using a stride greater than one (e.g., 2) to downsample the data. In other embodiments, the convolutional layer(s) may be implemented using a stride of 1.</div>
</li> <li> <para-num num="[0122]"> </para-num> <div class="description-line" id="p-0123" num="0122">Next, at act <b>214</b>, a locally connected layer is applied to spatial frequency domain data obtained at the completion of act <b>212</b>. In some embodiments, the local convolutional layer may be the local convolutional layer <b>106</b> described with reference to <figref idrefs="DRAWINGS">FIG. 1A</figref>. In some embodiments, the locally-connected layer has a respective set of weights for each data point in the spatial frequency domain data.</div>
</li> <li> <para-num num="[0123]"> </para-num> <div class="description-line" id="p-0124" num="0123">Next, at act <b>216</b>, one or more transposed convolutional layers are applied to spatial frequency domain data obtained at the completion of act <b>214</b>. In some embodiments, the transposed convolutional layer(s) may be the transposed convolutional layer(s) part of block <b>108</b> described with reference to <figref idrefs="DRAWINGS">FIG. 1A</figref> or block <b>158</b> described with reference to <figref idrefs="DRAWINGS">FIG. 1C</figref>. In some embodiments, the transposed convolutional layer(s) may upsample the data.</div>
</li> <li> <para-num num="[0124]"> </para-num> <div class="description-line" id="p-0125" num="0124">Next, at act <b>218</b>, a complex conjugate symmetry layer is applied to the spatial frequency domain data output at the completion of act <b>216</b>. In some embodiments, the complex conjugate symmetry layer may be the complex conjugate symmetry layer <b>105</b> described with reference to <figref idrefs="DRAWINGS">FIG. 1A</figref>. As described herein, applying the complex-conjugate symmetry layer <b>105</b> to spatial frequency domain data may involve symmetrically mapping any missing points from existing samples. For example, if a value were obtained for point (x,y), but no corresponding value were obtained for point (−x,−y), the complex-conjugate symmetry layer may be used to provide the value for point (−x,−y) as the complex-conjugate of the obtained value for the point (x,y).</div>
</li> <li> <para-num num="[0125]"> </para-num> <div class="description-line" id="p-0126" num="0125">Next, at act <b>220</b>, a data consistency layer is applied to the spatial frequency domain data output at the completion of act <b>218</b>. In some embodiments, the data consistency layer may be the data consistency layer <b>110</b> described with reference to <figref idrefs="DRAWINGS">FIG. 1A</figref>. As described herein, the data consistency layer may be used to ensure that the application of first neural network sub-model to the spatial frequency data does not alter the values of the spatial frequency data obtained by the MR scanner.</div>
</li> <li> <para-num num="[0126]"> </para-num> <div class="description-line" id="p-0127" num="0126"> <figref idrefs="DRAWINGS">FIG. 2C</figref> is a flowchart of an illustrative process for processing spatial frequency data, which may be part of the illustrative process <b>200</b>, to generate an MR image, in accordance with some embodiments of the technology described herein. In particular, <figref idrefs="DRAWINGS">FIG. 2C</figref> shows another illustrative embodiment for implementing act <b>204</b> of process <b>200</b>.</div>
</li> <li> <para-num num="[0127]"> </para-num> <div class="description-line" id="p-0128" num="0127">As shown in <figref idrefs="DRAWINGS">FIG. 2C</figref>, act <b>204</b> may be implemented using acts <b>222</b> and <b>224</b>. At act <b>222</b>, one or more fully connected layers are applied to the spatial frequency data obtained at act <b>202</b>. In some embodiments, the fully connected layer(s) applied at act <b>222</b> may be fully connected layer <b>502</b> described with reference to <figref idrefs="DRAWINGS">FIG. 5A</figref>. As described herein, the fully connected layer represents a learned mapping from non-Cartesian to Cartesian coordinates from data, which allows MR images to be reconstructed from non-Cartesian samples without relying on conventional gridding or other interpolation schemes, which are not data dependent.</div>
</li> <li> <para-num num="[0128]"> </para-num> <div class="description-line" id="p-0129" num="0128">In some embodiments, at act <b>222</b>, the spatial frequency data obtained at act <b>202</b> is split into real and imaginary portions and the same fully connected layer is applied to each of the two portions. Equivalently, one may consider these data as being provided to a fully connected layer with shared weights for the real and imaginary channels. Such a weight sharing scheme ensures that the same interpolation operation is applied to both the real and imaginary channels, which preserves the underlying spatial frequency domain symmetry throughout the process. In addition, sharing the weights between the real and imaginary portions reduces the number of trainable parameters in the model by a factor of two. However, in other embodiments, the spatial frequency data may be fed to a fully connected layer with partial or no weight sharing between the real and imaginary channels.</div>
</li> <li> <para-num num="[0129]"> </para-num> <div class="description-line" id="p-0130" num="0129">Next, at act <b>224</b>, batch normalization is applied so that the subsequent layer receives input having a substantially 0 mean and a substantially unit (or any other suitable constant) variance.</div>
</li> <li> <para-num num="[0130]"> </para-num> <div class="description-line" id="p-0131" num="0130">It should be appreciated that the process of <figref idrefs="DRAWINGS">FIG. 2C</figref> is illustrative and that there are variations. For example, in some embodiments, the batch normalization may be omitted.</div>
</li> <li> <para-num num="[0131]"> </para-num> <div class="description-line" id="p-0132" num="0131"> <figref idrefs="DRAWINGS">FIG. 2D</figref> is a flowchart of another illustrative process for processing image-domain data, which may be part of the illustrative process <b>200</b>, to generate an MR image, in accordance with some embodiments of the technology described herein. In particular, <figref idrefs="DRAWINGS">FIG. 2D</figref> shows an illustrative embodiment for implementing act <b>208</b> of process <b>200</b>.</div>
</li> <li> <para-num num="[0132]"> </para-num> <div class="description-line" id="p-0133" num="0132">As shown in <figref idrefs="DRAWINGS">FIG. 2D</figref>, act <b>208</b> may be implemented using acts <b>230</b>-<b>236</b> and decision block <b>238</b>. In particular, at act <b>230</b>, one or more convolutional layers are applied to image domain data obtained at act <b>206</b> by transforming spatial frequency domain data to the image domain. In some embodiments, the convolutional layer(s) applied at act <b>230</b> may be part of block <b>128</b> shown in <figref idrefs="DRAWINGS">FIG. 1A</figref> or block <b>512</b> shown in <figref idrefs="DRAWINGS">FIG. 5A</figref>. In some embodiments, the convolutional layer(s) may include any suitable number of layers including any number of layers in the range of 1-20 layers. In some embodiments, the convolutional layer(s) may be implemented using a stride greater than one (e.g., <b>2</b>) to downsample the data. In other embodiments, the convolutional layer(s) may be implemented using a stride of 1.</div>
</li> <li> <para-num num="[0133]"> </para-num> <div class="description-line" id="p-0134" num="0133">Next, at act <b>232</b>, one or more transposed convolutional layers may be applied to the image-domain data output at the completion of act <b>230</b>. In some embodiments, the transposed convolutional layer(s) applied at act <b>232</b> may be part of transpose block <b>128</b> shown in <figref idrefs="DRAWINGS">FIG. 1A</figref> or block <b>512</b> shown in <figref idrefs="DRAWINGS">FIG. 5A</figref>. In some embodiments, the convolutional layer(s) may include any suitable number of layers including any number of layers in the range of 1-20 layers. In some embodiments, the transposed convolutional layer(s) may be implemented to upsample the data (e.g., using a fractional stride).</div>
</li> <li> <para-num num="[0134]"> </para-num> <div class="description-line" id="p-0135" num="0134">Next, at act <b>234</b>, a complex-conjugate symmetry layer may be applied to the data. As the complex-conjugate symmetry layer is applied in the spatial frequency domain, the image domain data output at the completion of act <b>232</b> is transformed to the spatial frequency domain prior to the application of the complex-conjugate symmetry layer. In some embodiments, the complex conjugate symmetry layer may be the complex-conjugate symmetry layer <b>105</b> described with reference to <figref idrefs="DRAWINGS">FIG. 1A</figref>.</div>
</li> <li> <para-num num="[0135]"> </para-num> <div class="description-line" id="p-0136" num="0135">Next, at act <b>236</b>, a data consistency layer may be applied to the data. In some embodiments, the data consistency layer may be applied to spatial frequency domain data output at completion of act <b>234</b>. In other embodiments, if act <b>234</b> were omitted, the image domain data output at the completion of act <b>232</b> may be transformed to the spatial frequency domain and the data consistency layer may be applied thereto. In some embodiments, the data consistency layer may be the data consistency layer <b>110</b> described with reference to <figref idrefs="DRAWINGS">FIG. 1A</figref>.</div>
</li> <li> <para-num num="[0136]"> </para-num> <div class="description-line" id="p-0137" num="0136">Next, at decision block <b>238</b>, a determination is made as to whether one or more additional image-domain processing blocks are to be applied. When it is determined that no further blocks are to be applied, the process completes. Otherwise, the process returns to act <b>230</b>, via the “YES” branch, and acts <b>230</b>-<b>236</b> and decision block <b>238</b> are repeated. For example, as shown in <figref idrefs="DRAWINGS">FIG. 1A</figref>, after block <b>122</b> is applied to the image domain data, it may be determined that block <b>124</b> is to be applied to the data.</div>
</li> <li> <para-num num="[0137]"> </para-num> <div class="description-line" id="p-0138" num="0137">It should be appreciated that the process of <figref idrefs="DRAWINGS">FIG. 2D</figref> is illustrative and that there are variations. For example, in some embodiments, the image-domain data may be processed purely in the image domain without application of the complex-conjugate symmetry layer and the data consistency layer.</div>
</li> <li> <para-num num="[0138]"> </para-num> <div class="description-line" id="p-0139" num="0138"> <figref idrefs="DRAWINGS">FIG. 5A</figref> illustrates the architecture of another example neural network model <b>500</b> for generating a magnetic resonance (MR) image from input MR spatial frequency data, in accordance with some embodiments of the technology described herein.</div>
</li> <li> <para-num num="[0139]"> </para-num> <div class="description-line" id="p-0140" num="0139">As shown in <figref idrefs="DRAWINGS">FIG. 5A</figref>, the neural network model <b>500</b> comprises first neural network sub-model <b>502</b> configured to process spatial frequency domain data, inverse fast Fourier transform (IFFT) layer <b>508</b> configured to transform spatial frequency domain data to image domain data, and second neural network sub-model <b>510</b> configured to process image domain data. After initial spatial frequency MR data is obtained using an MR scanner (e.g., using any of the low-field MR scanners described herein or any other suitable type of MR scanner), the initial spatial frequency MR data may be processed using the first neural network sub-model <b>502</b> to obtain output MR spatial frequency data <b>511</b>. The MR spatial frequency data <b>511</b> is then transformed by IFFT layer <b>508</b> to obtain initial image-domain data <b>513</b>, which is processed by second neural network sub-model <b>510</b> to obtain an MR image <b>518</b>.</div>
</li> <li> <para-num num="[0140]"> </para-num> <div class="description-line" id="p-0141" num="0140">As shown in <figref idrefs="DRAWINGS">FIG. 5A</figref>, the initial spatial frequency domain MR data is split into a real portion <b>504</b> (e.g., magnitudes of the complex-valued data) and imaginary portion <b>506</b> (e.g., phases of the complex-valued data). The first neural network sub-model <b>502</b> includes a fully connected layer that operates on the real portion <b>504</b> and imaginary portion <b>506</b>. In the embodiment shown in <figref idrefs="DRAWINGS">FIG. 5A</figref>, the fully connected layer shares weights between the real and imaginary channels. As such, the fully connected layer applies the same operations to both the real and imaginary channels, which preserves the underlying spatial frequency domain symmetry throughout the process. In addition, sharing the weights between the real and imaginary portions reduces the number of trainable parameters in the model by a factor of two. However, in other embodiments (e.g., the embodiment of <figref idrefs="DRAWINGS">FIG. 5C</figref>), the spatial frequency data may be fed to a fully connected layer with partial or no weight sharing between the real and imaginary channels.</div>
</li> <li> <para-num num="[0141]"> </para-num> <div class="description-line" id="p-0142" num="0141">In some embodiments, when the neural network model including the fully-connected layer is trained using input MR images generated using the same sample trajectory, the fully-connected layer learns a data-dependent mapping from non-Cartesian to Cartesian coordinates, which can be used to perform a data-dependent gridding of non-Cartesian spatial-frequency data that may be generated by an MR scanner operating in accordance with a non-Cartesian sequence. This is illustrated further in <figref idrefs="DRAWINGS">FIGS. 6A-6C</figref>.</div>
</li> <li> <para-num num="[0142]"> </para-num> <div class="description-line" id="p-0143" num="0142"> <figref idrefs="DRAWINGS">FIG. 6A</figref> shows an illustrative embodiment in which each data point in the spatial frequency domain has a corresponding 128×128 weight matrix having a weight for each location in a 128×128 output k-space, creating a non-local interpolation. The distribution of weights for three spatial frequency domain data points (#300, #2800, and #5000) is shown in <figref idrefs="DRAWINGS">FIG. 6B</figref>. The 2D distributions of these same three data points are shown in <figref idrefs="DRAWINGS">FIG. 6C</figref>, with zoomed-in views to show the details of the weight distribution.</div>
</li> <li> <para-num num="[0143]"> </para-num> <div class="description-line" id="p-0144" num="0143">As shown in the 1D and 2D weight distributions of <figref idrefs="DRAWINGS">FIGS. 6B-6C</figref>, when plotting a two-dimensional weight map of a particular spatial frequency domain data point, it is predominantly the weights in a local neighborhood of the data point that have non-negligible values, with other weights having values close to zero. The weight distribution indicates that the mapping performed by the fully-connected layer performs a local interpolation. It should be noted that the first neural network sub-model <b>502</b> does not include a data consistency layer, which allows the first neural network sub-model <b>502</b> to process non-Cartesian samples.</div>
</li> <li> <para-num num="[0144]"> </para-num> <div class="description-line" id="p-0145" num="0144">Returning to <figref idrefs="DRAWINGS">FIG. 5A</figref>, after the spatial frequency data is processed by the first neural network model <b>502</b>, the data is provided as input to the IFFT layer <b>508</b>, which transforms the spatial frequency data to the image domain—the output is initial image domain data <b>513</b>. The transformation may be performed using a discrete Fourier transform, which may be implemented using a fast Fourier transformation, in some embodiments. The initial image domain data <b>513</b>, output by the IFFT layer <b>508</b>, is provided as input to the second neural sub-model <b>510</b>.</div>
</li> <li> <para-num num="[0145]"> </para-num> <div class="description-line" id="p-0146" num="0145">As shown in <figref idrefs="DRAWINGS">FIG. 5A</figref> the second neural network sub-model <b>510</b> includes multiple convolutional blocks <b>512</b>, <b>514</b>, and <b>516</b>. Convolutional block <b>512</b> may include one or more convolutional layers and a residual connection. Each of the convolutional blocks <b>512</b>, <b>514</b>, and <b>516</b> may have the same neural network architecture (e.g., these blocks may have the same types of layers arranged in the same sequence), though the various parameter values for the layers may vary (e.g., the weights of the convolutional layers in block <b>512</b> may be different from that of block <b>514</b>). Although in the illustrative embodiment of <figref idrefs="DRAWINGS">FIG. 5A</figref> the second neural network sub-model <b>510</b> includes three convolutional blocks, this is by way of example, as in other embodiments the second neural network sub-model <b>510</b> may include any suitable number of convolutional blocks (e.g., 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, or 15), as aspects of the technology described herein are not limited in this respect.</div>
</li> <li> <para-num num="[0146]"> </para-num> <div class="description-line" id="p-0147" num="0146">When the second neural network sub-model <b>510</b> is applied to initial image domain data <b>513</b> obtained at the output of the IFFT block <b>508</b>, the convolutional blocks <b>512</b>, <b>514</b>, and <b>516</b> are applied to initial image domain data <b>513</b> in that order. The application of convolutional block <b>512</b> is described next, and it should be appreciated that the convolutional blocks <b>514</b> and <b>516</b> may be applied in a similar way to the image domain data provided as input to them (after being output from the preceding block).</div>
</li> <li> <para-num num="[0147]"> </para-num> <div class="description-line" id="p-0148" num="0147">In some embodiments, convolutional block <b>512</b> includes one or more convolutional layers with stride greater than 1 (e.g., 2 or greater) to downsample the image, followed by one or more transposed convolutional layers with stride greater than 1 (e.g., 2 or greater), which upsample the image to its original size. This structure of down-sampling followed by up-sampling allows operations to be performed at different resolutions, which helps the neural network model to capture both local and global features. In turn, this helps to eliminate image artifacts that may result from under-sampling in the spatial frequency domain.</div>
</li> <li> <para-num num="[0148]"> </para-num> <div class="description-line" id="p-0149" num="0148">For example, in some embodiments, convolutional block <b>512</b> may include two sequential convolutional layers (having 32 3×3 and 64 3×3 filters in the two respective layers, with stride 2), followed by two transposed convolutional layers (128 3×3 and 64 3×3 filters in the two respective layers, with stride 2), followed by a final convolutional layer (2 3×3 filters with stride 1). A non-linear activation (e.g., a ReLU or a Leaky ReLU activation) may be applied in each of the first four layers, except for the final convolutional layer. Though, it should be appreciated that in other embodiments, different size filters and/or different activation functions may be used, as aspects of the technology described herein are not limited in this respect.</div>
</li> <li> <para-num num="[0149]"> </para-num> <div class="description-line" id="p-0150" num="0149"> <figref idrefs="DRAWINGS">FIG. 5B</figref> illustrates the architecture of another example neural network model <b>520</b> for generating a magnetic resonance (MR) image from input MR spatial frequency data, in accordance with some embodiments of the technology described herein. Neural network <b>520</b> has a first neural network sub-model <b>522</b> with a batch normalization layer <b>507</b> following application of the fully connected layer and prior to the output of data from the first neural network sub-model <b>522</b> to the IFFT layer <b>508</b>. Introducing a batch normalization layer at this juncture improves the performance of the neural network and may reduce the time required for training. In other respects, neural network models <b>520</b> and <b>500</b> are the same.</div>
</li> <li> <para-num num="[0150]"> </para-num> <div class="description-line" id="p-0151" num="0150"> <figref idrefs="DRAWINGS">FIG. 5C</figref> illustrates the architecture of another example neural network model <b>530</b> for generating a magnetic resonance (MR) image from input MR spatial frequency data, in accordance with some embodiments of the technology described herein. Neural network <b>530</b> has a first neural network sub-model <b>532</b> which includes a fully connected layer that does not use weight sharing between the real and imaginary portions of the obtained MR data. In other respects, neural network models <b>530</b> and <b>500</b> are the same.</div>
</li> <li> <para-num num="[0151]"> </para-num> <div class="description-line" id="p-0152" num="0151">The inventors have developed a novel non-Cartesian sampling trajectory to accelerate acquisition of spatial domain data, while retaining as much information as possible. The sampling trajectory consists of unstructured triangular and tetrahedral meshes to evenly under-sample the entire spatial frequency domain, and a fully sampling grid in the k-space center generated by a Gaussian kernel, as full coverage of the k-space center is important for reconstructions of images with low signal-to-noise ratio (SNR). This sampling trajectory samples 33% of the spatial frequency domain samples need to satisfy the Nyquist criterion (though as described above a sampling trajectory may be used with any other percentage described herein, including for example any percentage in the range of 25-100, such as 35%, 40%, 45%, 50%, 55%, 60%, 65%, 70%, 75%, 80%, etc.). K-space. <figref idrefs="DRAWINGS">FIG. 7</figref> illustrates the novel non-Cartesian sampling trajectory (panel <b>702</b>), the image reconstructed from samples obtained using the trajectory of panel <b>702</b> and a zero-padded inverse fast Fourier transform (panel <b>704</b>), the image reconstructed from samples obtained using the trajectory of panel <b>702</b> and the neural network model described with reference to <figref idrefs="DRAWINGS">FIG. 5B</figref> (panel <b>706</b>), and the original MR image. As can be seen from panels <b>704</b> and <b>706</b>, the MR image obtained using a zero-padded IFFT is blurred and has artifacts, while the MR image obtained using the neural network model of <figref idrefs="DRAWINGS">FIG. 5B</figref> does not suffer from these drawbacks.</div>
</li> <li> <para-num num="[0152]"> </para-num> <div class="description-line" id="p-0153" num="0152">The inventors have developed specialized techniques for training the neural network models described herein. The training procedure involves generating complex image data, under-sampling the complex image data, and using pairs of under-sampled and fully sampled complex image data to train the neural network model using any suitable training techniques (e.g., stochastic gradient descent and back-propagation). In order to generate complex image data, magnitude images were used to synthesize the phase information, as described below.</div>
</li> <li> <para-num num="[0153]"> </para-num> <div class="description-line" id="p-0154" num="0153"> <figref idrefs="DRAWINGS">FIG. 8</figref> illustrates aspects of training a neural network model for generating MR images from under-sampled spatial frequency domain data, in accordance with some embodiments of the technology described herein. As shown in <figref idrefs="DRAWINGS">FIG. 8</figref>, the training process involves using input magnitude images to synthesize the phase information. The magnitude and phase information that constitute the complex image data which can be retrospectively under-sampled in the spatial frequency domain using Cartesian or a non-Cartesian (e.g., radial. etc.) sampling trajectory. The under-sampled data will be used as the input to the neural network model being trained, while the full-sampled image will be the output of the model.</div>
</li> <li> <para-num num="[0154]"> </para-num> <div class="description-line" id="p-0155" num="0154">Although there are many publicly available MR image datasets available, they typically only include magnitude images. To simulate complex data as acquired by an MR scanner, the inventors have developed a technique for generating phase information to append to the magnitude images. Accordingly, in some embodiments, phase information is generated using a weighted sum of spherical harmonic basis functions. The combination of these functions can characterize magnetic field variation derived from inhomogeneity of the B<sub>0</sub>, magnetic field drifting with temperature, gradient eddy currents, spatially-varying RF coil sensitivity fields, inaccuracies in gradient fields in sequences and/or other effects that may contribute to phase variation. The process of generating phase information using spherical harmonics is illustrated in <figref idrefs="DRAWINGS">FIG. 9A</figref>.</div>
</li> <li> <para-num num="[0155]"> </para-num> <div class="description-line" id="p-0156" num="0155">In some embodiments, to simulate non-Cartesian under-sampling, a non-uniform FFT (NuFFT) was used to transform MR images to the spatial-frequency domain where a non-Cartesian under-sampling mask was applied. In turn, the under-sampled spatial frequency data can be converted to the image domain using an inverse (also called backward) NuFFT, which can be provided as input to the image-domain sub-models. In this way, the use of NuFFT, enables performing non-uniform K-space sampling, which highly resembles the non-Cartesian sampling in practice.</div>
</li> <li> <para-num num="[0156]"> </para-num> <div class="description-line" id="p-0157" num="0156">In some embodiments, the available training data was augmented by applying affine transformations to individual slices to create images with different orientation and size, adding noise to create images with different SNR, introducing motion artifacts, incorporating phase and/or signal modulation for more complex sequences like echo trains, and/or modeling the dephasing of the signal to adapt the model to a sequence like diffusion weighted imaging.</div>
</li> <li> <para-num num="[0157]"> </para-num> <div class="description-line" id="p-0158" num="0157">As the neural network models described herein operate both in the spatial frequency domain and in the image domain, the inventors have developed a new loss function to facilitate training such a mixed-domain neural network model. The new loss function accelerated the process of training the neural network models described herein (e.g., by reducing the number of training epochs needed to achieve a given level of performance).</div>
</li> <li> <para-num num="[0158]"> </para-num> <div class="description-line" id="p-0159" num="0158">In some embodiments, the loss function includes a first loss function to capture error in the spatial frequency domain and a second loss function to capture error in the image domain. For example, as shown in <figref idrefs="DRAWINGS">FIG. 9B</figref>, the output of the first neural network sub-model (labeled as “Subnet 1 k-Space”) may be compared to ground truth in the spatial frequency domain to obtain a first measure of error (e.g., mean squared error, labeled “MSE Loss 1”) in the spatial frequency domain, and the output of the second neural network sub-model (labeled as “Subnet 2 Image domain”) may be compared to ground truth in the image domain to obtain a second measure of error (e.g., mean squared error, labeled “MSE Loss 2”) in the image domain. The first and second measures of error may be combined (e.g., via a weighted combination) to produce an overall measure of error, which is to be minimized during the training process. For example, in the illustrative example of <figref idrefs="DRAWINGS">FIG. 9</figref>, the two loss functions were combined using a weight of λ&lt;1 such that the overall loss function was given by Loss1+λ*Loss2.</div>
</li> <li> <para-num num="[0159]"> </para-num> <div class="description-line" id="p-0160" num="0159">As described herein, in order to train the neural network models developed by the inventors to generate MR images from under-sampled spatial frequency data obtained by a low-field MRI system, training data obtained using the low-field MRI system is needed. However, there may not be a sufficient volume of such data to learn all the parameters of the models described herein.</div>
</li> <li> <para-num num="[0160]"> </para-num> <div class="description-line" id="p-0161" num="0160">Accordingly, in some embodiments, a neural network model is first trained using images obtained using one or more “high-field” and/or a “mid-field” MR systems and then transfer learning is used to adapt the trained neural network model to the “low-field” context by using one or more MR images obtained using a low-field MRI system.</div>
</li> <li> <para-num num="[0161]"> </para-num> <div class="description-line" id="p-0162" num="0161"> <figref idrefs="DRAWINGS">FIGS. 10A-10H</figref> illustrates MR images generated using a zero-padded inverse DFT and using neural network models, trained with and without transfer learning, in accordance with some embodiments of the technology described herein. The results show that using transfer learning (100 epochs in this illustrative example) improves performance of the model on low-field MR images. In particular, <figref idrefs="DRAWINGS">FIG. 10A-10D</figref> show reconstructed MR images obtained, respectively, using a zero-padded inverse FFT, the neural network model of <figref idrefs="DRAWINGS">FIG. 5B</figref> trained without transfer learning, the neural network of <figref idrefs="DRAWINGS">FIG. 5B</figref> trained with transfer learning, as well as the fully sampled data. The <figref idrefs="DRAWINGS">FIGS. 10E-10G</figref> show the absolute difference between the reconstructed MR images and the fully sampled MR images, while <figref idrefs="DRAWINGS">FIG. 10H</figref> shows the under-sampling mask.</div>
</li> <li> <para-num num="[0162]"> </para-num> <div class="description-line" id="p-0163" num="0162"> <figref idrefs="DRAWINGS">FIG. 11</figref> illustrates performance of some of the neural network models for generating MR images from under-sampled spatial frequency domain data, in accordance with some embodiments of the technology described herein. In particular, the second row of <figref idrefs="DRAWINGS">FIG. 11</figref> shows the performance of the neural network model <b>100</b> described with reference to <figref idrefs="DRAWINGS">FIG. 1A</figref>, and the third row of <figref idrefs="DRAWINGS">FIG. 11</figref> shows the performance of the neural network model <b>520</b> described with reference to <figref idrefs="DRAWINGS">FIG. 5B</figref>. For both models, <figref idrefs="DRAWINGS">FIG. 11</figref> shows the performance of the respective first and second sub-models (sub-models <b>102</b> and <b>120</b>, and sub-models <b>522</b> and <b>510</b>). The first row of <figref idrefs="DRAWINGS">FIG. 11</figref> shows the under-sampled and fully-sampled images (both magnitude and phase). As may be seen from <figref idrefs="DRAWINGS">FIG. 11</figref>, the output of the first sub-model of the neural network model <b>100</b> (first two columns in the middle row) has improved quality with fewer artifacts, which is also indicated by the increased peak SNR (PSNR). The output of the second sub-model of the neural network model <b>100</b> (last two columns in the middle row) shows that the second sub-model further improves the reconstruction by increasing the contrast of the magnitude image and generating a smoother phase map, which is closer to that of the fully sampled image. For the neural network model <b>520</b>, the second sub-model contributes less to the improvement as reflected by PSNR than the first sub-model. The situation is reversed for the first neural network sub-model.</div>
</li> <li> <para-num num="[0163]"> </para-num> <div class="description-line" id="p-0164" num="0163"> <figref idrefs="DRAWINGS">FIG. 12</figref> further illustrates performance of some of the neural network models for generating MR images from under-sampled spatial frequency domain data, in accordance with some embodiments of the technology described herein. In particular, <figref idrefs="DRAWINGS">FIG. 12</figref> illustrates the performance of some of the neural networks developed herein relative to other techniques on images under-sampled down to 33% of the number of samples required by the Nyquist sampling rate. The performance of the neural network models <b>100</b> and <b>520</b> (shown in fourth and fifth columns of <figref idrefs="DRAWINGS">FIG. 12</figref>) was compared to that of compressed sensing (implemented using the ADMM regularizer, with regularization parameter=5e-3, and shown in the second column of <figref idrefs="DRAWINGS">FIG. 12</figref>) and neural network model <b>100</b> without the first sub-model (shown in the third column of <figref idrefs="DRAWINGS">FIG. 12</figref>). Normalized mean squared error and peak-SNR were measured to quantify the difference of output images. As shown in the <figref idrefs="DRAWINGS">FIG. 12</figref>, under-sampling introduces blurring and inhomogeneous artifacts. The compressed sensing approach removes the artifacts, but over-smooths the image, and alters the phase image. The model <b>100</b> without its first sub-model failed to recover the image. By contrast, the neural network models <b>100</b> and <b>520</b>, output MR images that are much closer in both magnitude and phase to the fully sampled image, as reflected by higher PSNR and lower normalized MSE than competing methods.</div>
</li> <li> <para-num num="[0164]"> </para-num> <div class="description-line" id="p-0165" num="0164">As discussed herein, the inventors have developed neural network models for reconstructing MR images from spatial frequency data obtained using non-Cartesian sampling trajectories.</div>
</li> <li> <para-num num="[0165]"> </para-num> <div class="description-line" id="p-0166" num="0165"> <figref idrefs="DRAWINGS">FIG. 13A</figref> is a diagram of an illustrative architecture of an example neural network model <b>1310</b> for generating MR images from input MR spatial frequency data, in accordance with some embodiments of the technology described herein. As shown in <figref idrefs="DRAWINGS">FIG. 13A</figref>, neural network model <b>1310</b> reconstructs output MR image <b>1315</b> from input MR spatial frequency data <b>1305</b> by processing the input MR spatial frequency data in stages. First, the input MR spatial frequency data <b>1305</b> is processed using initial processing block <b>1312</b> to produce an initial image <b>1314</b>, and then the initial image <b>1314</b> is processed by a series of neural network blocks <b>1316</b>-<b>1</b>, <b>1316</b>-<b>2</b>, . . . , <b>1316</b>-<i>n. </i> </div>
</li> <li> <para-num num="[0166]"> </para-num> <div class="description-line" id="p-0167" num="0166">In some embodiments, one or more of the blocks <b>1316</b>-<b>1</b>, <b>1316</b>-<b>2</b>, . . . , <b>1316</b>-<i>n </i>may operator in the image domain. In some embodiments, one or more of the blocks <b>1316</b>-<b>1</b>, <b>1316</b>-<b>2</b>, . . . , <b>1316</b>-<i>n </i>may transform the input data to a different domain, including but not limited to the spatial frequency domain, perform processing (e.g., reconstruction processing) in the different domain, and subsequently transform back to the image domain.</div>
</li> <li> <para-num num="[0167]"> </para-num> <div class="description-line" id="p-0168" num="0167">In some embodiments, the initializer block transforms the input MR spatial frequency data to the image domain to generate an initial image for subsequent processing by the neural network model <b>1310</b>. The initializer block may be implemented in any suitable way. For example, in some embodiments, the initializer block may apply the adjoint non-uniform Fourier transformation to the input MR spatial frequency data to obtain the initial image. As another example, in some embodiments, the initializer block may apply the gridding reconstruction to the input MR spatial frequency data to obtain the initial image.</div>
</li> <li> <para-num num="[0168]"> </para-num> <div class="description-line" id="p-0169" num="0168">Illustrative architectures of neural network blocks <b>1316</b> are shown in <figref idrefs="DRAWINGS">FIG. 13B</figref> (corresponding to a non-uniform variational network) and <figref idrefs="DRAWINGS">FIG. 13E</figref> (corresponding to a generalized non-uniform variational network). Accordingly, in some embodiments, at least one, at least some, or all of the blocks <b>1316</b>-<b>1</b>, <b>1316</b>-<b>2</b>, . . . , <b>1316</b>-<i>n </i>may have an architecture as shown for illustrative block <b>1316</b>-<i>i </i>in <figref idrefs="DRAWINGS">FIG. 13B</figref>. As shown in <figref idrefs="DRAWINGS">FIG. 13</figref>-B, neural network block <b>1316</b>-<i>i </i>includes a data consistency block <b>1320</b>, and a convolutional neural network block <b>1350</b>, both of which are applied to the input x<sub>i</sub>, labeled as <b>1321</b>. The input x<sub>i </sub>may represent the MR image reconstruction generated by neural network <b>1310</b> at the completion of the (i−1)<sup>st </sup>neural network block. In this example, the output <b>1335</b> of the block <b>1316</b>-<i>i </i>is obtained by applying the data consistency block <b>1320</b> to the input x<sub>i</sub>, to obtain a first result, applying the convolutional neural network block <b>1350</b> to x<sub>i</sub>, to obtain a second result, and subtracting from x<sub>i </sub>a linear combination of the first result and the second result, where the linear combination is calculated using the block-specific weight λ<sub>i</sub>.</div>
</li> <li> <para-num num="[0169]"> </para-num> <div class="description-line" id="p-0170" num="0169">The data consistency block <b>1320</b> may be implemented in any of numerous ways. In some embodiments, the data consistency block <b>1320</b> may perform data consistency processing by transforming the input image represented by x<sub>i </sub>to the spatial frequency domain using a non-uniform Fourier transformation, comparing the result with the initial MR spatial frequency data <b>1305</b>, and transforming the difference between the two back to the image domain using an adjoint of the non-uniform Fourier transformation.</div>
</li> <li> <para-num num="[0170]"> </para-num> <div class="description-line" id="p-0171" num="0170">An illustrative implementation of data consistency block <b>1320</b> is shown in <figref idrefs="DRAWINGS">FIG. 13C</figref>. In the illustrative implementation of <figref idrefs="DRAWINGS">FIG. 13C</figref>, the image domain input <b>1322</b> (which may be the intermediate reconstruction x<sub>i </sub> <b>1321</b>), is transformed to the spatial frequency domain through a series of three transformations <b>1324</b>, <b>1326</b>, and <b>1328</b>, whose composition is used to implement a non-uniform fast Fourier transformation from the image domain to the spatial frequency domain. In particular, the transformation <b>1324</b> is a de-apodization and zero-padding transformation D, the transformation <b>1326</b> is an oversampled FFT transformation F<sub>s</sub>, and the transformation <b>1328</b> is the gridding interpolation transformation G. As described herein, the non-uniform fast Fourier transformation A is represented by the composition of these transformations according to: A=D F<sub>s </sub>G. Example realizations of these constituent transformations are described herein.</div>
</li> <li> <para-num num="[0171]"> </para-num> <div class="description-line" id="p-0172" num="0171">After the image domain input <b>1322</b> is transformed to the spatial frequency domain, it is compared with the initial MR spatial frequency data <b>1305</b>, and the difference between the two is transformed back to the image domain using the transformations <b>1330</b>, <b>1332</b>, and <b>1334</b>, in that order. The transformation <b>1330</b> is the adjoint of the gridding interpolation transformation <b>1328</b>. The transformation <b>1332</b> is the adjoint of the oversampled FFT transformation <b>1326</b>. The transformation <b>1334</b> is the adjoint of the deapodization transformation <b>1324</b>. In this way, the composition of the transformations <b>1330</b>, <b>1332</b>, <b>1334</b>, which may be written as G<sup>H</sup>F<sup>H</sup> <sub>s</sub>D<sup>H</sup>=A<sup>H</sup>, represents the adjoint A<sup>H </sup>of the non-uniform Fourier transformation A.</div>
</li> <li> <para-num num="[0172]"> </para-num> <div class="description-line" id="p-0173" num="0172">The convolutional neural network block <b>1350</b> may be implemented in any of numerous ways. In some embodiments, the block <b>1350</b> may have multiple convolutional layers, including one or more convolutional layers and one or more transpose convolutional layers. In some embodiments, the block <b>1350</b> may have a U-net structure, whereby multiple convolutional layers downsample the data and subsequent transpose convolutional layers upsample the data, for example, as shown in the illustrative U-net architecture of <figref idrefs="DRAWINGS">FIG. 13D</figref> for the block <b>1350</b>.</div>
</li> <li> <para-num num="[0173]"> </para-num> <div class="description-line" id="p-0174" num="0173">As shown in <figref idrefs="DRAWINGS">FIG. 13D</figref>, input to the convolutional network block <b>1350</b> is processing by a downsampling path followed an upsampling path. In the downsampling path, the input is processed by repeated application of two convolutions with 3×3 kernels, each followed by application of a non-linearity (e.g., a rectified linear unit or ReLU), an average 2×2 pooling operation with stride 2 for downsampling. At each downsampling step the number of feature channels is doubled from 64 to 128 to 256. In the upsampling path, the data is processed be repeated upsampling of the feature map using an average unpooling step that halves the number of feature channels, a concatenation with the corresponding feature map from the downsampling path, and two 3×3 convolutions, each followed by application of a non-linearity (e.g., a ReLU).</div>
</li> <li> <para-num num="[0174]"> </para-num> <div class="description-line" id="p-0175" num="0174"> <figref idrefs="DRAWINGS">FIG. 13E</figref> is a diagram of another type of architecture of a block of the neural network model of <figref idrefs="DRAWINGS">FIG. 13A</figref>, in accordance with some embodiments of the technology described herein. A neural network model with blocks having the architecture like the one shown in <figref idrefs="DRAWINGS">FIG. 13E</figref> may be termed a “generalized non-uniform variational network” or “GNVN”. It is “generalized” in the sense that, while data consistency blocks are not used directly, feature similar to the image features generated by such blocks may be useful to incorporate into a neural network model.</div>
</li> <li> <para-num num="[0175]"> </para-num> <div class="description-line" id="p-0176" num="0175">As shown in <figref idrefs="DRAWINGS">FIG. 13E</figref>, the i<sup>th </sup>GNVN block <b>1360</b>-<i>i </i>takes as input: (1) the image domain data x<sub>i</sub>, labeled as <b>1362</b>; and (2) the initial MR spatial frequency data <b>1364</b>. The input x<sub>i </sub>may represent the MR image reconstruction generated by neural network <b>1310</b> at the completion of the (i−1)<sup>st </sup>GNVN block (<b>1360</b>-(<i>i</i>−1)). These inputs to the block <b>1360</b>-<i>i </i>are then used to generate inputs to the convolutional neural network block <b>1372</b> part of block <b>1360</b>-<i>i</i>. In turn, from these inputs, the CNN block <b>1372</b> generates the next MR image reconstruction denoted by x<sub>i+1</sub>.</div>
</li> <li> <para-num num="[0176]"> </para-num> <div class="description-line" id="p-0177" num="0176">In the embodiment of <figref idrefs="DRAWINGS">FIG. 13E</figref>, the inputs <b>1362</b> and <b>1364</b> are used to generate three inputs to the CNN block <b>1372</b>: (1) the reconstruction x<sub>i </sub>itself is provided as input to the CNN block; (2) the result of applying, to the reconstruction x<sub>i</sub>, the non-uniform Fourier transformation <b>1366</b> followed by a spatial frequency domain convolutional neural network <b>1368</b>, followed by the adjoint non-uniform Fourier transformation <b>1370</b>; and (3) the result of applying, to the initial MR spatial frequency data <b>1364</b>, the spatial frequency domain convolutional neural network <b>1368</b> followed by an adjoint non-uniform Fourier transform <b>1370</b>.</div>
</li> <li> <para-num num="[0177]"> </para-num> <div class="description-line" id="p-0178" num="0177">In some embodiments, the non-uniform Fourier transformation <b>1366</b> may be the transformation A expressed as a composition of three transformations: the de-apodization transformation D, an oversampled Fourier transformation F<sub>s</sub>, and a local gridding interpolation transformation G such that A=D F<sub>s </sub>G. Example realizations of these constituent transformations are described herein.</div>
</li> <li> <para-num num="[0178]"> </para-num> <div class="description-line" id="p-0179" num="0178">The spatial frequency domain CNN <b>1368</b> may be any suitable type of convolutional neural network. For example, the CNN <b>1368</b> may be a five layer convolutional neural network with residual connection. However, in other embodiments, the spatial frequency domain network <b>1368</b> may be any other type of neural network (e.g., a fully convolutional neural network, a recurrent neural network, and/or any other suitable type of neural network), as aspects of the technology described herein are not limited in this respect.</div>
</li> <li> <para-num num="[0179]"> </para-num> <div class="description-line" id="p-0180" num="0179">A discussion of further aspects and details of neural network models for MR image reconstruction from non-Cartesian data, such as the neural network models illustrated in <figref idrefs="DRAWINGS">FIGS. 13A-13E</figref>, follows next. First, some notation is introduced. Let x∈<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/9f/b9/db/36921c9d4909ff/US20200033431A1-20200130-P00001.png"><img alt="Figure US20200033431A1-20200130-P00001" class="patent-full-image" file="US20200033431A1-20200130-P00001.TIF" he="3.22mm" height="13" id="CUSTOM-CHARACTER-00001" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/9f/b9/db/36921c9d4909ff/US20200033431A1-20200130-P00001.png" wi="2.12mm" width="8"/></a></div> <sup>N </sup>denote a complex-valued MR image to be reconstructed, represented as a vector with N=N<sub>x</sub>N<sub>y </sub>where N<sub>x </sub>and N<sub>y </sub>are width and height of the image. Let y∈<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/9f/b9/db/36921c9d4909ff/US20200033431A1-20200130-P00001.png"><img alt="Figure US20200033431A1-20200130-P00001" class="patent-full-image" file="US20200033431A1-20200130-P00001.TIF" he="3.22mm" height="13" id="CUSTOM-CHARACTER-00002" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/9f/b9/db/36921c9d4909ff/US20200033431A1-20200130-P00001.png" wi="2.12mm" width="8"/></a></div> <sup>M </sup>(M&lt;&lt;N) represent the undersampled k-space measurements from which the complex-valued MR image x is to be reconstructed. Reconstruct x from y may be formulated as an unconstrained optimization problem according to:</div>
</li> <li> <div class="description-line" id="p-0181" num="0000">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mtable>
<mtr>
<mtd>
<mrow>
<mrow>
<mrow>
<munder>
<mi>argmin</mi>
<mi>x</mi>
</munder>
<mo></mo>
<mfrac>
<mi>λ</mi>
<mn>2</mn>
</mfrac>
<mo></mo>
<msubsup>
<mrow>
<mo></mo>
<mrow>
<mi>Ax</mi>
<mo>-</mo>
<mi>y</mi>
</mrow>
<mo></mo>
</mrow>
<mn>2</mn>
<mn>2</mn>
</msubsup>
</mrow>
<mo>+</mo>
<mrow>
<mi></mi>
<mo></mo>
<mrow>
<mo>(</mo>
<mi>x</mi>
<mo>)</mo>
</mrow>
</mrow>
</mrow>
<mo>,</mo>
</mrow>
</mtd>
<mtd>
<mrow>
<mo>(</mo>
<mrow>
<mi>Eq</mi>
<mo>.</mo>
<mstyle>
<mspace height="0.8ex" width="0.8em"> </mspace>
</mstyle>
<mo></mo>
<mn>1</mn>
</mrow>
<mo>)</mo>
</mrow>
</mtd>
</mtr>
</mtable>
</math>
</maths>
</div>
</li> <li> <div class="description-line" id="p-0182" num="0000">where the operator A is a non-uniform Fourier sampling operator, <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/14/52/46/b371439c39bce9/US20200033431A1-20200130-P00002.png"><img alt="Figure US20200033431A1-20200130-P00002" class="patent-full-image" file="US20200033431A1-20200130-P00002.TIF" he="3.22mm" height="13" id="CUSTOM-CHARACTER-00003" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/14/52/46/b371439c39bce9/US20200033431A1-20200130-P00002.png" wi="2.79mm" width="11"/></a></div> expresses regularisation terms on x, and λ is a hyper-parameter associated to the noise level. In the case when the k-space measurements y are obtained using a Cartesian sampling trajectory, the operator A may expressed according to: A=MF where M is a sampling mask, and F is discrete Fourier transform. In the case of a non-Cartesian sampling trajectory, the measurements no longer fall on a uniform k-space grid and the sampling operator A is now given by a non-uniform discrete Fourier transform of type I:</div>
</li> <li> <div class="description-line" id="p-0183" num="0000">
<maths id="MATH-US-00002" num="00002">
<math overflow="scroll">
<mtable>
<mtr>
<mtd>
<mrow>
<mrow>
<mi>y</mi>
<mo></mo>
<mrow>
<mo>(</mo>
<mrow>
<mo>(</mo>
<mrow>
<msub>
<mi>k</mi>
<mi>x</mi>
</msub>
<mo>,</mo>
<msub>
<mi>k</mi>
<mi>y</mi>
</msub>
</mrow>
<mo>)</mo>
</mrow>
<mo>)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<munderover>
<mo>∑</mo>
<mrow>
<mi>l</mi>
<mo>=</mo>
<mn>0</mn>
</mrow>
<msub>
<mi>N</mi>
<mi>x</mi>
</msub>
</munderover>
<mo></mo>
<mrow>
<munderover>
<mo>∑</mo>
<mrow>
<mi>m</mi>
<mo>=</mo>
<mn>0</mn>
</mrow>
<msub>
<mi>N</mi>
<mi>y</mi>
</msub>
</munderover>
<mo></mo>
<mrow>
<msub>
<mi>x</mi>
<mrow>
<mi>l</mi>
<mo></mo>
<mstyle>
<mspace height="0.3ex" width="0.3em"> </mspace>
</mstyle>
<mo></mo>
<mi>m</mi>
</mrow>
</msub>
<mo></mo>
<mrow>
<msup>
<mi>e</mi>
<mrow>
<mn>2</mn>
<mo></mo>
<mi>π</mi>
<mo></mo>
<mstyle>
<mspace height="0.3ex" width="0.3em"> </mspace>
</mstyle>
<mo></mo>
<mi>i</mi>
</mrow>
</msup>
<mo></mo>
<mrow>
<mo>(</mo>
<mrow>
<mrow>
<mfrac>
<mi>l</mi>
<msub>
<mi>N</mi>
<mi>x</mi>
</msub>
</mfrac>
<mo></mo>
<msub>
<mi>k</mi>
<mi>x</mi>
</msub>
</mrow>
<mo>+</mo>
<mrow>
<mfrac>
<mi>m</mi>
<msub>
<mi>N</mi>
<mi>y</mi>
</msub>
</mfrac>
<mo></mo>
<msub>
<mi>k</mi>
<mi>y</mi>
</msub>
</mrow>
</mrow>
<mo>)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
</mrow>
</mrow>
</mtd>
<mtd>
<mrow>
<mo>(</mo>
<mrow>
<mi>Eq</mi>
<mo>.</mo>
<mstyle>
<mspace height="0.8ex" width="0.8em"> </mspace>
</mstyle>
<mo></mo>
<mn>2</mn>
</mrow>
<mo>)</mo>
</mrow>
</mtd>
</mtr>
</mtable>
</math>
</maths>
</div>
</li> <li> <div class="description-line" id="p-0184" num="0000">where (k<sub>x</sub>, k<sub>y</sub>)∈<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/96/f0/9f/2bdf64e5e053d5/US20200033431A1-20200130-P00003.png"><img alt="Figure US20200033431A1-20200130-P00003" class="patent-full-image" file="US20200033431A1-20200130-P00003.TIF" he="3.22mm" height="13" id="CUSTOM-CHARACTER-00004" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/96/f0/9f/2bdf64e5e053d5/US20200033431A1-20200130-P00003.png" wi="2.46mm" width="10"/></a></div> <sup>2 </sup>(rather than (k<sub>x</sub>, k<sub>y</sub>)∈<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/cb/ea/67/a68d192818b5d0/US20200033431A1-20200130-P00004.png"><img alt="Figure US20200033431A1-20200130-P00004" class="patent-full-image" file="US20200033431A1-20200130-P00004.TIF" he="3.22mm" height="13" id="CUSTOM-CHARACTER-00005" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/cb/ea/67/a68d192818b5d0/US20200033431A1-20200130-P00004.png" wi="2.12mm" width="8"/></a></div> <sup>2</sup>). An efficient implementation of the above forward model may be implemented using the so-called non-uniform Fast Fourier Transform (NUFFT). The idea is to approximate Eq. 2 by the following decomposition: A=GF<sub>s</sub>D, where G is a gridding interpolation kernel, F<sub>s </sub>is fast Fourier transform (FFT) with an oversampling factor of s, and D is a de-apodization weights. This decomposition is described in further detail below.</div>
</li> <li> <para-num num="[0180]"> </para-num> <div class="description-line" id="p-0185" num="0180">In contrast, the inversion of A is considerably more involved. For the (approximately) fully-sampled case, one can consider direct inversion (<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/8c/48/6c/30d1363aa8bd3f/US20200033431A1-20200130-P00005.png"><img alt="Figure US20200033431A1-20200130-P00005" class="patent-full-image" file="US20200033431A1-20200130-P00005.TIF" he="3.22mm" height="13" id="CUSTOM-CHARACTER-00006" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/8c/48/6c/30d1363aa8bd3f/US20200033431A1-20200130-P00005.png" wi="2.12mm" width="8"/></a></div>(N<sup>3</sup>)) or a more computationally efficient gridding reconstruction, which has the form x<sub>gridding</sub>=A<sup>H</sup>Wy, where W is a diagonal matrix used for the density compensation of non-uniformly spaced measurements. For the undersampled case, the inversion is ill-posed, and Eq. 1 should be solved by iterative algorithms.</div>
</li> <li> <para-num num="[0181]"> </para-num> <div class="description-line" id="p-0186" num="0181">The inventors have developed a new deep learning algorithm to approximate the solution to the optimization problem of Eq. 1. The approach begins by considering a gradient descent algorithm, which provides a locally optimal solution to Eq. 1, specified by the following equations for initialization and subsequent iterations:</div>
</li> <li> <div class="description-line" id="p-0187" num="0000"> <br/> <i>x</i> <sub>0</sub> <i>=f</i> <sub>init</sub>(<i>A,y</i>);  (Eq. 3)
</div>
</li> <li> <div class="description-line" id="p-0188" num="0000"> <br/> <i>x</i> <sub>i+1</sub> <i>=x</i> <sub>i</sub>−α<sub>i</sub>∇<sub>x</sub> <i>f</i>(<i>x</i>)<sub>x=x</sub> <sub> <sub2>i</sub2> </sub>,  (Eq. 4)
</div>
</li> <li> <div class="description-line" id="p-0189" num="0000">where f<sub>init </sub>is an initializer, α is a step size and ∇f is the gradient of the objective functional, which is given by:</div>
</li> <li> <div class="description-line" id="p-0190" num="0000"> <br/>∇<sub>x</sub> <i>f</i>(<i>x</i>)=λ<i>A</i> <sup>H</sup>(<i>Ax−y</i>)+∇<sub>x</sub> <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/14/52/46/b371439c39bce9/US20200033431A1-20200130-P00002.png"><img alt="Figure US20200033431A1-20200130-P00002" class="patent-full-image" file="US20200033431A1-20200130-P00002.TIF" he="3.22mm" height="13" id="CUSTOM-CHARACTER-00007" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/14/52/46/b371439c39bce9/US20200033431A1-20200130-P00002.png" wi="2.79mm" width="11"/></a></div>(<i>x</i>).  (Eq. 5)
</div>
</li> <li> <para-num num="[0182]"> </para-num> <div class="description-line" id="p-0191" num="0182">In some embodiments, the initializer may be selected as the adjoint f<sub>init</sub>(A,y)=A<sup>H</sup>y reconstruction or the gridding reconstruction f<sub>init</sub>(A, y)=A<sup>H</sup>Wy. The deep learning approach to solving Eq. 1 involves unrolling the sequential updates of Eq. 4 into a feed-forward model, and approximating the gradient term ∇<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/14/52/46/b371439c39bce9/US20200033431A1-20200130-P00002.png"><img alt="Figure US20200033431A1-20200130-P00002" class="patent-full-image" file="US20200033431A1-20200130-P00002.TIF" he="3.22mm" height="13" id="CUSTOM-CHARACTER-00008" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/14/52/46/b371439c39bce9/US20200033431A1-20200130-P00002.png" wi="2.79mm" width="11"/></a></div> by a series of trainable convolutional (or other types of neural network) layers and non-linearities. This approach results in an end-to-end trainable network with N<sub>it </sub>blocks given by:</div>
</li> <li> <div class="description-line" id="p-0192" num="0000">
<maths id="MATH-US-00003" num="00003">
<math overflow="scroll">
<mtable>
<mtr>
<mtd>
<mrow>
<msub>
<mi>x</mi>
<mn>0</mn>
</msub>
<mo>=</mo>
<mrow>
<msub>
<mi>f</mi>
<mrow>
<mi>init</mi>
<mo></mo>
<mstyle>
<mtext>-</mtext>
</mstyle>
<mo></mo>
<mi>cnn</mi>
</mrow>
</msub>
<mo></mo>
<mrow>
<mo>(</mo>
<mrow>
<mi>A</mi>
<mo>,</mo>
<mrow>
<mi>y</mi>
<mo>|</mo>
<msub>
<mi>θ</mi>
<mn>0</mn>
</msub>
</mrow>
</mrow>
<mo>)</mo>
</mrow>
</mrow>
</mrow>
</mtd>
<mtd>
<mrow>
<mo>(</mo>
<mrow>
<mi>Eq</mi>
<mo>.</mo>
<mstyle>
<mspace height="0.8ex" width="0.8em"> </mspace>
</mstyle>
<mo></mo>
<mn>6</mn>
</mrow>
<mo>)</mo>
</mrow>
</mtd>
</mtr>
<mtr>
<mtd>
<mrow>
<msub>
<mi>x</mi>
<mrow>
<mi>i</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
</msub>
<mo>=</mo>
<mrow>
<msub>
<mi>x</mi>
<mi>i</mi>
</msub>
<mo>-</mo>
<mrow>
<msub>
<mi>λ</mi>
<mi>i</mi>
</msub>
<mo></mo>
<munder>
<mrow>
<msup>
<mi>A</mi>
<mi>H</mi>
</msup>
<mo></mo>
<mrow>
<mo>(</mo>
<mrow>
<msub>
<mi>Ax</mi>
<mi>i</mi>
</msub>
<mo>-</mo>
<mi>y</mi>
</mrow>
<mo>)</mo>
</mrow>
</mrow>
<munder>
<mi></mi>
<mrow>
<mi>D</mi>
<mo></mo>
<mstyle>
<mspace height="0.3ex" width="0.3em"> </mspace>
</mstyle>
<mo></mo>
<mi>C</mi>
<mo></mo>
<mstyle>
<mtext>-</mtext>
</mstyle>
<mo></mo>
<mi>i</mi>
</mrow>
</munder>
</munder>
</mrow>
<mo>-</mo>
<munder>
<mrow>
<msub>
<mi>f</mi>
<mi>cnn</mi>
</msub>
<mo></mo>
<mrow>
<mo>(</mo>
<mrow>
<msub>
<mi>x</mi>
<mi>i</mi>
</msub>
<mo>|</mo>
<msub>
<mi>θ</mi>
<mi>i</mi>
</msub>
</mrow>
<mo>)</mo>
</mrow>
</mrow>
<munder>
<mi></mi>
<mrow>
<mi>CNN</mi>
<mo></mo>
<mstyle>
<mtext>-</mtext>
</mstyle>
<mo></mo>
<mi>i</mi>
</mrow>
</munder>
</munder>
</mrow>
</mrow>
</mtd>
<mtd>
<mrow>
<mo>(</mo>
<mrow>
<mi>Eq</mi>
<mo>.</mo>
<mstyle>
<mspace height="0.8ex" width="0.8em"> </mspace>
</mstyle>
<mo></mo>
<mn>7</mn>
</mrow>
<mo>)</mo>
</mrow>
</mtd>
</mtr>
</mtable>
</math>
</maths>
</div>
</li> <li> <div class="description-line" id="p-0193" num="0000">where the learnable parameters are {θ<sub>0</sub>, . . . , θ<sub>N</sub> <sub> <sub2>it</sub2> </sub>, λ<sub>1</sub>, . . . , λ<sub>N</sub> <sub> <sub2>it</sub2> </sub>}. Note that the step size α<sub>i </sub>is absorbed in the learnable parameters. In this way, a general non-convex regularization functional is used (e.g., instead of a Fields-of-Experts model), and regularization functional can be approximated by convolutional neural networks. Indeed, the neural network model illustrated in <figref idrefs="DRAWINGS">FIGS. 13A-13D</figref> is implemented in accordance with Equations 6 and 7. For example, an implementation of the data consistency term DC-i is shown in <figref idrefs="DRAWINGS">FIG. 13C</figref> and an implementation of the CNN-i term is shown in <figref idrefs="DRAWINGS">FIG. 13D</figref>.</div>
</li> <li> <para-num num="[0183]"> </para-num> <div class="description-line" id="p-0194" num="0183">The inventors have recognized that the computational complexity of such an approach is a function of how the forward operator A∈<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/9f/b9/db/36921c9d4909ff/US20200033431A1-20200130-P00001.png"><img alt="Figure US20200033431A1-20200130-P00001" class="patent-full-image" file="US20200033431A1-20200130-P00001.TIF" he="3.22mm" height="13" id="CUSTOM-CHARACTER-00009" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/9f/b9/db/36921c9d4909ff/US20200033431A1-20200130-P00001.png" wi="2.12mm" width="8"/></a></div> <sup>M×N </sup>is implemented because A is large complex-valued matrix that can occupy a lot of memory to store. As described herein, in contrast to the Cartesian case, A is expressed as GF<sub>s</sub>D. For 2D cases, this can be a large matrix, which consumes a large portion of GPU memory (e.g., for N=192<sup>2 </sup>and M=10,000 (i.e., ≈3×acceleration), storing the complex-valued matrix alone already takes 3 GB of memory). To overcome this challenge, the inventors have implemented the gridding interpolation transformation G i as a sparse GPU matrix multiplication. F<sub>s </sub>is an FFT, where an efficient GPU implementation is available. Finally, D is a diagonal matrix, which can be implemented as a Hadamard product of matrices. The adjoint can similarly be implemented as A<sup>H</sup>=D<sup>H</sup>F<sub>s</sub> <sup>H</sup>G<sup>H</sup>, where .<sup>H </sup>is a complex-conjugate transpose.</div>
</li> <li> <para-num num="[0184]"> </para-num> <div class="description-line" id="p-0195" num="0184">Further details of the decomposition of the forward operator A=GF<sub>s</sub>D are described next. First, some preliminaries. The spatial frequency domain (sometimes referred to as k-space) may be indexed using two-dimensional or three-dimensional coordinates (e.g. (k<sub>x</sub>, k<sub>y</sub>) or (k<sub>x</sub>,k<sub>y</sub>,k<sub>z</sub>)). In this way, each entry of the vector y representing input MR spatial frequency data represents a value associated to a specific coordinate in k-space. A regular grid in k-space refers to a regularly-spaced grid of points k-space such that there is a fixed distance Δ between each k-space coordinate that can be indexed. Generally, the input MR spatial frequency data y may include k-space samples spaced on a regular-grid or irregularly spaced. Regularly spaced points are sometimes termed Cartesian data points. Irregularly spaced points are sometimes termed non-Cartesian (data) points.</div>
</li> <li> <para-num num="[0185]"> </para-num> <div class="description-line" id="p-0196" num="0185">The interpolation transformation G operates to interpolate non-Cartesian sensor data y onto a regular k-space grid. When the transformation is represented as a matrix G, each row in the matrix corresponds to a specific regular grid point in k-space, and the entry j in the row i (i.e., the entry GO expresses how much weight is associated between ith regular grid and jth k-space sample.</div>
</li> <li> <para-num num="[0186]"> </para-num> <div class="description-line" id="p-0197" num="0186">In some embodiments, the interpolation matrix entries may be computed any one of the following four functions:
</div> </li> <ul> <li id="ul0001-0001" num="0000"> <ul> <li id="ul0002-0001" num="0187">Two term cosine</li> </ul> </li> </ul>
<li> <div class="description-line" id="p-0198" num="0000">
<maths id="MATH-US-00004" num="00004">
<math overflow="scroll">
<mrow>
<mi>α</mi>
<mo>+</mo>
<mrow>
<mrow>
<mo>(</mo>
<mrow>
<mn>1</mn>
<mo>-</mo>
<mi>α</mi>
</mrow>
<mo>)</mo>
</mrow>
<mo></mo>
<mrow>
<mi>cos</mi>
<mo></mo>
<mrow>
<mo>(</mo>
<mrow>
<mfrac>
<mrow>
<mrow>
<mn>2</mn>
<mo></mo>
<mi>π</mi>
</mrow>
<mo></mo>
<mstyle>
<mspace height="0.3ex" width="0.3em"> </mspace>
</mstyle>
</mrow>
<mi>W</mi>
</mfrac>
<mo></mo>
<mi>u</mi>
</mrow>
<mo>)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
</math>
</maths>
</div> </li> <ul>
<li id="ul0003-0001" num="0000">
<ul>
<li id="ul0004-0001" num="0188">Three-term cosine:</li>
</ul>
</li>
</ul>
<li> <div class="description-line" id="p-0199" num="0000">
<maths id="MATH-US-00005" num="00005">
<math overflow="scroll">
<mrow>
<mi>α</mi>
<mo>+</mo>
<mrow>
<mi>β</mi>
<mo></mo>
<mstyle>
<mspace height="0.3ex" width="0.3em"> </mspace>
</mstyle>
<mo></mo>
<mrow>
<mi>cos</mi>
<mo></mo>
<mrow>
<mo>(</mo>
<mrow>
<mfrac>
<mrow>
<mn>2</mn>
<mo></mo>
<mi>π</mi>
</mrow>
<mi>W</mi>
</mfrac>
<mo></mo>
<mi>u</mi>
</mrow>
<mo>)</mo>
</mrow>
</mrow>
</mrow>
<mo>+</mo>
<mrow>
<mrow>
<mo>(</mo>
<mrow>
<mn>1</mn>
<mo>-</mo>
<mi>α</mi>
<mo>-</mo>
<mi>β</mi>
</mrow>
<mo>)</mo>
</mrow>
<mo></mo>
<mrow>
<mi>cos</mi>
<mo></mo>
<mrow>
<mo>(</mo>
<mrow>
<mfrac>
<mrow>
<mn>4</mn>
<mo></mo>
<mi>π</mi>
</mrow>
<mi>W</mi>
</mfrac>
<mo></mo>
<mi>u</mi>
</mrow>
<mo>)</mo>
</mrow>
</mrow>
</mrow>
</mrow>
</math>
</maths>
</div> </li> <ul>
<li id="ul0005-0001" num="0000">
<ul>
<li id="ul0006-0001" num="0189">Gaussian:</li>
</ul>
</li>
</ul>
<li> <div class="description-line" id="p-0200" num="0000">
<maths id="MATH-US-00006" num="00006">
<math overflow="scroll">
<mrow>
<mi>exp</mi>
<mo></mo>
<mrow>
<mo>[</mo>
<mrow>
<mrow>
<mo>-</mo>
<mfrac>
<mn>1</mn>
<mn>2</mn>
</mfrac>
</mrow>
<mo></mo>
<msup>
<mrow>
<mo>(</mo>
<mfrac>
<mi>u</mi>
<mi>σ</mi>
</mfrac>
<mo>)</mo>
</mrow>
<mn>2</mn>
</msup>
</mrow>
<mo>]</mo>
</mrow>
</mrow>
</math>
</maths>
</div> </li> <ul>
<li id="ul0007-0001" num="0000">
<ul>
<li id="ul0008-0001" num="0190">Kaiser-Bessel:</li>
</ul>
</li>
</ul>
<li> <div class="description-line" id="p-0201" num="0000">
<maths id="MATH-US-00007" num="00007">
<math overflow="scroll">
<mrow>
<mfrac>
<mn>1</mn>
<mi>W</mi>
</mfrac>
<mo></mo>
<mrow>
<msub>
<mi>I</mi>
<mn>0</mn>
</msub>
<mo></mo>
<mrow>
<mo>[</mo>
<mrow>
<mi>β</mi>
<mo></mo>
<msqrt>
<mrow>
<mn>1</mn>
<mo>-</mo>
<msup>
<mrow>
<mo>(</mo>
<mrow>
<mn>2</mn>
<mo></mo>
<mrow>
<mi>u</mi>
<mo>/</mo>
<mi>W</mi>
</mrow>
</mrow>
<mo>)</mo>
</mrow>
<mn>2</mn>
</msup>
</mrow>
</msqrt>
</mrow>
<mo>]</mo>
</mrow>
</mrow>
</mrow>
</math>
</maths>
</div>
</li> <li> <div class="description-line" id="p-0202" num="0000">where u is a distance between ith regular grid point and jth non-Cartesian data coordinate. The parameters α, β, W, σ are free design parameters to be specified by user, and I<sub>0 </sub>is the zeroth-order modified Bessel function of the first kind. However, it should be appreciated than any other function may be used for computing the interpolation matrix entries instead of or in addition to the example four functions listed above.</div>
</li> <li> <para-num num="[0191]"> </para-num> <div class="description-line" id="p-0203" num="0191">In some embodiments, the entries of the interpolation weight matrix may be computing using an optimization approach. For example, the entries may be computed by solving a min-max optimization problem, as shown in Equations 16 and 21 of Fessler, J. A., Sutton B. P.: Non-uniform fast Fourier transforms using min-max interpolation. IEEE Transactions of Signal Processing 51(2), 560-574 (2003), which is incorporated by reference herein in its entirety. In some embodiments, the Fourier transformation F may be represented by an oversampled Fourier matrix F<sub>s</sub>, which is a dense matrix in which each entry is a complex exponential of the form e<sup>iγ </sup>for γ which depends on the index. The role of this matrix is to perform Fourier transform. In some embodiments, F<sub>s </sub>may be implemented using the fast Fourier transform with oversampling factor s. For example, if the image to be reconstructed x is N×N pixels, then oversampling FFT is performed for image size sN×sN.</div>
</li> <li> <para-num num="[0192]"> </para-num> <div class="description-line" id="p-0204" num="0192">In some embodiments, the de-apodization transformation may be represented by a matrix D that will weigh each pixel in the image by a corresponding weight to reduce the interpolation error of approximating A with the given decomposition. In some embodiments, this may be implemented via a pixel-wise weighting of the intermediate reconstruction in the image domain. For example, the pixel-wise weighting may be implemented using a spatially-varying low-order smooth polynomial. In some embodiments, the matrix D may be set as discussed in Section IV-C of Fessler, J. A., Sutton B. P.: Non-uniform fast Fourier transforms using min-max interpolation. IEEE Transactions of Signal Processing 51(2), 560-574 (2003).</div>
</li> <li> <para-num num="[0193]"> </para-num> <div class="description-line" id="p-0205" num="0193">The inventors have also appreciated that the network of <figref idrefs="DRAWINGS">FIGS. 13A-13D</figref> forces a bottleneck at the end of each iteration. However, an alternative view is that the network simply benefits from the image features given by data consistency (DC-i) blocks. This observation motivates a generalized approach where, instead of using a data consistency block, each CNN-i block in the model of <figref idrefs="DRAWINGS">FIGS. 13A-13D</figref> is provided a concatenation of the following inputs: the intermediate reconstruction x<sub>i</sub>, the self-adjoint A<sup>H</sup>Ax<sub>i</sub>, and the adjoint of the input A<sup>H</sup>y. Furthermore, one can also consider applying 1D-convolution in raw sensory domain using f, f<sub>sensor-cnn</sub>(.|ϕ) to exploit the information along the sampling trajectory and remove unnecessary information (e.g. isolatable artifacts or noise). The resulting network, shown in <figref idrefs="DRAWINGS">FIGS. 13A, 13D, and 13E</figref>, is given by:</div>
</li> <li> <div class="description-line" id="p-0206" num="0000"> <br/> <i>x</i> <sub>0</sub> <i>=f</i> <sub>init-cnn</sub>(<i>A,f</i> <sub>sensor-cnn</sub>(<i>y|ϕ</i> <sub>0</sub>)|θ<sub>0</sub>,)<i>x</i> <sub>i+1 </sub>
</div>
</li> <li> <div class="description-line" id="p-0207" num="0000"> <br/> <i>f</i> <sub>cnn</sub>(<i>x</i> <sub>i</sub> <i>,A</i> <sup>H</sup> <i>f</i> <sub>sensor-cnn</sub>(<i>Ax</i> <sub>i</sub>|ϕ<sub>i</sub>),<i>x</i> <sub>0</sub>|θ<sub>i</sub>,),
</div>
</li> <li> <div class="description-line" id="p-0208" num="0000">where the learnable parameters are {ϕ<sub>0</sub>, . . . , ϕ<sub>N</sub> <sub> <sub2>it</sub2> </sub>, θ<sub>0</sub>, . . . , θ<sub>N</sub> <sub> <sub2>it</sub2> </sub>}. As described herein, this type of neural network model is termed Generalized Non-uniform Variational Network (GNVN).</div>
</li> <li> <para-num num="[0194]"> </para-num> <div class="description-line" id="p-0209" num="0194">The inventors have recognized that some embodiments of neural network architectures described herein may be considered as embodiments of a neural network model that may be expressed according to the following:</div>
</li> <li> <div class="description-line" id="p-0210" num="0000"> <br/> <i>x</i> <sub>rec</sub> <i>=f</i> <sub>rec</sub>(<i>A,y</i>|θ)  (Eq. 8),
</div>
</li> <li> <para-num num="[0195]"> </para-num> <div class="description-line" id="p-0211" num="0195">This general type of neural network model may accepts as input any input that is a combination of the forward operator A and raw spatial frequency domain data y, as well as additional learnable parameters θ, which can be an arbitrary dimension. The parameters θ may be adjusted during training process.</div>
</li> <li> <para-num num="[0196]"> </para-num> <div class="description-line" id="p-0212" num="0196">The input to the neural network of Eq. 8 may be data obtained by one or multiple RF coils of an MRI system, as aspects of the technology described herein are not limited to reconstructing images from data collected by a single RF coil. In addition, the input data y may have been obtained using multiple contrasts and/or different sets of acquisition parameters (e.g., by varying repetition time (TR), echo time (TE), flip angle θ, etc.). In some embodiments, input into the network may be, but is not limited to, the raw data y. Additionally or alternatively, the input to the network may be the adjoint reconstruction A<sup>H</sup>y where (.)<sup>H </sup>is the conjugate transpose of the matrix.</div>
</li> <li> <para-num num="[0197]"> </para-num> <div class="description-line" id="p-0213" num="0197">In some embodiments, where the data y includes data collected by multiple RF coils, these data y may be split into N<sub>coil </sub>separate data sets, denoted y<sup>(i) </sup>for i=1, . . . , N<sub>coil</sub>. N<sub>coil </sub>can be any number (e.g., any number in the range of 2-20 such, for example, 8 or 9 or 10). In some such embodiments, the neural network input may be the adjoint reconstruction of each coil images x<sub>0</sub> <sup>(i)</sup>=A<sup>H</sup>y<sup>(i)</sup>, and x<sub>0</sub> <sup>(i) </sup>for i=1, . . . , N<sub>coil </sub>can be stacked together and form the input to the network (e.g., to the convolutional layers part of the network).</div>
</li> <li> <para-num num="[0198]"> </para-num> <div class="description-line" id="p-0214" num="0198">In some embodiments, the raw data y may include multiple measurements obtained by each of one or more RF coils. For example, if the data is measured multiple times, say N<sub>avg </sub>times, then these data, or the adjoint reconstruction of these data, or any other function of these data measurements and the forward operator A, may form an input to the neural network. For example, multiple measurements may be obtained for signal averaging and/or as part of acquiring images with different contrast.</div>
</li> <li> <para-num num="[0199]"> </para-num> <div class="description-line" id="p-0215" num="0199">In some embodiments, as described above, the input to the neural network of Eq. 8 may be also be any function based on A and/or y. For example, in some embodiments, the gridding reconstruction may be an input to the network. Gridding reconstruction may have the form of x<sub>0</sub>=A<sup>H</sup>Wy, where W is called sample density compensation weights, which is a matrix that scales each element in the vector y.</div>
</li> <li> <para-num num="[0200]"> </para-num> <div class="description-line" id="p-0216" num="0200">Any of numerous techniques may be used to compute the sample density compensation weights W. For example, in some embodiments, the weights W may be computed according to: W=A<sup>H</sup>A1, where 1 is a vector of ones. As another example, the weights W may be any suitable user-defined function. As yet another example, the weights W may be learned and adjusted during neural network training, in which case the weights may be referred to as learned sample density compensation weights. In some embodiments, the input to the network may be a combination of y and the weights W, whether learned or fixed learnable, without the use of the forward operator A.</div>
</li> <li> <para-num num="[0201]"> </para-num> <div class="description-line" id="p-0217" num="0201">It should also be appreciated that the neural network need not operate on the raw data y, and in some embodiments these data may be pre-processed. For example, in some embodiments these data may be pre-processed to perform operations such as interference removal, denoising, filtering, smoothing, image prewhitening, etc. More generally, the network has the form f(y, A, θ).</div>
</li> <li> <para-num num="[0202]"> </para-num> <div class="description-line" id="p-0218" num="0202">With regard to the neural network weights θ, these weights may be initialized in any suitable way as part of the training procedure. For example, the weights may be initialized randomly (e.g., using He initialization following Equation 12 in He, K., et al.: Deep residual learning for image recognition. Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR). pp. 1026-1034 (2015)). As another example, the network weights may be initialized according to a setting provided by a user. As another example, the network weights may include the learned sampling density weights (e.g., the learned sampling density weights may be a subset of the network weights, the network weights may be initialized using the learned sampling density weights, and all the weights may subsequently be adjusted during training).</div>
</li> <li> <para-num num="[0203]"> </para-num> <div class="description-line" id="p-0219" num="0203">With regard to the output x<sub>rec </sub>of the neural network in Eq. 8, the output may include one or more images per respective RF coil. For example, if the input data contains data from each of N<sub>coil </sub>RF coils, the output may include one MR image for each such RF coil or multiple MR images for each such coil (e.g., when each coil performs multiple acquisitions, for example, using different contrasts).</div>
</li> <li> <para-num num="[0204]"> </para-num> <div class="description-line" id="p-0220" num="0204">In some embodiments, multiple neural networks of the type specified in Eq. 8 may be employed and the output of these networks may be combined such that the multiple neural networks are utilized as an ensemble. The combination may be performed using any suitable type of aggregation rule including, but not limited to, average, weighted averaging, averaging with outlier rejection, and selection of the “best” reconstruction according to a user-defined criterion (e.g., manual inspection, automated selection based on a quantitative metric such as the signal to noise ratio, a perceptual metric, and/or any other suitable metric). Alternatively, in some embodiments, multiple instances of x<sub>rec </sub>from individual neural networks may be stacked together, and be considered as the output of the network.</div>
</li> <li> <para-num num="[0205]"> </para-num> <div class="description-line" id="p-0221" num="0205">As described above, there are numerous possible embodiments of the neural network formulation of Eq. 8 including, but not limited to, the embodiments described herein such as: (1) the non-uniform variational network (NVN) as described herein including with reference to <figref idrefs="DRAWINGS">FIGS. 13A-D</figref>; (2) the generalized non-uniform variational network (GNVN) as described herein with reference to <figref idrefs="DRAWINGS">FIGS. 13A, 13D, and 13E</figref>; (3) the Deep K-space Interpolation Reconstruction (DKIR) network as described herein including with reference to <figref idrefs="DRAWINGS">FIGS. 1A-C</figref>; and (4) the Deep non-local reconstruction (DNR) network as described herein including with reference to <figref idrefs="DRAWINGS">FIGS. 5A-5C</figref>.</div>
</li> <li> <para-num num="[0206]"> </para-num> <div class="description-line" id="p-0222" num="0206">It should be noted that while some of the above described networks architectures include convolutional neural network blocks, other types of blocks may be used in addition to or instead of the convolutional neural network blocks including, for example, residual network, densely connected networks, or squeeze and excitation networks.</div>
</li> <li> <para-num num="[0207]"> </para-num> <div class="description-line" id="p-0223" num="0207">In some embodiments, any one of the networks described above may be trained using mean-squared error. For example, in some embodiments, each of the reconstruction blocks in the NVN (e.g., blocks <b>1316</b>-<i>i</i>) or GNVN (e.g., blocks <b>1360</b>-<i>i</i>) architectures may be trained using the mean squared-error criterion according to:</div>
</li> <li> <div class="description-line" id="p-0224" num="0000">
<maths id="MATH-US-00008" num="00008">
<math overflow="scroll">
<mrow>
<mrow>
<mi>ℒ</mi>
<mo></mo>
<mrow>
<mo>(</mo>
<mi>θ</mi>
<mo>)</mo>
</mrow>
</mrow>
<mo>=</mo>
<mrow>
<munder>
<mo>∑</mo>
<mrow>
<mrow>
<mo>(</mo>
<mrow>
<mi>y</mi>
<mo>,</mo>
<mi>x</mi>
</mrow>
<mo>)</mo>
</mrow>
<mo>∈</mo>
<mi></mi>
</mrow>
</munder>
<mo></mo>
<msub>
<mrow>
<mo></mo>
<mrow>
<mi>x</mi>
<mo>-</mo>
<msub>
<mi>x</mi>
<mi>rec</mi>
</msub>
</mrow>
<mo></mo>
</mrow>
<mn>2</mn>
</msub>
</mrow>
</mrow>
</math>
</maths>
</div>
</li> <li> <para-num num="[0208]"> </para-num> <div class="description-line" id="p-0225" num="0208">In some embodiments, a reconstruction block can reconstruct each coil-weighted images x<sub>c </sub>separately or jointly. It can also attempt to reconstruct each signal n<sub>avg</sub>=1, . . . , N<sub>avg </sub>jointly or separately.</div>
</li> <li> <para-num num="[0209]"> </para-num> <div class="description-line" id="p-0226" num="0209"> <figref idrefs="DRAWINGS">FIG. 14</figref> is a flowchart of an illustrative process <b>1400</b> for using a neural network model to generate an MR image from input MR spatial frequency data obtained using non-Cartesian sampling, in accordance with some embodiments of the technology described herein. In some embodiments, process <b>1400</b> may be performed using a non-uniform variational network (e.g., the neural network described with reference to <figref idrefs="DRAWINGS">FIGS. 13A-D</figref>), a generalized non-uniform variation network (e.g., the neural network described with reference to <figref idrefs="DRAWINGS">FIGS. 13A, 13D, and 13E</figref>), or any other suitable type of neural network model.</div>
</li> <li> <para-num num="[0210]"> </para-num> <div class="description-line" id="p-0227" num="0210">In some embodiments, the illustrative process <b>1400</b> may be performed using any suitable computing device. For example, in some embodiments, the process <b>1400</b> may be performed by a computing device co-located (e.g., in the same room as) with an MRI system that obtained the input MR spatial frequency data by imaging a subject. As another example, in some embodiments, the process <b>1400</b> may be performed by one or more processors located remotely from the MRI system (e.g., as part of a cloud computing environment) that obtained the input spatial frequency data by imaging a subject.</div>
</li> <li> <para-num num="[0211]"> </para-num> <div class="description-line" id="p-0228" num="0211">Process <b>1400</b> begins at act <b>1402</b>, where input MR spatial frequency data is obtained. In some embodiments, the input MR spatial frequency data had been previously obtained by an MRI system and stored for subsequent analysis, so that it is accessed at act <b>1402</b>. In other embodiments, the input MR spatial frequency data may be obtained by an MRI system (including any of the MRI systems described herein) as part of process <b>1400</b>. Regardless of when an MRI system performed the imaging to obtain the input MR spatial frequency data, the data may have been obtained using a non-Cartesian sampling trajectory, examples of which are provided herein.</div>
</li> <li> <para-num num="[0212]"> </para-num> <div class="description-line" id="p-0229" num="0212">Next, process <b>1400</b> proceeds to act <b>1404</b>, where the input MR spatial frequency data may be pre-processed to obtain an initial image reconstruction. For example, in some embodiments, the input MR spatial frequency data may be transformed to the image domain by using a non-uniform Fourier transformation. For example, the input MR spatial frequency data y may be transformed to the image domain using the adjoint operator A<sup>H </sup>described herein (e.g., by computing A<sup>H</sup>y). As another example, the input MR spatial frequency data may be transformed to the image domain using a gridding reconstruction such as A<sup>H</sup>Wy, where the matrix W is a sampling density compensation matrix that could be: the matrix A<sup>H</sup>A1, where 1 is a vector of one's, a user-specified matrix, a matrix learned during training, and/or any suitable combination thereof. In the illustrative example of <figref idrefs="DRAWINGS">FIG. 13A</figref>, the pre-processing may be performed by the initial processing block <b>1312</b>.</div>
</li> <li> <para-num num="[0213]"> </para-num> <div class="description-line" id="p-0230" num="0213">In some embodiments, the initializer block transforms the input MR spatial frequency data to the image domain to generate an initial image for subsequent processing by the neural network model <b>1310</b>. The initializer block may be implemented in any suitable way. For example, in some embodiments, the initializer block may apply the adjoint non-uniform Fourier transformation to the input MR spatial frequency data to obtain the initial image. As another example, in some embodiments, the initializer block may apply the gridding reconstruction to the input MR spatial frequency data to obtain the initial image.</div>
</li> <li> <para-num num="[0214]"> </para-num> <div class="description-line" id="p-0231" num="0214">Next, process <b>1400</b> proceeds to act <b>1406</b>, where a block of a neural network model is applied to the initial image obtained at act <b>1404</b> (or to the current image data when act <b>1406</b> is being executed on a return path from decision block <b>1408</b> after one or more neural network blocks have already been applied to the initial image). In some embodiments, the block of the neural network model may be configured to perform data consistency processing by using a non-uniform Fourier transformation to take into account the initial MR spatial frequency data obtained at act <b>1402</b>. This may be done in any suitable way. For example, in some embodiments, the data consistency processing may be performed by a data consistency block such as block <b>1316</b>-<i>i </i>described with reference to <figref idrefs="DRAWINGS">FIG. 13B</figref>. In such a block, data consistency processing involves transforming intermediate reconstructions transformed to the spatial frequency domain using a non-uniform Fourier transformation and comparing the result to the input MR spatial frequency data. As another example, in some embodiments, the data consistency processing may be performed by transforming the input MR spatial frequency data to the image domain using the non-uniform Fourier transformation and providing the result as input to one or more convolutional blocks as is done, for example, in neural network block <b>1360</b>-<i>i </i>described with reference to <figref idrefs="DRAWINGS">FIG. 13E</figref>.</div>
</li> <li> <para-num num="[0215]"> </para-num> <div class="description-line" id="p-0232" num="0215">Next, process <b>1400</b> proceeds to decision block <b>1408</b> where it is determined whether another neural network block is to be applied. If it is determined that another block is to be applied, process <b>1400</b> returns to act <b>1406</b>, where another neural network block is applied to the image data generated at the completion of the last iteration of block <b>1406</b>. Otherwise, this image data is output as the final reconstructed MR image at act <b>1410</b>.</div>
</li> <li> <para-num num="[0216]"> </para-num> <div class="description-line" id="p-0233" num="0216">The inventors have evaluated the performance of the neural network architectures described herein including with reference to <figref idrefs="DRAWINGS">FIGS. 13A-E</figref> and <b>14</b> on real-world MR images. The details of these experiments are described next.</div>
</li> <li> <para-num num="[0217]"> </para-num> <div class="description-line" id="p-0234" num="0217">As part of the experiments, <b>640</b> randomly selected T1-weighted and T2-weighted brain images were obtained from Human Connectome Project (https:///www.humanconnectome.org/study/hcp-young-adult/document/1200-subjects-data-release). Six hundred of the images were used for training the neural network, while 40 of the images were used for evaluating the performance of the trained neural network. To perform a realistic simulation, a number of pre-processing steps were performed. First, since only magnitude images were provided from the Human Connectome Project, complex-valued images were created by adding phase information to the magnitude data using two-dimensional Fourier bases with randomly sampled low order coefficients. Second, the images were multiplied by spatially localized complex coil sensitivity profiles, which was derived from an analytical model of an MRI RF coil. Finally, a realistic amount of noise observable for parallel image acquisition was added to the images. For the experiments, the images were resampled to a field of view (FOV) of 180×180×180 mm<sup>3</sup>, with the isotrophic resolution of 3.4×3.4×3.4 mm<sup>3</sup>, 1.7×1.7×1.7 mm<sup>3 </sup>and 1.15×1.15×1.15 mm<sup>3</sup>, resulting in the matrix sizes 64<sup>3</sup>, 128<sup>3 </sup>and 192<sup>3</sup>, respectively.</div>
</li> <li> <para-num num="[0218]"> </para-num> <div class="description-line" id="p-0235" num="0218">In these experiments, single coil reconstruction is evaluated in order to study the behavior of non-uniform MR data reconstruction. The MR data was under-sampled using 2D non-uniform variable density, where the sampling density decays from the k-space center at quadratic speed. For each matrix size, the sampling trajectory with the target acceleration factor R∈{2,4} was generated. For evaluation, we measured mean squared error (MSE), structural similarity index measurement (SSIM), and peak signal-to-noise ratio (PSNR).</div>
</li> <li> <para-num num="[0219]"> </para-num> <div class="description-line" id="p-0236" num="0219">The techniques developed herein were developed with a number of conventional techniques that have been applied to non-uniform MR data including: (1) AUTOMAP (Zhu B., et al.: Image reconstruction by domain-transform manifold learning. Nature 555(7697), 487 (2018)); (2) image domain U-net (Han, Y., et al.: Deep learning with domain adaptation for acceleration projection-reconstruction MR. Magnetic resonance in medicine 80(3), 118-1205 (2018)); and (3) k-space domain U-net. Id. All deep learning methods were trained using MSE. Due to its high GPU memory requirements, AUTOMAP was trained only for the matrix size of 64×64. For the NVN approach having the architecture shown in <figref idrefs="DRAWINGS">FIGS. 13A-D</figref>, a U-net with 3 levels of downsampling (see e.g., <figref idrefs="DRAWINGS">FIG. 13D</figref>) for each convolutional sub-block. N<sub>it</sub>=5 blocks was used for the number of blocks, and the adjoint A<sup>H</sup>y was used for f<sub>init</sub>. For the GNVN approach, a 5-layer convolutional neural network was used f<sub>sensor-cnn</sub>. Each network was trained for 8,000 epochs using Adam optimizer with α=10<sup>−4</sup>, β<sub>1</sub>=0.9, β<sub>2</sub>=0.999. All methods were implemented in TensorFlow.</div>
</li> <li> <para-num num="[0220]"> </para-num> <div class="description-line" id="p-0237" num="0220">Results of the evaluations are summarized in Table 1 below. The NVN and GNVN approaches developed by the inventors consistently outperformed the baseline approaches for both acceleration factors. AUTOMAP and k-space U-net both underperformed compared to other methods.</div>
</li> <li> <div class="description-line" id="p-0238" num="0000">
<tables id="TABLE-US-00001" num="00001">
<patent-tables colsep="0" frame="none" pgwide="1" rowsep="0">
<table align="left" class="description-table" cols="1" colsep="0" rowsep="0" width="100%">
<thead>
<tr class="description-tr">
<td class="description-td" colspan="1" nameend="1" namest="1" rowsep="1">TABLE 1</td>
</tr>
</thead>
<tbody><tr class="description-tr">
<td align="center" class="description-td" colspan="1" nameend="1" namest="1" rowsep="1"> </td>
</tr>
<tr class="description-tr">
<td class="description-td">Quantitative result for acceleration factor (R) 2 and 4. For each metric, mean and standard</td>
</tr>
<tr class="description-tr">
<td class="description-td">deviation is computed. For mean squared error (MSE), the values are scaled by 10<sup>3</sup>.</td>
</tr>
</tbody></table>
<table align="left" class="description-table" cols="5" colsep="0" rowsep="0" width="100%">
<tbody><tr class="description-tr">
<td class="description-td"> </td>
<td class="description-td">R = 2</td>
<td class="description-td"> </td>
<td class="description-td">R = 4</td>
<td class="description-td"> </td>
</tr>
</tbody></table>
<table align="left" class="description-table" cols="8" colsep="0" rowsep="0" width="100%">
<tbody><tr class="description-tr">
<td class="description-td"> </td>
<td class="description-td">Methods</td>
<td class="description-td">MSE</td>
<td class="description-td">SSIM</td>
<td class="description-td">PSNR</td>
<td class="description-td">MSE</td>
<td class="description-td">SSIM</td>
<td class="description-td">PSNR</td>
</tr>
<tr class="description-tr">
<td class="description-td"> </td>
<td align="center" class="description-td" colspan="8" nameend="7" namest="offset" rowsep="1"> </td>
</tr>
</tbody></table>
<table align="left" class="description-table" cols="10" colsep="0" rowsep="0" width="100%">
<tbody><tr class="description-tr">
<td class="description-td">64 × 64</td>
<td class="description-td">AUTOMAP</td>
<td class="description-td">2.40</td>
<td class="description-td">(42.14)</td>
<td class="description-td">0.87 (0.14)</td>
<td class="description-td">29.87 (3.73)</td>
<td class="description-td">2.59</td>
<td class="description-td">(8.09)</td>
<td class="description-td">0.84 (0.14)</td>
<td class="description-td">28.36 (3.51)</td>
</tr>
<tr class="description-tr">
<td class="description-td">64 × 64</td>
<td class="description-td">U-net</td>
<td class="description-td">1.53</td>
<td class="description-td">(18.13)</td>
<td class="description-td">0.92 (0.11)</td>
<td class="description-td">31.44 (3.86)</td>
<td class="description-td">2.25</td>
<td class="description-td">(21.87)</td>
<td class="description-td">0.90 (0.10)</td>
<td class="description-td">29.81 (3.74)</td>
</tr>
<tr class="description-tr">
<td class="description-td">64 × 64</td>
<td class="description-td">U-net (k)</td>
<td class="description-td">1.91</td>
<td class="description-td">(7.40)</td>
<td class="description-td">0.86 (0.13)</td>
<td class="description-td">30.07 (3.57)</td>
<td class="description-td">2.51</td>
<td class="description-td">(6.58)</td>
<td class="description-td">0.81 (0.13)</td>
<td class="description-td">28.48 (3.34)</td>
</tr>
<tr class="description-tr">
<td class="description-td">64 × 64</td>
<td class="description-td">NVN</td>
<td class="description-td">1.22</td>
<td class="description-td">(12.51)</td>
<td class="description-td">0.93 (0.11)</td>
<td class="description-td">32.33 (3.92)</td>
<td class="description-td">1.38</td>
<td class="description-td">(4.04)</td>
<td class="description-td">0.92 (0.09)</td>
<td class="description-td">30.95 (3.62)</td>
</tr>
<tr class="description-tr">
<td class="description-td">64 × 64</td>
<td class="description-td">GNVN</td>
<td class="description-td">1.22</td>
<td class="description-td">(16.88)</td>
<td class="description-td">0.93 (0.09)</td>
<td class="description-td">32.54 (4.00)</td>
<td class="description-td">1.37</td>
<td class="description-td">(4.58)</td>
<td class="description-td">0.92 (0.08)</td>
<td class="description-td">31.08 (3.66)</td>
</tr>
<tr class="description-tr">
<td class="description-td">128 × 128</td>
<td class="description-td">U-net</td>
<td class="description-td">0.75</td>
<td class="description-td">(3.73)</td>
<td class="description-td">0.94 (0.09)</td>
<td class="description-td">34.06 (3.68)</td>
<td class="description-td">0.91</td>
<td class="description-td">(4.10)</td>
<td class="description-td">0.94 (0.07)</td>
<td class="description-td">32.76 (3.50)</td>
</tr>
<tr class="description-tr">
<td class="description-td">128 × 128</td>
<td class="description-td">U-net (k)</td>
<td class="description-td">1.02</td>
<td class="description-td">(1.26)</td>
<td class="description-td">0.89 (0.10)</td>
<td class="description-td">32.51 (3.58)</td>
<td class="description-td">1.54</td>
<td class="description-td">(13.77)</td>
<td class="description-td">0.87 (0.11)</td>
<td class="description-td">31.32 (3.48)</td>
</tr>
<tr class="description-tr">
<td class="description-td">128 × 128</td>
<td class="description-td">NVN</td>
<td class="description-td">0.57</td>
<td class="description-td">(0.86)</td>
<td class="description-td">0.95 (0.06)</td>
<td class="description-td">34.68 (3.57)</td>
<td class="description-td">0.82</td>
<td class="description-td">(1.07)</td>
<td class="description-td">0.93 (0.07)</td>
<td class="description-td">32.95 (3.54)</td>
</tr>
<tr class="description-tr">
<td class="description-td">128 × 128</td>
<td class="description-td">GNVN</td>
<td class="description-td">0.58</td>
<td class="description-td">(1.99)</td>
<td class="description-td">0.95 (0.07)</td>
<td class="description-td">34.83 (3.64)</td>
<td class="description-td">0.67</td>
<td class="description-td">(0.79)</td>
<td class="description-td">0.95 (0.03)</td>
<td class="description-td">33.65 (3.47)</td>
</tr>
<tr class="description-tr">
<td class="description-td">192 × 192</td>
<td class="description-td">U-net</td>
<td class="description-td">0.47</td>
<td class="description-td">(1.55)</td>
<td class="description-td">0.96 (0.05)</td>
<td class="description-td">35.68 (3.67)</td>
<td class="description-td">0.67</td>
<td class="description-td">(1.13)</td>
<td class="description-td">0.94 (0.07)</td>
<td class="description-td">33.71 (3.23)</td>
</tr>
<tr class="description-tr">
<td class="description-td">192 × 192</td>
<td class="description-td">U-net (k)</td>
<td class="description-td">0.77</td>
<td class="description-td">(0.81)</td>
<td class="description-td">0.89 (0.10)</td>
<td class="description-td">33.83 (3.62)</td>
<td class="description-td">1.31</td>
<td class="description-td">(7.53)</td>
<td class="description-td">0.87 (0.11)</td>
<td class="description-td">31.84 (3.35)</td>
</tr>
<tr class="description-tr">
<td class="description-td">192 × 192</td>
<td class="description-td">NVN</td>
<td class="description-td">0.40</td>
<td class="description-td">(0.60)</td>
<td class="description-td">0.96 (0.06)</td>
<td class="description-td">36.11 (3.60)</td>
<td class="description-td">0.66</td>
<td class="description-td">(1.40)</td>
<td class="description-td">0.91 (0.12)</td>
<td class="description-td">34.01 (3.43)</td>
</tr>
<tr class="description-tr">
<td class="description-td">192 × 192</td>
<td class="description-td">GNVN</td>
<td class="description-td">0.40</td>
<td class="description-td">(0.77)</td>
<td class="description-td">0.96 (0.05)</td>
<td class="description-td">36.15 (3.57)</td>
<td class="description-td">0.52</td>
<td class="description-td">(0.44)</td>
<td class="description-td">0.96 (0.03)</td>
<td class="description-td">34.36 (3.07)</td>
</tr>
<tr class="description-tr">
<td align="center" class="description-td" colspan="10" nameend="10" namest="1" rowsep="1"> </td>
</tr>
</tbody></table>
</patent-tables>
</tables>
</div>
</li> <li> <para-num num="[0221]"> </para-num> <div class="description-line" id="p-0239" num="0221">As between the NVN and GNVN approaches, while the NVN approach showed higher data fidelity (lower mean-squared error), the GNVN approach offered better values for PSNR and SSIM. The sample reconstructions of T1-weighted image for R=2 and T2-weighted image for R=4 is shown in <figref idrefs="DRAWINGS">FIG. 15A</figref> and <figref idrefs="DRAWINGS">FIG. 15B</figref> respectively. While the overall differences between U-net, NVN and GNVN were small, the reconstructions from NVN and GNVN resulted in lower error, owing to the data consistency processing. GNVN resulted in the lowest overall errors and preserved more of the fine details. Nevertheless, a certain level of blurriness can be observed in all images, due to the added noise. Again, U-net (k-space) for single coil resulted in a suboptimal reconstruction qualitatively. In <figref idrefs="DRAWINGS">FIG. 15C</figref>, we visualize the output of NVN and GNVN at each block. Interestingly, unlike compressed sensing methods, the intermediate image can diverge from the final image. This is unsurprising as there was no constraint to enforce such behavior. For NVN, most output of each block seems closer to the ground truth, presumably because the output of the DC-i and CNN-i blocks are explicitly combined. In comparison, GNVN showed more interesting features for all the intermediate stages, mainly highlighting the high frequency information.</div>
</li> <li> <para-num num="[0222]"> </para-num> <div class="description-line" id="p-0240" num="0222">In these experiments, the number of parameters were 128.1M, 22.0M, 6.6M and 7.3M for AUTOMAP (64×64), U-net, NVN and GNVN respectively. The reconstruction speed were 5.928±0.020 ms, 19.145±0.072 ms, 19.459±0.077 ms, 44.934±0.088 ms, and 65.520±0.100 ms for AUTOMAP (for the image size 64<sup>3</sup>), U-net, U-net (k-space), NVN and GNVN respectively for the image size 192<sup>3</sup>.</div>
</li> <li> <para-num num="[0223]"> </para-num> <div class="description-line" id="p-0241" num="0223"> <figref idrefs="DRAWINGS">FIG. 16</figref> is a block diagram of exemplary components of a MRI system <b>1600</b>. In the illustrative example of <figref idrefs="DRAWINGS">FIG. 16</figref>, MRI system <b>1600</b> comprises workstation <b>1604</b>, controller <b>1606</b>, pulse sequences store <b>1608</b>, power management system <b>1610</b>, and magnetic components <b>1620</b>. It should be appreciated that system <b>1600</b> is illustrative and that an MRI system may have one or more other components of any suitable type in addition to or instead of the components illustrated in <figref idrefs="DRAWINGS">FIG. 16</figref>.</div>
</li> <li> <para-num num="[0224]"> </para-num> <div class="description-line" id="p-0242" num="0224">As illustrated in <figref idrefs="DRAWINGS">FIG. 16</figref>, magnetic components <b>1620</b> comprises B<sub>0 </sub>magnet <b>1622</b>, shim coils <b>1624</b>, RF transmit and receive coils <b>1626</b>, and gradient coils <b>1628</b>. B<sub>0 </sub>magnet <b>1622</b> may be used to generate, at least in part, the main magnetic field B<sub>0</sub>. B<sub>0 </sub>magnet <b>1622</b> may be any suitable type of magnet that can generate a main magnetic field (e.g., a low-field strength of approximately 0.2 T or less), and may include one or more B<sub>0 </sub>coils, correction coils, etc. Shim coils <b>1624</b> may be used to contribute magnetic field(s) to improve the homogeneity of the B<sub>0 </sub>field generated by magnet <b>1622</b>. Gradient coils <b>1628</b> may be arranged to provide gradient fields and, for example, may be arranged to generate gradients in the magnetic field in three substantially orthogonal directions (X, Y, Z) to localize where MR signals are induced.</div>
</li> <li> <para-num num="[0225]"> </para-num> <div class="description-line" id="p-0243" num="0225">RF transmit and receive coils <b>1626</b> may comprise one or more transmit coils that may be used to generate RF pulses to induce a magnetic field B<sub>1</sub>. The transmit/receive coil(s) may be configured to generate any suitable type of RF pulses configured to excite an MR response in a subject and detect the resulting MR signals emitted. RF transmit and receive coils <b>1626</b> may include one or multiple transmit coils and one or multiple receive coils. The configuration of the transmit/receive coils varies with implementation and may include a single coil for both transmitting and receiving, separate coils for transmitting and receiving, multiple coils for transmitting and/or receiving, or any combination to achieve single channel or parallel MRI systems. Thus, the transmit/receive magnetic component is often referred to as Tx/Rx or Tx/Rx coils to generically refer to the various configurations for the transmit and receive component of an MRI system.</div>
</li> <li> <para-num num="[0226]"> </para-num> <div class="description-line" id="p-0244" num="0226">Each of magnetics components <b>1620</b> may be of any suitable type and may be constructed in any suitable way. For example, in some embodiments, the B<sub>0 </sub>magnet <b>1622</b> may be an electromagnet or a permanent magnet (e.g., as described below with reference to <figref idrefs="DRAWINGS">FIGS. 17A-B</figref> and <b>18</b>A-B). As another example, in some embodiments, one or more magnetics components <b>1620</b> (e.g., shim coils <b>1624</b> and/or gradient coils <b>1628</b>) may be fabricated using the laminate techniques.</div>
</li> <li> <para-num num="[0227]"> </para-num> <div class="description-line" id="p-0245" num="0227">Power management system <b>1610</b> includes electronics to provide operating power to one or more components of the low-field MRI system <b>1600</b>. For example, power management system <b>1610</b> may include one or more power supplies, gradient power amplifiers, transmit coil amplifiers, and/or any other suitable power electronics needed to provide suitable operating power to energize and operate components of the low-field MRI system <b>1600</b>.</div>
</li> <li> <para-num num="[0228]"> </para-num> <div class="description-line" id="p-0246" num="0228">As illustrated in <figref idrefs="DRAWINGS">FIG. 16</figref>, power management system <b>1610</b> comprises power supply <b>1612</b>, amplifier(s) <b>1614</b>, transmit/receive switch <b>1616</b>, and thermal management components <b>1618</b>. Power supply <b>1612</b> includes electronics to provide operating power to magnetic components <b>1620</b> of the low-field MRI system <b>1600</b>. For example, in some embodiments, power supply <b>1612</b> may include electronics to provide operating power to one or more B<sub>0 </sub>coils (e.g., B<sub>0 </sub>magnet <b>1622</b>) to produce the main magnetic field for the low-field MRI system, one or more shim coils <b>1624</b>, and/or one or more gradient coils <b>1628</b>. In some embodiments, power supply <b>1612</b> may be a unipolar, continuous wave (CW) power supply, however, any suitable power supply may be used. Transmit/receive switch <b>1616</b> may be used to select whether RF transmit coils or RF receive coils are being operated.</div>
</li> <li> <para-num num="[0229]"> </para-num> <div class="description-line" id="p-0247" num="0229">In some embodiments, amplifier(s) <b>1614</b> may include one or more RF receive (Rx) pre-amplifiers that amplify MR signals detected by one or more RF receive coils (e.g., coils <b>1624</b>), one or more RF transmit (Tx) amplifiers configured to provide power to one or more RF transmit coils (e.g., coils <b>1626</b>), one or more gradient power amplifiers configured to provide power to one or more gradient coils (e.g., gradient coils <b>1628</b>), and/or one or more shim amplifiers configured to provide power to one or more shim coils (e.g., shim coils <b>1624</b>).</div>
</li> <li> <para-num num="[0230]"> </para-num> <div class="description-line" id="p-0248" num="0230">In some embodiments, thermal management components <b>1618</b> provide cooling for components of low-field MRI system <b>1600</b> and may be configured to do so by facilitating the transfer of thermal energy generated by one or more components of the low-field MRI system <b>1600</b> away from those components. Thermal management components <b>1618</b> may include, without limitation, components to perform water-based or air-based cooling, which may be integrated with or arranged in close proximity to MRI components that generate heat including, but not limited to, B<sub>0 </sub>coils, gradient coils, shim coils, and/or transmit/receive coils. Thermal management components <b>1618</b> may include any suitable heat transfer medium including, but not limited to, air and water, to transfer heat away from components of the low-field MRI system <b>1600</b>.</div>
</li> <li> <para-num num="[0231]"> </para-num> <div class="description-line" id="p-0249" num="0231">As illustrated in <figref idrefs="DRAWINGS">FIG. 16</figref>, low-field MRI system <b>1600</b> includes controller <b>1606</b> (also referred to as a console) having control electronics to send instructions to and receive information from power management system <b>1610</b>. Controller <b>1606</b> may be configured to implement one or more pulse sequences, which are used to determine the instructions sent to power management system <b>1610</b> to operate the magnetic components <b>1620</b> in a desired sequence. For example, controller <b>1606</b> may be configured to control the power management system <b>1610</b> to operate the magnetic components <b>1620</b> in accordance with a balanced steady-state free precession (bSSFP) pulse sequence, a low-field gradient echo pulse sequence, a low-field spin echo pulse sequence, a low-field inversion recovery pulse sequence, arterial spin labeling, diffusion weighted imaging (DWI), and/or any other suitable pulse sequence. Controller <b>1606</b> may be implemented as hardware, software, or any suitable combination of hardware and software, as aspects of the disclosure provided herein are not limited in this respect.</div>
</li> <li> <para-num num="[0232]"> </para-num> <div class="description-line" id="p-0250" num="0232">In some embodiments, controller <b>1606</b> may be configured to implement a pulse sequence by obtaining information about the pulse sequence from pulse sequences repository <b>1608</b>, which stores information for each of one or more pulse sequences. Information stored by pulse sequences repository <b>1608</b> for a particular pulse sequence may be any suitable information that allows controller <b>1606</b> to implement the particular pulse sequence. For example, information stored in pulse sequences repository <b>1608</b> for a pulse sequence may include one or more parameters for operating magnetics components <b>1620</b> in accordance with the pulse sequence (e.g., parameters for operating the RF transmit and receive coils <b>1626</b>, parameters for operating gradient coils <b>1628</b>, etc.), one or more parameters for operating power management system <b>1610</b> in accordance with the pulse sequence, one or more programs comprising instructions that, when executed by controller <b>1606</b>, cause controller <b>1606</b> to control system <b>1600</b> to operate in accordance with the pulse sequence, and/or any other suitable information. Information stored in pulse sequences repository <b>1608</b> may be stored on one or more non-transitory storage media.</div>
</li> <li> <para-num num="[0233]"> </para-num> <div class="description-line" id="p-0251" num="0233">As illustrated in <figref idrefs="DRAWINGS">FIG. 16</figref>, in some embodiments, controller <b>1606</b> may interact with computing device <b>1604</b> programmed to process received MR data (which, in some embodiments, may be spatial frequency domain MR data). For example, computing device <b>1604</b> may process received MR data to generate one or more MR images using any suitable image reconstruction process(es) including using any of the techniques described herein that make use of neural network models to generate MR images from spatial frequency MR data. For example, computing device <b>1604</b> may perform any of the processes described herein with reference to <figref idrefs="DRAWINGS">FIGS. 2A, 2B, 2C, 2D, and 14</figref>. Controller <b>1606</b> may provide information about one or more pulse sequences to computing device <b>1604</b> for the processing of data by the computing device. For example, controller <b>1606</b> may provide information about one or more pulse sequences to computing device <b>1604</b> and the computing device may perform an image reconstruction process based, at least in part, on the provided information.</div>
</li> <li> <para-num num="[0234]"> </para-num> <div class="description-line" id="p-0252" num="0234">In some embodiments, computing device <b>1604</b> may be any electronic device or devices configured to process acquired MR data and generate one or more images of the subject being imaged. In some embodiments, computing device <b>1604</b> may include a fixed electronic device such as a desktop computer, a server, a rack-mounted computer, or any other suitable fixed electronic device that may be configured to process MR data and generate one or more images of the subject being imaged. Alternatively, computing device <b>1604</b> may be a portable device such as a smart phone, a personal digital assistant, a laptop computer, a tablet computer, or any other portable device that may be configured to process MR data and generate one or images of the subject being imaged. In some embodiments, computing device <b>1304</b> may comprise multiple computing devices of any suitable type, as the aspects of the technology described herein are not limited in this respect.</div>
</li> <li> <para-num num="[0235]"> </para-num> <div class="description-line" id="p-0253" num="0235">In some embodiments, a user <b>1602</b> may interact with computing device <b>1604</b> to control aspects of the low-field MR system <b>1600</b> (e.g., program the system <b>1600</b> to operate in accordance with a particular pulse sequence, adjust one or more parameters of the system <b>1600</b>, etc.) and/or view images obtained by the low-field MR system <b>1600</b>. According to some embodiments, computing device <b>1604</b> and controller <b>1606</b> form a single controller, while in other embodiments, computing device <b>1604</b> and controller <b>1606</b> each comprise one or more controllers. It should be appreciated that the functionality performed by computing device <b>1604</b> and controller <b>1606</b> may be distributed in any way over any combination of one or more controllers, as the aspects of the technology described herein are not limited for use with any particular implementation or architecture.</div>
</li> <li> <para-num num="[0236]"> </para-num> <div class="description-line" id="p-0254" num="0236"> <figref idrefs="DRAWINGS">FIGS. 17A and 17B</figref> illustrate bi-planar permanent magnet configurations for a B<sub>0 </sub>magnet, in accordance with some embodiments of the technology described herein. <figref idrefs="DRAWINGS">FIG. 17A</figref> illustrates a permanent B<sub>0 </sub>magnet <b>2100</b>, in accordance with some embodiments. In the illustrated embodiment, B<sub>0 </sub>magnet <b>2100</b> is formed by permanent magnets <b>2110</b> <i>a </i>and <b>2110</b> <i>b </i>arranged in a bi-planar geometry and a yoke <b>2120</b> that captures electromagnetic flux produced by the permanent magnets and transfers the flux to the opposing permanent magnet to increase the flux density between permanent magnets <b>2110</b> <i>a </i>and <b>2110</b> <i>b</i>. Each of permanent magnets <b>2110</b> <i>a </i>and <b>2110</b> <i>b </i>is formed from a plurality of concentric permanent magnet rings. In particular, as visible in <figref idrefs="DRAWINGS">FIG. 17A</figref>, permanent magnet <b>2110</b> <i>b </i>comprises an outer ring of permanent magnets <b>2114</b> <i>a</i>, a middle ring of permanent magnets <b>2114</b> <i>b</i>, an inner ring of permanent magnets <b>2114</b> <i>c</i>, and a permanent magnet disk <b>2114</b> <i>d </i>at the center. Though shown with four concentric permanent magnet rings, permanent magnet <b>2110</b> <i>b </i>(and permanent magnet <b>2110</b> <i>a</i>) may have any suitable number of permanent magnet rings, as aspects of the technology described herein are not limited in this respect. Permanent magnet <b>2110</b> <i>a </i>may be formed substantially identically to permanent magnet <b>2110</b> <i>b </i>and, for example, comprise the same set of permanent magnet rings as permanent magnet <b>2110</b> <i>b. </i> </div>
</li> <li> <para-num num="[0237]"> </para-num> <div class="description-line" id="p-0255" num="0237">The permanent magnet material used may be selected depending on the design requirements of the system. For example, according to some embodiments, the permanent magnets (or some portion thereof) may be made of NdFeB, which produces a magnetic field with a relatively high magnetic field per unit volume of material once magnetized. In some embodiments, SmCo material is used to form the permanent magnets, or some portion thereof. While NdFeB produces higher field strengths (and in general is less expensive than SmCo), SmCo exhibits less thermal drift and thus provides a more stable magnetic field in the face of temperature fluctuations. Other types of permanent magnet material(s) may be used as well, as the aspects of the technology described herein are not limited in this respect. In general, the type or types of permanent magnet material utilized will depend, at least in part, on the field strength, temperature stability, weight, cost and/or ease of use requirements of a given B<sub>0 </sub>magnet implementation.</div>
</li> <li> <para-num num="[0238]"> </para-num> <div class="description-line" id="p-0256" num="0238">In some embodiments, the permanent magnet rings are sized and arranged to produce a homogenous field of a desired strength in the imaging region (field of view) between permanent magnets <b>2110</b> <i>a </i>and <b>2110</b> <i>b</i>. In the exemplary embodiment illustrated in <figref idrefs="DRAWINGS">FIG. 17A</figref>, each permanent magnet ring comprises a plurality segments, each segment formed using a plurality of permanent magnet blocks stacked in the radial direction and positioned adjacent to one another about the periphery to form the respective ring. The inventors have appreciated that by varying the width (in the direction tangent to the ring) of each permanent magnet, less waste of useful space may be achieved while using less material. For example, the space between stacks that does not produce useful magnetic fields can be reduced by varying the width of the blocks, for example, as function of the radial position of the block, allowing for a closer fit to reduce wasted space and maximize the amount of magnetic field that can be generated in a given space. The dimensions of the blocks may also be varied in any desired way to facilitate the production of a magnetic field of desired strength and homogeneity. For example, in some embodiments, the heights of the blocks different rings may be different from one another and/or the heights of one or more blocks within a particular ring may be different from one another in order to achieve a magnetic field of desired strength and homogeneity.</div>
</li> <li> <para-num num="[0239]"> </para-num> <div class="description-line" id="p-0257" num="0239">As shown in <figref idrefs="DRAWINGS">FIG. 17A</figref>, B<sub>0 </sub>magnet <b>2100</b> further comprises yoke <b>2120</b> configured and arranged to capture magnetic flux generated by permanent magnets <b>2110</b> <i>a </i>and <b>2110</b> <i>b </i>and direct it to the opposing side of the B<sub>0 </sub>magnet to increase the flux density in between permanent magnets <b>2110</b> <i>a </i>and <b>2110</b> <i>b</i>, increasing the field strength within the field of view of the B<sub>0 </sub>magnet. By capturing magnetic flux and directing it to the region between permanent magnets <b>2110</b> <i>a </i>and <b>2110</b> <i>b</i>, less permanent magnet material can be used to achieve a desired field strength, thus reducing the size, weight and cost of the B<sub>0 </sub>magnet <b>2100</b>. Alternatively, for given permanent magnets, the field strength can be increased, thus improving the SNR of the system without having to use increased amounts of permanent magnet material. For exemplary B<sub>0 </sub>magnet <b>2100</b>, yoke <b>2120</b> comprises a frame <b>2122</b> and plates <b>2124</b> <i>a </i>and <b>2124</b> <i>b</i>. Plates <b>2124</b> <i>a </i>and <b>2124</b> <i>b </i>may capture magnetic flux generated by permanent magnets <b>2110</b> <i>a </i>and <b>2110</b> <i>b </i>and direct it to frame <b>2122</b> to be circulated via the magnetic return path of the yoke to increase the flux density in the field of view of the B<sub>0 </sub>magnet. Yoke <b>2120</b> may be constructed of any desired ferromagnetic material, for example, low carbon steel, CoFe and/or silicon steel, etc. to provide the desired magnetic properties for the yoke. In some embodiments, plates <b>2124</b> <i>a </i>and <b>2124</b> <i>b </i>(and/or frame <b>2122</b> or portions thereof) may be constructed of silicon steel or the like in areas where the gradient coils could most prevalently induce eddy currents.</div>
</li> <li> <para-num num="[0240]"> </para-num> <div class="description-line" id="p-0258" num="0240">Exemplary frame <b>2122</b> comprises arms <b>2123</b> <i>a </i>and <b>2123</b> <i>b </i>that attach to plates <b>2124</b> <i>a </i>and <b>2124</b> <i>b</i>, respectively, and supports <b>2125</b> <i>a </i>and <b>2125</b> <i>b </i>providing the magnetic return path for the flux generated by the permanent magnets. The arms are generally designed to reduce the amount of material needed to support the permanent magnets while providing sufficient cross-section for the return path for the magnetic flux generated by the permanent magnets. Frame <b>2122</b> has two supports within a magnetic return path for the B<sub>0 </sub>field produced by the B<sub>0 </sub>magnet. Supports <b>2125</b> <i>a </i>and <b>2125</b> <i>b </i>are produced with a gap <b>2127</b> formed between, providing a measure of stability to the frame and/or lightness to the structure while providing sufficient cross-section for the magnetic flux generated by the permanent magnets. For example, the cross-section needed for the return path of the magnetic flux can be divided between the two support structures, thus providing a sufficient return path while increasing the structural integrity of the frame.</div>
</li> <li> <para-num num="[0241]"> </para-num> <div class="description-line" id="p-0259" num="0241"> <figref idrefs="DRAWINGS">FIG. 17B</figref> illustrates a B<sub>0 </sub>magnet <b>2200</b>, in accordance with some embodiments. B<sub>0 </sub>magnet <b>2200</b> may share design components with B<sub>0 </sub>magnet <b>2100</b> illustrated in <figref idrefs="DRAWINGS">FIG. 17A</figref>. In particular, B<sub>0 </sub>magnet <b>2200</b> is formed by permanent magnets <b>2210</b> <i>a </i>and <b>2210</b> <i>b </i>arranged in a bi-planar geometry with a yoke <b>2220</b> coupled thereto to capture electromagnetic flux produced by the permanent magnets and transfer the flux to the opposing permanent magnet to increase the flux density between permanent magnets <b>2210</b> <i>a </i>and <b>2210</b> <i>b</i>. Each of permanent magnets <b>2210</b> <i>a </i>and <b>2210</b> <i>b </i>is formed from a plurality of concentric permanent magnets, as shown by permanent magnet <b>2210</b> <i>b </i>comprising an outer ring of permanent magnets <b>2214</b> <i>a</i>, a middle ring of permanent magnets <b>2214</b> <i>b</i>, an inner ring of permanent magnets <b>2214</b> <i>c</i>, and a permanent magnet disk <b>2214</b> <i>d </i>at the center. Permanent magnet <b>2210</b> <i>a </i>may comprise the same set of permanent magnet elements as permanent magnet <b>2210</b> <i>b</i>. The permanent magnet material used may be selected depending on the design requirements of the system (e.g., NdFeB, SmCo, etc. depending on the properties desired).</div>
</li> <li> <para-num num="[0242]"> </para-num> <div class="description-line" id="p-0260" num="0242">The permanent magnet rings are sized and arranged to produce a homogenous field of a desired strength in the central region (field of view) between permanent magnets <b>2210</b> <i>a </i>and <b>2210</b> <i>b</i>. In the exemplary embodiment of <figref idrefs="DRAWINGS">FIG. 17B</figref>, each permanent magnet ring comprises a plurality of circular arc segments sized and positioned to produce a desired B<sub>0 </sub>magnetic field. In a similar manner to yoke <b>2120</b> illustrated in <figref idrefs="DRAWINGS">FIG. 17A</figref>, yoke <b>2220</b> is configured and arranged to capture magnetic flux generated by permanent magnets <b>2210</b> <i>a </i>and <b>2210</b> <i>b </i>and direct it to the opposing side of the B<sub>0 </sub>magnet to increase the flux density between permanent magnets <b>2210</b> <i>a </i>and <b>2210</b> <i>b</i>. Yoke <b>2220</b> thereby increases the field strength within the field of view of the B<sub>0 </sub>magnet with less permanent magnet material, reducing the size, weight and cost of the B<sub>0 </sub>magnet. Yoke <b>2220</b> also comprises a frame <b>2222</b> and plates <b>2224</b> <i>a </i>and <b>2224</b> <i>b </i>that, in a manner similar to that described above in connection with yoke <b>2220</b>, captures and circulates magnetic flux generated by the permanent magnets <b>2210</b> <i>a </i>and via the magnetic return path of the yoke to increase the flux density in the field of view of the B<sub>0 </sub>magnet. The structure of yoke <b>2220</b> may be similar to that described above to provide sufficient material to accommodate the magnetic flux generated by the permanent magnets and providing sufficient stability, while minimizing the amount of material used to, for example, reduce the cost and weight of the B<sub>0 </sub>magnet.</div>
</li> <li> <para-num num="[0243]"> </para-num> <div class="description-line" id="p-0261" num="0243">Because a permanent B<sub>0 </sub>magnet, once magnetized, will produce its own persistent magnetic field, power is not required to operate the permanent B<sub>0 </sub>magnet to generate its magnetic field. As a result, a significant (often dominant) contributor to the overall power consumption of an MRI system is eliminated through the use of a permanent magnet (as opposed to, e.g., an electro-magnet which requires power), facilitating the development of an MRI system that can be powered using mains electricity (e.g., via a standard wall outlet or common large household appliance outlets). As described above, the inventors have developed low power, portable low-field MRI systems that can be deployed in virtually any environment and that can be brought to the patient who will undergo an imaging procedure. In this way, patients in emergency rooms, intensive care units, operating rooms and a host of other locations can benefit from MRI in circumstances where MRI is conventionally unavailable.</div>
</li> <li> <para-num num="[0244]"> </para-num> <div class="description-line" id="p-0262" num="0244"> <figref idrefs="DRAWINGS">FIGS. 18A and 18B</figref> illustrate views of a portable MRI system <b>3800</b>, in accordance with some embodiments of the technology described herein. Portable MRI system <b>3800</b> comprises a B<sub>0 </sub>magnet <b>3810</b> formed in part by an upper magnet <b>3810</b> <i>a </i>and a lower magnet <b>3810</b> <i>b </i>having a yoke <b>3820</b> coupled thereto to increase the flux density within the imaging region. The B<sub>0 </sub>magnet <b>3810</b> may be housed in magnet housing <b>3812</b> along with gradient coils <b>3815</b> (e.g., any of the gradient coils described in U.S. application Ser. No. 14/845,652, titled “Low Field Magnetic Resonance Imaging Methods and Apparatus” and filed on Sep. 4, 2015, which is herein incorporated by reference in its entirety). In some embodiments, B<sub>0 </sub>magnet <b>3810</b> comprises an electromagnet. In some embodiments, B<sub>0 </sub>magnet <b>3810</b> comprises a permanent magnet (e.g., any permanent magnet described in U.S. application Ser. No. 15/640,369, titled “LOW-FIELD MAGNETIC RESONANCE IMAGING METHODS AND APPARATUS,” filed on Jun. 30, 2017, which is incorporated by reference herein in its entirety). For example, in some embodiments, B<sub>0 </sub>magnet <b>3810</b> may be the permanent magnet <b>2100</b> described with reference to <figref idrefs="DRAWINGS">FIG. 17A</figref> or the permanent magnet <b>2200</b> described with reference to <figref idrefs="DRAWINGS">FIG. 17B</figref>.</div>
</li> <li> <para-num num="[0245]"> </para-num> <div class="description-line" id="p-0263" num="0245">Illustrative portable MRI system <b>3800</b> further comprises a base <b>3850</b> housing the electronics that operates the MRI system. For example, base <b>3850</b> may house electronics including, but not limited to, one or more gradient power amplifiers, an on-system computer, a power distribution unit, one or more power supplies, and/or any other power components configured to operate the MRI system using mains electricity (e.g., via a connection to a standard wall outlet and/or a large appliance outlet). For example, base <b>3870</b> may house low power components, such as those described herein, enabling at least in part the portable MRI system to be powered from readily available wall outlets. Accordingly, portable MRI system <b>3800</b> can be brought to the patient and plugged into a wall outlet in his or her vicinity.</div>
</li> <li> <para-num num="[0246]"> </para-num> <div class="description-line" id="p-0264" num="0246">Portable MRI system <b>3800</b> further comprises moveable slides <b>3860</b> that can be opened and closed and positioned in a variety of configurations. Slides <b>3860</b> include electromagnetic shielding <b>3865</b>, which can be made from any suitable conductive or magnetic material, to form a moveable shield to attenuate electromagnetic noise in the operating environment of the portable MRI system to shield the imaging region from at least some electromagnetic noise. As used herein, the term electromagnetic shielding refers to conductive or magnetic material configured to attenuate the electromagnetic field in a spectrum of interest and positioned or arranged to shield a space, object and/or component of interest. In the context of an MRI system, electromagnetic shielding may be used to shield electronic components (e.g., power components, cables, etc.) of the MRI system, to shield the imaging region (e.g., the field of view) of the MRI system, or both.</div>
</li> <li> <para-num num="[0247]"> </para-num> <div class="description-line" id="p-0265" num="0247">The degree of attenuation achieved from electromagnetic shielding depends on a number of factors including the type material used, the material thickness, the frequency spectrum for which electromagnetic shielding is desired or required, the size and shape of apertures in the electromagnetic shielding (e.g., the size of the spaces in a conductive mesh, the size of unshielded portions or gaps in the shielding, etc.) and/or the orientation of apertures relative to an incident electromagnetic field. Thus, electromagnetic shielding refers generally to any conductive or magnetic barrier that acts to attenuate at least some electromagnetic radiation and that is positioned to at least partially shield a given space, object or component by attenuating the at least some electromagnetic radiation.</div>
</li> <li> <para-num num="[0248]"> </para-num> <div class="description-line" id="p-0266" num="0248">It should be appreciated that the frequency spectrum for which shielding (attenuation of an electromagnetic field) is desired may differ depending on what is being shielded. For example, electromagnetic shielding for certain electronic components may be configured to attenuate different frequencies than electromagnetic shielding for the imaging region of the MRI system. Regarding the imaging region, the spectrum of interest includes frequencies which influence, impact and/or degrade the ability of the MRI system to excite and detect an MR response. In general, the spectrum of interest for the imaging region of an MRI system correspond to the frequencies about the nominal operating frequency (i.e., the Larmor frequency) at a given B<sub>0 </sub>magnetic field strength for which the receive system is configured to or capable of detecting. This spectrum is referred to herein as the operating spectrum for the MRI system. Thus, electromagnetic shielding that provides shielding for the operating spectrum refers to conductive or magnetic material arranged or positioned to attenuate frequencies at least within the operating spectrum for at least a portion of an imaging region of the MRI system.</div>
</li> <li> <para-num num="[0249]"> </para-num> <div class="description-line" id="p-0267" num="0249">In portable MRI system <b>3800</b> illustrated in <figref idrefs="DRAWINGS">FIGS. 18A and 18B</figref>, the moveable shields are thus configurable to provide shielding in different arrangements, which can be adjusted as needed to accommodate a patient, provide access to a patient, and/or in accordance with a given imaging protocol. For example, for an imaging procedure such as a brain scan, once the patient has been positioned, slides <b>3960</b> can be closed, for example, using handle <b>3862</b> to provide electromagnetic shielding <b>3965</b> around the imaging region except for the opening that accommodates the patient's upper torso. As another example, for an imaging procedure such as a knee scan, slides <b>3960</b> may be arranged to have openings on both sides to accommodate the patient's leg or legs. Accordingly, moveable shields allow the shielding to be configured in arrangements suitable for the imaging procedure and to facilitate positioning the patient appropriately within the imaging region.</div>
</li> <li> <para-num num="[0250]"> </para-num> <div class="description-line" id="p-0268" num="0250">In some embodiments, a noise reduction system comprising one or more noise reduction and/or compensation techniques may be performed to suppress at least some of the electromagnetic noise that is not blocked or sufficiently attenuated by shielding <b>3865</b>. In particular, the inventors have developed noise reduction systems configured to suppress, avoid and/or reject electromagnetic noise in the operating environment in which the MRI system is located. According to some embodiments, these noise suppression techniques work in conjunction with the moveable shields to facilitate operation in the various shielding configurations in which the slides may be arranged. For example, when slides <b>3960</b> are opened, increased levels of electromagnetic noise will likely enter the imaging region via the openings. As a result, the noise suppression component will detect increased electromagnetic noise levels and adapt the noise suppression and/or avoidance response accordingly. Due to the dynamic nature of the noise suppression and/or avoidance techniques described herein, the noise reduction system is configured to be responsive to changing noise conditions, including those resulting from different arrangements of the moveable shields. Thus, a noise reduction system in accordance with some embodiments may be configured to operate in concert with the moveable shields to suppress electromagnetic noise in the operating environment of the MRI system in any of the shielding configurations that may be utilized, including configurations that are substantially without shielding (e.g., configurations without moveable shields).</div>
</li> <li> <para-num num="[0251]"> </para-num> <div class="description-line" id="p-0269" num="0251">To ensure that the moveable shields provide shielding regardless of the arrangements in which the slides are placed, electrical gaskets may be arranged to provide continuous shielding along the periphery of the moveable shield. For example, as shown in <figref idrefs="DRAWINGS">FIG. 18B</figref>, electrical gaskets <b>3867</b> <i>a </i>and <b>3867</b> <i>b </i>may be provided at the interface between slides <b>3860</b> and magnet housing to maintain to provide continuous shielding along this interface. According to some embodiments, the electrical gaskets are beryllium fingers or beryllium-copper fingers, or the like (e.g., aluminum gaskets), that maintain electrical connection between shields <b>3865</b> and ground during and after slides <b>3860</b> are moved to desired positions about the imaging region.</div>
</li> <li> <para-num num="[0252]"> </para-num> <div class="description-line" id="p-0270" num="0252">To facilitate transportation, a motorized component <b>3880</b> is provide to allow portable MRI system to be driven from location to location, for example, using a control such as a joystick or other control mechanism provided on or remote from the MRI system. In this manner, portable MRI system <b>3800</b> can be transported to the patient and maneuvered to the bedside to perform imaging.</div>
</li> <li> <para-num num="[0253]"> </para-num> <div class="description-line" id="p-0271" num="0253">The portable MRI systems described herein may be operated from a portable electronic device, such as a notepad, tablet, smartphone, etc. For example, tablet computer <b>3875</b> may be used to operate portable MRI system to run desired imaging protocols and to view the resulting images. Tablet computer <b>3875</b> may be connected to a secure cloud to transfer images for data sharing, telemedicine, and/or deep learning on the data sets. Any of the techniques of utilizing network connectivity described in U.S. application Ser. No. 14/846,158, titled “Automatic Configuration of a Low Field Magnetic Resonance Imaging System,” filed Sep. 4, 2015, which is herein incorporated by reference in its entirety, may be utilized in connection with the portable MRI systems described herein.</div>
</li> <li> <para-num num="[0254]"> </para-num> <div class="description-line" id="p-0272" num="0254">As discussed above, <figref idrefs="DRAWINGS">FIG. 18C</figref> illustrates a portable MRI system <b>3900</b> that has been transported to a patient's bedside to perform a brain scan. <figref idrefs="DRAWINGS">FIG. 18D</figref> illustrates portable MRI system <b>3900</b> that has been transported to a patient's bedside to perform a scan of the patient's knee. As shown in <figref idrefs="DRAWINGS">FIG. 18D</figref>, shield <b>3960</b> have electrical gaskets <b>3867</b> <i>c. </i> </div>
</li> <li> <para-num num="[0255]"> </para-num> <div class="description-line" id="p-0273" num="0255">It should be appreciated that the electromagnetic shields illustrated in <figref idrefs="DRAWINGS">FIGS. 18A-18D</figref> are exemplary and providing shielding for an MRI system is not limited to the example electromagnetic shielding described herein. Electromagnetic shielding can be implemented in any suitable way using any suitable materials. For example, electromagnetic shielding may be formed using conductive meshes, fabrics, etc. that can provide a moveable “curtain” to shield the imaging region. Electromagnetic shielding may be formed using one or more conductive straps (e.g., one or more strips of conducting material) coupled to the MRI system as either a fixed, moveable or configurable component to shield the imaging region from electromagnetic interference, some examples of which are described in further detail below. Electromagnetic shielding may be provided by embedding materials in doors, slides, or any moveable or fixed portion of the housing. Electromagnetic shields may be deployed as fixed or moveable components, as the aspects are not limited in this respect.</div>
</li> <li> <para-num num="[0256]"> </para-num> <div class="description-line" id="p-0274" num="0256"> <figref idrefs="DRAWINGS">FIG. 19</figref> is a diagram of an illustrative computer system on which embodiments described herein may be implemented. An illustrative implementation of a computer system <b>1900</b> that may be used in connection with any of the embodiments of the disclosure provided herein is shown in <figref idrefs="DRAWINGS">FIG. 19</figref>. For example, the processes described with reference to <figref idrefs="DRAWINGS">FIGS. 2A-2D and 14</figref> may be implemented on and/or using computer system <b>1900</b>. As another example, the computer system <b>1900</b> may be used to train and/or use any of the neural network statistical models described herein. The computer system <b>1900</b> may include one or more processors <b>1910</b> and one or more articles of manufacture that comprise non-transitory computer-readable storage media (e.g., memory <b>1920</b> and one or more non-volatile storage media <b>1930</b>). The processor <b>1910</b> may control writing data to and reading data from the memory <b>1920</b> and the non-volatile storage device <b>1930</b> in any suitable manner, as the aspects of the disclosure provided herein are not limited in this respect. To perform any of the functionality described herein, the processor <b>1910</b> may execute one or more processor-executable instructions stored in one or more non-transitory computer-readable storage media (e.g., the memory <b>1920</b>), which may serve as non-transitory computer-readable storage media storing processor-executable instructions for execution by the processor <b>1910</b>.</div>
</li> <li> <para-num num="[0257]"> </para-num> <div class="description-line" id="p-0275" num="0257">Having thus described several aspects and embodiments of the technology set forth in the disclosure, it is to be appreciated that various alterations, modifications, and improvements will readily occur to those skilled in the art. Such alterations, modifications, and improvements are intended to be within the spirit and scope of the technology described herein. For example, those of ordinary skill in the art will readily envision a variety of other means and/or structures for performing the function and/or obtaining the results and/or one or more of the advantages described herein, and each of such variations and/or modifications is deemed to be within the scope of the embodiments described herein. Those skilled in the art will recognize, or be able to ascertain using no more than routine experimentation, many equivalents to the specific embodiments described herein. It is, therefore, to be understood that the foregoing embodiments are presented by way of example only and that, within the scope of the appended claims and equivalents thereto, inventive embodiments may be practiced otherwise than as specifically described. In addition, any combination of two or more features, systems, articles, materials, kits, and/or methods described herein, if such features, systems, articles, materials, kits, and/or methods are not mutually inconsistent, is included within the scope of the present disclosure.</div>
</li> <li> <para-num num="[0258]"> </para-num> <div class="description-line" id="p-0276" num="0258">The above-described embodiments can be implemented in any of numerous ways. One or more aspects and embodiments of the present disclosure involving the performance of processes or methods may utilize program instructions executable by a device (e.g., a computer, a processor, or other device) to perform, or control performance of, the processes or methods. In this respect, various inventive concepts may be embodied as a computer readable storage medium (or multiple computer readable storage media) (e.g., a computer memory, one or more floppy discs, compact discs, optical discs, magnetic tapes, flash memories, circuit configurations in Field Programmable Gate Arrays or other semiconductor devices, or other tangible computer storage medium) encoded with one or more programs that, when executed on one or more computers or other processors, perform methods that implement one or more of the various embodiments described above. The computer readable medium or media can be transportable, such that the program or programs stored thereon can be loaded onto one or more different computers or other processors to implement various ones of the aspects described above. In some embodiments, computer readable media may be non-transitory media.</div>
</li> <li> <para-num num="[0259]"> </para-num> <div class="description-line" id="p-0277" num="0259">The terms “program” or “software” are used herein in a generic sense to refer to any type of computer code or set of computer-executable instructions that can be employed to program a computer or other processor to implement various aspects as described above. Additionally, it should be appreciated that according to one aspect, one or more computer programs that when executed perform methods of the present disclosure need not reside on a single computer or processor, but may be distributed in a modular fashion among a number of different computers or processors to implement various aspects of the present disclosure.</div>
</li> <li> <para-num num="[0260]"> </para-num> <div class="description-line" id="p-0278" num="0260">Computer-executable instructions may be in many forms, such as program modules, executed by one or more computers or other devices. Generally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types. Typically the functionality of the program modules may be combined or distributed as desired in various embodiments.</div>
</li> <li> <para-num num="[0261]"> </para-num> <div class="description-line" id="p-0279" num="0261">Also, data structures may be stored in computer-readable media in any suitable form. For simplicity of illustration, data structures may be shown to have fields that are related through location in the data structure. Such relationships may likewise be achieved by assigning storage for the fields with locations in a computer-readable medium that convey relationship between the fields. However, any suitable mechanism may be used to establish a relationship between information in fields of a data structure, including through the use of pointers, tags or other mechanisms that establish relationship between data elements.</div>
</li> <li> <para-num num="[0262]"> </para-num> <div class="description-line" id="p-0280" num="0262">When implemented in software, the software code can be executed on any suitable processor or collection of processors, whether provided in a single computer or distributed among multiple computers.</div>
</li> <li> <para-num num="[0263]"> </para-num> <div class="description-line" id="p-0281" num="0263">Further, it should be appreciated that a computer may be embodied in any of a number of forms, such as a rack-mounted computer, a desktop computer, a laptop computer, or a tablet computer, as non-limiting examples. Additionally, a computer may be embedded in a device not generally regarded as a computer but with suitable processing capabilities, including a Personal Digital Assistant (PDA), a smartphone or any other suitable portable or fixed electronic device.</div>
</li> <li> <para-num num="[0264]"> </para-num> <div class="description-line" id="p-0282" num="0264">Also, a computer may have one or more input and output devices. These devices can be used, among other things, to present a user interface. Examples of output devices that can be used to provide a user interface include printers or display screens for visual presentation of output and speakers or other sound generating devices for audible presentation of output. Examples of input devices that can be used for a user interface include keyboards, and pointing devices, such as mice, touch pads, and digitizing tablets. As another example, a computer may receive input information through speech recognition or in other audible formats.</div>
</li> <li> <para-num num="[0265]"> </para-num> <div class="description-line" id="p-0283" num="0265">Such computers may be interconnected by one or more networks in any suitable form, including a local area network or a wide area network, such as an enterprise network, and intelligent network (IN) or the Internet. Such networks may be based on any suitable technology and may operate according to any suitable protocol and may include wireless networks, wired networks or fiber optic networks.</div>
</li> <li> <para-num num="[0266]"> </para-num> <div class="description-line" id="p-0284" num="0266">Also, as described, some aspects may be embodied as one or more methods. The acts performed as part of the method may be ordered in any suitable way. Accordingly, embodiments may be constructed in which acts are performed in an order different than illustrated, which may include performing some acts simultaneously, even though shown as sequential acts in illustrative embodiments.</div>
</li> <li> <para-num num="[0267]"> </para-num> <div class="description-line" id="p-0285" num="0267">All definitions, as defined and used herein, should be understood to control over dictionary definitions, definitions in documents incorporated by reference, and/or ordinary meanings of the defined terms.</div>
</li> <li> <para-num num="[0268]"> </para-num> <div class="description-line" id="p-0286" num="0268">The indefinite articles “a” and “an,” as used herein in the specification and in the claims, unless clearly indicated to the contrary, should be understood to mean “at least one.”</div>
</li> <li> <para-num num="[0269]"> </para-num> <div class="description-line" id="p-0287" num="0269">The phrase “and/or,” as used herein in the specification and in the claims, should be understood to mean “either or both” of the elements so conjoined, i.e., elements that are conjunctively present in some cases and disjunctively present in other cases. Multiple elements listed with “and/or” should be construed in the same fashion, i.e., “one or more” of the elements so conjoined. Other elements may optionally be present other than the elements specifically identified by the “and/or” clause, whether related or unrelated to those elements specifically identified. Thus, as a non-limiting example, a reference to “A and/or B”, when used in conjunction with open-ended language such as “comprising” can refer, in one embodiment, to A only (optionally including elements other than B); in another embodiment, to B only (optionally including elements other than A); in yet another embodiment, to both A and B (optionally including other elements); etc.</div>
</li> <li> <para-num num="[0270]"> </para-num> <div class="description-line" id="p-0288" num="0270">As used herein in the specification and in the claims, the phrase “at least one,” in reference to a list of one or more elements, should be understood to mean at least one element selected from any one or more of the elements in the list of elements, but not necessarily including at least one of each and every element specifically listed within the list of elements and not excluding any combinations of elements in the list of elements. This definition also allows that elements may optionally be present other than the elements specifically identified within the list of elements to which the phrase “at least one” refers, whether related or unrelated to those elements specifically identified. Thus, as a non-limiting example, “at least one of A and B” (or, equivalently, “at least one of A or B,” or, equivalently “at least one of A and/or B”) can refer, in one embodiment, to at least one, optionally including more than one, A, with no B present (and optionally including elements other than B); in another embodiment, to at least one, optionally including more than one, B, with no A present (and optionally including elements other than A); in yet another embodiment, to at least one, optionally including more than one, A, and at least one, optionally including more than one, B (and optionally including other elements); etc.</div>
</li> <li> <para-num num="[0271]"> </para-num> <div class="description-line" id="p-0289" num="0271">In the claims, as well as in the specification above, all transitional phrases such as “comprising,” “including,” “carrying,” “having,” “containing,” “involving,” “holding,” “composed of,” and the like are to be understood to be open-ended, i.e., to mean including but not limited to. Only the transitional phrases “consisting of” and “consisting essentially of” shall be closed or semi-closed transitional phrases, respectively.</div>
</li> <li> <para-num num="[0272]"> </para-num> <div class="description-line" id="p-0290" num="0272">The terms “approximately” and “about” may be used to mean within ±20% of a target value in some embodiments, within ±10% of a target value in some embodiments, within ±5% of a target value in some embodiments, within ±2% of a target value in some embodiments. The terms “approximately” and “about” may include the target value.</div>
</li> </ul>
</div>
</section><section itemprop="claims" itemscope="">
<h2>Claims (<span itemprop="count">20</span>)</h2>
<div html="" itemprop="content"><div class="claims" lang="EN" load-source="patent-office" mxw-id="PCLM232609769">
<claim-statement>What is claimed is:</claim-statement>
<div class="claim"> <div class="claim" id="CLM-00001" num="00001">
<div class="claim-text"> <b>1</b>. A method, comprising:
<div class="claim-text">generating a magnetic resonance (MR) image from input MR spatial frequency data using a neural network model comprising one or more neural network blocks including a first neural network block,</div> <div class="claim-text">wherein the first neural network block is configured to perform data consistency processing using a non-uniform Fourier transformation for transforming image domain data to spatial frequency domain data.</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00002" num="00002">
<div class="claim-text"> <b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the neural network model comprises multiple neural network blocks each of which is configured to perform data consistency processing using the non-uniform Fourier transformation.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00003" num="00003">
<div class="claim-text"> <b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">obtaining the input MR spatial frequency data;</div> <div class="claim-text">generating an initial image from the input MR spatial frequency data using the non-uniform Fourier transformation; and</div> <div class="claim-text">applying the neural network model to the initial image at least in part by using the first neural network block to perform data consistency processing using the non-uniform Fourier transformation.</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00004" num="00004">
<div class="claim-text"> <b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first neural network block is configured to perform data consistency processing using the non-uniform Fourier transformation at least in part by performing the non-uniform Fourier transformation on data by applying a gridding interpolation transformation, a fast Fourier transformation, and a de-apodization transformation to the data.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00005" num="00005">
<div class="claim-text"> <b>5</b>. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein applying the gridding interpolation transformation to the data is performed using sparse graphical processing unit (GPU) matrix multiplication.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00006" num="00006">
<div class="claim-text"> <b>6</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first neural network block comprises:
<div class="claim-text">a data consistency block configured to perform the data consistency processing; and</div> <div class="claim-text">a plurality of convolutional layers.</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00007" num="00007">
<div class="claim-text"> <b>7</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the data consistency block is configured to:
<div class="claim-text">apply the non-uniform Fourier transformation to a first image, provided as input to the data consistency block, to obtain first MR spatial frequency data; and</div> <div class="claim-text">apply an adjoint non-uniform Fourier transformation to a difference between the first MR spatial frequency data and the input MR spatial frequency data.</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00008" num="00008">
<div class="claim-text"> <b>8</b>. The method of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein applying the non-uniform Fourier transformation to the first image domain data comprises:
<div class="claim-text">applying, to the first image domain data, a de-apodization transformation followed by a Fourier transformation, and followed by a gridding interpolation transformation.</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00009" num="00009">
<div class="claim-text"> <b>9</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the plurality of convolutional layers include one or more convolutional layers and one or more transpose convolutional layers.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00010" num="00010">
<div class="claim-text"> <b>10</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein the plurality of convolutional layers have a U-net structure.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00011" num="00011">
<div class="claim-text"> <b>11</b>. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, further comprising applying the first neural network block to image domain data, the applying comprising:
<div class="claim-text">applying the data consistency block to image domain data to obtain first output;</div> <div class="claim-text">applying the plurality of convolutional layers to the image domain data to obtain second output; and</div> <div class="claim-text">determining a linear combination of the first and second output.</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00012" num="00012">
<div class="claim-text"> <b>12</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first neural network block comprises:
<div class="claim-text">a plurality of convolutional layers configured to receive as input:
<div class="claim-text">image domain data; and</div>
<div class="claim-text">output obtained by applying an adjoint non-uniform Fourier transformation to the input MR spatial frequency data.</div>
</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00013" num="00013">
<div class="claim-text"> <b>13</b>. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the plurality of convolutional layers is further configured to receive as input:
<div class="claim-text">output obtained by applying the non-uniform Fourier transformation and the adjoint non-uniform Fourier transformation to the image domain data.</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00014" num="00014">
<div class="claim-text"> <b>14</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising applying the first neural network block to image domain data, the applying comprising:
<div class="claim-text">applying, to the image domain data, the non-uniform Fourier transformation followed by an adjoint non-uniform Fourier transformation to obtain first output;</div> <div class="claim-text">applying the adjoint non-uniform Fourier transformation to the input MR spatial frequency data to obtain second output; and</div> <div class="claim-text">providing the image domain data, the first output, and the second output as inputs to the plurality of convolutional layers.</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00015" num="00015">
<div class="claim-text"> <b>15</b>. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:
<div class="claim-text">applying a convolutional neural network to a result of applying the non-uniform Fourier transformation to the image domain data to obtain an intermediate output; and</div> <div class="claim-text">applying the adjoint non-uniform Fourier transformation to the intermediate output to obtain the first output.</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00016" num="00016">
<div class="claim-text"> <b>16</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein points in the input MR spatial frequency data were obtained using a non-Cartesian sampling trajectory.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00017" num="00017">
<div class="claim-text"> <b>17</b>. The method of <claim-ref idref="CLM-00016">claim 16</claim-ref>, wherein the non-uniform Fourier transformation is determined at least in part by using the non-Cartesian sampling trajectory.</div>
</div>
</div> <div class="claim"> <div class="claim" id="CLM-00018" num="00018">
<div class="claim-text"> <b>18</b>. At least one non-transitory computer-readable storage medium storing processor-executable instructions that, when executed by at least one computer hardware processor, cause the at least one computer hardware processor to perform a method comprising:
<div class="claim-text">generating a magnetic resonance (MR) image from input MR spatial frequency data using a neural network model comprising one or more neural network blocks including a first neural network block,</div> <div class="claim-text">wherein the first neural network block is configured to perform data consistency processing using a non-uniform Fourier transformation for transforming image domain data to spatial frequency domain data.</div> </div>
</div>
</div> <div class="claim"> <div class="claim" id="CLM-00019" num="00019">
<div class="claim-text"> <b>19</b>. A magnetic resonance imaging (MRI) system, comprising:
<div class="claim-text">a magnetics system comprising:
<div class="claim-text">a B<sub>0 </sub>magnet configured to provide a B<sub>0 </sub>field for the MRI system;</div>
<div class="claim-text">gradient coils configured to provide gradient fields for the MRI system; and</div>
<div class="claim-text">at least one RF coil configured to detect magnetic resonance (MR) signals;</div>
</div> <div class="claim-text">a controller configured to:
<div class="claim-text">control the magnetics system to acquire MR spatial frequency data using a non-Cartesian sampling trajectory; and</div>
<div class="claim-text">generate an MR image from the acquired MR spatial frequency data using a neural network model comprising one or more neural network blocks including a first neural network block,</div>
<div class="claim-text">wherein the first neural network block is configured to perform data consistency processing using a non-uniform Fourier transformation.</div>
</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00020" num="00020">
<div class="claim-text"> <b>20</b>. The MRI system of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the B<sub>0 </sub>magnet is a permanent magnet.</div>
</div>
</div> </div>
</div>
</section>
                </article>
            </search-app>
        </body>
    </html>
    