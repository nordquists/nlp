
    <html>
        <body>
            <search-app>
                <article class="result" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
    <h1 itemprop="pageTitle">US20210029367A1 - Method and apparatus for encoding or decoding blocks of pixel 
      - Google Patents</h1><section itemprop="abstract" itemscope="">
<h2>Abstract</h2>
<div html="" itemprop="content"><abstract lang="EN" load-source="docdb" mxw-id="PA432119541" source="national office">
<div class="abstract">The invention concerns a method and a device for processing a current pixel block of an image using a palette prediction mode according to HEVC RExt. The mode uses a current palette to build a predictor block of indexes to predict the current pixel block. The current palette comprises entries associating entry indexes with pixel values. The method comprises predicting the current palette from entries of two or more palettes that are palettes previously used to process blocks of pixels. A palette predictor may be used that is built from the two or more palettes, preferably from the last used palette for a coding unit in the current coding entity and from the previously used palette for which a flag bitmap indicates whether or not its elements have been copied into the last used palette. Accordingly, the coding of the palette mode is improved.</div>
</abstract>
</div>
</section><section itemprop="description" itemscope="">
<h2>Description</h2>
<div html="" itemprop="content"><ul class="description" lang="EN" load-source="patent-office" mxw-id="PDES284861818">
<heading id="h-0001">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<li> <para-num num="[0001]"> </para-num> <div class="description-line" id="p-0002" num="0001">This application is a continuation, and claims the benefit, of U.S. patent application Ser. No. 15/102,508, filed on Jun. 7, 2016, which is a National Phase application of PCT Application No. PCT/EP2014/077297, filed on Dec. 10, 2014. This application claims the benefit under 35 U.S.C. § 119(a)-(d) of United Kingdom Patent Application No. 1321850.8, filed on Dec. 10, 2013, United Kingdom Patent Application No. 1322468.8, filed on Dec. 18, 2013, and United Kingdom Patent Application No. 1403823.6 filed on Mar. 4, 2014. The above cited patent applications are hereby incorporated by reference herein in their entireties.</div>
</li> <heading id="h-0002">FIELD OF THE INVENTION</heading>
<li> <para-num num="[0002]"> </para-num> <div class="description-line" id="p-0003" num="0002">The present invention concerns a method and a device for processing, e.g. encoding or decoding, a current block of pixels of an image using a palette prediction mode. It particularly concerns the palette mode encoding as introduced in HEVC Range Extension.</div>
</li> <heading id="h-0003">BACKGROUND OF THE INVENTION</heading>
<li> <para-num num="[0003]"> </para-num> <div class="description-line" id="p-0004" num="0003">It applies more particularly to a mode of coding where a current block of pixels is predictively encoded based on a predictor block encoded with or built from a so-called palette.</div>
</li> <li> <para-num num="[0004]"> </para-num> <div class="description-line" id="p-0005" num="0004">A palette in this document is defined as a look up table having entries, or “elements”, associating an index with a value of a pixel. Typically, but not necessarily, the value of a pixel is constituted by the value of each colour component associated with the pixel, resulting in a colour palette. However, the value of a pixel may be made of a single pixel component, resulting in a monochrome palette.</div>
</li> <li> <para-num num="[0005]"> </para-num> <div class="description-line" id="p-0006" num="0005">This mode of encoding a block of pixel is generally referred to as Palette coding mode. It is contemplated to adopt this mode, for example, in the Range Extension of the High Efficiency Video Coding (HEVC: ISO/IEC 23008-2 MPEG-H Part 2/ ITU-T H.265) international standard.</div>
</li> <li> <para-num num="[0006]"> </para-num> <div class="description-line" id="p-0007" num="0006">When encoding an image in a video sequence, the image is first divided into coding entities of pixels of equal size referred to as Coding Tree Blocks (CTBs). The size of a Coding Tree Block is typically 64 by 64 pixels. Each Coding Tree Block may then be broken down into a hierarchical tree of smaller blocks whose size may vary and which are the actual blocks of pixels to encode. These smaller blocks to encode are referred to as Coding Units (CUs).</div>
</li> <li> <para-num num="[0007]"> </para-num> <div class="description-line" id="p-0008" num="0007">The encoding of a particular Coding Unit is typically predictive. This means that a predictor block is first determined. Next, the difference between the predictor block and the Coding Unit is calculated. This difference is called the residue. Next, this residue is compressed. The actual encoded information of the Coding Unit is made of some information to indicate the way of determining the predictor block and the compressed residue. Best predictor blocks are blocks as similar as possible to the Coding Unit in order to obtain a small residue that can be efficiently compressed.</div>
</li> <li> <para-num num="[0008]"> </para-num> <div class="description-line" id="p-0009" num="0008">The coding mode is defined based on the method used to determine the predictor block for the predictive encoding method of a Coding Unit.</div>
</li> <li> <para-num num="[0009]"> </para-num> <div class="description-line" id="p-0010" num="0009">A first coding mode is referred to as INTRA mode. According to INTRA mode, the predictor block is built based on the value of pixels immediately surrounding the Coding Unit within the current image. It is worth noting that the predictor block is not a block of the current image but a reconstruction thereof. A direction is used to determine which pixels neighbouring the border of the block are actually used to build the predictor block and how they are used. The idea behind INTRA mode is that, due to the general coherence of natural images, the pixels immediately surrounding the Coding Unit are likely to be similar to pixels of the current Coding Unit. Therefore, it is possible to get a good prediction of the value of pixels of the Coding Unit using a predictor block based on these surrounding pixels.</div>
</li> <li> <para-num num="[0010]"> </para-num> <div class="description-line" id="p-0011" num="0010">A second coding mode is referred to as INTER mode. According to INTER mode, the predictor block is a block of another image. The idea behind the INTER mode is that successive images in a sequence are generally very similar. The main difference comes typically from motion between these images due to the scrolling of the camera or due to moving objects in the scene. The predictor block is determined by a vector giving its location in a reference image relatively to the location of the Coding Unit within the current image. This vector is referred to as a motion vector. According to this mode, the encoding of such Coding Unit using this mode comprises motion information comprising the motion vector and the compressed residue.</div>
</li> <li> <para-num num="[0011]"> </para-num> <div class="description-line" id="p-0012" num="0011">This document focusses on a third coding mode called Palette mode. According to the Palette mode, it is possible to define a predictor block for a given Coding Unit as a block of indexes from a palette: for each pixel location in the predictor block, the predictor block contains the index associated with the pixel value in the Palette which is the closest to the value of the pixel having the same location (i.e. colocated) in the coding unit. The palette coding mode thus uses a current palette to build a predictor block of indexes to predict a current coding unit or block of pixels. A residue representing the difference between the predictor block and the coding unit is then calculated and encoded. Entry indexes in the Palette are also known as “levels”.</div>
</li> <li> <para-num num="[0012]"> </para-num> <div class="description-line" id="p-0013" num="0012">When using the Palette mode, the palette and the predictor block of indexes or “levels” have to be transmitted in the bitstream encoding the image. This represents a high cost of signalling because a palette, which may comprise tens of entries, needs to be transmitted for each Coding Unit.</div>
</li> <heading id="h-0004">SUMMARY OF THE INVENTION</heading>
<li> <para-num num="[0013]"> </para-num> <div class="description-line" id="p-0014" num="0013">The present invention has been devised to improve the encoding using the Palette mode, in particular to substantially decrease the signalling costs.</div>
</li> <li> <para-num num="[0014]"> </para-num> <div class="description-line" id="p-0015" num="0014">It provides for improving the encoding of the Palette mode by predicting the palette used when encoding a block of pixels. This results in having less information about the palette to be transmitted from the encoder to the decoder: the signalling costs are substantially reduced.</div>
</li> <li> <para-num num="[0015]"> </para-num> <div class="description-line" id="p-0016" num="0015">According to a first aspect of the present invention, there is provided a method for processing a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette that comprises a set of entries associating respective entry indexes with corresponding pixel values, the method comprising a step of predicting the current palette from entries of two or more palettes, the two or more palettes being palettes previously used to process blocks of pixels, wherein the prediction of the current palette comprises selecting an entry from a given palette of the two or more palettes, said selection of an entry being based on a bitmap of flags, each flag defining whether or not a corresponding entry in the given palette is selected as an entry to generate an entry in another palette, wherein the selected entry includes an entry of the given palette corresponding to a flag of the bitmap that defines no selection of the entry to generate the another palette. In this way, the entries of the given palette that have been abandoned when predicting the another palette can thus be retrieved to enrich the current palette or its palette predictor.</div>
</li> <li> <para-num num="[0016]"> </para-num> <div class="description-line" id="p-0017" num="0016">In an embodiment, the other palette is another one of the two or more palettes.</div>
</li> <li> <para-num num="[0017]"> </para-num> <div class="description-line" id="p-0018" num="0017">In an embodiment, said another palette is the palette used to process a block of pixels immediately preceding the current block of pixels in the image.</div>
</li> <li> <para-num num="[0018]"> </para-num> <div class="description-line" id="p-0019" num="0018">In an embodiment, the given palette is the palette used to process a block of pixels in the image immediately preceding the block of pixels immediately preceding the current block of pixels in the image.</div>
</li> <li> <para-num num="[0019]"> </para-num> <div class="description-line" id="p-0020" num="0019">In an embodiment, the bitmap of flags includes at least one element at a predefined position in the bitmap for signalling whether or not the bitmap includes, after the predefined position, at least one additional flag that defines selection of an entry of the given palette to generate the another palette.</div>
</li> <li> <para-num num="[0020]"> </para-num> <div class="description-line" id="p-0021" num="0020">In an embodiment, the current palette is generated from a palette predictor which is built from the two or more palettes.</div>
</li> <li> <para-num num="[0021]"> </para-num> <div class="description-line" id="p-0022" num="0021">In an embodiment, building the palette predictor comprises selecting all the entries from a palette last used to process a block of pixels that immediately precedes the current block of pixels in the image, and selecting at least one entry from another palette used to process another block of pixels in the image. This configuration makes it possible to supplement conventional palette predictors (usually the palette last used) with additional entries that may be of high relevancy, in particular selected as described above.</div>
</li> <li> <para-num num="[0022]"> </para-num> <div class="description-line" id="p-0023" num="0022">In an embodiment, the current palette is generated from the palette predictor using a bitmap of flags, each flag of which defining whether or not a corresponding entry in the palette predictor is selected as an entry to generate an entry in the current palette.</div>
</li> <li> <para-num num="[0023]"> </para-num> <div class="description-line" id="p-0024" num="0023">In an embodiment, an entry of the two or more palettes is added to the palette predictor being built if there is no similar entry already in the palette predictor being built.</div>
</li> <li> <para-num num="[0024]"> </para-num> <div class="description-line" id="p-0025" num="0024">According to a second aspect of the present invention, there is provided a method of encoding a sequence of digital images into a bitstream, at least one block of an image being encoded using a palette coding mode comprising the method of processing a current block of pixels according to the first aspect.</div>
</li> <li> <para-num num="[0025]"> </para-num> <div class="description-line" id="p-0026" num="0025">According to a third aspect of the present invention, there is provided a method of decoding a bitstream comprising an encoded sequence of digital images, at least one block of an image having been encoded using a palette coding mode, comprising the method of processing a current block of pixels according to the first aspect.</div>
</li> <li> <para-num num="[0026]"> </para-num> <div class="description-line" id="p-0027" num="0026">According to a fourth aspect of the present invention, there is provided a device for processing a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette that comprises a set of entries associating respective entry indexes with corresponding pixel values, the device comprising a prediction module configured to predict the current palette from entries of two or more palettes, the two or more palettes being palettes previously used to process blocks of pixels, wherein the prediction of the current palette comprises selecting an entry from a given palette of the two or more palettes, said selection of an entry being based on a bitmap of flags, each flag defining whether or not a corresponding entry in the given palette is selected as an entry to generate an entry in another palette, wherein the selected entry includes an entry of the given palette corresponding to a flag of the bitmap that defines no selection of the entry to generate the another palette.</div>
</li> <li> <para-num num="[0027]"> </para-num> <div class="description-line" id="p-0028" num="0027">According to a fifth aspect of the present invention, there is provided a device for processing a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette that comprises a set of entries associating respective entry indexes with corresponding pixel values, the device being configured to implement the processing method of the first aspect described above.</div>
</li> <li> <para-num num="[0028]"> </para-num> <div class="description-line" id="p-0029" num="0028">According to a sixth aspect of the present invention, there is provided a device for encoding a sequence of digital images into a bitstream comprising means for performing the method according to the second aspect.</div>
</li> <li> <para-num num="[0029]"> </para-num> <div class="description-line" id="p-0030" num="0029">According to a seventh aspect of the present invention, there is provided a device for decoding a bitstream comprising a sequence of digital images comprising means for performing the method according to the third aspect.</div>
</li> <li> <para-num num="[0030]"> </para-num> <div class="description-line" id="p-0031" num="0030">According to an eighth aspect of the present invention there is provided a non-transitory computer-readable medium storing a program which, when executed by a microprocessor or computer system in a device for processing a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette that comprises a set of entries associating respective entry indexes with corresponding pixel values, causes the device to perform a step of predicting the current palette from entries of two or more palettes, the two or more palettes being palettes previously used to process blocks of pixels, wherein the prediction of the current palette comprises selecting an entry from a given palette of the two or more palettes, said selection of an entry being based on a bitmap of flags, each flag defining whether or not a corresponding entry in the given palette is selected as an entry to generate an entry in another palette, wherein the selected entry includes an entry of the given palette corresponding to a flag of the bitmap that defines no selection of the entry to generate the another palette.</div>
</li> <li> <para-num num="[0031]"> </para-num> <div class="description-line" id="p-0032" num="0031">According to a ninth aspect, there is provided a computer program comprising instructions which upon execution by a computer cause the computer to perform the method of any one of the first, second or third aspects.</div>
</li> <li> <para-num num="[0032]"> </para-num> <div class="description-line" id="p-0033" num="0032">According to a further aspect of the invention there is provided a method for processing a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette that comprises a set of entries associating respective entry indexes with corresponding pixel values.</div>
</li> <li> <para-num num="[0033]"> </para-num> <div class="description-line" id="p-0034" num="0033">The method comprises a step of predicting the current palette from entries of two or more palettes, the two or more palettes being palettes previously used to process blocks of pixels.</div>
</li> <li> <para-num num="[0034]"> </para-num> <div class="description-line" id="p-0035" num="0034">Accordingly, as mentioned above, less information about the current palette is transmitted to the decoder, thus reducing the signalling in the bitstream. As explained below in this document, a palette predictor may be formed from the two or more palettes and all or part of the current palette may be predicted using the palette predictor. Thus, the invention is also to avoid having a poor palette when a single palette predictor to produce the palette proves to have very few elements. This may happen when such a palette predictor is imposed</div>
</li> <li> <para-num num="[0035]"> </para-num> <div class="description-line" id="p-0036" num="0035">In a variant, the palette coding mode uses a current palette to build a predictor block of indexes to predict a current block of pixels, and the method comprises a step of predicting the current palette using a palette predictor.</div>
</li> <li> <para-num num="[0036]"> </para-num> <div class="description-line" id="p-0037" num="0036">Correspondingly, according to other aspects of the invention there is provided a device for processing, i.e. an encoder or a decoder depending on the case, a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette that comprises a set of entries associating respective entry indexes with corresponding pixel values.</div>
</li> <li> <para-num num="[0037]"> </para-num> <div class="description-line" id="p-0038" num="0037">The device comprises a prediction module configured to predict the current palette from entries of two or more palettes, the two or more palettes being palettes previously used to process blocks of pixels.</div>
</li> <li> <para-num num="[0038]"> </para-num> <div class="description-line" id="p-0039" num="0038">In a variant, the palette coding mode uses a current palette to build a predictor block of indexes to predict a current block of pixels, and the prediction module is configured to predict the current palette using a palette predictor.</div>
</li> <li> <para-num num="[0039]"> </para-num> <div class="description-line" id="p-0040" num="0039">Optional features of embodiments of the invention are defined in the appended claims. Some of these features are explained here below with reference to a method, while they can be transposed into system features dedicated to a device according to embodiments of the invention.</div>
</li> <li> <para-num num="[0040]"> </para-num> <div class="description-line" id="p-0041" num="0040">In some embodiments of the invention, the prediction of the current palette comprises selecting an entry from a given palette of the two or more palettes, said selection of an entry being based on a bitmap of flags, each flag defining whether or not a corresponding entry in the given palette is selected as an entry to generate another palette. This is because the bitmap of flags makes it possible to know which elements/entries have already been reused for some palettes and which ones have been abandoned. Thanks to this information, it is possible to enrich the palette predictor or the current palette with some abandoned elements that may happen to be relevant for the block of pixels currently being processed.</div>
</li> <li> <para-num num="[0041]"> </para-num> <div class="description-line" id="p-0042" num="0041">In particular, this is the case when the selected entry includes an entry of the given palette corresponding to a flag of the bitmap that defines no selection of the entry to generate the another palette. Such flag means that the entry has been previously abandoned.</div>
</li> <li> <para-num num="[0042]"> </para-num> <div class="description-line" id="p-0043" num="0042">According to some features, the another palette is another one of the two or more palettes. This means that two palettes that are closely related due to the prediction of one based on the other are both used to predict the current palette. This configuration may occur for example when using the last used palettes to predict a new palette.</div>
</li> <li> <para-num num="[0043]"> </para-num> <div class="description-line" id="p-0044" num="0043">The entries of the given palette that have been abandoned when predicting the other palette can thus be retrieved to enrich the current palette or its palette predictor.</div>
</li> <li> <para-num num="[0044]"> </para-num> <div class="description-line" id="p-0045" num="0044">In particular, the other palette may be the palette last used to process a block of pixels that directly (i.e. immediately) precedes (according to the coding/decoding order) the current block of pixels in the image. In addition, the given palette and the another palette may be the two palettes used to process the last two blocks of pixels that directly precede (according to the same coding/decoding order) the current block of pixels in the image. In particular, the given palette may be the palette used to process a block of pixels in the image immediately preceding the block of pixels immediately preceding the current block of pixels in the image. These configurations take advantage of redundancy between consecutive and close blocks of pixels to obtain efficient coding.</div>
</li> <li> <para-num num="[0045]"> </para-num> <div class="description-line" id="p-0046" num="0045">According to other features, the bitmap of flags includes at least one element at a predefined position in the bitmap for signalling whether or not the bitmap includes, after the predefined position, at least one additional flag that defines selection of an entry of the given palette to generate the another palette. This is to reduce the size of the bitmap and thus to reduce signalling costs. This is because, depending on how the palettes are built up, the last entries of the given palette are more liable to be old and ineffective elements. Therefore, it is likely that the last flags of the bitmaps are all set to 0 defining no selection of the corresponding entry from the given palette.</div>
</li> <li> <para-num num="[0046]"> </para-num> <div class="description-line" id="p-0047" num="0046">In some embodiments as introduced above, the current palette is generated from a palette predictor which is built from the two or more palettes.</div>
</li> <li> <para-num num="[0047]"> </para-num> <div class="description-line" id="p-0048" num="0047">In some specific embodiments, building the palette predictor comprises selecting all the entries from a palette last used to process a block of pixels that directly precedes the current block of pixels in the image, and selecting at least one entry from another palette used to process another block of pixels in the image. This configuration makes it possible to supplement conventional palette predictors (usually the palette last used) with additional entries that may be of high relevancy, in particular selected as described above.</div>
</li> <li> <para-num num="[0048]"> </para-num> <div class="description-line" id="p-0049" num="0048">In other specific embodiments, the current palette is generated from the palette predictor using a bitmap of flags, each flag of which defining whether or not a corresponding entry in the palette predictor is selected as an entry to generate an entry in the current palette.</div>
</li> <li> <para-num num="[0049]"> </para-num> <div class="description-line" id="p-0050" num="0049">In some embodiments, an entry of the two or more palettes is added to the palette predictor being built if there is no similar entry already in the palette predictor being built. This is to avoid redundancy.</div>
</li> <li> <para-num num="[0050]"> </para-num> <div class="description-line" id="p-0051" num="0050">In some embodiments, blocks of pixels of the image are processed according to a predefined scanning order; and the palette predictor for the current block of pixels is selected from a set of palettes used to predict blocks of pixels previously processed according to the palette coding mode. This corresponds to an Inter prediction of the current palette since it is based on past palettes. This configuration has the potential to reduce a great amount of signalling costs since past palettes with a lot of information are already available at both sides (encoder and decoder) when processing the current block of pixels. Efficient palette prediction can thus be conducted.</div>
</li> <li> <para-num num="[0051]"> </para-num> <div class="description-line" id="p-0052" num="0051">In specific embodiments, the palette predictor for the current block of pixels is a palette used for the last block of pixels processed according to the palette coding mode. In other words, it is the last used (e.g. decoded) palette that is selected as a palette predictor. This provision takes advantage of high pixel redundancy between block of pixels that are processed successively, because they are often spatially close. It also reduces memory costs of storing previously used palettes, since only the last one needs to be stored. In addition, it may save bits in the encoded bitstream, since there is no need to designate which previously used palette is used as a palette predictor for the current block of pixels.</div>
</li> <li> <para-num num="[0052]"> </para-num> <div class="description-line" id="p-0053" num="0052">In other specific embodiments, the palette predictor for the current block of pixels is selected from the set of palettes used for blocks of pixels previously processed according to the palette coding mode and are contiguous to the current block of pixels. In practice, this is generally the pixels blocks that are above or on the left of the current pixel block. This provision also takes advantage of high pixel redundancy between adjacent blocks of pixels.</div>
</li> <li> <para-num num="[0053]"> </para-num> <div class="description-line" id="p-0054" num="0053">In yet other specific embodiments, the set of palettes used for previously processed blocks of pixels is reset when the current block of pixels starts a new coding entity made of blocks of pixels, such as a slice or an independent tile, or starts a new line of coding entities, each made of blocks of pixels. In a variant, the reset may occur at each new image or frame. This provision may speed up the processing (encoding or decoding) of the image, since the coding entities or the lines of coding entities (e.g. Coding Tree Blocks in HEVC) can be processed in parallel. Furthermore, the reset at each new line of coding entities proves to provide more efficient coding of pixel blocks than a reset at each coding entity.</div>
</li> <li> <para-num num="[0054]"> </para-num> <div class="description-line" id="p-0055" num="0054">An independent tile as defined in the HEVC standard comprises at least one slice and is spatially independent from the other tiles.</div>
</li> <li> <para-num num="[0055]"> </para-num> <div class="description-line" id="p-0056" num="0055">According to a specific feature, the set of palettes is reset to an empty set.</div>
</li> <li> <para-num num="[0056]"> </para-num> <div class="description-line" id="p-0057" num="0056">In a variant, the reset set of palettes comprises a by-default palette. This configuration may thus provide palette prediction even in case of reset, i.e. when a new coding entity is processed. This makes it possible to again reduce signalling costs for the first coding unit in a new coding entity.</div>
</li> <li> <para-num num="[0057]"> </para-num> <div class="description-line" id="p-0058" num="0057">In this variant, the by-default palette may comprise a set of predetermined entries corresponding to pixel values equally distributed over a colour space. For example, for pixels represented in the YUV colour space (the same would apply for a RGB colour space), the pixel values may be equally distributed over the Y component, while the U and V component values may be fixed at half the maximum possible value MAX given the bit-depth used to code each colour component (i.e. U and V take the median value of the corresponding components in the colour space), e.g. 1«(bitdepth−1) or (MAX+1)/2.</div>
</li> <li> <para-num num="[0058]"> </para-num> <div class="description-line" id="p-0059" num="0058">In other embodiments of the invention, reference palette predictors are associated with respective coding entities of blocks of pixels that form the image, and the palette predictor for the current block of pixels is the reference palette predictor associated with the coding entity that includes the current block of pixels. These embodiments of the invention make it possible to define very efficient palette predictors at the coding entity (e.g. CTB) level. As an example, a single reference palette predictor may be defined for a single line of coding entities, in the same spirit as the reset above. This is to reduce the costs of signalling the reference palette predictors to the decoder.</div>
</li> <li> <para-num num="[0059]"> </para-num> <div class="description-line" id="p-0060" num="0059">In specific embodiments, the reference palette predictor associated with a coding entity is used as the palette predictor for each block of pixels composing the coding entity. Thanks to this provision, a restricted amount of information, namely the reference palette predictor, is needed for the whole coding entity. This aims at substantially reducing signalling costs compared to conventional Palette mode.</div>
</li> <li> <para-num num="[0060]"> </para-num> <div class="description-line" id="p-0061" num="0060">Preferably, the reference palette predictors are inserted in a bitstream coding the image. This makes it possible for the decoder to have these reference palette predictors to efficiently perform palette prediction for each block of pixels in the coding entity, i.e. without need for a complex mechanism to determine those predictors.</div>
</li> <li> <para-num num="[0061]"> </para-num> <div class="description-line" id="p-0062" num="0061">In specific embodiments regarding the encoder, the method may further comprise selecting, as a reference palette predictor for a coding entity, a palette that minimizes a rate-distortion criterion from the palettes used to predict all the blocks of pixels of the coding entity. Then the encoder should signal the selected reference palette predictor in the bitstream to the decoder. This provides selection of an optimal Palette for all palettes of the coding entity.</div>
</li> <li> <para-num num="[0062]"> </para-num> <div class="description-line" id="p-0063" num="0062">In a variant regarding the encoder, the method may further comprise selecting, as a reference palette predictor for a coding entity, the palette used to predict the largest block of pixels of the coding entity. Then the encoder should signal the selected reference palette predictor in the bitstream to the decoder. The implementation of this selection of the reference palette predictor is very simple and this implementation has a low complexity.</div>
</li> <li> <para-num num="[0063]"> </para-num> <div class="description-line" id="p-0064" num="0063">In yet other embodiments of the invention, the palette predictor for the current block of pixels includes entries corresponding to values of pixels neighbouring the current block of pixels. This is to take advantage of high pixel redundancies between spatially close pixels.</div>
</li> <li> <para-num num="[0064]"> </para-num> <div class="description-line" id="p-0065" num="0064">In specific embodiments, the pixels neighbouring the current block of pixels are selected from pixels contiguous with the upper and left sides of the current block of pixels. This provision increases the above-specified advantage while maintaining dependency on pixels that are always available at the encoder and at the decoder given the causal effect of the block-by-block HEVC coding. Indeed, conventional scanning orders mean that the blocks contiguous with the upper and left sides of the current pixel blocks have already been reconstructed.</div>
</li> <li> <para-num num="[0065]"> </para-num> <div class="description-line" id="p-0066" num="0065">According to a specific feature, the pixels neighbouring the current block of pixels include the pixels that are, relative to the contiguous current block of pixels, top-left, top-right and bottom-left. Of course, these three specific pixels may form the selected neighbouring pixels. These pixels are those used for conventional Intra prediction mode. They provide relevant information on pixels of the current pixel block with a small amount of information.</div>
</li> <li> <para-num num="[0066]"> </para-num> <div class="description-line" id="p-0067" num="0066">In other specific embodiments, a predefined number of pixels are selected from a predetermined set of pixels neighbouring the current block of pixels, as entries of the palette predictor, the selected pixels being those having the highest spatial distances between them within the predetermined set of pixels. This creates diversity and avoids duplicate pixels.</div>
</li> <li> <para-num num="[0067]"> </para-num> <div class="description-line" id="p-0068" num="0067">In yet other specific embodiments, a pixel class is associated with each neighbouring pixel, and the neighbouring pixels are ordered according to a number of occurrences of their associated class within a predetermined set of pixels neighbouring the current block of pixels, to give lower entry indexes of the palette predictor to neighbouring pixels having more frequent pixel classes. This is to reduce the costs when encoding the palette predictor when appropriate. Note that the classes associated with a given pixel may be defined by the pixel values surrounding the value of the given pixel, for example given a predefined margin.</div>
</li> <li> <para-num num="[0068]"> </para-num> <div class="description-line" id="p-0069" num="0068">In yet other embodiments of the invention, the current palette has ordered entries, and predicting the current palette using the palette predictor comprises predicting an entry of the current palette from a preceding entry of the same current palette. In other words, the palette predictor when processing a given entry of the palette is made of (includes) the entries that are prior to the given entry in the colour palette. This resembles Intra prediction of the colour palette.</div>
</li> <li> <para-num num="[0069]"> </para-num> <div class="description-line" id="p-0070" num="0069">In specific embodiments, a given entry of the current palette is predicted from the entry directly preceding the given entry in the same current palette. This provision reduces signalling in the bitstream (and thus reduces coding costs) since it is no longer necessary to send (to the decoder) information on that preceding entry is used to predict the current entry.</div>
</li> <li> <para-num num="[0070]"> </para-num> <div class="description-line" id="p-0071" num="0070">In a similar manner, all the entries of the current palette, except the first one, may be predicted from the entry directly preceding them in the same current palette. This also reduces signalling in the bitstream. This is because all the entries are predicted and thus it is no longer necessary to identify which entries are predicted and which are not.</div>
</li> <li> <para-num num="[0071]"> </para-num> <div class="description-line" id="p-0072" num="0071">The above various embodiments to obtain the palette predictor may be combined in whole or in part. Taking into account such combination, the palette predictor used to predict the current palette thus combines two or more of:</div>
</li> <li> <para-num num="[0072]"> </para-num> <div class="description-line" id="p-0073" num="0072">a palette used to predict a previously processed block of pixels;</div>
</li> <li> <para-num num="[0073]"> </para-num> <div class="description-line" id="p-0074" num="0073">a reference palette predictor associated with a coding entity that includes the current block of pixels;</div>
</li> <li> <para-num num="[0074]"> </para-num> <div class="description-line" id="p-0075" num="0074">entries corresponding to values of pixels neighbouring the current block of pixels; and</div>
</li> <li> <para-num num="[0075]"> </para-num> <div class="description-line" id="p-0076" num="0075">at least one entry of the current palette that precedes a current entry to be predicted in the current palette.</div>
</li> <li> <para-num num="[0076]"> </para-num> <div class="description-line" id="p-0077" num="0076">Turning now to the prediction of the current palette from the palette predictor, several implementations may be contemplated.</div>
</li> <li> <para-num num="[0077]"> </para-num> <div class="description-line" id="p-0078" num="0077">In embodiments of the invention, predicting the current palette using the palette predictor comprises obtaining a bitmap of flags, each of which defining whether or not a corresponding entry in the palette predictor is selected as an entry of the current palette. This configuration has low (memory and coding) costs to define the actual prediction from the palette predictor. The costs are limited to a bitmap.</div>
</li> <li> <para-num num="[0078]"> </para-num> <div class="description-line" id="p-0079" num="0078">In specific embodiments, the bitmap of flags comprises the same number of bits as the number of entries in the palette predictor, and each bit at a position in the bitmap defines whether or not the entry having the corresponding position in the palette predictor is selected as an entry of the current palette. This configuration improves the coding efficiency. A variant that may further reduce the size of the bitmap may consider stopping the bitmap at the last entry that is selected as an entry of the current palette. This is particularly advantageous since, as suggested above, the entries in the palette predictor are ordered according to their occurrences. In some embodiments, this results in the last entries of the palette predictor being statistically not often used for the current palette.</div>
</li> <li> <para-num num="[0079]"> </para-num> <div class="description-line" id="p-0080" num="0079">In other specific embodiments, the method may further comprise adding additional entries at the end of the current palette having the selected entries from the palette predictor. These additional entries may be entries for additional pixels decoded (at both the decoder and the encoder using a decoding loop) and entries from a predetermined palette that is for example built by the encoder and transmitted (in the bitstream) to the decoder (as in the conventional Palette coding mode). This provision is to increase the coding efficiency of the current palette.</div>
</li> <li> <para-num num="[0080]"> </para-num> <div class="description-line" id="p-0081" num="0080">In other embodiments of the invention, predicting the current palette using the palette predictor comprises obtaining at least one (possibly two or more) entry residual corresponding to the difference between at least one corresponding entry of the current palette and an entry of the palette predictor. This means that the residuals from palette prediction have to be sent to the decoder. This configuration makes it possible to obtain a finer palette compared to the previous embodiments (based on a copy of entries from the predictor to the current palette).</div>
</li> <li> <para-num num="[0081]"> </para-num> <div class="description-line" id="p-0082" num="0081">In specific embodiments, the current palette and the palette predictor have respective ordered entries, and each entry residual corresponds to the difference between an entry of the current palette and an entry of the palette predictor that have the same entry index. This provision reduces signalling in the bitstream (and thus reduces coding costs) since it is no longer necessary to send (to the decoder) information on which entry of the predictor is used to predict the current entry.</div>
</li> <li> <para-num num="[0082]"> </para-num> <div class="description-line" id="p-0083" num="0082">In a similar manner, a residual may be obtained for every entry of the current palette that has a corresponding entry with the same entry index in the palette predictor. This also reduces signalling in the bitstream since it additionally makes it no longer necessary to identify which entries need prediction and which do not need prediction.</div>
</li> <li> <para-num num="[0083]"> </para-num> <div class="description-line" id="p-0084" num="0083">Note that both predictions based on copy of entries or on residuals may be used with the palette predictors obtained using any of the methods described above. Exception is made for the case where the current palette is intra predicted in which case only the residual approach can be used (otherwise two entries would be the same in the palette).</div>
</li> <li> <para-num num="[0084]"> </para-num> <div class="description-line" id="p-0085" num="0084">In some embodiments, the pixel values of the entries of the current palette have colour components, and only a subpart of the colour components are predicted using the palette predictor. In practice, one or two colour components out of three may be predicted. This provision reduces processing and signalling in the bitstream.</div>
</li> <li> <para-num num="[0085]"> </para-num> <div class="description-line" id="p-0086" num="0085">Another aspect of the invention relates to a device for processing a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette that comprises a set of entries associating respective entry indexes with corresponding pixel values, the device being configured to implement any embodiment of the processing method as defined above.</div>
</li> <li> <para-num num="[0086]"> </para-num> <div class="description-line" id="p-0087" num="0086">Another aspect of the invention relates to a non-transitory computer-readable medium storing a program which, when executed by a microprocessor or computer system in a device for processing a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette that comprises a set of entries associating respective entry indexes with corresponding pixel values, causes the device to perform the step of predicting the current palette from entries of two or more palettes, the two or more palettes being palettes previously used to process blocks of pixels.</div>
</li> <li> <para-num num="[0087]"> </para-num> <div class="description-line" id="p-0088" num="0087">The non-transitory computer-readable medium may have features and advantages that are analogous to those set out above and below in relation to the method and device, in particular that of improving coding efficiency of the Palette prediction mode.</div>
</li> <li> <para-num num="[0088]"> </para-num> <div class="description-line" id="p-0089" num="0088">Another aspect of the invention relates to a method for processing a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette to build a predictor block of indexes to predict the current block of pixels, wherein the current palette comprises a set of entries associating respective entry indexes with corresponding pixel values, substantially as herein described with reference to, and as shown in, <figref idrefs="DRAWINGS">FIG. 13 or 14 or 15 or 17 or 19 or 21 or 22</figref> of the accompanying drawings.</div>
</li> <li> <para-num num="[0089]"> </para-num> <div class="description-line" id="p-0090" num="0089">In a yet further aspect of the present invention there is provided a method for encoding or decoding a current block of pixels of an image according to a palette mode, the palette mode using a color palette comprising a set of values to represent at least one component of pixels of the current block, the method comprising obtaining a color palette predictor and predicting the color palette of the current block using the color palette predictor.</div>
</li> <li> <para-num num="[0090]"> </para-num> <div class="description-line" id="p-0091" num="0090">Preferably, blocks of said image are ordered according to a predefined scanning order and the color palette predictor is determined from the color palette of the last block encoded according to the palette mode in a given causal area of the image.</div>
</li> <li> <para-num num="[0091]"> </para-num> <div class="description-line" id="p-0092" num="0091">In an embodiment values of the current color palette are predicted from values comprised in the color palette predictor. The values of color palettes may be ordered and a value of the current color palette associated to a flag indicating whether said value is predicted from the value having the same order in the color palette predictor. In an embodiment, the given causal area is the part already reconstructed of an encoding entity comprising the current block of pixels.</div>
</li> <li> <para-num num="[0092]"> </para-num> <div class="description-line" id="p-0093" num="0092">In an embodiment values of color palettes are ordered and a value of the current palette is associated to a flag indicating whether said value is predicted from the value having a given order in the color palette predictor.</div>
</li> <li> <para-num num="[0093]"> </para-num> <div class="description-line" id="p-0094" num="0093">In embodiments, the color palette predictor is associated to each encoding entity of the image. The color palette predictor may be obtained from pixels neighboring the current block.</div>
</li> <li> <para-num num="[0094]"> </para-num> <div class="description-line" id="p-0095" num="0094">In one further aspect of the present invention, there is provided a method for encoding or decoding a current block of pixels of an image according to a palette mode, the palette mode using a color palette comprising a set of values to represent at least one component of pixels of the current block, the method comprising obtaining a color palette predictor and predicting the color palette of the current block using the color palette predictor, wherein predicting the color palette of the current block using the color palette predictor comprises obtaining a bitmap of flags, each of which defining whether or not a corresponding entry in the color palette predictor is selected as an entry of the color palette of the current block.</div>
</li> <li> <para-num num="[0095]"> </para-num> <div class="description-line" id="p-0096" num="0095">The bitmap of flags may comprise the same number of bits as the number of entries in the color palette predictor, and each bit at a position in the bitmap defines whether or not the entry having the corresponding position in the color palette predictor is selected as an entry of the color palette of the current block.</div>
</li> <li> <para-num num="[0096]"> </para-num> <div class="description-line" id="p-0097" num="0096">In an embodiment the method additionally comprises adding additional entries at the end of the color palette of the current block having the selected entries from the color palette predictor.</div>
</li> <li> <para-num num="[0097]"> </para-num> <div class="description-line" id="p-0098" num="0097">In yet another aspect of the present invention there is provided a method for encoding or decoding a current block of pixels of an image according to a palette mode, the palette mode using a color palette comprising a set of values to represent at least one component of pixels of the current block, the method comprising obtaining a color palette predictor and predicting the color palette of the current block using the color palette predictor wherein blocks of pixels of the image are processed according to a scanning order; and the palette predictor for the current block of pixels is selected from a set of palettes used to predict blocks of pixels previously processed according to the palette coding mode and wherein said set of palettes used for previously processed blocks of pixels is reset when the current block of pixels starts a new line of coding entities each comprising a block of pixels. Preferably, the set of palettes is reset to a by-default palette</div>
</li> <li> <para-num num="[0098]"> </para-num> <div class="description-line" id="p-0099" num="0098">According to the invention there is further provided a method for processing a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette to build a predictor block of indexes to predict the current block of pixels, wherein the current palette comprises a set of entries associating respective entry indexes with corresponding pixel values, the method comprising the step of predicting the current palette using a palette predictor.</div>
</li> <li> <para-num num="[0099]"> </para-num> <div class="description-line" id="p-0100" num="0099">In an embodiment, blocks of pixels of the image are processed according to a predefined scanning order; and the palette predictor for the current block of pixels is selected from a set of palettes used to predict blocks of pixels previously processed according to the palette coding mode. Preferably, the palette predictor for the current block of pixels is a palette used for the last block of pixels processed using the palette coding mode. The palette predictor for the current block of pixels may be selected from the set of palettes used for blocks of pixels previously processed according to the palette coding mode and are contiguous to the current block of pixels.</div>
</li> <li> <para-num num="[0100]"> </para-num> <div class="description-line" id="p-0101" num="0100">The set of palettes used for previously processed blocks of pixels is preferably reset when the current block of pixels starts a new coding entity made of blocks of pixels or starts a new line of coding entities, each made of blocks of pixels. The set of palettes may be reset to a null set or to a by-default palette. The by-default palette comprises a set of predetermined entries corresponding to pixel values equally distributed over a colour space.</div>
</li> <li> <para-num num="[0101]"> </para-num> <div class="description-line" id="p-0102" num="0101">In an embodiment, reference palette predictors are associated with respective coding entities of blocks of pixels that form the image, and the palette predictor for the current block of pixels is the reference palette predictor associated with the coding entity that includes the current block of pixels. The reference palette predictor associated with a coding entity is used as the palette predictor for each block of pixels composing the coding entity. The reference palette predictors are preferably inserted in a bitstream coding the image. The method may further comprise selecting, as a reference palette predictor for a coding entity, the palette used to predict the largest block of pixels of the coding entity. In an embodiment the method further comprises selecting, as a reference palette predictor for a coding entity, a palette that minimizes a rate-distortion criterion from the palettes used to predict all the blocks of pixels of the coding entity.</div>
</li> <li> <para-num num="[0102]"> </para-num> <div class="description-line" id="p-0103" num="0102">In an embodiment, the palette predictor for the current block of pixels includes entries corresponding to values of pixels neighbouring the current block of pixels. The pixels neighbouring the current block of pixels may be selected from pixels contiguous to the upper and left sides of the current block of pixels. The pixels neighbouring the current block of pixels can include the pixels that are, relative to the contiguous current block of pixels, top-left, top-right and bottom-left. In an embodiment a pixel class is associated with each neighbouring pixel, and the neighbouring pixels are ordered according to a number of occurrences of their associated class within a predetermined set of pixels neighbouring the current block of pixels, to give lower entry indexes of the palette predictor to neighbouring pixels having more frequent pixel classes. Preferably, a predefined number of pixels is selected from a predetermined set of pixels neighbouring the current block of pixels, as entries of the palette predictor, the selected pixels being those having the highest spatial distances between them within the predetermined set of pixels.</div>
</li> <li> <para-num num="[0103]"> </para-num> <div class="description-line" id="p-0104" num="0103">In an embodiment, the current palette has ordered entries, and predicting the current palette using the palette predictor comprises predicting an entry of the current palette from a preceding entry of the same current palette. A given entry of the current palette may be predicted from the entry directly preceding the given entry in the same current palette. All the entries of the current palette, except the first one, may be predicted from the entry directly preceding them in the same current palette.</div>
</li> <li> <para-num num="[0104]"> </para-num> <div class="description-line" id="p-0105" num="0104">In an embodiment the palette predictor used to predict the current palette combines two or more of: a palette used to predict a previously processed block of pixels; a reference palette predictor associated with a coding entity that includes the current block of pixels; entries corresponding to values of pixels neighbouring the current block of pixels; and at least one entry of the current palette that precedes a current entry to be predicted in the current palette.</div>
</li> <li> <para-num num="[0105]"> </para-num> <div class="description-line" id="p-0106" num="0105">In an embodiment, predicting the current palette using the palette predictor comprises obtaining a bitmap of flags, each of which defining whether or not a corresponding entry in the palette predictor is selected as an entry of the current palette. The bitmap of flags may comprise the same number of bits as the number of entries in the palette predictor, and each bit at a position in the bitmap defines whether or not the entry having the corresponding position in the palette predictor is selected as an entry of the current palette. In a further embodiment the method comprises adding additional entries at the end of the current palette having the selected entries from the palette predictor.</div>
</li> <li> <para-num num="[0106]"> </para-num> <div class="description-line" id="p-0107" num="0106">In an embodiment predicting the current palette using the palette predictor comprises obtaining at least one entry residual corresponding to the difference between at least one corresponding entry of the current palette and an entry of the palette predictor. The current palette and the palette predictor may have respective ordered entries, and each entry residual corresponds to the difference between an entry of the current palette and an entry of the palette predictor that have the same entry index. A residual is preferably obtained for every entry of the current palette that has a corresponding entry with the same entry index in the palette predictor.</div>
</li> <li> <para-num num="[0107]"> </para-num> <div class="description-line" id="p-0108" num="0107">In an embodiment, the pixel values of the entries of the current palette have colour components, and only a subpart of the colour components are predicted using the palette predictor.</div>
</li> <li> <para-num num="[0108]"> </para-num> <div class="description-line" id="p-0109" num="0108">In one more aspect of the present invention, there is provided a device for processing a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette to build a predictor block of indexes to predict the current block of pixels, wherein the current palette comprises a set of entries associating respective entry indexes with corresponding pixel values, the device comprising a prediction module configured to predicting the current palette using a palette predictor.</div>
</li> <li> <para-num num="[0109]"> </para-num> <div class="description-line" id="p-0110" num="0109">In an additional aspect of the present invention there is provided a device for processing a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette to build a predictor block of indexes to predict the current block of pixels, wherein the current palette comprises a set of entries associating respective entry indexes with corresponding pixel values, the device being configured to implement the processing method according to the further provided method and any of the embodiments described above.</div>
</li> <li> <para-num num="[0110]"> </para-num> <div class="description-line" id="p-0111" num="0110">At least parts of the methods according to the invention may be computer implemented. Accordingly, the present invention may take the form of an entirely hardware embodiment, an entirely software embodiment (including firmware, resident software, micro-code, etc.) or an embodiment combining software and hardware aspects that may all generally be referred to herein as a “circuit”, “module” or “system”. Furthermore, the present invention may take the form of a computer program product embodied in any tangible medium of expression having computer usable program code embodied in the medium.</div>
</li> <li> <para-num num="[0111]"> </para-num> <div class="description-line" id="p-0112" num="0111">Since the present invention can be implemented in software, the present invention can be embodied as computer readable code for provision to a programmable apparatus on any suitable carrier medium. A tangible carrier medium may comprise a storage medium such as a floppy disk, a CD-ROM, a hard disk drive, a magnetic tape device or a solid state memory device and the like. A transient carrier medium may include a signal such as an electrical signal, an electronic signal, an optical signal, an acoustic signal, a magnetic signal or an electromagnetic signal, e.g. a microwave or RF signal.</div>
</li> <description-of-drawings>
<heading id="h-0005">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<li> <para-num num="[0112]"> </para-num> <div class="description-line" id="p-0113" num="0112">Embodiments of the invention will now be described, by way of example only, and with reference to the following drawings in which:</div>
</li> <li> <para-num num="[0113]"> </para-num> <div class="description-line" id="p-0114" num="0113"> <figref idrefs="DRAWINGS">FIG. 1</figref> illustrates the HEVC encoder architecture;</div>
</li> <li> <para-num num="[0114]"> </para-num> <div class="description-line" id="p-0115" num="0114"> <figref idrefs="DRAWINGS">FIG. 2</figref> illustrates the HEVC decoder architecture;</div>
</li> <li> <para-num num="[0115]"> </para-num> <div class="description-line" id="p-0116" num="0115"> <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates the concept of the causal area;</div>
</li> <li> <para-num num="[0116]"> </para-num> <div class="description-line" id="p-0117" num="0116"> <figref idrefs="DRAWINGS">FIG. 4</figref> illustrates Chroma formats supported by HEVC RExt;</div>
</li> <li> <para-num num="[0117]"> </para-num> <div class="description-line" id="p-0118" num="0117"> <figref idrefs="DRAWINGS">FIG. 5</figref> illustrates the Coding Tree Block splitting into Coding Units and the scan order decoding of these Coding Unit;</div>
</li> <li> <para-num num="[0118]"> </para-num> <div class="description-line" id="p-0119" num="0118"> <figref idrefs="DRAWINGS">FIG. 6</figref> illustrates the Golomb based binary coding of a syntax element in HEVC;</div>
</li> <li> <para-num num="[0119]"> </para-num> <div class="description-line" id="p-0120" num="0119"> <figref idrefs="DRAWINGS">FIG. 7</figref> illustrates the principle of Palette mode prediction at the decoder side under investigation in the Range Extension of HEVC;</div>
</li> <li> <para-num num="[0120]"> </para-num> <div class="description-line" id="p-0121" num="0120"> <figref idrefs="DRAWINGS">FIG. 8</figref> illustrates an example of a coding unit with its corresponding block of levels and the associated palette;</div>
</li> <li> <para-num num="[0121]"> </para-num> <div class="description-line" id="p-0122" num="0121"> <figref idrefs="DRAWINGS">FIG. 9</figref> illustrates the same block of levels and the set of syntax elements used for the encoding of this block of levels;</div>
</li> <li> <para-num num="[0122]"> </para-num> <div class="description-line" id="p-0123" num="0122"> <figref idrefs="DRAWINGS">FIG. 10</figref> illustrates the decoding process of the syntax elements relating to the Palette mode;</div>
</li> <li> <para-num num="[0123]"> </para-num> <div class="description-line" id="p-0124" num="0123"> <figref idrefs="DRAWINGS">FIG. 11</figref> illustrates the reconstruction process to build the block of levels at the decoding side;</div>
</li> <li> <para-num num="[0124]"> </para-num> <div class="description-line" id="p-0125" num="0124"> <figref idrefs="DRAWINGS">FIG. 12</figref> illustrates an exemplary palette determination algorithm at the encoder;</div>
</li> <li> <para-num num="[0125]"> </para-num> <div class="description-line" id="p-0126" num="0125"> <figref idrefs="DRAWINGS">FIG. 13</figref> illustrates the selection of the Pred mode, Level and Run syntax elements at the encoder for the Palette mode;</div>
</li> <li> <para-num num="[0126]"> </para-num> <div class="description-line" id="p-0127" num="0126"> <figref idrefs="DRAWINGS">FIG. 14</figref> illustrates the principle of using the palette prediction;</div>
</li> <li> <para-num num="[0127]"> </para-num> <div class="description-line" id="p-0128" num="0127"> <figref idrefs="DRAWINGS">FIG. 14<i>a </i> </figref>shows a frame with several CTBs arranged in rows;</div>
</li> <li> <para-num num="[0128]"> </para-num> <div class="description-line" id="p-0129" num="0128"> <figref idrefs="DRAWINGS">FIG. 15</figref> illustrates the decoding process based on reference palette predictors transmitted in the bitstream according to embodiments of the invention;</div>
</li> <li> <para-num num="[0129]"> </para-num> <div class="description-line" id="p-0130" num="0129"> <figref idrefs="DRAWINGS">FIG. 16</figref> illustrates the current coding unit with neighboring pixels used as predictors in embodiments of the invention;</div>
</li> <li> <para-num num="[0130]"> </para-num> <div class="description-line" id="p-0131" num="0130"> <figref idrefs="DRAWINGS">FIG. 17</figref> illustrates the generation of the palette predictor for the current coding unit, based on the neighbouring pixels according to embodiments of the invention;</div>
</li> <li> <para-num num="[0131]"> </para-num> <div class="description-line" id="p-0132" num="0131"> <figref idrefs="DRAWINGS">FIG. 18</figref> shows an example of the building of a palette predictor according to embodiments of the invention;</div>
</li> <li> <para-num num="[0132]"> </para-num> <div class="description-line" id="p-0133" num="0132"> <figref idrefs="DRAWINGS">FIG. 19</figref> illustrates the decoding of the palette syntax based on a bitmap of flags according to embodiments of the invention;</div>
</li> <li> <para-num num="[0133]"> </para-num> <div class="description-line" id="p-0134" num="0133"> <figref idrefs="DRAWINGS">FIG. 20</figref> illustrates the process of <figref idrefs="DRAWINGS">FIG. 19</figref> in one example;</div>
</li> <li> <para-num num="[0134]"> </para-num> <div class="description-line" id="p-0135" num="0134"> <figref idrefs="DRAWINGS">FIG. 21</figref> illustrates a decoding process based on having residuals between palette elements and element predictors according to embodiments of the invention;</div>
</li> <li> <para-num num="[0135]"> </para-num> <div class="description-line" id="p-0136" num="0135"> <figref idrefs="DRAWINGS">FIG. 22</figref> illustrates the intra prediction of the palette according to embodiments of the invention;</div>
</li> <li> <para-num num="[0136]"> </para-num> <div class="description-line" id="p-0137" num="0136"> <figref idrefs="DRAWINGS">FIG. 23</figref> is a schematic block diagram of a computing device for implementation of one or more embodiments of the invention;</div>
</li> <li> <para-num num="[0137]"> </para-num> <div class="description-line" id="p-0138" num="0137"> <figref idrefs="DRAWINGS">FIG. 24</figref> is a flowchart illustrating general steps for building a palette predictor from two or more palettes already existing, according to some embodiments of the invention;</div>
</li> <li> <para-num num="[0138]"> </para-num> <div class="description-line" id="p-0139" num="0138"> <figref idrefs="DRAWINGS">FIG. 25</figref> illustrates an exemplary implementation of the approach of <figref idrefs="DRAWINGS">FIG. 24</figref>;</div>
</li> <li> <para-num num="[0139]"> </para-num> <div class="description-line" id="p-0140" num="0139"> <figref idrefs="DRAWINGS">FIG. 26</figref> illustrates an implementation of the process of <figref idrefs="DRAWINGS">FIG. 24</figref>; and</div>
</li> <li> <para-num num="[0140]"> </para-num> <div class="description-line" id="p-0141" num="0140"> <figref idrefs="DRAWINGS">FIG. 27</figref> illustrates a modified syntax for bitmaps of flags defining how a palette can be predicted from a palette predictor, and comprises a flowchart illustrating steps for decoding the modified syntax of a bitmap.</div>
</li> </description-of-drawings>
<heading id="h-0006">DETAILED DESCRIPTION OF EMBODIMENTS OF THE INVENTION</heading>
<li> <para-num num="[0141]"> </para-num> <div class="description-line" id="p-0142" num="0141"> <figref idrefs="DRAWINGS">FIG. 1</figref> illustrates the HEVC encoder architecture. In the video encoder, an original sequence <b>101</b> is divided into blocks of pixels <b>102</b>. A coding mode is then assigned to each block. There are two families of coding modes typically used in HEVC: the modes based on spatial prediction or INTRA modes <b>103</b> and the modes based on temporal prediction or INTER modes based on motion estimation <b>104</b> and motion compensation <b>105</b>. An extension of HEVC being currently designed, known as HEVC RExt, adds an additional coding mode, namely the Palette coding mode, that compete with INTRA and INTER coding modes to encode blocks of pixels. This Palette coding mode is described in more detail below, in particular with reference to <figref idrefs="DRAWINGS">FIGS. 7 to 13</figref>.</div>
</li> <li> <para-num num="[0142]"> </para-num> <div class="description-line" id="p-0143" num="0142">An INTRA Coding Unit is generally predicted from the encoded pixels at its causal border by a process called INTRA prediction.</div>
</li> <li> <para-num num="[0143]"> </para-num> <div class="description-line" id="p-0144" num="0143">Temporal prediction of an INTER coding mode first consists in finding in a previous or future frame called the reference frame <b>116</b> the reference area of which is the closest to the Coding Unit, in a motion estimation step <b>104</b>. This reference area constitutes the predictor block. Next this Coding Unit is predicted using the predictor block to compute the residue in a motion compensation step <b>105</b>.</div>
</li> <li> <para-num num="[0144]"> </para-num> <div class="description-line" id="p-0145" num="0144">In both cases, spatial and temporal prediction, a residual is computed by subtracting the Coding Unit from the original predictor block.</div>
</li> <li> <para-num num="[0145]"> </para-num> <div class="description-line" id="p-0146" num="0145">In the INTRA prediction, a prediction direction is encoded. In the temporal prediction, at least one motion vector is encoded. However, in order to further reduce the bitrate cost related to motion vector encoding, a motion vector is not directly encoded. Indeed, assuming that motion is homogeneous, it is particularly advantageous to encode a motion vector as a difference between this motion vector, and a motion vector in its surroundings. In the H.264/AVC coding standard for instance, motion vectors are encoded with respect to a median vector computed between 3 blocks located above and on the left of the current block. Only a difference, also called residual motion vector, computed between the median vector and the current block motion vector is encoded in the bitstream. This is processed in module “Mv prediction and coding” <b>117</b>. The value of each encoded vector is stored in the motion vector field <b>118</b>. The neighboring motion vectors, used for the prediction, are extracted from the motion vector field <b>118</b>.</div>
</li> <li> <para-num num="[0146]"> </para-num> <div class="description-line" id="p-0147" num="0146">Next, the mode optimizing the rate distortion performance is selected in module <b>106</b>. In order to further reduce the redundancies, a transform, typically a DCT, is applied to the residual block in module <b>107</b>, and a quantization is applied to the coefficients in module <b>108</b>. The quantized block of coefficients is then entropy coded in module <b>109</b> and the result is inserted into the bitstream <b>110</b>.</div>
</li> <li> <para-num num="[0147]"> </para-num> <div class="description-line" id="p-0148" num="0147">The encoder then performs a decoding of the encoded frame for the future motion estimation in modules <b>111</b> to <b>116</b>. This is a decoding loop at the encoder. These steps allow the encoder and the decoder to have the same reference frames. To reconstruct the coded frame, the residual is inverse quantized in module <b>111</b> and inverse transformed in module <b>112</b> in order to provide the “reconstructed” residual in the pixel domain. According to the encoding mode (INTER or INTRA), this residual is added to the INTER predictor <b>114</b> or to the INTRA predictor <b>113</b>.</div>
</li> <li> <para-num num="[0148]"> </para-num> <div class="description-line" id="p-0149" num="0148">Next, this first reconstruction is filtered in module <b>115</b> by one or several kinds of post filtering. These post filters are integrated into the decoding loop. This means that they need to be applied to the reconstructed frame at the encoder and decoder in order to use the same reference frames at the encoder and decoder. The aim of this post filtering is to remove compression artifacts.</div>
</li> <li> <para-num num="[0149]"> </para-num> <div class="description-line" id="p-0150" num="0149">The principle of an HEVC decoder has been represented in <figref idrefs="DRAWINGS">FIG. 2</figref>. The video stream <b>201</b> is first entropy decoded in a module <b>202</b>. The residual data are then inverse quantized in a module <b>203</b> and inverse transformed in a module <b>204</b> to obtain pixel values. The mode data are also entropy decoded and depending on the mode, an INTRA type decoding or an INTER type decoding is performed. In the case of INTRA mode, the INTRA prediction direction is decoded from the bitstream. The prediction direction is then used to locate the reference area <b>205</b>. If the mode is INTER, the motion information is decoded from the bitstream <b>202</b>. This is composed of the reference frame index and the motion vector residual. The motion vector predictor is added to the motion vector residual to obtain the motion vector <b>210</b>. The motion vector is then used to locate the reference area in the reference frame <b>206</b>. Note that the motion vector field data <b>211</b> is updated with the decoded motion vector in order to be used for the prediction of the next decoded motion vectors. This first reconstruction of the decoded frame is then post filtered <b>207</b> with exactly the same post filter as used at the encoder side. The output of the decoder is the de-compressed video <b>209</b>.</div>
</li> <li> <para-num num="[0150]"> </para-num> <div class="description-line" id="p-0151" num="0150"> <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates the causal principle resulting from block-by-block encoding as in HEVC.</div>
</li> <li> <para-num num="[0151]"> </para-num> <div class="description-line" id="p-0152" num="0151">At a high-level, an image is divided into Coding Units that are encoded in raster scan order. Thus, when coding block <b>3</b>.<b>1</b>, all the blocks of area <b>3</b>.<b>3</b> have already been encoded, and can be considered available to the encoder. Similarly, when decoding block <b>3</b>.<b>1</b> at the decoder, all the blocks of area <b>3</b>.<b>3</b> have already been decoded and thus reconstructed, and can be considered as available at the decoder. Area <b>3</b>.<b>3</b> is called the causal area of the Coding Unit <b>3</b>.<b>1</b>. Once Coding Unit <b>3</b>.<b>1</b> is encoded, it will belong to the causal area for the next Coding Unit. This next Coding Unit, as well as all the next ones, belongs to area <b>3</b>.<b>4</b> illustrated as a dotted area, and cannot be used for coding the current Coding Unit <b>3</b>.<b>1</b>. It is worth noting that the causal area is constituted by reconstructed blocks. The information used to encode a given Coding Unit is not the original blocks of the image for the reason that this information is not available at decoding. The only information available at decoding is the reconstructed version of the blocks of pixels in the causal area, namely the decoded version of these blocks. For this reason, at encoding, previously encoded blocks of the causal area are decoded to provide this reconstructed version of these blocks.</div>
</li> <li> <para-num num="[0152]"> </para-num> <div class="description-line" id="p-0153" num="0152">It is possible to use information from a block <b>3</b>.<b>2</b> in the causal area when encoding a block <b>3</b>.<b>1</b>. In the HEVC Range Extension draft specifications, a displacement vector <b>3</b>.<b>5</b>, which can be transmitted in the bitstream, may indicate this block <b>3</b>.<b>2</b>.</div>
</li> <li> <para-num num="[0153]"> </para-num> <div class="description-line" id="p-0154" num="0153"> <figref idrefs="DRAWINGS">FIG. 5</figref> illustrates a splitting of a Coding Tree Block into Coding Units and an exemplary scan order to sequentially process these Coding Units. In the HEVC standard, the block structure is organized by Coding Tree Blocks (CTBs). A frame contains several non-overlapped and square Coding Tree Blocks. The size of a Coding Tree Block can range in size from 64×64 to 16×16. This size is determined at sequence level. The most efficient size, in term of coding efficiency, is the largest one: 64×64. Note that all Coding Tree Blocks have the same size except for the image border, meaning that they are arranged in rows. The size of the border CTBs is adapted according to the amount of remaining pixels.</div>
</li> <li> <para-num num="[0154]"> </para-num> <div class="description-line" id="p-0155" num="0154">Each Coding Tree Block contains one or more square Coding Units (CU). The Coding Tree Block is split based on a quad-tree structure into several Coding Units. The processing (coding or decoding) order of each Coding Unit in the Coding Tree Block follows the quad-tree structure based on a raster scan order. <figref idrefs="DRAWINGS">FIG. 5</figref> shows an example of the processing order of Coding Units. In this figure, the number in each Coding Unit gives the processing order of each corresponding Coding Unit of this Coding Tree Block.</div>
</li> <li> <para-num num="[0155]"> </para-num> <div class="description-line" id="p-0156" num="0155">In HEVC, several methods are used to code the different syntax elements, for example block residuals, information on predictor blocks (motion vectors, INTRA prediction directions, etc.). HEVC uses several types of entropy coding such as the Context based Adaptive Binary Arithmetic Coding (CABAC), Golomb-rice Code, or simple binary representation called Fixed Length Coding. Most of the time a binary encoding process is performed to represent the different syntax elements. This binary encoding process is also very specific and depends on the different syntax element.</div>
</li> <li> <para-num num="[0156]"> </para-num> <div class="description-line" id="p-0157" num="0156">For example, the syntax element called “coeff_abs_level_remaining” contains the absolute value or a part of an absolute value of the coefficient residual. The idea of this binary encoding process is to use Golomb-Rice code for the first values and</div>
</li> <li> <para-num num="[0157]"> </para-num> <div class="description-line" id="p-0158" num="0157">Exponential Golomb for the higher values. More specifically, depending on a given parameter called Golomb Order, this means that for representing the first values, for example values from 0 to 3, a Golomb-Rice code is used, then for higher values, for example values from 4 and above, an Exponential Golomb code is used. The Golomb Order is a parameter used by both the Golomb-Rice code and the exponential Golomb code.</div>
</li> <li> <para-num num="[0158]"> </para-num> <div class="description-line" id="p-0159" num="0158"> <figref idrefs="DRAWINGS">FIG. 6</figref> illustrates this principle at the decoding side. The input data of the decoding process are the bitstream <b>601</b> and the Order which is known as the Rice Golomb parameter, or the Golomb Order. The output of this process is the decoded symbol <b>612</b>.</div>
</li> <li> <para-num num="[0159]"> </para-num> <div class="description-line" id="p-0160" num="0159">The prefix value is set equal to 1 at step <b>602</b> then 1 bit is extracted from the bitstream at step <b>601</b> and the variable flag is set equal to the decoded value <b>603</b>. If this flag is equal to 0 at step <b>604</b> the Prefix value is incremented <b>605</b> and another bit is extracted from the bitstream <b>603</b>. When the flag value is equal to 1, the decision module <b>606</b> checks if the value Prefix is strictly inferior to 3. If this is true, the N=Order bits are extracted <b>608</b> from the bitstream <b>601</b> and set to the variable “codeword”. This corresponds to the Golomb-Rice representation. The Symbol value <b>612</b> is set equal to ((prefix«Order)+codeword) as represented in step <b>609</b>. Where ‘«’ is the left shift operator.</div>
</li> <li> <para-num num="[0160]"> </para-num> <div class="description-line" id="p-0161" num="0160">If the Prefix is superior or equal to 3 at step <b>606</b>, the next step is <b>610</b> where N=(prefix−3+Order) bits are extracted from the bitstream and set to the variable “codeword” <b>610</b>. The symbol value <b>611</b> is set equal to ((1«(prefix−3))+2)«Order)+codeword. This corresponds to the exponential Golomb representation.</div>
</li> <li> <para-num num="[0161]"> </para-num> <div class="description-line" id="p-0162" num="0161">In the following, this decoding process, and in a symmetric way the corresponding encoding process, is called Golomb_H with an input parameter corresponding to the Golomb Order. It can be noted in a simple way Golomb_H(Order).</div>
</li> <li> <para-num num="[0162]"> </para-num> <div class="description-line" id="p-0163" num="0162">In HEVC, for some syntax elements such as residuals, the Golomb Order is updated in order to adapt the entropy coding to the signal to be encoded. The updating formula tries to reduce the Golomb code size by increasing the Golomb Order when the coefficients have large values. In the HEVC standard, the update is given by the following formula:</div>
</li> <li> <div class="description-line" id="p-0164" num="0000"> <br/>Order=Min(<i>c</i>LastRiceOrder+(<i>c</i>LastAbsLevel&gt;(3*(1&lt;&lt;<i>c</i>LastRiceOrder))? 1:0), 4)</div>
</li> <li> <para-num num="[0163]"> </para-num> <div class="description-line" id="p-0165" num="0163">Where cLastRiceOrder is the last used Order, cLastAbsLevel is the last decoded coeff_abs_level_remaining. Please note that for the first parameter to be encoded or decoded, cLastRiceOrder and cLastAbsLevel are set equal to 0. Morever please note that the parameter Order cannot exceed the value of 4 in this formula. And where the expression (C? A:B) has the value A if the condition C is true and B if the condition C is false.</div>
</li> <li> <para-num num="[0164]"> </para-num> <div class="description-line" id="p-0166" num="0164">The HEVC Range Extension, also commonly called HEVC RExt, is an extension that is currently being drafted for the new video coding standard HEVC.</div>
</li> <li> <para-num num="[0165]"> </para-num> <div class="description-line" id="p-0167" num="0165">An aim of this extension is to provide additional tools to code video sequences with additional colour formats and bit-depth, and possibly losslessly. In particular, this extension is designed to support 4:2:2 colour format as well as 4:4:4 video format in addition to 4;2.0 video format (see <figref idrefs="DRAWINGS">FIG. 4</figref>). A colour image is generally made of three colour components R, G and B. These components are generally correlated, and it is very common in image and video compression to de-correlate the colour components prior to processing the images. The most common format that de-correlates the colour components is the YUV colour format. YUV signals are typically created from RGB representation of images, by applying a linear transform to the three inputs R, G and B input frames. Y is usually called Luma component, U and V are generally called Chroma components. The term ‘YCbCr’ is also commonly used in place of the term ‘YUV’.</div>
</li> <li> <para-num num="[0166]"> </para-num> <div class="description-line" id="p-0168" num="0166">Regarding the bit-depth which is the number of bits used to code each colour component of a pixel, although the current HEVC standard is able to deal with 4:2:0 colour format with 8 and 10 bits bit-depth (i.e. 256 to 1,024 possible colours), HEVC RExt is about to be designed to additionally support 4:2:2 and 4:4:4 video format with an extended bit-depth ranging from 8 bits up to 16 bits (i.e. up to 65,536 possible colours). This is particularly useful to have a larger dynamic of colour components.</div>
</li> <li> <para-num num="[0167]"> </para-num> <div class="description-line" id="p-0169" num="0167">HEVC RExt is also designed to provide a lossless encoding of the input sequences; this is to have a decoded output <b>209</b> strictly identical to the input <b>101</b>. To achieve this, a number of tools have been modified or added, compared to the conventional HEVC lossy codec. A non-exhaustive list of exemplary modifications or additions to implement losslessly is provided here below:
</div> </li> <ul> <li id="ul0001-0001" num="0000"> <ul> <li id="ul0002-0001" num="0168">removal of the quantization step <b>108</b> (<b>203</b> at the decoder);</li> <li id="ul0002-0002" num="0169">forced activation of the bypass transform, as normal cosine/sine transforms <b>107</b> may introduce errors (<b>204</b> at the decoder);</li> <li id="ul0002-0003" num="0170">removal of tools specifically tailored for compensating quantization noise, such as post filtering <b>115</b> (<b>207</b> at the decoder).</li> </ul> </li> </ul>
<li> <para-num num="[0171]"> </para-num> <div class="description-line" id="p-0170" num="0171">For HEVC RExt, the updating formula of the Golomb Order has been further modified in order to be adapted to deal with higher bit-depth and to take into account very high quality required by application dealing with video compression of extended format (4:2:2 and 4:4:4) including lossless coding. For HEVC RExt, the updating formula has been changed as follows:</div>
</li> <li> <div class="description-line" id="p-0171" num="0000"> <br/>Order=Min(<i>c</i>LastRiceOrder+(<i>c</i>LastAbsLevel&gt;&gt;(2<i>+c</i>LastRiceOrder)),7)</div>
</li> <li> <para-num num="[0172]"> </para-num> <div class="description-line" id="p-0172" num="0172">With this formula, the maximum value of Order is 7. Moreover, for the first coding of the coeff_abs_level_remaining for a sub-block of Transform block, the Golomb order is set equal to:</div>
</li> <li> <div class="description-line" id="p-0173" num="0000"> <br/>Order=Max(0, <i>c</i>RiceOrder−(transform_skip_flag ||cu_transquant_bypass_flag? 1:2))
</div>
</li> <li> <div class="description-line" id="p-0174" num="0000">where
</div> </li> <ul> <li id="ul0003-0001" num="0000"> <ul> <li id="ul0004-0001" num="0173">the variable “transform_skip_flag” is set to 1 if the transform (e.g. DCT <b>107</b> or <b>204</b>) is skipped for the current coding unit and 0 if the transform is used,</li> <li id="ul0004-0002" num="0174">the variable “cu_transquant_bypass_flag” is set to 1 if the coding unit is losslessly encoded and 0 otherwise,</li> <li id="ul0004-0003" num="0175">the variable “cRiceOrder” is set equal to last used Order from another sub-block of the transform block and otherwise is set to 0.</li> </ul> </li> </ul>
<li> <para-num num="[0176]"> </para-num> <div class="description-line" id="p-0175" num="0176">Additional tools for HEVC RExt are currently being designed to efficiently encode “screen content” video sequences in addition to natural sequences. The “screen content” video sequences refer to particular video sequences which have a very specific content corresponding to those captured from a personal computer of any other device, containing for example text, PowerPoint presentation, Graphical User Interface, tables (e.g. screen shots). These particular video sequences have quite different statistics compared to natural video sequences. In video coding, performance of conventional video coding tools, including HEVC, proves sometimes to be underwhelming when processing such “screen content”.</div>
</li> <li> <para-num num="[0177]"> </para-num> <div class="description-line" id="p-0176" num="0177">The current tools currently discussed on in HEVC RExt to process “screen content” video sequences include the Intra Block Copy mode and the Palette mode. Prototypes for these modes have shown good coding efficiency compared to the conventional method targeting natural video sequences. The present application focuses on the Palette coding mode.</div>
</li> <li> <para-num num="[0178]"> </para-num> <div class="description-line" id="p-0177" num="0178">The Palette mode of HEVC RExt is a prediction mode. It means that the Palette method is used to build a predictor for the coding of a given coding unit similarly to a prediction performed by motion prediction (Inter case) or by an Intra prediction. After the generation of the prediction, a residual coding unit is transformed, quantized and coded. In other words, the same processes as described above with reference to <figref idrefs="DRAWINGS">FIGS. 1 and 2</figref> apply.</div>
</li> <li> <para-num num="[0179]"> </para-num> <div class="description-line" id="p-0178" num="0179">A palette is generally represented by a table containing a finite set of N-tuple of colors, each color being defined by its components in a given colour space (see for example <b>803</b> in <figref idrefs="DRAWINGS">FIG. 8</figref> based on YUV colour space). For example, in a typical RGB format, the palette is composed of a list of P elements of N-tuple (where N=3 for a RGB). More precisely, each element corresponds to a fixed triplet of colour components in the RGB format. Of course this is not limited to a RGB or YUV colour format. Any other colour format can be represented by a palette and can use a smaller or a higher number of colour components, meaning that N may be different from 3.</div>
</li> <li> <para-num num="[0180]"> </para-num> <div class="description-line" id="p-0179" num="0180">At the encoder side, the Palette mode, under consideration in RExt, consists in transforming pixel values of a given input coding unit into indexes called levels identifying the entries in an associated palette. After the transformation, the resulting coding unit or block is composed of levels and is then transmitted to the decoder with the associated palette, generally a table having a finite number of triplets of colours used to represent the coding unit. Since the palette defines a finite number of colours, the transformation into a block of indexes usually approximates the original input coding unit.</div>
</li> <li> <para-num num="[0181]"> </para-num> <div class="description-line" id="p-0180" num="0181">To apply the Palette mode at the encoder side, an exemplary way to transform a coding unit of pixels is performed as follows:
</div> </li> <ul> <li id="ul0005-0001" num="0000"> <ul> <li id="ul0006-0001" num="0182">find the P triplets best describing the coding unit of pixels to encode, for example by minimizing overall distortion;</li> <li id="ul0006-0002" num="0183">then associate with each pixel of the coding unit the closest colour among the P triplets: the value to encode (or level) (which thus forms part of the block of indexes) is then the index corresponding to the entry of the associated closest colour. The predictor block of indexes is thus obtained from the palette by comparing the entries of the palette to each pixel of the coding unit, in order to identify, for each pixel, the entry which defines the closest colour.</li> </ul> </li> </ul>
<li> <para-num num="[0184]"> </para-num> <div class="description-line" id="p-0181" num="0184">For each coding unit, the palette (i.e. the P triplets found), the block of indexes or levels and the residual representing the difference between the original coding unit and the block of indexes in the colour space (which is the block predictor) are coded in the bitstream <b>110</b> and sent to the decoder.</div>
</li> <li> <para-num num="[0185]"> </para-num> <div class="description-line" id="p-0182" num="0185">At the decoder, the Palette mode consists in performing the conversion in the reverse way. This means that each decoded index associated with each pixel of the coding unit is replaced by the corresponding colour in the palette decoded from the bitstream, in order to reconstruct the corresponding colour for each pixel of the coding unit. This is the reconstruction of the block of indexes in the colour space (i.e. of the coding unit predictor). Since the Palette mode is a prediction mode, the associated residual is decoded from the bitstream and then added to the reconstructed coding unit predictor to build the final reconstructed coding unit.</div>
</li> <li> <para-num num="[0186]"> </para-num> <div class="description-line" id="p-0183" num="0186"> <figref idrefs="DRAWINGS">FIG. 7</figref> further illustrates the principle of Palette mode at the decoder. The prediction mode for the current coding unit is extracted at step <b>702</b> from the bitstream <b>701</b>. Currently, the Palette mode is identified by a flag located before the skip flag in the bitstream (the other coding modes have been described above with reference to <figref idrefs="DRAWINGS">FIGS. 1 and 2</figref>). This flag is CABAC coded using a single context. If this mode is the Palette mode <b>703</b> then the related syntax of the Palette mode <b>705</b>, i.e. the information on the palette, the block of levels and the residual, is extracted and decoded <b>704</b> from the bitstream <b>701</b>.</div>
</li> <li> <para-num num="[0187]"> </para-num> <div class="description-line" id="p-0184" num="0187">Next, during step <b>706</b>, two elements are built from the decoded data: the palette <b>707</b> and the block of levels <b>708</b>. From this block of levels and the associated palette, the coding unit predictor in pixel domain <b>710</b> is built <b>709</b>. This means that for each level of the block of levels, a color (RGB or YUV) is associated with each pixel.</div>
</li> <li> <para-num num="[0188]"> </para-num> <div class="description-line" id="p-0185" num="0188">Then the coding unit residual is decoded <b>711</b> from the bitstream <b>701</b>. In the current implementation of Palette mode, the residual associated with a Palette mode is coded using the common HEVC Inter residual coding method, i.e. using Golomb coding. To obtain the residual of the coding unit, the conventional inverse quantization and inverse transformation are performed. The block predictor <b>710</b> is added <b>713</b> to this coding unit residual <b>712</b> in order to form the reconstructed coding unit <b>714</b>.</div>
</li> <li> <para-num num="[0189]"> </para-num> <div class="description-line" id="p-0186" num="0189"> <figref idrefs="DRAWINGS">FIG. 8</figref> illustrates the principle of the Palette mode at the encoder. The current coding unit <b>801</b> is converted into a block <b>802</b> of the same size which contains a level for each pixel instead of 3 colour values (Y, U, V) or (R, G, B). The palette <b>803</b> associated with this block of levels is built based on coding unit overall distortion minimization and associates at each entry, an entry index or level with corresponding pixel colour values. Note that for monochrome application, the pixel value can contain only one component.</div>
</li> <li> <para-num num="[0190]"> </para-num> <div class="description-line" id="p-0187" num="0190">As mentioned in relation to <figref idrefs="DRAWINGS">FIG. 7</figref>, the palette (as well as the residual) is coded and inserted into the bitstream for each coding unit. In the same way, the block of levels (corresponding to the coding unit predictor) is coded and inserted into the bitstream and an example of the coding is given below with reference to <figref idrefs="DRAWINGS">FIG. 9</figref>. In this example, the block of levels is scanned in a horizontal order.</div>
</li> <li> <para-num num="[0191]"> </para-num> <div class="description-line" id="p-0188" num="0191">The block of levels <b>91</b> is exactly the same as the one illustrated in <figref idrefs="DRAWINGS">FIG. 8</figref> under reference <b>802</b>. The tables <b>92</b> and <b>93</b> describe the successive syntax elements used to code the block of levels <b>91</b>. Table <b>93</b> should be read as the continuation of table <b>92</b>. The syntax elements in the table correspond to the encoding of the groups of levels surrounded by bold lines in the block <b>91</b>.</div>
</li> <li> <para-num num="[0192]"> </para-num> <div class="description-line" id="p-0189" num="0192">The block of levels is encoded by group of successive pixels in scan order. Each group is encoded using a first syntax element giving a prediction direction, a second element giving the repetition, and an optional third element giving the value of the pixel, namely the level. The repetition corresponds to the number of pixels in the group.</div>
</li> <li> <para-num num="[0193]"> </para-num> <div class="description-line" id="p-0190" num="0193">These two tables represent the current syntax associated with the Palette mode. These syntax elements correspond to the encoded information associated in the bitstream for the block of levels <b>91</b>. In these tables, three main syntax elements are used to fully represent the operations of the Palette mode and are used as follows when successively considering the levels of the block of levels <b>91</b>.</div>
</li> <li> <para-num num="[0194]"> </para-num> <div class="description-line" id="p-0191" num="0194">A first syntax element, called “Pred mode” makes it possible to distinguish between two encoding modes. In a first mode corresponding to “Pred mode” flag equal to “0”, a new level is used for the current pixel. The level is immediately signaled after this flag in the bitstream. In a second mode corresponding to “Pred mode” flag equal to “1”, a “copy up” mode is used. More specifically, this means that the current pixel level corresponds to the pixel level located at the line immediately above starting on the same position for a raster scan order. In that case of “Pred mode” flag equal to “1”, there is no need to signal a level immediately after the flag because the value of the level is known by reference to the value of the level of the pixel just above in the block of levels <b>91</b>.</div>
</li> <li> <para-num num="[0195]"> </para-num> <div class="description-line" id="p-0192" num="0195">A second syntax element called “Level” indicates the level value of the palette for the current pixel only in the first mode of “Pred mode”.</div>
</li> <li> <para-num num="[0196]"> </para-num> <div class="description-line" id="p-0193" num="0196">A third syntax element, called “Run”, is used to encode a repetition value in both modes of “Pred mode”. Considering that the block of levels <b>91</b> is scanned from the top left corner to the bottom right corner, row by row from left to right and top to bottom, the Run syntax element gives the number of successive pixels in block <b>91</b> having the same encoding.</div>
</li> <li> <para-num num="[0197]"> </para-num> <div class="description-line" id="p-0194" num="0197">This “Run” syntax element has a different meaning which depends on the “pred mode” flag. When Pred mode is 0, “Run” element is the number of successive pixels of the predictor block having the same level value. For example, if Run=8 this means that the current “Level” is applied to the current pixel and to the following 8 pixels which corresponds to 9 identical successive samples in raster scan order.</div>
</li> <li> <para-num num="[0198]"> </para-num> <div class="description-line" id="p-0195" num="0198">When Pred mode is 1, “Run” element is the number of successive pixels of the predictor block having a level value corresponding to the level value of their above pixel in block <b>91</b>, i.e. where the “copy up” mode is applied. For example, if Run=31 this means that the level of the current pixel is copied from the pixel of the line above as well as the following 31 pixels which corresponds to 32 pixels in total.</div>
</li> <li> <para-num num="[0199]"> </para-num> <div class="description-line" id="p-0196" num="0199">Tables <b>92</b> and <b>93</b> represent the eight steps to represent the block <b>91</b> by using the Palette mode. Each step starts with the coding of the “Pred mode” flag which is followed by the “Level” syntax element when “Pred mode” flag equals “0”, or by the “Run” syntax element when “Pred mode” flag equals “1”. The “Level” syntax element is always followed by a “Run” syntax element.</div>
</li> <li> <para-num num="[0200]"> </para-num> <div class="description-line" id="p-0197" num="0200">When the prediction mode decoded for the current block is the palette mode, the decoder first decodes the syntax relating to this block and then applies the reconstruction process for the coding unit.</div>
</li> <li> <para-num num="[0201]"> </para-num> <div class="description-line" id="p-0198" num="0201"> <figref idrefs="DRAWINGS">FIG. 10</figref> illustrates the decoding process of the syntax elements relating to the Palette mode. First, the size of the palette is extracted and decoded <b>1002</b> from the bitstream <b>1001</b>. The exact size of the palette (Palette_size) is obtained by adding 1 to this size value decoded at step <b>1002</b>. Indeed, the size is coded by using a unary code for which the value 0 has the smallest number of bits (1 bit) and the size of the palette cannot be equal to 0, otherwise no pixel value can be used to build the block predictor.</div>
</li> <li> <para-num num="[0202]"> </para-num> <div class="description-line" id="p-0199" num="0202">Next the process corresponding to the palette values decoding starts. A variable i corresponding to the index of the palette is set equal to 0 at step <b>1004</b> next a test is performed at step <b>1005</b> to check whether i is equal to the palette size (Palette_size) or not. If it is different from the palette size at step <b>1005</b>, one palette element is extracted from the bitstream <b>1001</b> and decoded at step <b>1006</b> and is then added to the palette with the associated level/index equal to i. Then the variable i is incremented through step <b>1007</b>. If i is equal to the palette size at step <b>1005</b>, the palette has been completely decoded.</div>
</li> <li> <para-num num="[0203]"> </para-num> <div class="description-line" id="p-0200" num="0203">Next the process corresponding to the decoding of the block of levels <b>91</b> is performed. First, the variable j, corresponding to a pixel counter, is set to 0 as well as the variable syntax_i <b>1008</b>. Then a check is performed to know whether the pixel counter corresponds to the number of pixels contained in the block. If the answer is yes at step <b>1009</b> the process ends at step <b>1017</b>, otherwise the value of the flag “Pred mode” corresponding to one prediction mode is extracted from the bitstream <b>1001</b> and decoded <b>1010</b>.</div>
</li> <li> <para-num num="[0204]"> </para-num> <div class="description-line" id="p-0201" num="0204">The value of “Pred mode” is added to a table at the index syntax_i containing all “Pred mode” value decoded. If the value of this “Pred mode” is equal to 0, step <b>1011</b>, the syntax element corresponding to “Level” is extracted from the bitstream <b>1001</b> and decoded <b>1012</b>. This variable “Level” is added to a table at the index syntax_i containing all levels decoded. The variable j corresponding to the pixel counter is incremented by one <b>1013</b>.</div>
</li> <li> <para-num num="[0205]"> </para-num> <div class="description-line" id="p-0202" num="0205">Next the “Run” syntax element is decoded at step <b>1014</b>. If the syntax element “Pred Mode” is equal to 1, step <b>1011</b>, the “Run” value is also decoded at step <b>1014</b>. This syntax element “Run” is added to a table at the index syntax_i containing all the runs decoded.</div>
</li> <li> <para-num num="[0206]"> </para-num> <div class="description-line" id="p-0203" num="0206">Next at step <b>1015</b>, the value j is incremented by the value of the run decoded at step <b>1014</b>. The variable syntax_i is incremented by one to consider the next set of syntax elements. If the counter j is equal to the number of pixels in the block then the syntax to build the block of levels <b>91</b> is finished <b>1017</b>. At the end of this process related to the Palette, the decoder knows the palette, and the tables containing the list of all the “Pred mode”, “Level” and “Run” syntax elements associated with the Palette mode of this coding unit. The decoder can then proceed with the reconstruction process of the coding unit as described through <figref idrefs="DRAWINGS">FIG. 7</figref>.</div>
</li> <li> <para-num num="[0207]"> </para-num> <div class="description-line" id="p-0204" num="0207">In a slight variant of this embodiment of <figref idrefs="DRAWINGS">FIG. 10</figref>, the “Pred mode” element is not provided for the first line of pixels at the top of the block of levels <b>91</b>. This is because, since these pixels are deprived of levels at a line above, the “copy up” mode cannot be executed. Therefore, as long as j is less than the block width at step <b>1009</b>, no “Pred mode” element is provided and steps <b>1010</b>-<b>1011</b> are shortcut, thereby directly performing step <b>1012</b>. Note that this slight variant decreases the size of the encoded block of levels.</div>
</li> <li> <para-num num="[0208]"> </para-num> <div class="description-line" id="p-0205" num="0208">In an embodiment that can be combined with either the above embodiment of <figref idrefs="DRAWINGS">FIG. 10</figref> or its slight variant, several blocks of levels may be generated instead of only one. This means that several levels are used for all or parts of the pixels. For instance, a first block of levels may be built for a first colour component (Y for example), while another block of levels may be built for the at least one remaining component (U and V for example). Of course, three blocks of levels for the three colour components may be contemplated. The choice to have several blocks of level and their correspondence with the colour components may be signalled in the bitstream using specific flags. In a variant, this may be implied by the colour format of the image.</div>
</li> <li> <para-num num="[0209]"> </para-num> <div class="description-line" id="p-0206" num="0209">The process of <figref idrefs="DRAWINGS">FIG. 10</figref> has been described above in relation with the Palette mode prediction process of <figref idrefs="DRAWINGS">FIG. 7</figref>, where a residual is encoded and thus extracted and decoded at steps <b>711</b> and <b>712</b> before being added to the Coding Unit predictor.</div>
</li> <li> <para-num num="[0210]"> </para-num> <div class="description-line" id="p-0207" num="0210">In a variant of the Palette mode prediction process as described in <figref idrefs="DRAWINGS">FIG. 7</figref>, no residual may be provided (i.e. encoded at the encoding side). It results in <figref idrefs="DRAWINGS">FIG. 7</figref> being deprived of steps <b>711</b>, <b>712</b> and <b>713</b>, the reconstructed Coding Unit <b>714</b> being the same as the Coding Unit predictor <b>710</b>.</div>
</li> <li> <para-num num="[0211]"> </para-num> <div class="description-line" id="p-0208" num="0211">However, there may still be pixels of the Coding Unit that are improperly described by levels of the palette, meaning that no corresponding relevant levels have been found in the palette. These pixels are referred to as “escape” pixels, since no corresponding value is set in the block of levels.</div>
</li> <li> <para-num num="[0212]"> </para-num> <div class="description-line" id="p-0209" num="0212">The syntax elements built during the process of <figref idrefs="DRAWINGS">FIG. 10</figref> for the block of levels may thus be supplemented, for those “escape” pixels, with explicit pixel values from the original Coding Unit. The explicit pixel values may be signalled and transmitted in the bitstream.</div>
</li> <li> <para-num num="[0213]"> </para-num> <div class="description-line" id="p-0210" num="0213">An example of signalling the pixels is to add an “escape” flag before the “Pred mode” element (i.e. before step <b>1010</b>) indicating whether a pixel is palette-coded (therefore subject to step <b>1010</b>) or escape-coded (therefore with an explicit pixel value). The “escape” flag is followed by the explicit pixel value (no “Pred mode”, “Level” and “Run” elements are provided for this pixel).</div>
</li> <li> <para-num num="[0214]"> </para-num> <div class="description-line" id="p-0211" num="0214">In a variant to the “escape” flag, a specific Level value (dedicated to “escape” pixels and obtained at step <b>1012</b>) may be used to signal an “escape” pixel. In this case, the “Run” element should be the explicit pixel value. This specific value may only occur when the palette being built reaches its maximum size, thereby saving the cost of signalling escape values for each palette size.</div>
</li> <li> <para-num num="[0215]"> </para-num> <div class="description-line" id="p-0212" num="0215">In any embodiment, the explicit pixel values may be coded predictively (e.g. as a difference to a neighbour pixel value) or not, and may be quantized or not, with possible consequences for the entropy coding (contextual and number of bits, etc.).</div>
</li> <li> <para-num num="[0216]"> </para-num> <div class="description-line" id="p-0213" num="0216">Referring back to the palette, each palette element, constituted by three values in the above examples, is generally encoded using three binary codes. The length of the binary codes corresponds to the bit-depth of each color component. The palette size is typically encoded using unary code. The “Pred mode” element is encoded using one bit (as well as the “escape” flag if any). The “Level” element is encoded using binary code with binary code length equal to b, where 2b is the smallest integer equal or above the palette size. And the “Run” element is encoded using Golomb_H(Order=3) as explained above in relation to <figref idrefs="DRAWINGS">FIG. 6</figref>.</div>
</li> <li> <para-num num="[0217]"> </para-num> <div class="description-line" id="p-0214" num="0217"> <figref idrefs="DRAWINGS">FIG. 11</figref> illustrates the reconstruction process to build the block of levels <b>91</b> and then the block predictor in the colour space that has to be used as predictor. The input data of this process are the tables obtained using the process of <figref idrefs="DRAWINGS">FIG. 10</figref> above, and containing the list of “Pred mode”, “Level” and “Run”. Note that one skilled in the art is able to adapt the teachings below to the embodiments relying on the presence of “escape” pixels.</div>
</li> <li> <para-num num="[0218]"> </para-num> <div class="description-line" id="p-0215" num="0218">An additional item of input data to the “Pred mode”, “Level” and “Run” elements is the size of the coding unit <b>801</b> (which is the same as the size of the block of levels <b>802</b>/<b>91</b>) known from the quadtree (<figref idrefs="DRAWINGS">FIG. 5</figref>) signalled in the bitstream.</div>
</li> <li> <para-num num="[0219]"> </para-num> <div class="description-line" id="p-0216" num="0219">In a first step <b>1101</b>, a variable i, representing a pixel counter, is set equal to 0 and a variable j, to successively consider each set of syntax elements, is also set equal to 0. At step <b>1104</b>, the element Pred_mode[j] extracted from the table of “Pred mode” at index j is checked against 0.</div>
</li> <li> <para-num num="[0220]"> </para-num> <div class="description-line" id="p-0217" num="0220">If it is equal to 0, a new level is encoded for the current pixel i. As a consequence, the value of the pixel at position i is set equal to the level at the index j from the table of levels; Block[i]=Level[j]. This is step <b>1105</b>. The variable i is incremented by one at step <b>1106</b> to consider the next pixel, and the variable k, dedicated to count the pixels already processed in the current Run, is set equal to 0 at step <b>1107</b>.</div>
</li> <li> <para-num num="[0221]"> </para-num> <div class="description-line" id="p-0218" num="0221">A check is performed at step <b>1108</b> to determine whether or not k is equal to the “Run” element of the table of runs at the index j: k =Run[j]?. If not equal, the level of the pixel at position i is set equal to the level value of the pixel at position i−1: Block[i]=Block[i−1]. This is step <b>1109</b>. The variable i and the variable k are then incremented by one at respectively steps <b>1110</b> and <b>1111</b>. If k=Run[j] at step <b>1108</b>, the propagation of the left level value is finished and step <b>1120</b> is performed (described below).</div>
</li> <li> <para-num num="[0222]"> </para-num> <div class="description-line" id="p-0219" num="0222">If Pred_mode[j] is different from 0 at step <b>1104</b>, the “copy up” mode starts with the variable k set equal to 0 at step <b>1112</b>. Next, step <b>1113</b> checks whether or not (k−1) is equal to the “Run” element of the table of runs at the index j: k=Run[j]+1? If not equal, the level value of the pixel at position i is set equal to the level value of the pixel at position i of the above line: Block[i]=Block[i-width], where “width” is the width of the block of levels (the same as the coding unit) as deduced from the input size of the coding unit. This is step <b>1114</b>. Next, the variable i and the variable k are incremented by one at respectively steps <b>1115</b> and <b>1116</b>. If k=Run[j]+1 at step <b>1113</b>, the prediction mode ‘copy up’ is completed and the process goes on at step <b>1120</b>.</div>
</li> <li> <para-num num="[0223]"> </para-num> <div class="description-line" id="p-0220" num="0223">At step <b>1120</b>, a check is performed to determine whether or not the variable i is equal to the amount of pixels in the block <b>91</b>/CU <b>801</b>. If not equal, the variable j is incremented by one at step <b>1121</b> to consider the next set of syntax elements and the process loops back to step <b>1104</b> described above.</div>
</li> <li> <para-num num="[0224]"> </para-num> <div class="description-line" id="p-0221" num="0224">If all the pixels have been processed at step <b>1120</b>, the final block of levels <b>91</b> is obtained at step <b>1122</b>: this corresponds to table Block[ ]. Then a final step <b>1123</b> consists in converting each level in colour values using the palette <b>803</b> decoded using the process of <figref idrefs="DRAWINGS">FIG. 10</figref> (except for the “escape” pixels which directly have their pixel values). This final step affects pixel values (Y, U, V) or (R, G, B) at each block position according to the level of this position in the block and the corresponding entries in the palette.</div>
</li> <li> <para-num num="[0225]"> </para-num> <div class="description-line" id="p-0222" num="0225">Other aspects of the palette mode as introduced in HEVC RExt concern the determination by the encoder of the palette to be used to encode the current coding unit (see <figref idrefs="DRAWINGS">FIG. 12</figref> below), and the selection of the Pred mode, Level and Run syntax elements at the encoder (see <figref idrefs="DRAWINGS">FIG. 13</figref> below).</div>
</li> <li> <para-num num="[0226]"> </para-num> <div class="description-line" id="p-0223" num="0226"> <figref idrefs="DRAWINGS">FIG. 12</figref> illustrates an exemplary palette determination algorithm at the encoder. The input data of this process are the original coding unit of pixels and its coding unit size. In this example, a YUV palette is built, but other implementations may result in having an RGB palette built in the same way.</div>
</li> <li> <para-num num="[0227]"> </para-num> <div class="description-line" id="p-0224" num="0227">At a first step <b>1201</b>, a variable j representing a pixel counter is set to 0, a variable “Palette_size” to follow the growth of the palette as it is being built is also set to 0, and a variable “TH” representing a threshold is set to 9. Next at step <b>1203</b>, the pixel p<sub>i</sub>, i.e. having the index i according to a scanning order, is read at step <b>1203</b> from the original coding unit <b>1204</b>. Then the variable j is set equal to 0 at <b>1205</b> and at step <b>1206</b> a check is performed to determine whether or not the palette size is equal to the variable “j” (meaning that all the palette elements of the palette under construction have been considered).</div>
</li> <li> <para-num num="[0228]"> </para-num> <div class="description-line" id="p-0225" num="0228">If the palette size is equal to j, the palette at the index “j” is set equal to the pixel value p<sub>i </sub>at step <b>1209</b>. This means that the current pixel p<sub>i </sub>becomes a new element in the palette, with index j associated with it. More precisely the following assignment is performed:</div>
</li> <li> <div class="description-line" id="p-0226" num="0000"> <br/>PAL<sub>Y</sub> <i>[j</i>]=(<i>Yi</i>)</div>
</li> <li> <div class="description-line" id="p-0227" num="0000"> <br/>PAL<sub>U</sub> <i>[j</i>]=(<i>Ui</i>)</div>
</li> <li> <div class="description-line" id="p-0228" num="0000"> <br/>PAL<sub>V</sub> <i>[j</i>]=(<i>Vi</i>)</div>
</li> <li> <div class="description-line" id="p-0229" num="0000">where PAL<sub>Y,U,V </sub>are three tables to store the colour values.</div>
</li> <li> <para-num num="[0229]"> </para-num> <div class="description-line" id="p-0230" num="0229">The palette size (Palette_size) is incremented by one at step <b>1210</b> and an occurrence table Counter is set equal to 1 for the index ‘Palette size’ at step <b>1211</b>. Then the variable i is incremented by one at step <b>1213</b> to consider the next pixel “ i” of the current coding unit. A check is then performed at step <b>1214</b> to determine whether or not all the pixels of the current coding unit have been processed. If they have all been processed, the process is completed by an ordering step <b>1215</b> explained later on, otherwise the next pixel is considered at step <b>1203</b> described above.</div>
</li> <li> <para-num num="[0230]"> </para-num> <div class="description-line" id="p-0231" num="0230">Back to step <b>1206</b>, if j is different from palette_size, step <b>1207</b> is performed where the absolute value for each colour component between p<sub>i </sub>and the palette element at the index j is computed. The formulas are shown in the Figure. If all the absolute differences are strictly less than the predefined threshold TH, the occurrence counter regarding the element “j” in the palette is incremented by one at step <b>1212</b>. Step <b>1207</b> creates a class for each element of the palette under construction, such a class encompassing colours neighbouring the colour of the element, given the margin TH.</div>
</li> <li> <para-num num="[0231]"> </para-num> <div class="description-line" id="p-0232" num="0231">Thus step <b>1212</b> counts the occurrences of each class. Step <b>1212</b> is followed by step <b>1213</b> already described.</div>
</li> <li> <para-num num="[0232]"> </para-num> <div class="description-line" id="p-0233" num="0232">If the condition of step <b>1207</b> is not met, the variable j is incremented by one at step <b>1208</b> to consider the next palette element in the palette. This is to compare the other palette colour elements to the current pixel through new occurrence of step <b>1207</b>.</div>
</li> <li> <para-num num="[0233]"> </para-num> <div class="description-line" id="p-0234" num="0233">If no element in the palette meets the criterion of step <b>1207</b>, a new element is added to the palette as described above with reference to steps <b>1209</b>, <b>1210</b> and <b>1211</b>.</div>
</li> <li> <para-num num="[0234]"> </para-num> <div class="description-line" id="p-0235" num="0234">One may note that the decision module <b>1207</b> can compared each color element for a 4:4:4 (YUV or RGB) sequences and can only compare the Luma colour component for 4:2:0 sequences.</div>
</li> <li> <para-num num="[0235]"> </para-num> <div class="description-line" id="p-0236" num="0235">At the end of the process of <figref idrefs="DRAWINGS">FIG. 12</figref>, the table “Counter” contains the number of occurrences of the classes defined by the respective palette elements. Then the palette elements are ordered at step <b>1215</b> according to their occurrences so that the most frequent element is in the first position (entry with the lowest index or “level”) in the palette.</div>
</li> <li> <para-num num="[0236]"> </para-num> <div class="description-line" id="p-0237" num="0236">One may also note that the size of the palette can be limited to a maximum size, for example 24 entries. In such a case, if the size of the palette resulting from step <b>1215</b> exceeds 24, the palette is reduced by removing the elements (entries) from the 25<sup>th </sup>position in the ordered palette. This results in a palette being built.</div>
</li> <li> <para-num num="[0237]"> </para-num> <div class="description-line" id="p-0238" num="0237">Turning now to the selection of the Pred mode, Level and Run syntax elements at the encoder, input data of the process of <figref idrefs="DRAWINGS">FIG. 13</figref> are the original coding unit of pixels, the palette as built through the process of <figref idrefs="DRAWINGS">FIG. 12</figref> and the coding unit size. In particular, this evaluation is performed when determining which coding mode between INTRA coding, INTER coding and Palette coding has to be used.</div>
</li> <li> <para-num num="[0238]"> </para-num> <div class="description-line" id="p-0239" num="0238">At a first step <b>1301</b>, the variable “i” representing a pixel counter is set to 0. The process described below seeks to determine the syntax elements for the pixels starting from i. The two modes of prediction are evaluated independently: “Pred mode”=0 on the right hand part of the Figure, and “Pred mode”=1 on the left hand part of the Figure.</div>
</li> <li> <para-num num="[0239]"> </para-num> <div class="description-line" id="p-0240" num="0239">For the ‘copy up’ prediction (corresponding to “Pred mode”=1), the variable “i<sub>copy</sub>” used to count the number of levels in the current Run is set equal to 0 at step <b>1303</b>. Then at step <b>1304</b> the current level at pixel location i : Block[i+i<sub>copy</sub>], is compared to the level of the pixel located just above in the above line: Block[i+i<sub>copy</sub>−width], where “width” corresponds to the width of the current coding unit. Note that the level Block[i+i<sub>copy</sub>] of each pixel of the coding unit is determined in parallel at step <b>1308</b>. This step consists in associating with the pixel at the position i, the closest palette element (in practice its index or level) as already explained above. This step uses the position i, the palette <b>1306</b> and the original coding unit <b>1307</b>.</div>
</li> <li> <para-num num="[0240]"> </para-num> <div class="description-line" id="p-0241" num="0240">If Block[i+i<sub>copy</sub>]=Block[i+i<sub>copy</sub>−width] at step <b>1304</b>, the variable “i<sub>copy</sub>” is incremented by one at step <b>1305</b> to consider the next pixel value of the block of pixels and to indicate that the current pixel level at position i+i<sub>copy </sub>can be included in the current “copy up” Run. If Block[i+i<sub>copy</sub>] is different from Block[i+i<sub>copy</sub>−width] at step <b>1304</b> meaning that the current evaluation of a “copy up” Run has ended, the variable “i<sub>copy</sub>” is transmitted to the decision module <b>1314</b>. At this stage of the process, the variable “i<sub>copy</sub>” corresponds to the number of values copied from the line just above.</div>
</li> <li> <para-num num="[0241]"> </para-num> <div class="description-line" id="p-0242" num="0241">For the left value prediction (corresponding to “Pred mode”=0), the loop to determine the Run value (i<sub>left</sub>) is processed in parallel or sequentially. First the variable “i<sub>Start</sub>” used to store the index i of the current pixel is set to “i”, and the variable “j” used to consider successively the pixel levels following index “i” is also set equal to “i” and the variable “i<sub>left</sub>” used to count the current Run under construction is set equal to 0. This is step <b>1309</b>. Next, step <b>1310</b> consists in determining whether or not j !=0 and “Pred_mode[j−1]”=0 and Block[j]=Block[j−1]. Pred_mode[ ] is a table used by the encoder to store the prediction mode (either 1 or 0 for respectively the “copy up” prediction and the left value prediction). It is filled up progressively at step <b>1317</b> described below as the successive pixels are processed, and has been initialized with zero values for example at step <b>1301</b>: Pred_mode[k]=0 for any k.</div>
</li> <li> <para-num num="[0242]"> </para-num> <div class="description-line" id="p-0243" num="0242">If the condition at step <b>1310</b> is met, the variable “i<sub>left</sub>” is incremented by one at step <b>1311</b> to indicate that the current pixel level at position j can be included in the current “left value” Run, and the variable j is incremented by one at step <b>1312</b> to consider the next pixel value of the block of pixels.</div>
</li> <li> <para-num num="[0243]"> </para-num> <div class="description-line" id="p-0244" num="0243">If the condition at step <b>1310</b> is not met, the variable “j” is compared to “i<sub>start</sub>” to determine if it is the first pixel value to be examined for the current “left value”Run. This is step <b>1313</b>. If “j” is equal to or less than “i<sub>start</sub>”, meaning that it is the first pixel value to be examined for the current Run, then it starts the current Run and the next pixel value is considered at step <b>1312</b> described above. If “j” is strictly higher than “i<sub>Start</sub>”, meaning that a first pixel value different from the pixel value of the current “left value”Run has been detected, the variable “i<sub>left</sub>” which corresponds to the length of the current “left value” Run is transmitted to the decision module <b>1314</b>. Note that, as the loop for “copy up” prediction, the level Block[i] at the index i is determined in the same loop at step <b>1308</b>.</div>
</li> <li> <para-num num="[0244]"> </para-num> <div class="description-line" id="p-0245" num="0244">After having computed the maximum run for the ‘left value prediction’ and the ‘copy up’ mode, the variable “i<sub>left</sub>” and “i<sub>copy</sub>” are compared at step <b>1314</b>. This is to determine whether or not “i<sub>copy</sub>”!=0 and “i<sub>copy</sub>”+2 is higher than “i<sub>left</sub>”. This is an exemplary criterion to select either the copy up mode or the left value prediction mode. In particular, the parameter “2” may be slightly changed.</div>
</li> <li> <para-num num="[0245]"> </para-num> <div class="description-line" id="p-0246" num="0245">The condition at step <b>1314</b> means that if “i<sub>copy</sub>” is equal to 0 or is smaller than or equal to i<sub>left</sub>−2, the “left value prediction” mode is selected at step <b>1315</b>. In that case, a “PredMode” variable is set equal to 0 and a Run variable is set equal to “i<sub>left</sub>” at same step <b>1315</b>. On the other hand, if “i<sub>copy</sub>” is different from 0 and is strictly higher than “i<sub>left</sub>−2”, the “copy-up” mode is selected at step <b>1316</b>. In that case, the “PredMode” variable is set equal to 1 and the Run variable to i<sub>copy</sub>−1 at step <b>1316</b>.</div>
</li> <li> <para-num num="[0246]"> </para-num> <div class="description-line" id="p-0247" num="0246">Next the tables containing the “Pred_mode” and the “Run” at the encoder are updated with the current value “Predmode” and “Run”, at step <b>1317</b>. Then, the next position to consider in the block of pixels is computed at step <b>1318</b>, which corresponds to the current position i incremented by the “run” value+1. Then a check is performed at step <b>1319</b> to determine whether the last pixels of the coding unit have been processed. If it is the case, the process ends at step <b>1320</b>, otherwise the evaluation of the two prediction modes “left prediction” and “copy up” are evaluated starting at steps <b>1303</b> and <b>1309</b> for the next pixel position to obtain a new set of syntax elements.</div>
</li> <li> <para-num num="[0247]"> </para-num> <div class="description-line" id="p-0248" num="0247">At the end of this process, the encoder knows the levels for each sample of the coding unit, and is able to encode the corresponding syntax of the block of levels based on the content of the three tables Pred_mode[ ], Block[ ] and Run[ ].</div>
</li> <li> <para-num num="[0248]"> </para-num> <div class="description-line" id="p-0249" num="0248">As described above, the Palette mode as currently designed in HEVC RExt requires a palette to be transmitted for each coding unit. This represents a large amount of data in the bitstream, and thus a coding cost. The inventors have envisaged an improvement of the Palette mode to improve its coding efficiency</div>
</li> <li> <para-num num="[0249]"> </para-num> <div class="description-line" id="p-0250" num="0249">According to one aspect of the invention, the current palette for a current coding unit is predicted using a palette predictor. In a variant regarding the invention, the current palette is predicted from entries of two or more palettes, the two or more palettes being palettes previously used to process blocks of pixels, for example using a palette predictor built from the two or more palettes. This makes it possible to reduce the amount of information to be transmitted for each palette associated with a coding unit. Various embodiments are described below.</div>
</li> <li> <para-num num="[0250]"> </para-num> <div class="description-line" id="p-0251" num="0250">As the approach of the invention is prediction-based, the obtaining of the predictor for the current coding unit is first described with reference to <figref idrefs="DRAWINGS">FIGS. 14 to 18, 22 and 24 to 26</figref>, and then the syntax elements to actually describe the prediction to the decoder are described with reference to <figref idrefs="DRAWINGS">FIGS. 19 to 22 and 27</figref>.</div>
</li> <li> <para-num num="[0251]"> </para-num> <div class="description-line" id="p-0252" num="0251">General steps of a decoding process implementing the invention are shown in <figref idrefs="DRAWINGS">FIG. 14</figref> which is based on <figref idrefs="DRAWINGS">FIG. 7</figref> described above. One skilled in the art would directly understand the corresponding operations at the encoder to appropriately build the bitstream. Blocks <b>14</b>xx in <figref idrefs="DRAWINGS">FIG. 14</figref> are similar to blocks <b>7</b>xx in <figref idrefs="DRAWINGS">FIG. 7</figref>. As shown in the Figure, the main idea of the invention is implemented at step <b>1406</b> where the palette is at least partly predicted from a palette predictor <b>1416</b> instead of being entirely decoded from the bitstream. Several ways to obtain <b>1415</b> the palette predictor are described below, including obtaining
</div> </li> <ul> <li id="ul0007-0001" num="0000"> <ul> <li id="ul0008-0001" num="0252">a palette used to predict a previously processed block of pixels or coding unit;</li> <li id="ul0008-0002" num="0253">a reference palette predictor associated with a coding entity that includes the current coding unit;</li> <li id="ul0008-0003" num="0254">entries corresponding to values of pixels neighbouring the current coding unit; and</li> <li id="ul0008-0004" num="0255">at least one entry of the current palette that precedes a current entry to be predicted in the current palette.</li> </ul> </li> </ul>
<li> <para-num num="[0256]"> </para-num> <div class="description-line" id="p-0253" num="0256">According to first embodiments to obtain the palette predictor, blocks of pixels of the image are processed according to a predefined scanning order as described above with reference to <figref idrefs="DRAWINGS">FIG. 5</figref> where the CUs of a CTB are coded/decoded according to a scan order. The palette predictor for the current block of pixels is then selected from a set of palettes used to predict previously processed blocks of pixels. Preferably, the palette predictor for the current block of pixels is a palette used for the last processed block of pixels. This may be implemented by storing the last used decoding palette (for the last processed coding unit) in memory. Of course another palette from among the already used palettes may be selected as a palette predictor, in which case an identifier of such selected palette should be provided to the decoder.</div>
</li> <li> <para-num num="[0257]"> </para-num> <div class="description-line" id="p-0254" num="0257">According to the scan order used, it is generally observed that the last used palette, and thus the palette predictor, is one of the palettes used for previously processed coding units that are contiguous with the current coding unit. This ensures high redundancy between the coding units is taken into account to obtain an efficient coding. For example, based on <figref idrefs="DRAWINGS">FIG. 5</figref>, the palette predictor can be one of the palettes used to process the left or above coding units <b>15</b>, <b>17</b>, <b>12</b> and <b>13</b>.</div>
</li> <li> <para-num num="[0258]"> </para-num> <div class="description-line" id="p-0255" num="0258">To avoid poor palette prediction due to a palette predictor which has content far from the actual content of the current coding unit, specific embodiments provide a reset of the last used palette (or of the set of previously used palettes). Such reset may occur at each new CTB, i.e. when the current coding unit starts a new coding entity made of blocks of pixels, or at each new line or row of CTBs as introduced above, or even at each new frame.</div>
</li> <li> <para-num num="[0259]"> </para-num> <div class="description-line" id="p-0256" num="0259">Such reset also makes it possible for the encoder or the decoder to estimate the palette mode for each CTB (or row of CTBs or frame) in parallel. However, since some correlations often exist between the coding units of 2 CTBs, the reset is preferably performed for each new row of CTBs. This is illustrated using <figref idrefs="DRAWINGS">FIG. 14<i>a </i> </figref>which shows a frame with several CTBs (each represented by a square). The CTBs on the left in thick lines are the CTBs for which the last used Palette is reset because each of them starts a new line of CTBs.</div>
</li> <li> <para-num num="[0260]"> </para-num> <div class="description-line" id="p-0257" num="0260">The reset at the first CTB of a line is a more efficient approach than the reset at Frame level. This is because the CTBs are encoded in a horizontal raster scan order, and thus for the first CTB of a line of CTBs, the last used palette is potentially predicted from a spatially far CTB (the last one of the CTB line just above). Given the spatial distance between the CTBs, the correlation between them is very low and thus a dependency (prediction) between their respective palettes is not worthwhile.</div>
</li> <li> <para-num num="[0261]"> </para-num> <div class="description-line" id="p-0258" num="0261">The reset of the last used palette may mean that no palette is available as a palette predictor to possibly predict a current palette. In that case, the current palette, e.g. the palette of the very first coding unit processed in the first CTB of the line, cannot be predicted. This reset may be performed by setting the Previous_Palette_size variable (storing the size of the last used palette) to 0.</div>
</li> <li> <para-num num="[0262]"> </para-num> <div class="description-line" id="p-0259" num="0262">In addition, the reset of the last used palette also increases the global coding cost of the palette mode in a substantial way since no value can be predicted, thereby biasing towards smaller palette sizes and therefore smaller and less efficient palette predictors. This is because new elements in the block can be reused by other blocks, therefore actually mutualizing the bits spent for the first block. A typical solution would be using dynamic programming algorithms such as Viterbi, where the coding decision for a block is selected only after a few blocks have been encoded. This is however prohibitively complex and simpler solutions are preferred.</div>
</li> <li> <para-num num="[0263]"> </para-num> <div class="description-line" id="p-0260" num="0263">Such increase of the coding cost may thus cause the coding mode selector (see step <b>106</b>) to select it more rarely and not immediately after the reset (thus with delay). However, it is worth having the palette mode selected for coding the coding units. For this purpose, embodiments provide to boost the probability that the palette mode is selected by cheating on the bit coding cost of the first coding of a coding unit after the reset occurred (i.e. with an empty or default palette predictor). This is to have a bit coding cost lower than it should be, thereby increasing the probability that the palette mode is selected.</div>
</li> <li> <para-num num="[0264]"> </para-num> <div class="description-line" id="p-0261" num="0264">False information on the bits used for coding may be provided to artificially obtain this lowering of the bit coding costs. This false or cheating information or “bonus” for a color component may depend on the operating point of the codec (i.e. how much distortion improvement a bit should bring), on the chroma format, on the at least one color component concerned and/or the number of elements in the palette for the current coding unit.</div>
</li> <li> <para-num num="[0265]"> </para-num> <div class="description-line" id="p-0262" num="0265">For instance, the case may be considered of a palette of RGB or YUV elements, each component R/G/B/Y/U/V having e.g. 8 bits components. Therefore, the bit cost resulting from the coding of one entry of the palette used for the first coding unit after palette reset is normally 3×8=24 bits. However, in the embodiments discussed here, a bonus may be applied to correct this bit cost, for example by artificially decreasing it to only 8 bits. The palette mode is thus more likely to be selected at step <b>106</b>.</div>
</li> <li> <para-num num="[0266]"> </para-num> <div class="description-line" id="p-0263" num="0266">In particular embodiments where two or more levels are needed to represent a pixel (e.g. one level for the component Y and one level for the pair of components U and V), two or more palettes are actually used to code a block of pixels. A bonus may be applied to each of the two or more palettes. For example, if two palettes, one for component Y and the other for component U+V, are provided, a bonus may consist in modifying the bit cost of one Y element from 8 bits to 4 bits and the bit cost of one U+V element from 16 bits to 6 bits.</div>
</li> <li> <para-num num="[0267]"> </para-num> <div class="description-line" id="p-0264" num="0267">As it may be worth predicting the palette for the coding unit first processed, a variant includes replacing the last used palette by a by-default palette, so that the by-default palette is used as a palette predictor for the first coding unit of the line of CTBs. Various ways to generate a by-default palette (both the encoder and the decoder operate in the same way) may be considered. As an example, the by-default palette may include a set of predetermined entries corresponding to colour values equally distributed over a colour space. The equidistribution may concern the three colour components. However, in a preferred embodiment, the colour values may be equally distributed over the Y component. And the U and V component values are fixed, for example at the median value of the U or V components in the colour space. The U and V values may be directly computed from the bit-depth of the components, by assigning the value bit-depth/2 or bit-depth » <b>1</b>, where ‘»’ is the right shift operator. An example of the distribution along the Y component is the following formula: YLevel=(Level*bit-depth)/Previous_Palette_size, where Level corresponds to the entry index of the by-default table as explained above (and thus is incremented by one at each new value Y), bit-depth is the bit-depth of the Y component. Note that the Previous_Palette_size may be equal to the last used palette, or to an average Palette_size computed from the last decoded CTB or line of CTBs or frame, or to a predefined number such as 4.</div>
</li> <li> <para-num num="[0268]"> </para-num> <div class="description-line" id="p-0265" num="0268">According to other embodiments to obtain the palette predictor, reference palette predictors are associated with respective coding entities of coding units that form the image, such as CTBs, lines of CTBs, slices, slice segment, tile, frame or sequence. And the palette predictor for the current block of pixels is the reference palette predictor associated with the coding entity that includes the current block of pixels. These embodiments may require the reference palette predictor to be transmitted in the bitstream for each coding entity.</div>
</li> <li> <para-num num="[0269]"> </para-num> <div class="description-line" id="p-0266" num="0269"> <figref idrefs="DRAWINGS">FIG. 15</figref> illustrates the decoding process based on reference palette predictors transmitted in the bitstream. This Figure is based on <figref idrefs="DRAWINGS">FIG. 14</figref> and thus blocks <b>1501</b> to <b>1514</b> are similar to blocks <b>1401</b> to <b>1414</b>, except that the module <b>1506</b> builds the palette using the reference palette predictor <b>1516</b> decoded from the bitstream. Of course, a corresponding process is performed at the encoder to include the reference palette predictor in the bitstream.</div>
</li> <li> <para-num num="[0270]"> </para-num> <div class="description-line" id="p-0267" num="0270">At the beginning of the CTB decoding (or CTB line, Slice, Frame, etc. decoding), the reference palette predictor <b>1516</b> is extracted from the bitstream at step <b>1515</b>. Note that the use of the reference palette predictor may lead to having no palette provided in the bitstream for any coding unit of the current coding entity CTB. In this case one flag may be provided in the bitstream and thus be extracted therefrom in order to signal not to decode any palette for the coding units. In a variant, this flag may be replaced by using the value 0 for the Palette_size to indicate the decoder that no palette is to be decoded for the current coding unit. This variant requires that the Palette_size be equal to decodedSize instead of decodedSize +1 in step <b>1003</b> above. To save any bit used for signaling the use of the reference palette predictor, the reference palette predictor can be transmitted at the end of the CTB if at least one CU of the current CTB is coded using the Palette coding mode.</div>
</li> <li> <para-num num="[0271]"> </para-num> <div class="description-line" id="p-0268" num="0271">In any case, the reference palette predictor is extracted and decoded if needed to decode one of the coding units of the current CTB. Module <b>1502</b> extracts the prediction mode. If it is not the Palette mode (test <b>1503</b>), the decoder decodes the CU with the corresponding mode <b>1517</b>. Otherwise (the palette mode), the palette for the current coding unit is decoded as in <figref idrefs="DRAWINGS">FIG. 7</figref>. However, the building <b>1506</b> of the palette <b>1507</b> in this embodiment depends on the reference palette predictor <b>1516</b>. Examples of this dependency and of corresponding syntax elements <b>1505</b> are described below. When the coding unit is decoded (<b>1517</b>, <b>1520</b>) as described above for</div>
</li> <li> <para-num num="[0272]"> </para-num> <div class="description-line" id="p-0269" num="0272"> <figref idrefs="DRAWINGS">FIGS. 7 and 13</figref>, the decoder checks whether or not it was the last coding unit of the CTB at step <b>1518</b>. Note that this figure does not contain the full syntax decoding of a CTB which may involve other syntax elements. If it was not the last coding unit, the prediction mode for the next CU is extracted at step <b>1502</b>. If it was the last coding unit, the remaining processes to entirely decode the CTB are performed (not shown) and the decoder checks whether or not it was the last CTB of the frame at step <b>1519</b>. If it was not the last CTB, the reference palette predictor for the next CTB is extracted from the bitstream at step <b>1515</b> described above. Of course, this figure is not complete and several decoding steps that do not concern the present invention have been omitted. As described, the reference palette predictor transmitted is used as the predictor of the palette used for each coding unit CU in the current CTB. As described below, the reference palette predictor can be used to predict elements of the palette or, in a variant, the reference palette predictor can be used as the palette for the current coding unit. In that case, the reference palette predictor <b>1516</b> is directly transmitted to module <b>1509</b> thereby causing module <b>1507</b> to be no longer required.</div>
</li> <li> <para-num num="[0273]"> </para-num> <div class="description-line" id="p-0270" num="0273">The selection of the reference palette predictor at the encoder may contribute to coding efficiency. Several algorithms can be used to determine the “best” reference palette predictor. For example, the palette used to predict the largest coding unit in the current CTB can be selected as the reference palette predictor for the CTB. In another example, the palette that minimizes a rate-distortion criterion from the palettes used to predict all the coding units composing the current CTB may be determined and used as the reference palette predictor for the CTB. Of course, other selection criteria may be used.</div>
</li> <li> <para-num num="[0274]"> </para-num> <div class="description-line" id="p-0271" num="0274">According to yet other embodiments to obtain the palette predictor, the palette predictor for the current coding unit includes entries corresponding to values of pixels neighbouring the current coding unit. In these embodiments, the palette predictor for the current CU is extracted from the neighboring pixels as shown by way of example in <figref idrefs="DRAWINGS">FIG. 16</figref>.</div>
</li> <li> <para-num num="[0275]"> </para-num> <div class="description-line" id="p-0272" num="0275">In this example, the selected pixels are pixels contiguous with the upper and left sides of the current block of pixels, because they belong to the causal area as defined above with reference to <figref idrefs="DRAWINGS">FIG. 3</figref>. These contiguous pixels are shown in grey color in the Figure. In particular, the selected pixels are a fixed number, for example the same three pixels (dark grey pixels <b>1601</b> to <b>1603</b> in the Figure) as those used for INTRA prediction mode, namely the pixels that are, relative to the contiguous current coding unit, top-left, top-right and bottom-left. Of course, another number of pixels may be considered. Preferably the relevant pixels to select are known by both the encoder and the decoder so that no additional signalling information is needed. However, some embodiments may envisage selecting specific pixels at the encoder and then signalling, in the bitstream, the number of selected pixels and those selected pixels.</div>
</li> <li> <para-num num="[0276]"> </para-num> <div class="description-line" id="p-0273" num="0276">In one embodiment, a restricted set of neighbouring pixels is considered. For example, this set of pixels is selected in order that the pixels have the highest spatial distance. This creates diversity and avoids duplicate pixels.</div>
</li> <li> <para-num num="[0277]"> </para-num> <div class="description-line" id="p-0274" num="0277"> <figref idrefs="DRAWINGS">FIG. 17</figref> illustrates the generation of the palette predictor for the current coding unit, based on the neighbouring pixels. As noted above, the order of the elements in the palette predictor is important. This requires the definition of classes for the palette elements (here neighbouring pixels). This determination process can be performed at both the encoder and the decoder.</div>
</li> <li> <para-num num="[0278]"> </para-num> <div class="description-line" id="p-0275" num="0278">In one embodiment, the neighbouring pixels <b>1701</b> are classified <b>1702</b>. Note that the neighbouring pixels may include pixels that are not directly contiguous with the current coding unit. Each neighboring pixel of the considered set of neighbouring pixels is associated with a class (so with an entry index) depending on its colour distance from already existing entries in the palette predictor, for example using the criteria of step <b>1207</b> in <figref idrefs="DRAWINGS">FIG. 12</figref>. In an embodiment, the classes are defined by the three pixels <b>1601</b> to <b>1603</b> shown in <figref idrefs="DRAWINGS">FIG. 16</figref>. This results in a non-ordered palette predictor <b>1703</b>. In addition, during the classification <b>1702</b>, the occurrences <b>1704</b> of each class are counted.</div>
</li> <li> <para-num num="[0279]"> </para-num> <div class="description-line" id="p-0276" num="0279">Based on the non-ordered palette predictor <b>1703</b> and the occurrences <b>1704</b>, the palette predictor <b>1706</b> with ordered entries is built at step <b>1705</b>, for example having the most frequent entries first. Note that the entries having insignificant occurrences (for example below a threshold) may be discarded from the palette predictor.</div>
</li> <li> <para-num num="[0280]"> </para-num> <div class="description-line" id="p-0277" num="0280">In an embodiment, two pixels of the same class have exactly the same pixel value (the criterion used for classification thus does not involve absolute value and requires a threshold TH set to zero). Note that in the images targeted by HEVC RExt (and thus by the Palette mode) which include text or screenshots, there are few different values in contiguous coding units. Classifying the pixels based on an identity of pixel values is thus relevant.</div>
</li> <li> <para-num num="[0281]"> </para-num> <div class="description-line" id="p-0278" num="0281"> <figref idrefs="DRAWINGS">FIG. 18</figref> illustrates an example of classification. <b>1801</b> show the current coding unit with contiguous pixels which have either a first pixel value (represented by class ‘1’), or a second pixel value (represented by class ‘2’) or a third pixel value (represented by class ‘3’). The set of neighboring pixels is represented with its related classes in table <b>1802</b>. Table <b>1802</b> gives the occurrences associated with each class. The palette predictor that is built from table <b>1802</b> is shown in table <b>1803</b>, by ordering the classes according to their occurrences and removing non-significant predictor entries (here entry corresponding to class “1” due to its low number of occurrences, namely 2 in the example). To remove a predictor entry, the algorithm can take into account the number of neighbouring pixels, the number of classes and/or the occurrences of the most probable neighbouring pixels.</div>
</li> <li> <para-num num="[0282]"> </para-num> <div class="description-line" id="p-0279" num="0282">According to yet other embodiments to obtain the palette predictor, the current palette has ordered entries, and predicting the current palette using the palette predictor comprises predicting an entry of the current palette from a preceding entry of the same current palette. In other words, the palette predictor when processing a given entry of the palette is made of (includes) the entries that are prior to the given entry in the colour palette currently being built. The current palette is thus intra predicted.</div>
</li> <li> <para-num num="[0283]"> </para-num> <div class="description-line" id="p-0280" num="0283">This is illustrated by <figref idrefs="DRAWINGS">FIG. 22</figref> which shows the decoding process to obtain the predicted palette based on signaling in the bitstream when appropriate. <figref idrefs="DRAWINGS">FIG. 22</figref> only reproduces the part corresponding to the top left part of <figref idrefs="DRAWINGS">FIG. 10</figref>, i.e. the generation of the predicted palette. The remainder of <figref idrefs="DRAWINGS">FIG. 10</figref> thus has to be performed to obtain the syntax elements defining the block predictor <b>91</b>.</div>
</li> <li> <para-num num="[0284]"> </para-num> <div class="description-line" id="p-0281" num="0284">As shown, the Palette_size is decoded and computed at steps <b>2201</b> and <b>2202</b>. Next, the first palette element is decoded. As the palette is intra predicted, the first palette element is not predicted and thus is directly decoded from the bitstream. Then the variable i provided to successively consider each palette entry is set equal to 1 at step <b>2204</b>. The other palette elements are decoded through the next steps. In particular, for each palette element, a flag, namely Use_Pred, is decoded at step <b>2206</b> to determine whether or not (test <b>2207</b>) the palette element at index i uses intra prediction or not. If it does not use Intra prediction, the palette element is decoded directly from the bitstream at step <b>2208</b>. Otherwise, index j corresponding to the index of the palette element predictor in the current palette is decoded from the bitstream at step <b>2210</b>. Note that the encoder may have coded index j relatively to index i in order to save bits, in which case the decoder operates in the reverse way. Then the residual is decoded at step <b>2211</b> and the palette element Pal[i] is set equal to Res[i]+Pal[j] and added to the palette at step <b>2212</b>. Then the index i is incremented by one at step <b>2209</b> to consider the next palette element. Once all the palette elements have been decoded (test <b>2205</b>), the process continues at step <b>1008</b> of <figref idrefs="DRAWINGS">FIG. 10</figref>.</div>
</li> <li> <para-num num="[0285]"> </para-num> <div class="description-line" id="p-0282" num="0285">In one embodiment, the element predictor of the palette element i is the palette element i−1, i.e. the palette entry directly preceding the current palette element in the current palette. In such case, module <b>2210</b> can be omitted, and the palette element Pal[i] is set equal to Res[i]+Pal[i−1] when it is predicted. In one embodiment, all the palette entries, except the first one, are predicted from the palette element directly preceding them in the current palette. In such case, the Use_pred flag may be omitted since the decoder knows how to obtain/decode the palette elements using intra prediction. This means that modules <b>2206</b> and <b>2208</b> can be omitted.</div>
</li> <li> <para-num num="[0286]"> </para-num> <div class="description-line" id="p-0283" num="0286">To improve the coding efficiency of the intra prediction of the palette element, the palette element may be ordered according to their values and not to their occurrences at the encoder.</div>
</li> <li> <para-num num="[0287]"> </para-num> <div class="description-line" id="p-0284" num="0287">According to yet other embodiments, the current palette is predicted from entries of two or more palettes. This means that a palette predictor could be built from two or more palettes. In particular, the two or more palettes may be partly or entirely merged to form a new palette predictor for the current palette.</div>
</li> <li> <para-num num="[0288]"> </para-num> <div class="description-line" id="p-0285" num="0288">This is because the prediction mechanisms as introduced above may rely on a single palette selected, as palette predictor, from e.g. a set of palettes used to predict previously processed blocks of pixels. This may impact the quality of the palette predictor. For example, if among successive blocks of pixels B<b>1</b>, B<b>2</b> and B<b>3</b>, blocks B<b>1</b> and B<b>3</b> are each made of a lot of different pixels but B<b>2</b> is made of few different pixels, the fact of using the directly previous palette as a palette predictor for the next palette leads to using the palette of B<b>2</b> (which has few palette elements) as a palette predictor for B<b>3</b>. But this would drastically reduce the number of elements in the palette predictor for B<b>3</b> and thus the ability to efficiently predict the palette for B<b>3</b>.</div>
</li> <li> <para-num num="[0289]"> </para-num> <div class="description-line" id="p-0286" num="0289">The inventors have found it is worth combining two or more palettes to build a new palette to process a new block of pixels.</div>
</li> <li> <para-num num="[0290]"> </para-num> <div class="description-line" id="p-0287" num="0290"> <figref idrefs="DRAWINGS">FIG. 24</figref> is a flowchart illustrating general steps for building a palette predictor from two or more palettes already existing. The existing palettes may include all or part of the current palette, last palette predictors (including reference palette predictors), spatially or temporally neighboring palettes, and a by-default palette (e.g. containing by-default palette elements such as the one whose components are all 0).</div>
</li> <li> <para-num num="[0291]"> </para-num> <div class="description-line" id="p-0288" num="0291">In the process of <figref idrefs="DRAWINGS">FIG. 24</figref>, P represents the number of already existing palettes taken into account; pal<sub>0</sub>, . . . pal<sub>P−1 </sub>are the corresponding palettes; “pred” is the palette predictor as formed by the process, with N<sub>MAX </sub>its maximum number of palette elements; J<sub>k</sub>, k∈[0;P[ is the number of elements in palette pal<sub>k</sub>; “i” is a variable representing a palette counter to successively consider each of the P palettes pal<sub>0</sub>, . . . , pal<sub>P−1</sub>; “n” is a variable representing the current number of palette elements in the palette predictor “pred” being built; and “j” is a variable representing a palette element counter to successively consider each palette element of the current palette pal<sub>i</sub>.</div>
</li> <li> <para-num num="[0292]"> </para-num> <div class="description-line" id="p-0289" num="0292">The palettes pal<sub>0</sub>, . . . , pal<sub>P−1 </sub>may be ordered for example to first process the most recent palettes, e.g. with low indexes. This is to add more recent elements as close as possible to the beginning in the palette predictor.</div>
</li> <li> <para-num num="[0293]"> </para-num> <div class="description-line" id="p-0290" num="0293">The process starts at step <b>2400</b> by initializing the first palette to consider (“i”=0) and the current predictor element in the palette predictor “pred” to be built (“n”=0). The process then enters the loops to successively consider each palette pal<sub>i</sub>.</div>
</li> <li> <para-num num="[0294]"> </para-num> <div class="description-line" id="p-0291" num="0294">At step <b>2401</b>, the palette element counter “j” is initialized at 0 to consider the first palette element of the current palette pal<sub>i</sub>.</div>
</li> <li> <para-num num="[0295]"> </para-num> <div class="description-line" id="p-0292" num="0295">At step <b>2402</b>, it is checked whether or not the current palette element pal<sub>i</sub>[j] of the current palette pal, satisfies a particular criterion to trigger or not addition of this palette element to the palette predictor “pred”.</div>
</li> <li> <para-num num="[0296]"> </para-num> <div class="description-line" id="p-0293" num="0296">The triggering criterion may simply rely on comparing pal<sub>i</sub>[j] to the elements already added in the palette predictor “pred” (i.e. pred[0]. . . pred[n−1]) to decide the addition of the current palette element to “pred” if pal<sub>i</sub>[j] is different from pred[0]. . . pred[n−1, ]and to decide not to add the current palette element to “pred” if pal<sub>i</sub>[j] is the same as one element of “pred”. Note that the comparison between two elements pal<sub>i</sub>[j] and pred[k] may be a strict comparison or strict similarity (strict equality between their components) or a loosen comparison/similarity (the differences between corresponding components of the elements are below respective thresholds). In a variant, only a specific amount of the n elements pred[k] may be involved in the comparison, the exact amount depending on the value of “n”. This is because the number of comparisons may quickly increase. This, using for example n/2 or at most 4 elements involved in the comparison may be a good trade-off between coding efficiency and complexity.</div>
</li> <li> <para-num num="[0297]"> </para-num> <div class="description-line" id="p-0294" num="0297">However other triggering criteria may be involved such as a bitmap of Use_pred flags as described below with reference to <figref idrefs="DRAWINGS">FIGS. 19 to 21</figref>. These Use_pred flags are generated by an encoder to signal which values can be reused as a value in the current palette, e.g. by comparing one by one each of the palette entries with the palette predictor entries. In particular, this approach advantageously makes it possible not to transmit explicitly or not to duplicate palette elements. The number of flags depends on the sizes of the palette predictor and how the elements are signaled.</div>
</li> <li> <para-num num="[0298]"> </para-num> <div class="description-line" id="p-0295" num="0298">The outcome of step <b>2402</b> is that a decision is taken as to add or not the current palette element pal<sub>i</sub>[j] to the palette predictor “pred”.</div>
</li> <li> <para-num num="[0299]"> </para-num> <div class="description-line" id="p-0296" num="0299">If decision is taken not to add it, the process goes to step <b>2405</b>. If decision is taken to add it, the process goes to step <b>2403</b> where the current predictor element pred[n] is set to the current palette element pal<sub>i</sub>[j]. The next predictor element in “pred” is next selected by incrementing “n”.</div>
</li> <li> <para-num num="[0300]"> </para-num> <div class="description-line" id="p-0297" num="0300">Next, step <b>2404</b> consists in checking whether or not a maximum number of predictor elements of “pred” have been determined. If they have not been, the process goes to step <b>2405</b>. Otherwise, the palette predictor “pred” is fully determined and the process ends at step <b>2409</b>.</div>
</li> <li> <para-num num="[0301]"> </para-num> <div class="description-line" id="p-0298" num="0301">At step <b>2405</b>, the next element in the current palette pal, is selected by incrementing the palette element counter “j”.</div>
</li> <li> <para-num num="[0302]"> </para-num> <div class="description-line" id="p-0299" num="0302">At step <b>2406</b>, it is checked whether or not all the palette elements of the current palette pal, have been considered and processed: j&lt;J<sub>i</sub>. If not, the process loops back to step <b>2402</b> to process the next palette element pal<sub>i</sub>[j]. If the whole current palette pal, has been processed, the process goes to step <b>2407</b>, where the palette counter “i” is incremented to consider the next palette, if all the palettes pal<sub>0</sub>, . . . pal<sub>P−1 </sub>have not yet been processed (check at step <b>2408</b>).</div>
</li> <li> <para-num num="[0303]"> </para-num> <div class="description-line" id="p-0300" num="0303">If all the palettes pal<sub>0</sub>, . . . , pal<sub>P−1 </sub>have been processed, the process ends at step <b>2409</b>.</div>
</li> <li> <para-num num="[0304]"> </para-num> <div class="description-line" id="p-0301" num="0304">Note that the above various embodiments to obtain the palette predictor may be partly or all combined to provide several basis for predicting all or some of the palette elements.</div>
</li> <li> <para-num num="[0305]"> </para-num> <div class="description-line" id="p-0302" num="0305">Turning now to the the syntax elements to actually describe the palette prediction to the decoder, reference is now made to <figref idrefs="DRAWINGS">FIGS. 19 to 21</figref>, although <figref idrefs="DRAWINGS">FIG. 22</figref> described above already introduces a mechanism to define the palette prediction. The palette predictor is considered to be retrieved and its size (Predictor_of_palette_size) is known.</div>
</li> <li> <para-num num="[0306]"> </para-num> <div class="description-line" id="p-0303" num="0306">According to embodiments concerning the syntax elements, predicting the current palette using the palette predictor comprises obtaining a bitmap of flags, each of which defining whether or not a corresponding entry in the palette predictor is selected as an entry of the current palette. As a result, in addition to information making it possible for the decoder to retrieve the appropriate palette predictor, only the bitmap needs to be sent to the decoder. This bitmap may be sent in replacement of the palette as defined in HEVC RExt for the current coding unit.</div>
</li> <li> <para-num num="[0307]"> </para-num> <div class="description-line" id="p-0304" num="0307">The syntax of the bitmap contains M flags, M being equal to the number of elements in the palette predictor. The i<sup>th </sup>decoded flag defines whether or not the element i from the palette predictor is used to fill (predict) the current palette for the current coding unit. In a variant, the bitmap may be restricted to a lower number of flags from a flag corresponding to the first element in the palette predictor to a flag corresponding to the last element that has to be used as an element predictor. The size of the bitmap is specified in the bitstream in a similar fashion to that in which the palette size is specified in HEVC RExt bitstream.</div>
</li> <li> <para-num num="[0308]"> </para-num> <div class="description-line" id="p-0305" num="0308">For example, the elements of the palette predictor that are associated with a flag (bit) equal to 1 are copied in the current palette at the first available position, keeping their order.</div>
</li> <li> <para-num num="[0309]"> </para-num> <div class="description-line" id="p-0306" num="0309">In another embodiment, additional entries are added at the end of the current palette having the selected entries from the palette predictor. For example, first the bitmap is decoded from the bitstream and the corresponding entries of the palette predictor are copied into the current palette, then additional pixels may be added at the end of the current palette in the same way as the conventional palette transmission.</div>
</li> <li> <para-num num="[0310]"> </para-num> <div class="description-line" id="p-0307" num="0310">In one embodiment seeking to provide the predicted palette element as additional palette element, the determining of the Palette_size is adapted to be increased by the number of predicted palette elements: to do so, the Palette_size is set equal to the decoded size+the number of flags set equal to 1 in the bitmap (Palette_pred_enable_size). If Palette_pred_enabled_size is equal to 0, the Palette_size is set equal to the decoded size+1 as described in step <b>1003</b>.</div>
</li> <li> <para-num num="[0311]"> </para-num> <div class="description-line" id="p-0308" num="0311"> <figref idrefs="DRAWINGS">FIG. 19</figref> illustrates the decoding of the palette syntax of these embodiments based on the bitmap of flags. As for <figref idrefs="DRAWINGS">FIG. 22</figref>, <figref idrefs="DRAWINGS">FIG. 19</figref> is based on <figref idrefs="DRAWINGS">FIG. 10</figref> but only the part relating to the palette decoding is shown.</div>
</li> <li> <para-num num="[0312]"> </para-num> <div class="description-line" id="p-0309" num="0312">First, the palette predictor <b>1902</b> is obtained at step <b>1901</b> according to any of the embodiments described above. In addition, the Predictor_of_palette_size <b>1903</b> is also obtained. Module <b>1905</b> decodes N flags from the bitstream <b>1904</b>, where N=Predictor_of_palette_size.</div>
</li> <li> <para-num num="[0313]"> </para-num> <div class="description-line" id="p-0310" num="0313">For each flag equal to 1, the corresponding element from the palette predictor is added to the current palette <b>1907</b> at the first available index, during step <b>1906</b>. Palette_pred_enabled_size <b>1908</b> representing the number of flags equal to 1 in the bitmap is transmitted to decision module <b>1910</b>. The size of the remainder of the palette is also decoded from the bitstream <b>1909</b>. Decision module <b>1910</b> determines whether or not Palette_pred_enabled_size is equal to 0. If it is equal to 0 meaning that there is no predicted palette element in the current palette, the Palette_size is set equal to the decoded Size+1 at step <b>1911</b>, and the variable i used to successively consider each entry of the current palette is set equal to 0 at step <b>1912</b>. If Palette_pred_enabled_size is different from 0 meaning that there is at least one predicted palette element in the current palette, the Palette_size is set equal to the decoded Size+Palette_pred_enabled_size at step <b>1913</b>, and the variable i is set equal to Palette_pred_enabled_size. Next, the decoding loop of palette elements is performed through steps <b>1915</b>, <b>1916</b> and <b>1917</b> corresponding to steps <b>1005</b>, <b>1006</b> and <b>1007</b> of <figref idrefs="DRAWINGS">FIG. 10</figref>. This loop stops when the variable i is equal to the Palette_size. The decoded Palette elements <b>1916</b> are added at the end of the current Palette <b>1907</b>, i.e. after the predicted palette elements. In one embodiment, Palette_size is always set equal to the decoded Size+Palette_pred_enabled_size at step <b>1913</b> to simplify the implementation so that modules <b>1910</b>, <b>1911</b> and <b>1912</b> can be omitted.</div>
</li> <li> <para-num num="[0314]"> </para-num> <div class="description-line" id="p-0311" num="0314">Note that the values “0” and “1” for the flags may be inverted, meaning that flag=1 is used when the corresponding element in the palette predictor is not used to predict an element of the palette under construction (the reverse for flag=0).</div>
</li> <li> <para-num num="[0315]"> </para-num> <div class="description-line" id="p-0312" num="0315">This inversion of the meaning of the values of the flags is useful to prevent a phenomenon called “start code emulation”: if a series of bytes matches what is called a start code, the series must be transformed to make it no longer matching the start code and to have a unique start code, through an expansion process increasing the size of the bitstream. By using 1 instead of 0, this size increase is avoided.</div>
</li> <li> <para-num num="[0316]"> </para-num> <div class="description-line" id="p-0313" num="0316"> <figref idrefs="DRAWINGS">FIG. 20</figref> illustrates the process of <figref idrefs="DRAWINGS">FIG. 19</figref> with an example. The palette predictor obtained using any of the embodiments described above with reference to <figref idrefs="DRAWINGS">FIGS. 14 to 18</figref> is table <b>2001</b> which contains five elements associating an index or level with colour values. The decoded flags of the bitmap are represented in table <b>2002</b>. In this example, two flags are set equal to 1: one for level 0 and one for level 2 of the palette predictor. The corresponding palette elements are thus added to the current palette <b>2003</b> with the first level available, respectively level 0 and level 1. Then new palette entries may be decoded from the bitstream as proposed in HEVC RExt and added to the position <b>2</b> and <b>3</b>.</div>
</li> <li> <para-num num="[0317]"> </para-num> <div class="description-line" id="p-0314" num="0317">One may note that when the palette predictor is transmitted, only the flags (bitmap) corresponding to the palette predictors is needed. To reduce signaling, the same bitmap may be used for all the coding units belonging to the same CTB, slice, tile, slice segment, frame or sequence for which a single reference palette predictor is transmitted.</div>
</li> <li> <para-num num="[0318]"> </para-num> <div class="description-line" id="p-0315" num="0318">The bitmap of Use_pred flags has been defined in the above description referring to <figref idrefs="DRAWINGS">FIGS. 19 and 20</figref>. Reference is now made back to <figref idrefs="DRAWINGS">FIG. 24</figref>, and more specifically to step <b>2402</b>, where a triggering criterion to authorize addition of a current palette element pal<sub>i</sub>[j] to the palette predictor “pred” under construction is used. As introduced above, this triggering criterion may involve the bitmap of Use_pred flags.</div>
</li> <li> <para-num num="[0319]"> </para-num> <div class="description-line" id="p-0316" num="0319">In some embodiments, the palette predictor under construction includes entries from a first palette which has been predicted based on a second palette (used as predictor) using a bitmap of flags as described above, each flag of which defining whether or not a corresponding entry in the second palette is selected as an entry to predict an entry in the first palette. Particular to this embodiment is that the palette predictor is built by also including the entries of the second palette corresponding to a flag of the bitmap that defines no selection of the entry to predict the first palette.</div>
</li> <li> <para-num num="[0320]"> </para-num> <div class="description-line" id="p-0317" num="0320"> <figref idrefs="DRAWINGS">FIG. 25</figref> illustrates an exemplary implementation of such approach.</div>
</li> <li> <para-num num="[0321]"> </para-num> <div class="description-line" id="p-0318" num="0321">Three Coding Units, CU<b>1</b> to CU<b>3</b>, are shown that may be consecutive coding units being processed in a current image.</div>
</li> <li> <para-num num="[0322]"> </para-num> <div class="description-line" id="p-0319" num="0322">Reference <b>2500</b> represents the palette used to process (encode or decode) CU<b>1</b>. This palette may have been encoded in the bitstream (and thus retrieved by the decoder) or predicted using any mechanism described in the present application.</div>
</li> <li> <para-num num="[0323]"> </para-num> <div class="description-line" id="p-0320" num="0323">Using the predictor generation mechanism based on the last used palette as described above, this palette <b>2500</b> is used as a palette predictor for building the palette <b>2501</b> to process CU<b>2</b>. The prediction of palette <b>2501</b> is based on bitmap <b>2506</b> of Use_pred flags as described above. It is to be recalled that the flags take the value 1 or 0 depending of the use or not, respectively, of the corresponding element for predicting the palette of a next CU. In a variant, flag=1 may mean not selecting the corresponding element, while flag=0 may mean selecting the element for predicting the palette of the next CU.</div>
</li> <li> <para-num num="[0324]"> </para-num> <div class="description-line" id="p-0321" num="0324">As a result, in the present example, the first, third, fourth and fifth elements of palette predictor <b>2500</b> are copied into palette <b>2501</b> as defined in the bitmap <b>2506</b>. The second element <b>2502</b> is not reused (flag=0 in bitmap <b>2506</b>). Note that an additional palette element <b>2503</b> may have been added to the end of palette <b>2501</b> being built, based on the mechanisms described above (e.g. explicitly transmitted in the bitstream).</div>
</li> <li> <para-num num="[0325]"> </para-num> <div class="description-line" id="p-0322" num="0325">Also, palette <b>2501</b> is used as a palette predictor to build the palette to process CU<b>3</b>. In the example of the Figure, all the elements of palette <b>2501</b> are copied (step <b>2504</b>) into the palette for CU<b>3</b>. In a variant to this example, a bitmap (not shown) may be provided to identify which elements of palette <b>2501</b> should be copied into the palette for</div>
</li> <li> <para-num num="[0326]"> </para-num> <div class="description-line" id="p-0323" num="0326">CU<b>3</b>, similarly to the bitmap <b>2506</b> defining the elements to be copied into palette <b>2501</b>.</div>
</li> <li> <para-num num="[0327]"> </para-num> <div class="description-line" id="p-0324" num="0327">Specific to this embodiment of the invention, palette predictor <b>2500</b> is also used as a predictor for building the palette to process CU<b>3</b>.</div>
</li> <li> <para-num num="[0328]"> </para-num> <div class="description-line" id="p-0325" num="0328">To achieve such building, a palette predictor <b>2505</b> is built from palettes <b>2500</b> and <b>2501</b>. As mentioned above, all the elements of palette <b>2501</b> are copied (step <b>2504</b>) into palette predictor <b>2505</b>. In this example, the entries of palette predictor <b>2500</b> corresponding to a flag of the bitmap that defines no selection of the entry to predict palette <b>2501</b> (i.e. usually with flag=0, for example element <b>2502</b>), are added (step <b>2508</b>) to palette predictor <b>2505</b>. This is because the other entries of palette predictor <b>2500</b> are already in palette predictor <b>2505</b> thanks to the copying step <b>2504</b>. This selection of element <b>2502</b> can be performed very quickly thanks to the flags in bitmap <b>2506</b>.</div>
</li> <li> <para-num num="[0329]"> </para-num> <div class="description-line" id="p-0326" num="0329">A bitmap may be provided to predict, based on palette predictor <b>2505</b>, the palette to process CU<b>3</b>.</div>
</li> <li> <para-num num="[0330]"> </para-num> <div class="description-line" id="p-0327" num="0330">Of course, palette predictor <b>2505</b> may also be directly the palette to process CU<b>3</b>. However, palette predictor <b>2505</b> continuously grows as it includes all the elements defined in previous palettes. It grows up to a limit from which the elements of the palette predictor no longer fitting in it are not added to the predictor in spite of the value of their Use_pred flag.</div>
</li> <li> <para-num num="[0331]"> </para-num> <div class="description-line" id="p-0328" num="0331">The addition of element <b>2502</b> is preferably performed at the end of palette predictor <b>2505</b>. One may directly observe that the resulting palette predictor is enriched compared to situations described above.</div>
</li> <li> <para-num num="[0332]"> </para-num> <div class="description-line" id="p-0329" num="0332">One particular advantage of adding the unused elements at the end of the palette predictor is that the elements are approximately ordered by their age and their level of use. This results in having the last elements in the palette predictor that are the least useful ones and the most likely to be removed. A decision can thus be taken to remove some elements from the palette predictor under construction, for example based on the number of uses of this element when processing to the last M (M integer to be defined) blocks of pixels using respective palettes that include this element.</div>
</li> <li> <para-num num="[0333]"> </para-num> <div class="description-line" id="p-0330" num="0333">Of course, this process can be adapted so as to put unused elements first in the palette predictor, or even interleaved with some of the elements from palette <b>2401</b>.</div>
</li> <li> <para-num num="[0334]"> </para-num> <div class="description-line" id="p-0331" num="0334">Note that the selection of unused elements from a previous palette guarantees that the elements are unique, and therefore the Use_pred flags are not redundant. The palette predictor efficiency is thus maximized.</div>
</li> <li> <para-num num="[0335]"> </para-num> <div class="description-line" id="p-0332" num="0335">The above approach of the invention involving the building of a palette predictor from two or more palettes only impacts the palette predictor building step <b>1901</b> of <figref idrefs="DRAWINGS">FIG. 19</figref>.</div>
</li> <li> <para-num num="[0336]"> </para-num> <div class="description-line" id="p-0333" num="0336"> <figref idrefs="DRAWINGS">FIG. 26</figref> illustrates an embodiment of step <b>1901</b> to build a palette predictor, such as predictor <b>2505</b>, with the above approach, which embodiment is more specific than the general steps described above with reference to <figref idrefs="DRAWINGS">FIG. 24</figref>. Such palette predictor <b>2505</b> is used to build the palette to process CU<b>3</b>, based on Use_pred flags of a corresponding bitmap (not shown).</div>
</li> <li> <para-num num="[0337]"> </para-num> <div class="description-line" id="p-0334" num="0337">To sum up this process with reference to the example of <figref idrefs="DRAWINGS">FIG. 25</figref>, it consists in copying the elements of CU<b>2</b> palette <b>2501</b> represented by an array “pal” into an array of predictor elements “pred” (step <b>2504</b>). “pred” is a temporary buffer used to copy the elements from the palette array “pal”. At the end of the process, “pred” is the palette predictor.</div>
</li> <li> <para-num num="[0338]"> </para-num> <div class="description-line" id="p-0335" num="0338">In addition, the possible stuffing elements (such as <b>2502</b>) are added to “pred”, further to the already copied elements.</div>
</li> <li> <para-num num="[0339]"> </para-num> <div class="description-line" id="p-0336" num="0339">Structure “pred” contains a maximum of N<sub>MAX </sub>elements. N<sub>MAX </sub>ideally can be bigger than the maximum number of elements in a palette. A good compromise between coding efficiency and memory has been found with N<sub>MAX</sub>=64, i.e. twice the maximum size of a palette in the example.</div>
</li> <li> <para-num num="[0340]"> </para-num> <div class="description-line" id="p-0337" num="0340">“pal” is a structure containing N<sub>cur </sub>elements, dedicated to storing the last palette used, i.e. palette <b>2501</b> in the example of <figref idrefs="DRAWINGS">FIG. 25</figref>.</div>
</li> <li> <para-num num="[0341]"> </para-num> <div class="description-line" id="p-0338" num="0341">“last” is a structure containing N<sub>last </sub>elements, dedicated to storing a previous palette or predictor, for example the palette predictor of the last used palette, i.e. palette predictor <b>2500</b> in the example of <figref idrefs="DRAWINGS">FIG. 25</figref>. Corresponding Use-pred flags are also stored in memory, for example in a so-called “Use_pred” array.</div>
</li> <li> <para-num num="[0342]"> </para-num> <div class="description-line" id="p-0339" num="0342">Note that “pal” is the last palette used while “last” is the palette predictor of this last palette used.</div>
</li> <li> <para-num num="[0343]"> </para-num> <div class="description-line" id="p-0340" num="0343">Step <b>2600</b> initializes the copy of “pal” into “pred”: the first element of each structure is selected by setting the loop counter “i” to 0. Then the copy loop starts at step <b>2601</b>: the current element of “pred” is set equal to the one of “pred”. Then step <b>2602</b> makes it possible to select the next element of “pal” by incrementing the loop counter “i”.</div>
</li> <li> <para-num num="[0344]"> </para-num> <div class="description-line" id="p-0341" num="0344">Step <b>2603</b> then checks whether or not the last element of either the palette predictor under construction “pred” or the palette “pal” has been reached (given N<sub>MAX </sub>for “pred” and N<sub>cur </sub>for “pal”).</div>
</li> <li> <para-num num="[0345]"> </para-num> <div class="description-line" id="p-0342" num="0345">If the last element has not been reached, the process loops back to step <b>2601</b> to copy the next element. Otherwise, the process goes to step <b>2604</b>.</div>
</li> <li> <para-num num="[0346]"> </para-num> <div class="description-line" id="p-0343" num="0346">The contribution of the other palette, here previous palette <b>2500</b>, to the building of the palette predictor <b>2505</b> according to this embodiment of the invention results from the following steps <b>2604</b> to <b>2608</b>.</div>
</li> <li> <para-num num="[0347]"> </para-num> <div class="description-line" id="p-0344" num="0347">These steps allow the stuffing operation referenced <b>2508</b> in <figref idrefs="DRAWINGS">FIG. 25</figref>. They provide additional elements to “pred” in addition to the elements resulting from the copy of the preceding palette “pal”.</div>
</li> <li> <para-num num="[0348]"> </para-num> <div class="description-line" id="p-0345" num="0348">Step <b>2604</b> selects the first element of the previous palette “last” by initializing the loop counter “j” to 0.</div>
</li> <li> <para-num num="[0349]"> </para-num> <div class="description-line" id="p-0346" num="0349">Step <b>2605</b> then occurs where it is checked whether or not the last element of either “pred” or “last” has been reached.</div>
</li> <li> <para-num num="[0350]"> </para-num> <div class="description-line" id="p-0347" num="0350">If not, the process continues in step <b>2606</b>. Otherwise, the process ends at step <b>2609</b>.</div>
</li> <li> <para-num num="[0351]"> </para-num> <div class="description-line" id="p-0348" num="0351">Step <b>2606</b> consists in checking whether or not the current element “j” in “last” has already been reused. Like at step <b>2402</b> above, this may consist in checking whether the Use_pred flag associated with this element in the “Use_pred” array is set to 0 (not reused) or 1 (reused). In a variant, it may consist in verifying whether or not the current element already exists in “pred” being built.</div>
</li> <li> <para-num num="[0352]"> </para-num> <div class="description-line" id="p-0349" num="0352">If not reused, step <b>2607</b> occurs where the current element “j” is added from “last” to “pred” (at the end of “pred”). So the next element of “pred” is selected by incrementing “i”.</div>
</li> <li> <para-num num="[0353]"> </para-num> <div class="description-line" id="p-0350" num="0353">In any case, the next element in “last” is selected by incrementing “j” at step <b>2608</b>.</div>
</li> <li> <para-num num="[0354]"> </para-num> <div class="description-line" id="p-0351" num="0354">When all the elements of “last” or “pred” have been processed, the process ends at step <b>2609</b>.</div>
</li> <li> <para-num num="[0355]"> </para-num> <div class="description-line" id="p-0352" num="0355">Note that for a next iteration of the process of <figref idrefs="DRAWINGS">FIG. 26</figref>, the structure “last” may be updated to store the palette predictor of the palette used for CU<b>3</b> (which is about to be the last used palette), i.e. by receiving a copy of “pred” which stores the palette predictor <b>2505</b> for CU<b>3</b>. Note that the last used palette for the next iteration (when processing a new coding unit CU<b>4</b>) is the palette built for CU<b>3</b> from palette predictor <b>2505</b>. Therefore, this is the palette built for CU<b>3</b> which has to be stored in “pal” for the next iteration.</div>
</li> <li> <para-num num="[0356]"> </para-num> <div class="description-line" id="p-0353" num="0356">As mentioned above, this embodiment provides a way to build each new palette predictor in such a way that the size of the palette predictor tends to continuously increase. Of course, the number N<sub>MAX </sub>provides a limit to the maximum size of the palette predictor. However, N<sub>MAX </sub>is usually selected quite large, often larger than the maximum size of the palettes.</div>
</li> <li> <para-num num="[0357]"> </para-num> <div class="description-line" id="p-0354" num="0357">It is to be recalled that a bitmap of Use_pred flags has to be provided to the client device to perform prediction of the new palette from the newly constructed palette predictor. The larger the value of N<sub>MAX</sub>, the greater the number of extraneous Use_pred flags in the bitmap. This has a cost in transmission because each flag costs at least one bit.</div>
</li> <li> <para-num num="[0358]"> </para-num> <div class="description-line" id="p-0355" num="0358">A way to mitigate these extraneous costs, without additional techniques, is to compute N<sub>MAX </sub>as a combination of N<sub>cur </sub>and N<sub>last</sub>. For example, N<sub>MAX </sub>may be defined as fact*N<sub>last</sub>, where fact may depend on the color format and the component(s) affected. For instance, fact=6 for 4:4:4 color format, while fact=1 for luma and fact=2 for chroma in other formats.</div>
</li> <li> <para-num num="[0359]"> </para-num> <div class="description-line" id="p-0356" num="0359">However, this approach has been found not to be the optimal solution, in particular in the case of the embodiment of <figref idrefs="DRAWINGS">FIG. 26</figref> where an optimal N<sub>MAX </sub>has been determined to be about 64.</div>
</li> <li> <para-num num="[0360]"> </para-num> <div class="description-line" id="p-0357" num="0360">An embodiment as proposed in <figref idrefs="DRAWINGS">FIG. 27</figref> below provides a modified syntax for the bitmaps to decrease their size. In particular, the bitmap of flags includes at least one element at a predefined position in the bitmap for signalling whether or not the bitmap includes, after the predefined position, at least one additional flag that defines selection of an entry of the a palette predictor to predict another palette.</div>
</li> <li> <para-num num="[0361]"> </para-num> <div class="description-line" id="p-0358" num="0361"> <figref idrefs="DRAWINGS">FIG. 27</figref> illustrates a modified syntax for the Use_pred flags associated with a palette predictor (e.g. predictor <b>2505</b>) to predict a palette (e.g. the palette to process CU<b>3</b>). Note that the modified syntax may be used for any bitmap.</div>
</li> <li> <para-num num="[0362]"> </para-num> <div class="description-line" id="p-0359" num="0362">A bitmap as described above (i.e. without the modified syntax) is shown at the top of <figref idrefs="DRAWINGS">FIG. 27</figref>. It usually includes two parts:</div>
</li> <li> <para-num num="[0363]"> </para-num> <div class="description-line" id="p-0360" num="0363">part referenced <b>2700</b> which intermingles flags set to “0” and flags set to “1”. Part <b>2700</b> ends with the last flag set to “1”. This part defines all the elements of the palette predictor that are used in the predicted palette; and</div>
</li> <li> <para-num num="[0364]"> </para-num> <div class="description-line" id="p-0361" num="0364">part referenced <b>2701</b> which is the remaining part of the bitmap, exclusively made of flags set to “0” and thus corresponding to elements not reused. Note that it is usual that the last part of the bitmap is made exclusively of “0”s since the corresponding elements are usually the old and less used ones.</div>
</li> <li> <para-num num="[0365]"> </para-num> <div class="description-line" id="p-0362" num="0365">Note that this split into two parts is provided here only for illustrative purposes. The bitmap <b>2700</b>+<b>2701</b> is provided if the modified syntax according to the invention is not implemented.</div>
</li> <li> <para-num num="[0366]"> </para-num> <div class="description-line" id="p-0363" num="0366">Below this bitmap, the bitmap with the modified syntax is shown. One may note that its size is drastically reduced.</div>
</li> <li> <para-num num="[0367]"> </para-num> <div class="description-line" id="p-0364" num="0367">The modified syntax exploits the existence of consecutive “0” flags <b>2702</b> by inserting additional elements or bits at specific locations in the series of Use_pred flags.</div>
</li> <li> <para-num num="[0368]"> </para-num> <div class="description-line" id="p-0365" num="0368">As an illustration, bits <b>2703</b> and <b>2704</b> have been added to indicate whether or not there are other Use_pred flags set to “1” afterwards in the bitmap.</div>
</li> <li> <para-num num="[0369]"> </para-num> <div class="description-line" id="p-0366" num="0369">These additional bits are designated “end-of-prediction” flags and they do not provide indication as to whether or not a corresponding entry in the palette predictor is selected as an entry to predict an entry in the palette currently under construction. On the contrary, these additional flags shift the Use_pred flags to the right.</div>
</li> <li> <para-num num="[0370]"> </para-num> <div class="description-line" id="p-0367" num="0370">As an example, the “end-of-prediction” flags may take the value “0” to indicate that there are other flags equal to 1 in the remaining part of the bitmap, while they may take the value “1” when there are no other flags equal to 1 in the remaining of the bitmap.</div>
</li> <li> <para-num num="[0371]"> </para-num> <div class="description-line" id="p-0368" num="0371">Regarding the example of <b>2703</b> and <b>2704</b>, the value “0” of flag <b>2703</b> indicates that there are remaining elements to predict using the bitmap, as evidenced by the flags being set to 1 in the subpart <b>2705</b>, while flag <b>2704</b> is set to 1, because there is no longer any element predicted (all the other Use_pred flags are set to 0). As a consequence, while flags <b>2703</b> and <b>2704</b> were added, subpart <b>2701</b> could be entirely skipped, although only subpart <b>2702</b> is skipped in the example, thus reducing costs of transmission.</div>
</li> <li> <para-num num="[0372]"> </para-num> <div class="description-line" id="p-0369" num="0372">The locations for the additional “end-of-prediction” flags are preferably predefined depending on the properties of the palette mode. However, they should be selected taking into account what follows:</div>
</li> <li> <para-num num="[0373]"> </para-num> <div class="description-line" id="p-0370" num="0373">it is worth having an end-of-prediction flag early to avoid sending too many Use_pred flags for small palettes; and</div>
</li> <li> <para-num num="[0374]"> </para-num> <div class="description-line" id="p-0371" num="0374">it is worth having end-of-prediction flags at periodic intervals, ideally powers of 2, to parse the bitmap easily.</div>
</li> <li> <para-num num="[0375]"> </para-num> <div class="description-line" id="p-0372" num="0375">Taking this into account, an embodiment provides predefined positions for the end-of-prediction flags after the 4<sup>th </sup>Use_pred flag location, and then every eight Use_pred flags starting after the 16<sup>th </sup>Use_pred flag, then after the 24<sup>th </sup>Use_pred flag and so on.</div>
</li> <li> <para-num num="[0376]"> </para-num> <div class="description-line" id="p-0373" num="0376">The bottom of <figref idrefs="DRAWINGS">FIG. 27</figref> is a flowchart illustrating steps for decoding the modified syntax of a bitmap.</div>
</li> <li> <para-num num="[0377]"> </para-num> <div class="description-line" id="p-0374" num="0377">The steps <b>2715</b> to <b>2717</b> of the process are specific to the modified syntax. Step <b>2710</b> initializes the decoding loop by setting the loop counter “i” to 0 and the number “j” of predicted elements to 0.</div>
</li> <li> <para-num num="[0378]"> </para-num> <div class="description-line" id="p-0375" num="0378">Step <b>2711</b> then checks whether or not there is any element left in the palette predictor (i&lt;N), as it may happen that the predictor is empty (N=0), and that there is no flag left to decode (a palette having a maximum number N<sub>MAX </sub>of elements).</div>
</li> <li> <para-num num="[0379]"> </para-num> <div class="description-line" id="p-0376" num="0379">If there is no further element to process, the process ends at step <b>2718</b>. Otherwise, the Use_pred flag is decoded for element i of the palette predictor at step <b>2712</b>.</div>
</li> <li> <para-num num="[0380]"> </para-num> <div class="description-line" id="p-0377" num="0380">At step <b>2713</b>, it is determined whether or not the element i is used for predicting the palette under construction. For example, a flag set to 1 means that the corresponding element i of the palette predictor is used.</div>
</li> <li> <para-num num="[0381]"> </para-num> <div class="description-line" id="p-0378" num="0381">In the affirmative, the number “j” of used elements is incremented at step <b>2714</b>.</div>
</li> <li> <para-num num="[0382]"> </para-num> <div class="description-line" id="p-0379" num="0382">In any case, the process continues with step <b>2715</b>, rather than going directly to step <b>2719</b> as it would without the modified syntax.</div>
</li> <li> <para-num num="[0383]"> </para-num> <div class="description-line" id="p-0380" num="0383">Step <b>2715</b> checks whether or not an “end-of-prediction” flag (e.g. <b>2703</b> or <b>2704</b>) is present next to the current i<sup>th </sup>Use_pred flag. For example, the check can be based on the value of “i” (e.g. whether it is 4, 16, 24, . . . as suggested above).</div>
</li> <li> <para-num num="[0384]"> </para-num> <div class="description-line" id="p-0381" num="0384">If the next flag is not an “end-of-prediction” flag, a normal process resumes by going to step <b>2719</b>.</div>
</li> <li> <para-num num="[0385]"> </para-num> <div class="description-line" id="p-0382" num="0385">Otherwise, the “end-of-prediction” flag is decoded at step <b>2716</b>. Once it has been decoded, step <b>2717</b> determines whether or not the “end-of-prediction” flag indicates the end of the prediction, i.e. if it is set to 1.</div>
</li> <li> <para-num num="[0386]"> </para-num> <div class="description-line" id="p-0383" num="0386">If the “end-of-prediction” flag does not indicate the end of the prediction, the decoding of the Use_pred flags proceeds at step <b>2719</b> by selecting the next Use_pred flag through incrementing of the loop counter “i”.</div>
</li> <li> <para-num num="[0387]"> </para-num> <div class="description-line" id="p-0384" num="0387">If the “end-of-prediction” flag indicates the end of the prediction, the process ends at <b>2718</b>.</div>
</li> <li> <para-num num="[0388]"> </para-num> <div class="description-line" id="p-0385" num="0388">The outcome of this process is that all relevant Use_pred flags have been obtained to determine which element of the palette predictor should be used for predicting the palette under construction. Note that the elements for which no Use_pred flag has been obtained must be considered as unused.</div>
</li> <li> <para-num num="[0389]"> </para-num> <div class="description-line" id="p-0386" num="0389">According to other embodiments regarding the syntax elements, predicting the current palette using the palette predictor comprises obtaining at least one (possibly two or more) entry residual corresponding to the difference between at least one corresponding entry of the current palette and an entry of the palette predictor. In these embodiments, a residual between the current palette element and the palette predictor is transmitted in the bitstream. The residual Res[i] is equal to Pal[i]-Pal_Pred[j],</div>
</li> <li> <para-num num="[0390]"> </para-num> <div class="description-line" id="p-0387" num="0390">where Res[i] is the residual for level i, Pal[i] is the current palette element for level i, and Pal_Pred[j] is the element predictor identified by level j. Note that the palette predictor j usually needs to be transmitted unless it is known by the decoder (for example because j is fixed relatively to i, for instance j=i).</div>
</li> <li> <para-num num="[0391]"> </para-num> <div class="description-line" id="p-0388" num="0391">The decoding of the residual for the three colour components is different from the decoding of the palette element. Indeed, as mentioned in the prior art, a palette element is coded with a fix length of N bits, with N=3*bit-depth. For the residual and in order to save bits, each color component residual may be coded with an adaptive code, such as a Golomb code (in the same way as the coefficients of the block residual).</div>
</li> <li> <para-num num="[0392]"> </para-num> <div class="description-line" id="p-0389" num="0392"> <figref idrefs="DRAWINGS">FIG. 21</figref> illustrates a decoding process based on having such residuals between the palette elements and element predictors. Again, this Figure only shows the part related to the palette decoding. In addition, to simplify the Figure, the bitstream has not been represented.</div>
</li> <li> <para-num num="[0393]"> </para-num> <div class="description-line" id="p-0390" num="0393">The decoded size of the palette is extracted from the bitstream at step <b>2101</b> and the Palette_size is set equal to the decoded Size+1 at step <b>2102</b>. The variable i used to successively consider each palette entry is set to 0 at step <b>2103</b>. Then the loop to decode the palette starts with test <b>2104</b> to determine whether or not all the palette entries have been processed. For the palette element i, a flag, Use_pred, is decoded from the bitstream at step <b>2105</b> to determine (test <b>2106</b>) whether or not the palette element i uses prediction or not. If the palette element i does not use prediction, it is decoded at step <b>2107</b> using conventional mechanisms and added to the palette at the level equal to i. Then the variable i is incremented by one at step <b>2108</b> to consider the next palette element. If the palette element i uses prediction, the predictor index j is decoded from the bitstream at step <b>2112</b>. Note that for coding efficiency purposes, the length of the code used to encode the predictor index j depends on Predictor_of_Palette_size <b>2110</b>. Thus, in parallel, the palette predictor <b>2110</b> is obtained as described above and Predictor_of_Palette_size <b>2011</b> is also obtained.</div>
</li> <li> <para-num num="[0394]"> </para-num> <div class="description-line" id="p-0391" num="0394">Once the predictor index j is known, the residual Res[i] of the palette element is also decoded from the bitstream at step <b>2113</b>. Then, the palette element Pal[i] is computed from the formula Res[i] +Pal_Pred[j] at step <b>2114</b> using the palette predictor Pal_Pred <b>2111</b>. The palette element Pal[i] is then added to the current palette. Next, the variable i is incremented by one at step <b>2108</b> to consider the next palette element. At the end of this process, the current palette has been decoded.</div>
</li> <li> <para-num num="[0395]"> </para-num> <div class="description-line" id="p-0392" num="0395">In one embodiment, the index j is set equal to i, in which case the predictor index j is no longer required to be transmitted to the decoder. Consequently, module <b>2112</b> can be omitted. In addition, a residual may be obtained for every element of the current palette that has a corresponding entry with the same entry index/level in the palette predictor. In this case, if i is superior or equal to the Predictor_of_Palette_size, no residual is decoded. Furthermore, the flag Use_pred is no longer required since the decoder knows which palette elements to predict based on Predictor_of_Palette_size. Consequently, modules <b>2105</b> and <b>2106</b> can be omitted. These approaches reduce the number of signaling bits required for the palette prediction, by removing the signaling of the predictors. This is useful when the palette elements are ordered according to their occurrences.</div>
</li> <li> <para-num num="[0396]"> </para-num> <div class="description-line" id="p-0393" num="0396">In embodiments, only one or two colour components out of the three (or more) are predicted.</div>
</li> <li> <para-num num="[0397]"> </para-num> <div class="description-line" id="p-0394" num="0397">Above have been described several ways to obtain a palette predictor (<figref idrefs="DRAWINGS">FIGS. 14 to 18, 22 and 24 to 26</figref>) and several ways to define and signal the prediction of the palette from the palette predictor (<figref idrefs="DRAWINGS">FIGS. 19 to 22 and 27</figref>). These embodiments can be combined, except that when the current palette is intra predicted, only the residual approach can be used (otherwise two entries would be the same in the palette). In a preferred embodiment, the palette predictor is the last decoded CU with a reset at each line of CTBs or at each CTB; and the palette predictor is signaled with a flag bitmap indicating whether or not the elements of the palette predictor have to be copied in the current palette being built.</div>
</li> <li> <para-num num="[0398]"> </para-num> <div class="description-line" id="p-0395" num="0398"> <figref idrefs="DRAWINGS">FIG. 23</figref> is a schematic block diagram of a computing device <b>2300</b> for implementation of one or more embodiments of the invention. The computing device <b>2300</b> may be a device such as a micro-computer, a workstation or a light portable device. The computing device <b>2300</b> comprises a communication bus connected to:
</div> </li> <ul> <li id="ul0009-0001" num="0000"> <ul> <li id="ul0010-0001" num="0399">a central processing unit <b>2301</b>, such as a microprocessor, denoted CPU;</li> <li id="ul0010-0002" num="0400">a random access memory <b>2302</b>, denoted RAM, for storing the executable code of the method of embodiments of the invention as well as the registers adapted to record variables and parameters necessary for implementing the method for encoding or decoding at least part of an image according to embodiments of the invention, the memory capacity thereof can be expanded by an optional RAM connected to an expansion port for example;</li> <li id="ul0010-0003" num="0401">a read only memory <b>2303</b>, denoted ROM, for storing computer programs for implementing embodiments of the invention;</li> <li id="ul0010-0004" num="0402">a network interface <b>2304</b> is typically connected to a communication network over which digital data to be processed are transmitted or received. The network interface <b>2304</b> can be a single network interface, or composed of a set of different network interfaces (for instance wired and wireless interfaces, or different kinds of wired or wireless interfaces). Data packets are written to the network interface for transmission or are read from the network interface for reception under the control of the software application running in the CPU <b>2301</b>;</li> <li id="ul0010-0005" num="0403">a user interface <b>2305</b> may be used for receiving inputs from a user or to display information to a user;</li> <li id="ul0010-0006" num="0404">a hard disk <b>2306</b> denoted HD may be provided as a mass storage device;</li> <li id="ul0010-0007" num="0405">an I/O module <b>2307</b> may be used for receiving/sending data from/to external devices such as a video source or display.</li> </ul> </li> </ul>
<li> <para-num num="[0406]"> </para-num> <div class="description-line" id="p-0396" num="0406">The executable code may be stored either in read only memory <b>2303</b>, on the hard disk <b>2306</b> or on a removable digital medium such as for example a disk. According to a variant, the executable code of the programs can be received by means of a communication network, via the network interface <b>2304</b>, in order to be stored in one of the storage means of the communication device <b>2300</b>, such as the hard disk <b>2306</b>, before being executed.</div>
</li> <li> <para-num num="[0407]"> </para-num> <div class="description-line" id="p-0397" num="0407">The central processing unit <b>2301</b> is adapted to control and direct the execution of the instructions or portions of software code of the program or programs according to embodiments of the invention, which instructions are stored in one of the aforementioned storage means. After powering on, the CPU <b>2301</b> is capable of executing instructions from main RAM memory <b>2302</b> relating to a software application after those instructions have been loaded from the program ROM <b>2303</b> or the hard-disk (HD) <b>2306</b> for example. Such a software application, when executed by the CPU <b>2301</b>, causes the steps of the flowcharts shown in <figref idrefs="DRAWINGS">FIGS. 14, 15, 17, 19, 21, 22 and 24 to 27</figref> to be performed.</div>
</li> <li> <para-num num="[0408]"> </para-num> <div class="description-line" id="p-0398" num="0408">Any step of the algorithms shown in <figref idrefs="DRAWINGS">FIGS. 14, 15, 17, 19, 21, 22 and 24 to 27</figref> may be implemented in software by execution of a set of instructions or program by a programmable computing machine, such as a PC (“Personal Computer”), a DSP (“Digital Signal Processor”) or a microcontroller; or else implemented in hardware by a machine or a dedicated component, such as an FPGA (“Field-Programmable Gate Array”) or an ASIC (“Application-Specific Integrated Circuit”).</div>
</li> <li> <para-num num="[0409]"> </para-num> <div class="description-line" id="p-0399" num="0409">Although the present invention has been described hereinabove with reference to specific embodiments, the present invention is not limited to the specific embodiments, and modifications will be apparent to a skilled person in the art which lie within the scope of the present invention.</div>
</li> <li> <para-num num="[0410]"> </para-num> <div class="description-line" id="p-0400" num="0410">Many further modifications and variations will suggest themselves to those versed in the art upon making reference to the foregoing illustrative embodiments, which are given by way of example only and which are not intended to limit the scope of the invention, that being determined solely by the appended claims. In particular the different features from different embodiments may be interchanged, where appropriate.</div>
</li> <li> <para-num num="[0411]"> </para-num> <div class="description-line" id="p-0401" num="0411">In the claims, the word “comprising” does not exclude other elements or steps, and the indefinite article “a” or “an” does not exclude a plurality. The mere fact that different features are recited in mutually different dependent claims does not indicate that a combination of these features cannot be advantageously used.</div>
</li> </ul>
</div>
</section><section itemprop="claims" itemscope="">
<h2>Claims (<span itemprop="count">6</span>)</h2>
<div html="" itemprop="content"><div class="claims" lang="EN" load-source="patent-office" mxw-id="PCLM280375432">
<div class="claim"> <div class="claim" id="CLM-00001" num="00001">
<div class="claim-text"> <b>1</b>. A method for processing a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette that comprises a set of entries associating respective entry indexes with corresponding pixel values,
<div class="claim-text">the method comprising a step of predicting the current palette using a palette predictor built from entries of two or more palettes, wherein:</div> <div class="claim-text">a first palette of the two or more palettes is used in processing a block of pixels immediately preceding the current block of the image, and</div> <div class="claim-text">the building of the palette predictor comprises:
<div class="claim-text">taking all of the entries from the first palette as entries of the palette predictor;</div>
<div class="claim-text">determining if the size of the palette predictor is smaller than the maximum predictor size limit;</div>
<div class="claim-text">determining if one or more entries of the second palette are used in predicting the first palette using corresponding one or more flags, wherein each flag is represented by a bit and indicates whether or not a corresponding entry of a second palette of the two or more palettes is to be used in predicting the first palette;</div>
<div class="claim-text">if the size of the palette predictor is smaller than the maximum predictor size limit, and if the corresponding one or more flags indicate the one or more entries are not used in predicting the first palette,</div>
<div class="claim-text">taking said one or more entries as entries of the palette predictor; the entries from the second palette coming after the entries from the first palette in the built palette.</div>
</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00002" num="00002">
<div class="claim-text"> <b>2</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the second palette is a palette predictor built from entries of two or more palettes used in processing the block of pixels immediately preceding the current block of the image.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00003" num="00003">
<div class="claim-text"> <b>3</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the flags form a bitmap which includes at least one element at a predefined position in the bitmap for signalling whether or not the bitmap includes, after the predefined position, at least one additional flag that indicates whether or not a corresponding entry of the second palette is in the first palette, whereby it defines selection of that entry of the second palette to generate the first palette.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00004" num="00004">
<div class="claim-text"> <b>4</b>. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the current palette is predicted from the palette predictor using flags, each flag indicating whether or not a corresponding entry in the palette predictor is in the current palette.</div>
</div>
</div> <div class="claim"> <div class="claim" id="CLM-00005" num="00005">
<div class="claim-text"> <b>5</b>. A device for processing a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette that comprises a set of entries associating respective entry indexes with corresponding pixel values, the device comprising:
<div class="claim-text">prediction means for predicting the current palette using a palette predictor built from entries of two or more palettes, wherein:</div> <div class="claim-text">a first palette of the two or more palettes is used in processing a block of pixels immediately preceding the current block of the image; and</div> <div class="claim-text">the prediction means is arranged to build the palette predictor by:
<div class="claim-text">taking all of the entries from the first palette as entries of the palette predictor; and</div>
<div class="claim-text">determining if the size of the palette predictor is smaller than the maximum predictor size limit,</div>
<div class="claim-text">determining if one or more entries of the second palette are used in predicting the first palette using corresponding one or more flags, wherein each flag is represented by a bit and indicating whether or not a corresponding entry of a second palette of the two or more palettes is to be used in predicting the first palette,</div>
</div> <div class="claim-text">if the size of the palette predictor is smaller than the maximum predictor size limit, and if the corresponding one or more flags indicate the one or more entries are not used in predicting the first palette,</div> <div class="claim-text">taking said one or more entries as entries of the palette predictor; the entries from the second palette coming after the entries from the first palette in the built palette.</div> </div>
</div>
</div> <div class="claim"> <div class="claim" id="CLM-00006" num="00006">
<div class="claim-text"> <b>6</b>. A non-transitory computer readable carrier medium comprising processor executable code for a programmable apparatus, the computer readable carrier medium comprising a sequence of instructions for implementing a method for processing a current block of pixels of an image using a palette coding mode, the palette coding mode using a current palette that comprises a set of entries associating respective entry indexes with corresponding pixel values,
<div class="claim-text">the method comprising a step of predicting the current palette using a palette predictor built from entries of two or more palettes, wherein:</div> <div class="claim-text">a first palette of the two or more palettes is used in processing a block of pixels immediately preceding the current block of the image, and</div> <div class="claim-text">the building of the palette predictor comprises:
<div class="claim-text">taking all of the entries from the first palette as entries of the palette predictor;</div>
<div class="claim-text">determining if the size of the palette predictor is smaller than the maximum predictor size limit;</div>
<div class="claim-text">determining if one or more entries of the second palette are used in predicting the first palette using corresponding one or more flags, wherein each flag is represented by a bit and indicates whether or not a corresponding entry of a second palette of the two or more palettes is to be used in predicting the first palette;</div>
<div class="claim-text">if the size of the palette predictor is smaller than the maximum predictor size limit, and if the corresponding one or more flags indicate the one or more entries are not used in predicting the first palette,</div>
<div class="claim-text">taking said one or more entries as entries of the palette predictor; the entries from the second palette coming after the entries from the first palette in the built palette.</div>
</div> </div>
</div>
</div> </div>
</div>
</section>
                </article>
            </search-app>
        </body>
    </html>
    