
    <html>
        <body>
            <search-app>
                <article class="result" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
    <h1 itemprop="pageTitle">US9832569B1 - Multichannel acoustic echo cancellation with unique individual channel estimations 
        - Google Patents</h1><section itemprop="abstract" itemscope="">
<h2>Abstract</h2>
<div html="" itemprop="content"><abstract lang="EN" load-source="patent-office" mxw-id="PA210331083">
<div class="abstract" id="p-0001" num="0000">A multi-channel echo cancellation system that dynamically adapts to changes in acoustic conditions. The system does not require a sequence of “start-up” tones to determine the impulse responses. Rather, the adaptive filters approximate estimated transfer functions for each channel. A secondary adaptive filter adjusts cancellation to adapt to changes in the actual transfer functions over time after the adaptive filters have been trained, even if the reference signals are not unique relative to each other.</div>
</abstract>
</div>
</section><section itemprop="description" itemscope="">
<h2>Description</h2>
<div html="" itemprop="content"><div class="description" lang="EN" load-source="patent-office" mxw-id="PDES122939683">
<heading id="h-0001">CROSS-REFERENCE TO RELATED APPLICATION</heading>
<div class="description-paragraph" id="p-0002" num="0001">This application is a continuation of, and claims the benefit of priority of, U.S. Non-provisional patent application Ser. No. 14/750,540, filed Jun. 25, 2015 and entitled “MULTICHANNEL ACOUSTIC ECHO CANCELLATION WITH UNIQUE INDIVIDUAL CHANNEL ESTIMATIONS,” the contents of which is expressly incorporated herein by reference in its entirety.</div>
<heading id="h-0002">BACKGROUND</heading>
<div class="description-paragraph" id="p-0003" num="0002">In audio systems, acoustic echo cancellation (AEC) refers to techniques that are used to recognize when a system has recaptured sound via a microphone after some delay that the system previously output via a speaker. Systems that provide AEC subtract a delayed and filtered version of the original audio signal from the captured audio, producing a version of the captured audio that ideally eliminates the “echo” of the original audio signal, leaving only new audio information. For example, if someone were singing karaoke into a microphone while prerecorded music is output by a loudspeaker, AEC can be used to remove any of the recorded music from the audio captured by the microphone, allowing the singer's voice to be amplified and output without also reproducing a delayed “echo” of the original music. As another example, a media player that accepts voice commands via a microphone can use AEC to remove reproduced sounds corresponding to output media that are captured by the microphone, making it easier to process input voice commands.</div>
<description-of-drawings>
<heading id="h-0003">BRIEF DESCRIPTION OF DRAWINGS</heading>
<div class="description-paragraph" id="p-0004" num="0003">For a more complete understanding of the present disclosure, reference is now made to the following description taken in conjunction with the accompanying drawings.</div>
<div class="description-paragraph" id="p-0005" num="0004"> <figref idrefs="DRAWINGS">FIG. 1</figref> illustrates a multi-channel echo cancellation system that dynamically adapts to changes in acoustic conditions.</div>
<div class="description-paragraph" id="p-0006" num="0005"> <figref idrefs="DRAWINGS">FIG. 2</figref> illustrates an example of a controller-executed process of the system in <figref idrefs="DRAWINGS">FIG. 1</figref>.</div>
<div class="description-paragraph" id="p-0007" num="0006"> <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates a coherence estimate.</div>
<div class="description-paragraph" id="p-0008" num="0007"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a graph illustrating a performance metric for the system in <figref idrefs="DRAWINGS">FIG. 1</figref> measured over time.</div>
<div class="description-paragraph" id="p-0009" num="0008"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a block diagram conceptually illustrating example components of a system for echo cancellation.</div>
<div class="description-paragraph" id="p-0010" num="0009"> <figref idrefs="DRAWINGS">FIG. 6</figref> illustrates an example of a prior art echo cancellation system.</div>
</description-of-drawings>
<div class="description-paragraph" id="p-0011" num="0010">To simplify explanation of these figures, the same reference numbers and notation will be used to identify and discuss both an adaptive filter and that filter's estimated transfer function.</div>
<heading id="h-0004">DETAILED DESCRIPTION</heading>
<div class="description-paragraph" id="p-0012" num="0011">When sounds are output by multiple speakers in a room, and those sounds are captured by one-or-more microphones, how much sound from each speaker will reach each microphone can be characterized by a “transfer” function h(k), where “k” is a digital sample of an audio signal. In principle, if the transfer function for each speaker-to-microphone coupling is known, then by adjusting for the time delay between sound being output by the speakers and being captured by the microphone(s), and filtering the time-delayed sound to reproduce the transfer functions, the sound output by each speaker can be subtracted from captured ambient sounds.</div>
<div class="description-paragraph" id="p-0013" num="0012">Acoustic echo cancellation (AEC) systems utilize adaptive filters to determine estimated transfer functions ĥ(k) for each speaker-to-microphone coupling, mathematically modelling the acoustic “impulse response” of the room relative to the individual components (e.g., speakers, microphones). The impulse response of the room can be used to predictively characterize the signals that will be captured by a microphone when presented with a brief input signal (e.g., an audible noise), called an impulse. The impulse response describes the reaction of the system as a function of time, and the (theoretical) impulse has its own frequency response. In addition, the actual transfer functions h(k) can change dynamically, such as when movement of something in the room (e.g., a person) subtly alters room acoustics. As a result, it is necessary to continually update the estimated transfer functions ĥ(k) to maintain good echo cancellation.</div>
<div class="description-paragraph" id="p-0014" num="0013">A fundamental problem of AEC in stereo and multichannel systems when updating the estimated transfer functions ĥ(k) is a “non-uniqueness” problem. When signals sent to the speakers are perfectly correlated (e.g., playing back a monaural sound recording through a stereo), there can be more than one solution to the adaptive filter equation that is used to estimate the transfer functions between output speakers and input microphones (e.g., estimated transfer functions ĥ<sub>1</sub>(k) and ĥ<sub>2</sub>(k)). Accurate estimated transfer functions are essential for obtaining good echo cancellation, so obtaining a good result in this correlated condition is challenging. In this case, it is impossible to recover h<sub>1 </sub>and h<sub>2</sub>.</div>
<div class="description-paragraph" id="p-0015" num="0014"> <figref idrefs="DRAWINGS">FIG. 1</figref> illustrates a multi-channel echo cancellation system <b>100</b> that includes acoustic echo cancellers <b>102</b> that dynamically adapt to changes in acoustic conditions. The system <b>100</b> does not require a sequence of “start-up” tones to determine the impulse response of the room <b>104</b>. Rather, the adaptive filters <b>122</b> determine estimated transfer functions ĥ<sub>m</sub>(k) for each channel even if the initial reference audio signals x<sub>m</sub>(k) <b>112</b> are highly correlated (e.g., perfectly correlated non-unique monaural signals). A secondary adaptive filter h<sub>aec </sub> <b>128</b> adjusts cancellation to adapt to changes in the actual transfer functions h<sub>m</sub>(k) <b>116</b> over time after the adaptive filters <b>122</b> have been trained, even if the reference signals are not perfectly uncorrelated relative to each other.</div>
<div class="description-paragraph" id="p-0016" num="0015">To better explain the operation of the improved system, a conventional multi-channel AEC system <b>700</b> will be discussed in connection with <figref idrefs="DRAWINGS">FIG. 6</figref>. The conventional AEC system <b>700</b> derives adaptive filter coefficients using techniques such as least mean squares (LMS) or other stochastic gradient algorithms. Such algorithms use an instantaneous estimate of a gradient to update an adaptive weight vector at each time or sample step “k”. The “echo” signal y<sub>1</sub>(k) <b>120</b> <i>a </i>from the microphone <b>118</b> <i>a </i>contains some of the reproduced sounds from the reference signals x<sub>1</sub>(k) <b>112</b> <i>a </i>and x<sub>2</sub>(k) <b>112</b> <i>b </i>(i.e., the “echo”), in addition to any sounds picked up in the room <b>104</b>. The reference signals x<sub>1</sub>(k) <b>112</b> <i>a </i>and x<sub>2</sub>(k) <b>112</b> <i>b </i>are sent to and output by the speakers <b>116</b> <i>a</i>/<b>116</b> <i>b</i>. For example, the reference signals might be music.</div>
<div class="description-paragraph" id="p-0017" num="0016">The reference signals x<sub>1</sub>(k) <b>112</b> <i>a </i>and x<sub>2</sub>(k) <b>112</b> <i>b </i>are also provided to the adaptive filters <b>722</b> <i>a </i>and <b>722</b> <i>b </i>of the AEC <b>702</b> <i>a </i>so that the AEC can remove the contribution of the reference signals from the echo signal(s) (e.g., <b>120</b> <i>a</i>, <b>120</b> <i>b</i>). Focusing on the “left” microphone for the purpose of explanation, if there is no utterance <b>182</b> or other ambient noise in the room <b>104</b>, the echo signal y<sub>1</sub>(k) <b>120</b> <i>a </i>(the portion of the microphone signal due to the reference signals) can be expressed as:
<br/>
<i>y</i> <sub>1</sub>(<i>k</i>)=<i>h</i> <sub>1</sub>(<i>k</i>)*<i>x</i> <sub>1</sub>(<i>k</i>)+<i>h</i> <sub>2</sub>(<i>k</i>)*<i>x</i> <sub>2</sub>(<i>k</i>)  [1]
<br/>
where h<sub>1</sub>(k) <b>116</b> <i>a </i>and h<sub>2</sub>(k) <b>116</b> <i>b </i>are the loudspeaker-to-microphone impulse responses in the receiving room <b>104</b>, x<sub>1</sub>(k) <b>112</b> <i>a </i>and x<sub>2</sub>(k) <b>112</b> <i>b </i>are the loudspeaker reference signals, * denotes a mathematical convolution, and “k” is an audio sample.
</div>
<div class="description-paragraph" id="p-0018" num="0017">The adaptive filters <b>722</b> <i>a</i>/<b>722</b> <i>b </i>of the acoustic echo canceller <b>702</b> <i>a </i>may use a series of test tones from a test tone generator <b>760</b> to calculate the estimated transfer functions ĥ<sub>1</sub>(k) <b>722</b> <i>a </i>and ĥ<sub>2 </sub>(k) <b>722</b> <i>b </i>that approximate the actual transfer functions h<sub>1</sub>(k) <b>116</b> <i>a </i>and h<sub>2</sub>(k) <b>116</b> <i>b </i>when the system <b>700</b> first starts up. The system <b>700</b> may further adjust the estimated transfer functions during regular device operations, but as noted above, if the reference signals x<sub>1</sub>(k) <b>712</b> <i>a </i>and x<sub>2</sub>(k) <b>712</b> <i>b </i>are correlated, the accuracy of echo cancellation will degrade.</div>
<div class="description-paragraph" id="p-0019" num="0018">These estimates are combined with the reference signals x<sub>1</sub>(k) <b>712</b> <i>a </i>and x<sub>2</sub>(k) <b>712</b> <i>b</i>, and then each other, to produce an estimated echo signal ŷ<sub>1</sub>(k) <b>726</b> <i>a</i>, corresponding to an estimate of the echo component in the microphone-captured echo signal y<sub>1</sub>(k) <b>120</b> <i>a</i>. The estimated echo signal ŷ<sub>1</sub>(k) <b>724</b> <i>a </i>can be expressed as:
<br/>
<i>ŷ</i> <sub>1</sub>(<i>k</i>)=<i>ĥ</i> <sub>1</sub>(<i>k</i>)*<i>x</i> <sub>1</sub>(<i>k</i>)+<i>ĥ</i> <sub>2</sub>(<i>k</i>)*<i>x</i> <sub>2</sub>(<i>k</i>)  [2]
<br/>
where * again denotes convolution.
</div>
<div class="description-paragraph" id="p-0020" num="0019">Subtracting the estimated echo signal ŷ<sub>1</sub>(k) <b>726</b> <i>a </i>from the echo signal <b>120</b> <i>a </i>produces an “error” signal e<sub>1</sub>(k), which serves as the audio output <b>150</b>. Specifically:
<br/>
<i>e</i> <sub>1</sub>(<i>k</i>)=<i>y</i> <sub>1</sub>(<i>k</i>)−<i>ŷ</i> <sub>1</sub>(<i>k</i>)  [3]
<br/>
The “error” signal e<sub>1</sub>(k) <b>740</b> <i>a </i>is so-named because if it is not equal to zero when there are no ambient noise sources in the room <b>104</b> (in other words, all captured sounds emanated from the speakers <b>114</b> <i>a </i>and <b>114</b> <i>b</i>), then the value is the result of an error in one or more of the estimated transfer functions ĥ(k) (i.e., <b>722</b> <i>a</i>, <b>722</b> <i>b</i>, or both), assuming non-linearities and/or time-variation.
</div>
<div class="description-paragraph" id="p-0021" num="0020">The estimated transfer functions ĥ<sub>1</sub>(k) <b>722</b> <i>a </i>and ĥ<sub>2 </sub>(k) <b>722</b> <i>b </i>are calculated using adaptive filter coefficients. With this notation, an LMS algorithm can be iteratively expressed in the form:
<br/>
<i>ĥ</i> <sub>new</sub> <i>=ĥ</i> <sub>old</sub> <i>+μ*e*x</i>  [4]
<br/>
where ĥ<sub>new </sub>is an updated estimated transfer function, ĥ<sub>old </sub>is an estimated transfer function from a prior iteration, μ is the step size between samples, e is an error signal, and x is a reference signal.
</div>
<div class="description-paragraph" id="p-0022" num="0021">Applying such adaptation over time (i.e., over a series of samples), it follows that the error signal e<sub>1</sub>(k) <b>740</b> <i>a </i>should approximately “converge” to a point where the mean square error is minimum for a suitable choice of the step size μ. This assumes that the sounds captured by the microphone <b>118</b> <i>a </i>corresponds to sound entirely based on the references signals <b>712</b> <i>a </i>and <b>712</b> <i>b </i>rather than additional ambient noises, such that the estimated echo signal ŷ<sub>1</sub>(k) <b>726</b> <i>a </i>cancels out the echo signal y<sub>1</sub>(k) <b>120</b> <i>a</i>. However, e→0 does not always imply that h−ĥ→0, where the estimated transfer function ĥ cancelling the corresponding actual transfer function h is the goal of the adaptive filter. For example, the estimated transfer functions ĥ<sub>1</sub>(k) <b>722</b> <i>a </i>and ĥ<sub>2 </sub>(k) <b>722</b> <i>b </i>may cancel a particular string of samples, but may unable to cancel all signals, e.g., if the string of samples has no energy at one or more frequencies. As a result, accurate echo cancellation may be intermittent or transitory. Requiring that ĥ→h is the goal of single-channel echo cancellation, and becomes even more critical in the case of multichannel echo cancellers that require estimation of multiple transfer functions.</div>
<div class="description-paragraph" id="p-0023" num="0022">Returning to <figref idrefs="DRAWINGS">FIG. 1</figref>, the AEC system <b>100</b> includes improved automatic echo cancellers <b>102</b> <i>a </i>and <b>102</b> <i>b</i>. A feature that distinguishes stereo echo cancelers <b>102</b> <i>a</i>/<b>102</b> <i>b </i>from conventional single-channel cancelers <b>702</b> <i>a</i>/<b>702</b> <i>b </i>can be explained even without considering the control aspects of the adaptation algorithm. Setting aside the important question of how convergence is achieved, assume that the error signal e<sub>1</sub>(k) <b>126</b> <i>a </i>has been driven to be exactly zero. From Equation [3], it follows that
<br/>
(<i>h</i> <sub>1</sub>(<i>k</i>)−<i>ĥ</i> <sub>1</sub>(<i>k</i>))*<i>x</i> <sub>1</sub>(<i>k</i>)+(<i>h</i> <sub>2</sub>(<i>k</i>)−<i>ĥ</i> <sub>2</sub>(<i>k</i>))*<i>x</i> <sub>2</sub>(<i>k</i>)=0  [5]
</div>
<div class="description-paragraph" id="p-0024" num="0023">Converting from the time domain in Equation [5] to the frequency domain, this becomes:
<br/>
(<i>H</i> <sub>1</sub>(<i>f</i>)−<i>H</i> <sub>1</sub> <sub>_</sub> <sub>est</sub>(<i>f</i>)*<i>X</i> <sub>1</sub>(<i>f</i>)=(<i>H</i> <sub>2</sub>(<i>f</i>)−<i>H</i> <sub>2</sub> <sub>_</sub> <sub>est</sub>(<i>f</i>))*<i>X</i> <sub>2</sub>(<i>f</i>)=0  [6]
<br/>
where the frequency-domain Fourier transforms of the time-domain functions in Equation [5] are denoted by corresponding uppercase letters in Equation [6]. However, Equation [6] does not necessarily mean H<sub>1</sub>=H<sub>1</sub> <sub>_</sub> <sub>est </sub>and H<sub>2</sub>=H<sub>2</sub> <sub>_</sub> <sub>est</sub>, which is the condition required for complete alignment. As used herein, notation with the carat accent symbol “^” and subscript “est” both denote that the function or value is an estimate, and these two notations are used interchangeably.
</div>
<div class="description-paragraph" id="p-0025" num="0024">A problem with stereo echo cancelers is that to maintain accuracy over time, the adaptive filters' adaptation algorithm must adjust the filter coefficients that provide the estimated transfer functions h<sub>1</sub> <sub>_</sub> <sub>est </sub> <b>122</b> <i>a </i>and h<sub>2</sub> <sub>_</sub> <sub>est </sub> <b>122</b> <i>b </i>to track variations in the receiving room <b>104</b> due to environmental factors such as the movement of a person <b>181</b> altering the acoustic impulse response of the room. However, as is apparent from Equation [6], even if the actual impulse responses h<sub>1</sub>(k) <b>116</b> <i>a </i>and h<sub>2</sub>(k) <b>116</b> <i>b </i>in the receiving room <b>104</b> are static, changes in coherence between x<sub>1</sub>(k) and x<sub>2</sub>(k) may result in incorrect adjustment/adaptation of H<sub>1</sub> <sub>_</sub> <sub>est</sub>(f) and H<sub>2</sub> <sub>_</sub> <sub>est</sub>(f), except in the unlikely condition where H=H_<sub> <sup2>est</sup2> </sub>. Thus, not only must the adaptation algorithm make adjustments to filter coefficients to track variations in the acoustic impulse responses in the receiving room <b>104</b>, such as adaptations to adjust for variations in the actual transfer functions h<sub>m </sub> <b>116</b> due to movement of a person <b>181</b>, but the adaptation algorithm must also track variations in in the coherence of the reference signals x<sub>m</sub>(k) <b>112</b>.</div>
<div class="description-paragraph" id="p-0026" num="0025">This latter variation is particularly difficult to track. Consider the case the reference signals from the audio input <b>110</b> are from a recording studio where one talker in the studio stops talking and another person starts talking, but from a different physical location within the recording studio. In this case, the coherence of the reference signals x<sub>m</sub>(k) <b>112</b> may change abruptly and by very large amounts. The challenge then, is to devise an algorithm which (as in the case of a single-channel canceler) converges independently of variations in coherence of the reference signals x<sub>m</sub>(k) <b>112</b>.</div>
<div class="description-paragraph" id="p-0027" num="0026">Coherence, which is also known as “spectral coherence” or “magnitude-squared coherence,” is a statistic used in signal processing to characterize the relationship between signals or data sets. For example, between two time-domain signals a(t) and b(t), a real-valued coherence function may be defined as:</div>
<div class="description-paragraph" id="p-0028" num="0027"> <maths id="MATH-US-00001" num="00001"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mrow> <msub> <mi>C</mi> <mi>ab</mi> </msub> <mo>⁡</mo> <mrow> <mo>(</mo> <mi>f</mi> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mfrac> <msup> <mrow> <mo></mo> <mrow> <msub> <mi>S</mi> <mi>ab</mi> </msub> <mo>⁡</mo> <mrow> <mo>(</mo> <mi>f</mi> <mo>)</mo> </mrow> </mrow> <mo></mo> </mrow> <mn>2</mn> </msup> <mrow> <mrow> <msub> <mi>S</mi> <mi>aa</mi> </msub> <mo>⁡</mo> <mrow> <mo>(</mo> <mi>f</mi> <mo>)</mo> </mrow> </mrow> <mo>⁢</mo> <mrow> <msub> <mi>S</mi> <mi>bb</mi> </msub> <mo>⁡</mo> <mrow> <mo>(</mo> <mi>f</mi> <mo>)</mo> </mrow> </mrow> </mrow> </mfrac> </mrow> </mtd> <mtd> <mrow> <mo>[</mo> <mn>7</mn> <mo>]</mo> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
where S<sub>ab</sub>(f) is the cross-spectral density between a and b, and S<sub>aa</sub>(f) and S<sub>bb</sub>(f) are the frequency domain auto-spectral density of a and b respectively. The magnitude of the spectral density is denoted as |S|. The coherence function estimates the extent to which b(t) may be predicted from a(t) by an optimum least squares function, with the values of coherence satisfying 0≦C<sub>ab</sub>(f)≦1. If the signals a(t) and b(t) are perfectly or fully correlated, the coherence function will be equal to one (e.g., if the signals a(t) and b(t) are identical). If the signals are fully decorrelated, the coherence function will be equal to zero.
</div>
<div class="description-paragraph" id="p-0029" num="0028">If the input source <b>110</b> provides reference signals x<sub>m</sub>(k) <b>112</b> that are perfectly uncorrelated and the loudspeakers <b>116</b> that playback the reference signals x<sub>m</sub>(k) <b>112</b> are spatially-separated (that is, referring to Equation [7], C(f)=0), then the non-uniqueness problem essentially disappears. As a result, H=H_<sub> <sup2>est </sup2> </sub>(at convergence). In comparison, errors ordinarily occur when estimating transfer functions in stereo/multichannel echo cancellation systems when the reference signals x<sub>1</sub>(k) <b>112</b> <i>a </i>and x<sub>2</sub>(k) <b>112</b> <i>b </i>are correlated. These errors may not be instantaneously apparent, but as noted above, as the signals-to-be-cancelled change over time, the inaccurate estimated transfer functions may produce errors as the signals x<sub>1</sub>(k) <b>112</b> <i>a </i>and x<sub>2</sub>(k) <b>112</b> <i>b </i>diverge.</div>
<div class="description-paragraph" id="p-0030" num="0029">If the reference signals x<sub>1</sub>(k) <b>112</b> <i>a </i>and x<sub>2</sub>(k) <b>112</b> <i>b </i>are insufficiently decorrelated to address the non-uniqueness problem, they may be selectively decorrelated. For example, if an average of C<sub>x</sub> <sub> <sub2>1</sub2> </sub> <sub>x</sub> <sub> <sub2>2</sub2> </sub>(f)&lt;0.5 (f=20 Hz to 20 kHz), the reference signals may be determined to be sufficiently decorrelated for adapting the filters h<sub>m</sub> <sub>_</sub> <sub>est</sub>(k) <b>122</b>, and if the average of C<sub>x</sub> <sub> <sub2>1</sub2> </sub> <sub>x</sub> <sub> <sub2>2</sub2> </sub>(f)≧0.5, the reference signals may be determined to be insufficiently decorrelated for adapting the filters h<sub>m</sub> <sub>_</sub> <sub>est</sub>(k) <b>122</b>. There are several well-known methods that may be used to reduce the correlation between channels. One of them is Benesty non-linear distortion added for both channels:
<br/>
<i>z</i> <sub>1</sub> <i>=x</i> <sub>1</sub>+0.15*(<i>x</i> <sub>1</sub> <i>+|x</i> <sub>1</sub>|)→if <i>x</i> <sub>1</sub>&lt;=0,<i>z</i> <sub>1</sub> <i>=x</i> <sub>1 </sub>else <i>z</i> <sub>1</sub> <i>=x</i> <sub>1</sub>+0.3*<i>x</i> <sub>1</sub>  [8]
<br/>
<i>z</i> <sub>2</sub> <i>=x</i> <sub>2</sub>+0.15*(<i>x</i> <sub>2</sub> <i>−|x</i> <sub>2</sub>|)→if <i>x</i> <sub>2</sub>&gt;=0,<i>z</i> <sub>2</sub> <i>=x</i> <sub>2 </sub>else <i>z</i> <sub>2</sub> <i>=x</i> <sub>2</sub>+0.3*<i>x</i> <sub>2</sub>  [9]
<br/>
where z<sub>1 </sub>(<b>113</b> <i>a</i>) and z<sub>2 </sub>(<b>113</b> <i>b</i>) correspond to the decorrelated versions of the reference signals x<sub>1 </sub>(<b>112</b> <i>a</i>) and x<sub>2 </sub>(<b>112</b> <i>b</i>). Another method to generate decorrelated reference signals z<sub>1 </sub>(<b>113</b> <i>a</i>) and z<sub>2 </sub>(<b>113</b> <i>b</i>) from the reference signals x<sub>1</sub>(<b>112</b> <i>a</i>) and x<sub>2</sub>(<b>112</b> <i>b</i>) is to use time-varying all-pass filters. There are other methods as well, such as adding a variable sample delay that is different for each channel, and adding uncorrelated noise.
</div>
<div class="description-paragraph" id="p-0031" num="0030">Consider a system that consists of M loudspeakers with reference signals x<sub>1</sub>(k), x<sub>2</sub>(k), . . . x<sub>M</sub>(k). For simplicity, in <figref idrefs="DRAWINGS">FIG. 1</figref>, M=2. For each loudspeaker m (m=1, 2, . . . , M), there is a dedicated adaptive filter ĥ<sub>m</sub>(k) <b>122</b> (illustrated as h<sub>m</sub> <sub>_</sub> <sub>est</sub>(k) <b>122</b>). Input into each adaptive filter h<sub>m</sub> <sub>_</sub> <sub>est</sub>(k) <b>122</b> is either a reference signal x<sub>m</sub>(k) <b>112</b> or a decorrelated reference signal z<sub>m</sub>(k) <b>113</b>, which corresponds to audio reproduced from loudspeaker m <b>114</b>.</div>
<div class="description-paragraph" id="p-0032" num="0031">The output of each adaptive filter h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b> is a signal y<sub>m</sub> <sub>_</sub> <sub>est</sub>(k) <b>124</b>:
<br/>
<i>Y</i> <sub>m</sub> <sub>_</sub> <sub>est</sub>(<i>k</i>)=<i>h</i> <sub>m</sub> <sub>_</sub> <sub>est</sub>(<i>k</i>)*<i>x</i> <sub>m</sub>(<i>k</i>)  [10]
<br/>
The sum of outputs of the adaptive filters y<sub>m</sub> <sub>_</sub> <sub>est </sub>(m=1, 2, . . . , M) is Σy<sub>est</sub>(k) <b>126</b>:
<br/>
Σ<i>y</i> <sub>est</sub>(<i>k</i>)=<i>y</i> <sub>1</sub> <sub>_</sub> <sub>est</sub>(<i>k</i>)+<i>y</i> <sub>2</sub> <sub>_</sub> <sub>est</sub>(<i>k</i>)+ . . . +<i>y</i> <sub>M</sub> <sub>_</sub> <sub>est</sub>(<i>k</i>)  [11]
<br/>
In a conventional design such as that discussed in <figref idrefs="DRAWINGS">FIG. 5</figref>, the combined signal Σy<sub>est</sub>(k) <b>126</b> would be subtracted from an echo signal y(k), resulting in an error signal e(k). Instead, as illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>, the combined signal Σy<sub>est</sub>(k) <b>126</b> is instead input into a secondary adaptive filter h<sub>aec </sub> <b>128</b>. While the filter coefficients of the adaptive filters <b>122</b> <i>a </i>and <b>122</b> <i>b </i>are adapted to converge, the secondary adaptive filter h<sub>aec </sub> <b>128</b> is bypassed, as will be explained in connection with <figref idrefs="DRAWINGS">FIG. 2</figref>, and the value Σy<sub>est</sub>(k) <b>126</b> is subtracted from the echo signal y<sub>1</sub>(k) <b>120</b> <i>a </i>to produce the echo signal e<sub>1</sub>(k) <b>140</b> <i>a</i>. However, once the adaptive filters <b>122</b> <i>a </i>and <b>122</b> <i>b </i>have converged, their filter coefficients are locked while the filter coefficients of the secondary adaptive filter <b>128</b> adapt to adjust for changing ambient conditions in the receiving room <b>104</b>.
</div>
<div class="description-paragraph" id="p-0033" num="0032">A controller <b>101</b> controls (among other things) whether the secondary adaptive filter h<sub>aec </sub> <b>128</b> is active or bypassed, and whether decorrelation is applied to the reference signals <b>112</b>. An example of the process executed by the controller is illustrated in <figref idrefs="DRAWINGS">FIG. 2</figref>. The filter coefficients of the adaptive filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b> and h<sub>aec </sub> <b>128</b> may be initialized to default values (e.g., zeros) when the system starts up, although this is not essential since the filters will rapidly converge toward new coefficients during operation without regard to the initial values.</div>
<div class="description-paragraph" id="p-0034" num="0033">Initially, the controller <b>101</b> places (<b>202</b>) the secondary adaptive filter h<sub>aec </sub> <b>128</b> into a bypass mode. As illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>, an example of how this may be performed is by changing the mode signal <b>111</b> to “false” (i.e., logic zero). An inverter <b>132</b> inverts the mode signal <b>111</b> and applied it to a “hold” input of the secondary adaptive filter h<sub>aec </sub> <b>128</b>, freezing its filter coefficients. The inverted signal is also applied to a bypass switch <b>134</b>, which directs the signal Σy<sub>est</sub>(k) <b>126</b> around the secondary adaptive filter h<sub>aec </sub> <b>128</b>. While in bypass mode, Σy<sub>est</sub>(k) <b>126</b> is subtracted from the echo signal y<sub>1</sub>(k) to obtain the error signal e<sub>1</sub>(k) <b>140</b> <i>a. </i> </div>
<div class="description-paragraph" id="p-0035" num="0034">The controller <b>101</b> also places (<b>204</b>) the adaptive filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b> for each of the M channels (m=1, 2, . . . , M) into an adaptation mode. As illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref>, this may be accomplished by applying the mode signal <b>111</b> in the “false” state to the “hold” input of each adaptive filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b>, such that each filter is free-running and continually adapt and refine their filter coefficients to minimize a function of the absolute value of the error signal e<sub>1</sub>(k) <b>140</b> <i>a </i>over time.</div>
<div class="description-paragraph" id="p-0036" num="0035">The controller <b>101</b> determines (<b>206</b>) audio spectral content of the reference signals x<sub>1</sub>, x<sub>2</sub>, . . . , x<sub>M</sub>, converting each signal from time domain to frequency domain (i.e., X<sub>1</sub>, X<sub>2</sub>, . . . , X<sub>M</sub>) by performing a Fourier transform on each reference signal. The controller <b>206</b> may perform this conversion using any technique, such as performing Fourier transforms using a Digital Signal Processor (DSP), or using a fast Fourier transform (FFT) processor.</div>
<div class="description-paragraph" id="p-0037" num="0036">The controller <b>101</b> takes the spectral content information (i.e., X<sub>1</sub>, X<sub>2</sub>, . . . , X<sub>M</sub>) and measures (<b>208</b>) the coherence (correlation level) between them. Any spectral correlation/coherence comparison technique may be used, such as the magnitude-squared coherence function determined based on cross-spectral density functions, as discussed above in connection with Equation [7].</div>
<div class="description-paragraph" id="p-0038" num="0037">The results of the correlation/coherence function (such as that in Equation [7]) is usually frequency dependent, such that the reference signals x<sub>m </sub> <b>112</b> may have different coherence values at different frequencies. The controller <b>101</b> may determine a degree of coherence value based on the coherence function, and compare that coherence value with a correlation threshold value. For example, the controller <b>101</b> may take an average of the coherence values C(f) across the audible spectrum (i.e., 20 Hz to 20 kHz), an average across a defined range of the audible spectrum (e.g., 200 Hz to 8 KHz), or an average of a plurality of predefined frequencies. As the directionality of higher frequencies is greater than that of lower frequencies, a weighted average may be used, giving the coherence function results of higher frequencies more weight than the coherence function results of lower frequencies. In the alternative, the controller <b>101</b> may determine the degree of coherence value based on a statistic of the coherence function across a range of the audible spectrum, such as selecting the maximum result as the degree of coherence value. For instance, if a minimum of C(f) is zero at 20 Hz (fully decorrelated) and a maximum of C(f) is one at 5 kHz (perfectly correlated), the correlation value would be one.</div>
<div class="description-paragraph" id="p-0039" num="0038">Based on a comparison of the degree of coherence and the threshold value, the controller <b>101</b> determines (<b>210</b>) whether the channels are sufficiently decorrelated to train the adaptive filters <b>122</b>. <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates a coherence estimate C<sub>x</sub> <sub> <sub2>1</sub2> </sub> <sub>x</sub> <sub> <sub2>2</sub2> </sub>(f) in a frequency range from approximately 20 Hz to 8 kHz for a sample of each reference signal x<sub>1</sub>(k) and x<sub>2</sub>(k), exhibiting signal correlation at low frequencies, and strong decorrelation around 3.4 kHz. A function is applied to the coherence estimate C<sub>x</sub> <sub> <sub2>1</sub2> </sub> <sub>x</sub> <sub> <sub2>2</sub2> </sub>(f). The function may be a statistical metric such as an average of the coherence estimate across a defined frequency range, to determine a coherence value characterizing the correlation between the reference signals. The coherence value is compared to a threshold value to determine whether the signals are sufficiently decorrelated (<b>210</b>). For example, if an average of C<sub>x</sub> <sub> <sub2>1</sub2> </sub> <sub>x</sub> <sub> <sub2>2</sub2> </sub>(f)&lt;0.5 (f=20 Hz to 20 kHz), the reference signals may be determined to be sufficiently decorrelated (<b>210</b> “Yes”) for adapting the filters h<sub>m</sub> <sub>_</sub> <sub>est</sub>(k) <b>122</b>, and if the average of C<sub>x</sub> <sub> <sub2>1</sub2> </sub> <sub>x</sub> <sub> <sub2>2</sub2> </sub>(f)≧0.5, the reference signals may be determined to be insufficiently decorrelated (<b>210</b> “No”) for adapting the filters h<sub>m</sub> <sub>_</sub> <sub>est</sub>(k) <b>122</b>.</div>
<div class="description-paragraph" id="p-0040" num="0039">If the reference signals x<sub>m</sub>(k) <b>122</b> are sufficiently decorrelated (<b>210</b> “Yes”), then the adaptive filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b> are “trained” (i.e., configured to adapt their filter coefficients) in the conventional manner using the reference signals x<sub>m</sub>(k) <b>122</b>, which are also transmitted to the M speakers <b>114</b> in room <b>104</b>. Otherwise (<b>210</b> “No”), a decorrelation technique such as the functions in Equations [8] and [<b>9</b>] are applied to the reference signals x<sub>m</sub>(k) <b>122</b>, producing decorrelated reference signals z<sub>m</sub>(k) <b>113</b>. These decorrelated signals are then used to train the adaptive filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b>, and are output to the M speakers <b>114</b> in room <b>104</b>. Decorrelation may be applied if and only if the reference signals x<sub>1</sub>, . . . , x<sub>M </sub> <b>112</b> contain a wide range of frequencies and these signals are not already sufficiently decorrelated. Training the filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b> with decorrelated signals z<sub>m</sub>(k) <b>113</b> will resolve the channel ambiguity problem, which is to say that the filter coefficients approximating each estimated transfer function h<sub>m</sub> <sub>_</sub> <sub>est</sub>(k) will converge toward the corresponding (but unknown) actual transfer function h<sub>m</sub>(k) <b>116</b>.</div>
<div class="description-paragraph" id="p-0041" num="0040">The controller <b>101</b> monitors the error signals e<sub>n</sub>(k) <b>140</b> over time (n=1, 2, . . . , N, where N is the number of microphones <b>118</b>) as the h<sub>m</sub> <sub>_</sub> <sub>est </sub>filters <b>122</b> adapt to determine whether the filters <b>122</b> have converged to approximately a stable value. (The connections between the error signals e<sub>n</sub>(k) <b>140</b> to controller <b>101</b> are not illustrated).</div>
<div class="description-paragraph" id="p-0042" num="0041">Any technique may be used to determine filter convergence, which may be approximated (among other ways) based on absolute values of the error signals reaching stable minima. Upon convergence, the filter coefficients of a filter stabilize to approximately steady state values in the absence of time-varying impulse responses.</div>
<div class="description-paragraph" id="p-0043" num="0042">An example of a function that may be applied to the error values e<sub>n</sub>(k) <b>140</b> to determine convergence is a peak detection algorithm. One peak-detection based approach to determining convergence calculates the mean square of the energy of the error signal e<sub>n</sub>(k) over a plurality of samples to determine whether a majority of the energy of the error signal e<sub>n</sub>(k) is in a narrow window, such as taking 2048 samples, determining a sum of the squares of the first 300 samples, determining a sum of the squares of all 2048 samples, and then comparing a ratio of the two sums with a threshold value to determine whether a majority of the energy is in a narrow window at and around the initial energy peak. In signal processing the energy E<sub>S </sub>of a continuous time-domain signal x(t) is defined as:
<br/>
<i>E</i> <sub>S</sub> <i>=</i> <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/98/f8/a3/98dd6a2761a527/US09832569-20171128-P00001.png"><img alt="Figure US09832569-20171128-P00001" class="patent-full-image" file="US09832569-20171128-P00001.TIF" he="3.22mm" height="13" id="CUSTOM-CHARACTER-00001" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/98/f8/a3/98dd6a2761a527/US09832569-20171128-P00001.png" wi="1.10mm" width="4"/></a></div> <i>x</i>(<i>t</i>),<i>x</i>(<i>t</i>)<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/94/10/58/95335f9aa1d8fc/US09832569-20171128-P00002.png"><img alt="Figure US09832569-20171128-P00002" class="patent-full-image" file="US09832569-20171128-P00002.TIF" he="3.22mm" height="13" id="CUSTOM-CHARACTER-00002" img-content="character" img-format="tif" inline="no" orientation="portrait" src="https://patentimages.storage.googleapis.com/94/10/58/95335f9aa1d8fc/US09832569-20171128-P00002.png" wi="1.10mm" width="4"/></a></div>=∫<sub>−∞</sub> <sup>∞</sup> <i>|x</i>(<i>t</i>)|<sup>2</sup> <i>dt</i>  [12]
</div>
<div class="description-paragraph" id="p-0044" num="0043">Another example of a function that may be applied to the error values e<sub>n</sub>(k) <b>140</b> to determine convergence is to take the mean square of the error signals e<sub>n</sub>(k) over a series of samples, divide by the number of samples, and then determine an allowed amount of deviation to determine whether the mean square value indicates a steady-state value. Yet another example of a function that may be applied to the error values e<sub>n</sub>(k) <b>140</b> to determine convergence is to apply a signal entropy analysis function to the error signals e<sub>n</sub>(k), determining that there is filter coefficient stability based on entropy. Another example of a function to determine convergence is to take the mean of the absolute value of ĥ<sub>old</sub>−ĥ<sub>new </sub>and compare the result to a threshold.</div>
<div class="description-paragraph" id="p-0045" num="0044">As long as there are filters <b>122</b> in at least one of the N AECs <b>102</b> (where N is the number of microphones <b>118</b>) that have not yet converged (<b>216</b> “No”), the controller <b>101</b> may continue to monitor (<b>206</b>) coherence of the reference signals <b>112</b> and apply decorrelation (<b>214</b>) as needed. Once the filter coefficients in each of the N AECs <b>102</b> are estimated to have converged (<b>216</b> “Yes”), the controller <b>101</b> disables (<b>216</b>) decorrelation. If decorrelation had been applied (i.e., <b>214</b>), this means that the original reference signals x<sub>1</sub>, . . . , x<sub>M </sub> <b>112</b> are instead provided to the speakers <b>114</b> and adaptive filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b>. The controller <b>101</b> also freezes the filter coefficients of the adaptive filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b>. This may be performed by changing the state of the mode signal <b>111</b>, changing from “False” (logic zero) to “True” (logic one). This change to mode signal <b>111</b>, which is input into the “hold” input of the adaptive filters <b>122</b>, causes each of the filters <b>122</b> to freeze their filter coefficients. As a consequence, the filters <b>122</b> continue to apply the filter coefficients corresponding to the estimated transfer functions h<sub>m</sub> <sub>_</sub> <sub>est </sub>that had been determined as of the time of convergence (<b>216</b> “Yes”).</div>
<div class="description-paragraph" id="p-0046" num="0045">In the alternative to monitoring whether the filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b> have converged, the controller <b>101</b> may apply decorrelation (<b>214</b>) for a defined duration, such as thirty seconds or a minute, with the duration being longer than would ordinarily be required for the filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b> to converge. As another alternative, instead of monitoring the error signals e<sub>n</sub>(k) <b>140</b> to determine convergence, an echo return loss enhancement (ERLE) may be determined for each AEC <b>102</b>, which the controller <b>101</b> may use to approximate convergence, such as comparing the ERLE with a threshold value to determine that the filters have converged (<b>216</b> “Yes”) when the ERLE values have each exceeded the threshold.</div>
<div class="description-paragraph" id="p-0047" num="0046">The controller <b>101</b> also puts (<b>222</b>) the secondary adaptive filter h<sub>aec </sub> <b>128</b> into adaptation mode. For example, the changing of the mode signal <b>111</b> from “False” (logic zero) to “True” (logic one) is inverted by the inverter <b>132</b>, releasing the coefficient “hold” on the secondary adaptive filter h<sub>aec </sub> <b>128</b>, and changing the state of the bypass switch <b>134</b>. The secondary adaptive filter h<sub>aec </sub> <b>128</b> outputs an estimated echo signal y<sub>aec</sub>(k) <b>130</b>:
<br/>
<i>y</i> <sub>aec</sub>(<i>k</i>)=<i>h</i> <sub>aec</sub>(<i>k</i>)*Σ<i>y</i> <sub>est</sub>  [13]
<br/>
In this mode, the estimated echo signal y<sub>aec</sub>(k) <b>130</b> is subtracted from the echo signal y<sub>1</sub>(k) to obtain the error signal e<sub>1</sub>(k) <b>140</b> <i>a: </i>
<br/>
<i>e</i> <sub>1</sub>(<i>k</i>)=<i>y</i> <sub>1</sub>(<i>k</i>)−<i>y</i> <sub>aec</sub>  [14]
</div>
<div class="description-paragraph" id="p-0048" num="0047">From this point on, the filters h<sub>m</sub> <sub>_</sub> <sub>est </sub>122 (m=1, 2, . . . , M) will only be used for filtering the reference signals x<sub>m</sub>(k) <b>112</b> in order to get Σy<sub>est</sub>(k) <b>126</b>. However, the coefficients are locked, such that the estimated transfer functions h<sub>m</sub> <sub>_</sub> <sub>est </sub>approximated by each filter's filter coefficients correspond to the values as of the time of convergence (<b>216</b> “Yes”).</div>
<div class="description-paragraph" id="p-0049" num="0048">The secondary adaptive filter h<sub>aec </sub> <b>128</b> remains in adaptation mode, continually applying an adaptive-filter filter coefficient adaptation method. The filter coefficients of the secondary adaptive filter h<sub>aec </sub> <b>128</b> converge in an attempt to minimize a function of the absolute value of the error signal e<sub>n</sub>(k) <b>140</b> <i>b</i>. Using LMS, for example, convergence requires a sufficiently small step size, among other things. For as long as the locked filter coefficients of the adaptive filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b> continue to provide an accurate prediction of the actual transfer functions <b>116</b>, the estimated echo signal y<sub>aec</sub>(k) <b>130</b> output by the secondary adaptive filter h<sub>aec </sub> <b>128</b> may be the same as the signal Σy<sub>est</sub>(k) <b>126</b> that it receives as input (or the secondary filter <b>128</b> will rapidly converge until the estimated echo signal y<sub>aec</sub>(k) <b>130</b> corresponds to the signal Σy<sub>est</sub>(k) <b>126</b>. However, when a dynamic change in the impulse responses in room <b>104</b> occurs and introduces error into the signal Σy<sub>est</sub>(k) <b>126</b>, the secondary adaptive filter h<sub>aec </sub> <b>128</b> adapts the estimated echo signal y<sub>aec</sub>(k) <b>130</b> to compensate for the error, so as to minimize a function of the error signal e<sub>1</sub>(k). However, it is not possible to perfectly compensate for a dynamic change in this manner for the vast majority of dynamic changes.</div>
<div class="description-paragraph" id="p-0050" num="0049">The secondary adaptive filter h<sub>aec </sub> <b>128</b> may use any adaptive filter method, such as the least mean squares (LMS) algorithm discussed in connection with Equation [4], or some other stochastic gradient algorithm. The method utilized by the secondary adaptive filter h<sub>aec </sub> <b>128</b> may be the same as those used by the filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b>, or may be different. Since the signals input into the secondary adaptive filter h<sub>aec </sub> <b>128</b> are already aggregated, whether the reference signals x<sub>1</sub>, . . . , x<sub>M </sub> <b>112</b> are or are not decorrelated is not as important to the operation of the secondary adaptive filter h<sub>aec </sub> <b>128</b> as it is to the individual channel filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b>. As a result, the improved acoustic echo cancellers <b>102</b> provide robust echo cancellation in a dynamic acoustic environment, even if the reference signals x<sub>m </sub> <b>112</b> are highly correlated.</div>
<div class="description-paragraph" id="p-0051" num="0050">The controller's selective initial application of decorrelation (<b>214</b>) minimizes unnecessary distortion of the reference signals <b>112</b> by allowing distortion to be applied for only a short period of time. This method allows the system <b>100</b> to compute each individual channel's filter coefficients in a manageable way, based on the condition of the acoustic environment and the reference signals. The audio output <b>150</b> may then be processed by other components, such as inputting the output <b>150</b> into a speech processing system to detect and/or recognize an utterance <b>182</b> from the person <b>181</b> in the receiving room <b>104</b>.</div>
<div class="description-paragraph" id="p-0052" num="0051">The controller <b>101</b> may determine other metrics characterizing performance of the system periodically over time. For example, the controller <b>101</b> may monitor playback signal statistics, the noise environment spectrum, the physical movement of a device containing the speakers <b>114</b> and/or the microphones, the statistical deviation of the delta between Σy<sub>est </sub> <b>126</b> and y<sub>aec</sub>(k) <b>130</b> over time, etc. Variations in performance due to noises in the room <b>104</b>, human speech, etc., tend to be transitory, and are ordinarily unlikely to result in the sort of continual errors that impact such metrics.</div>
<div class="description-paragraph" id="p-0053" num="0052">Based on comparing one or more of these metrics to one or more threshold values, the controller <b>101</b> may periodically reinitiate training of the filters <b>122</b> (i.e., changing the state of mode signal <b>111</b>). Poor metrics over time may indicate that the differences between the actual (unknown) transfer functions h<sub>m</sub>(k) <b>116</b> in room <b>104</b> and the estimated transfer functions corresponding to the filter coefficients of the adaptive filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b> have reached a point where the secondary adaptive filter h<sub>aec </sub> <b>128</b> is no longer able to adequately compensate. Likewise, if the speakers <b>114</b> or microphones <b>118</b> are determined to have been moved (e.g., due to device movement), then it can be assumed that the estimated transfer functions corresponding to the filter coefficients of the adaptive filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b> are no longer accurate, as the impulse responses within the system will have changed.</div>
<div class="description-paragraph" id="p-0054" num="0053">Reference signals x<sub>m</sub>(k) <b>112</b> with a wide spectrum produce the most robust approximation of estimated transfer functions by the adaptive filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>122</b>. When the controller <b>101</b> has determined that the filter coefficients of the adaptive filters h<sub>m</sub> <sub>_</sub> <sub>est </sub> <b>112</b> should be retrained, the controller <b>101</b> may execute a subroutine to monitor the spectrum of the reference signals (<b>206</b>) and determine whether the number of frequencies of a spectrum have a sufficient amount of energy to exceed pre-defined thresholds. If not, the controller <b>101</b> may wait until the spectrum does exceed the set of frequency distribution parameters. For example, music is more likely to exhibit a wide frequency distribution than speech, such that the controller <b>101</b> may wait for suitable reference signals before reinitiating training of the filters <b>122</b>.</div>
<div class="description-paragraph" id="p-0055" num="0054">The controller <b>101</b> may apply more than one metric threshold when determining when it should abandon waiting for wide spectrum signals before reinitiating training. For example, if a triggering metric exceeds (or falls below, depending upon the metric) a threshold corresponding to “marginal” echo cancellation, the controller <b>101</b> may launch the routine to monitor for wide spectrum reference signals, and wait to reinitiate training until such reference signals are detected. However, if the triggering metric further degrades to exceed (or fall below) another threshold corresponding to “failed” echo cancellation, the controller <b>101</b> may abandon waiting for wide-spectrum signals and reinitiate training of the filters <b>122</b> using whatever reference signals x<sub>m</sub>(k) are received/available (applying decorrelation as discussed in connection with the process in <figref idrefs="DRAWINGS">FIG. 2</figref>).</div>
<div class="description-paragraph" id="p-0056" num="0055">As another possible retraining routine, the controller <b>101</b> may periodically monitor the spectrum of the reference signals (<b>206</b>) and determine whether the number of frequencies of a spectrum have a sufficient amount of energy to exceed pre-defined thresholds. If they do exceed the distribution parameters, the controller <b>101</b> may also determine whether the reference signals are sufficiently decorrelated (<b>210</b>). If they are, the controller <b>101</b> may opportunistically reinitiate training of the filters <b>122</b>, even if not necessitated by the quality metrics. This might occur, for example, if the reference signals are music where there is a low correlation between left and right stereo channels in a two-channel system. This also avoids the potential necessity of decorrelating (<b>214</b>) the signals, which may be noticeable by a listener.</div>
<div class="description-paragraph" id="p-0057" num="0056">Although the system <b>100</b> does not require test tones upon startup to decorrelate the reference signals <b>112</b>, startup sounds may optionally be used. However, there is no need for any calibration sounds at boot time, or when the room environment changes. This method is dynamically adaptive, without requiring the disruption of an intrusive training period.</div>
<div class="description-paragraph" id="p-0058" num="0057">To test the performance of the system, two main KPIs (Key Performance Indicators) are ERLE (echo return loss enhancement) and re-convergence time. These two KPIs may be combined into a single measure of “goodness” for AEC, by processing an audio stream (real or computed) with the AEC algorithm under test. For example, testing system performance may include using test audio that includes a variety of audio types (music, speech, mixture of the two), audio source locations (movement of the human talker within the multi-channel stereo field), speaker types (small, large), double talk (a human starts and stops talking in the room), and echo path changes (movement of furniture in a room, opening/closing of a door, movement of people in the room).</div>
<div class="description-paragraph" id="p-0059" num="0058"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a graph illustrating ERLE as a performance metric for the system in <figref idrefs="DRAWINGS">FIG. 1</figref> measured over time. Calculating the area under the ERLE curve for the duration of the test audio stream provides a metric of how the system performs in an environment.</div>
<div class="description-paragraph" id="p-0060" num="0059"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a block diagram conceptually illustrating example components of the system <b>100</b>. In operation, the system <b>100</b> may include computer-readable and computer-executable instructions that reside on the device <b>600</b>, as will be discussed further below.</div>
<div class="description-paragraph" id="p-0061" num="0060">The system <b>100</b> may include audio capture devices, such as an array of N microphones <b>118</b>, where N&gt;2. The audio capture devices may be integrated into the device <b>600</b> or may be separate. The system <b>100</b> may also include an audio output device for producing sound, such as speaker(s) <b>116</b>. The audio output device may be integrated into the device <b>600</b> or may be separate.</div>
<div class="description-paragraph" id="p-0062" num="0061">The device <b>600</b> may include an address/data bus <b>424</b> for conveying data among components of the device <b>600</b>. Each component within the device <b>600</b> may also be directly connected to other components in addition to (or instead of) being connected to other components across the bus <b>424</b>.</div>
<div class="description-paragraph" id="p-0063" num="0062">The device <b>600</b> may include one or more controllers/processors <b>604</b>, that may each include a central processing unit (CPU) for processing data and computer-readable instructions, and a memory <b>606</b> for storing data and instructions. The memory <b>606</b> may include volatile random access memory (RAM), non-volatile read only memory (ROM), non-volatile magnetoresistive (MRAM) and/or other types of memory. The device <b>100</b> may also include a data storage component <b>608</b>, for storing data and controller/processor-executable instructions (e.g., instructions to perform the process illustrated in <figref idrefs="DRAWINGS">FIG. 2</figref>, and related operations of the controller <b>101</b> such as Fourier transforms). The data storage component <b>608</b> may include one or more non-volatile storage types such as magnetic storage, optical storage, solid-state storage, etc. The device <b>600</b> may also be connected to removable or external non-volatile memory and/or storage (such as a removable memory card, memory key drive, networked storage, etc.) through the input/output device interfaces <b>602</b>.</div>
<div class="description-paragraph" id="p-0064" num="0063">Computer instructions for operating the device <b>600</b> and its various components may be executed by the controller(s)/processor(s) <b>604</b>, using the memory <b>606</b> as temporary “working” storage at runtime. The computer instructions may be stored in a non-transitory manner in non-volatile memory <b>606</b>, storage <b>608</b>, or an external device. Alternatively, some or all of the executable instructions may be embedded in hardware or firmware in addition to or instead of software.</div>
<div class="description-paragraph" id="p-0065" num="0064">The device <b>600</b> includes input/output device interfaces <b>602</b>. A variety of components may be connected through the input/output device interfaces <b>602</b>, such as the speaker(s) <b>116</b>, the N microphones <b>118</b>, and a media source such as a digital media player (not illustrated). The input/output device interfaces <b>602</b> may also include an interface for an external peripheral device connection such as universal serial bus (USB), FireWire, Thunderbolt or other connection protocol. The input/output device interfaces <b>602</b> may also include a connection to one or more networks <b>699</b> via an Ethernet port, a wireless local area network (WLAN) (such as WiFi) radio, Bluetooth, and/or wireless network radio, such as a radio capable of communication with a wireless communication network such as a Long Term Evolution (LTE) network, WiMAX network, 3G network, etc. Through the network <b>699</b>, the system <b>100</b> may be distributed across a networked environment.</div>
<div class="description-paragraph" id="p-0066" num="0065">The device <b>600</b> further includes an AEC module <b>630</b> that includes the controller <b>101</b>, and the individual AEC <b>102</b>, where there may be an AEC <b>102</b> for each microphone <b>118</b>.</div>
<div class="description-paragraph" id="p-0067" num="0066">Multiple devices <b>600</b> may be employed in a single system <b>100</b>. In such a multi-device system, each of the devices <b>600</b> may include different components for performing different aspects of the AEC process. The multiple devices may include overlapping components. The components of device <b>600</b> as illustrated in <figref idrefs="DRAWINGS">FIG. 6</figref> are exemplary, and may be included in a stand-alone device or may be included, in whole or in part, as a component of a larger device or system. For example, in certain system configurations, one device may transmit and receive the audio data, another device may perform AEC, and yet another device may use the audio output <b>150</b> for operations such as speech recognition.</div>
<div class="description-paragraph" id="p-0068" num="0067">The concepts disclosed herein may be applied within a number of different devices and computer systems, including, for example, general-purpose computing systems, multimedia set-top boxes, televisions, stereos, radios, server-client computing systems, telephone computing systems, laptop computers, cellular phones, personal digital assistants (PDAs), tablet computers, wearable computing devices (watches, glasses, etc.), other mobile devices, etc.</div>
<div class="description-paragraph" id="p-0069" num="0068">The above aspects of the present disclosure are meant to be illustrative. They were chosen to explain the principles and application of the disclosure and are not intended to be exhaustive or to limit the disclosure. Many modifications and variations of the disclosed aspects may be apparent to those of skill in the art. Persons having ordinary skill in the field of digital signal processing and echo cancellation should recognize that components and process steps described herein may be interchangeable with other components or steps, or combinations of components or steps, and still achieve the benefits and advantages of the present disclosure. Moreover, it should be apparent to one skilled in the art, that the disclosure may be practiced without some or all of the specific details and steps disclosed herein.</div>
<div class="description-paragraph" id="p-0070" num="0069">Aspects of the disclosed system may be implemented as a computer method or as an article of manufacture such as a memory device or non-transitory computer readable storage medium. The computer readable storage medium may be readable by a computer and may comprise instructions for causing a computer or other device to perform processes described in the present disclosure. The computer readable storage medium may be implemented by a volatile computer memory, non-volatile computer memory, hard drive, solid-state memory, flash drive, removable disk and/or other media. Some or all of the AEC module <b>430</b> may be implemented by a digital signal processor (DSP).</div>
<div class="description-paragraph" id="p-0071" num="0070">As used in this disclosure, the term “a” or “one” may include one or more items unless specifically stated otherwise. Further, the phrase “based on” is intended to mean “based at least in part on” unless specifically stated otherwise.</div>
</div>
</div>
</section><section itemprop="claims" itemscope="">
<h2>Claims (<span itemprop="count">20</span>)</h2>
<div html="" itemprop="content"><div class="claims" lang="EN" load-source="patent-office" mxw-id="PCLM116829421">
<claim-statement>What is claimed is:</claim-statement>
<div class="claim"> <div class="claim" id="CLM-00001" num="00001">
<div class="claim-text">1. A computing device comprising:
<div class="claim-text">at least one processor;</div>
<div class="claim-text">memory including instructions operable to be executed by the at least one processor to perform a set of actions to configure the device to:
<div class="claim-text">provide a first audio signal as input to a first adaptive filter;</div>
<div class="claim-text">determine that first filter coefficients of the first adaptive filter have converged to thereby produce a first estimated signal output;</div>
<div class="claim-text">provide a second audio signal as input to a second adaptive filter;</div>
<div class="claim-text">determine that second filter coefficients of the second adaptive filter have converged to thereby produce a second estimated signal output;</div>
<div class="claim-text">disable adapting of the first filter coefficients after the first adaptive filter is determined to have converged;</div>
<div class="claim-text">disable adapting of the second filter coefficients after the second adaptive filter is determined to have converged;</div>
<div class="claim-text">provide the sum of the first estimated signal output and the second estimated signal output as input to a third adaptive filter to generate a third estimated signal output;</div>
<div class="claim-text">cause the third adaptive filter to converge to third filter coefficients; and</div>
<div class="claim-text">subtract the third estimated signal from a microphone signal to determine an audio output signal.</div>
</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00002" num="00002">
<div class="claim-text">2. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions further configure the device to:
<div class="claim-text">determine a first frequency distribution corresponding to the first audio signal;</div>
<div class="claim-text">determine a second frequency distribution corresponding to the second audio signal;</div>
<div class="claim-text">determine that the first audio signal and the second audio signal are correlated using the first frequency distribution and second frequency distribution;</div>
<div class="claim-text">decorrelate the first and second audio signals prior to transmitting the first and second audio signals; and</div>
<div class="claim-text">end decorrelation of the first and second audio signals after the first and second adaptive filters are determined to have converged.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00003" num="00003">
<div class="claim-text">3. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions further configure the device to:
<div class="claim-text">determine that the first adaptive filter and the second adaptive filter have converged when a preset duration of time has expired.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00004" num="00004">
<div class="claim-text">4. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions further configure the device to:
<div class="claim-text">determine a first frequency distribution of the first audio signal;</div>
<div class="claim-text">determine a second frequency distribution of the second audio signal;</div>
<div class="claim-text">determine that the first frequency distribution exceeds a threshold distribution parameter;</div>
<div class="claim-text">determine that the second frequency distribution exceeds the threshold distribution parameter; and cause the first filter coefficients and the second filter coefficients to reconverge.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00005" num="00005">
<div class="claim-text">5. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions further configure the device to:
<div class="claim-text">determine a first frequency distribution of the first audio signal;</div>
<div class="claim-text">determine a second frequency distribution of the second audio signal;</div>
<div class="claim-text">determine that the first frequency distribution exceeds a threshold distribution parameter;</div>
<div class="claim-text">determine that the second frequency distribution exceeds the threshold distribution parameter;</div>
<div class="claim-text">determine that the first audio signal and the second audio signal are decorrelated with each other using the first frequency distribution and second frequency distribution;</div>
<div class="claim-text">configure the first adaptive filter to further adapt the first filter coefficients to reconverge;</div>
<div class="claim-text">configure the second adaptive filter to further adapt the second filter coefficients to reconverge;</div>
<div class="claim-text">determine that the first adaptive filter has reconverged;</div>
<div class="claim-text">determine that the second adaptive filter has reconverged; and</div>
<div class="claim-text">disable adapting of the first and second filter coefficients after the first and second adaptive filters are determined to have reconverged.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00006" num="00006">
<div class="claim-text">6. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the first, second, and third adaptive filters apply a least mean squares (LMS) or a stochastic gradient algorithm to adapt their respective filter coefficients.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00007" num="00007">
<div class="claim-text">7. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions further configure the device to:
<div class="claim-text">receive the first audio signal;</div>
<div class="claim-text">receive the second audio signal;</div>
<div class="claim-text">transmit a first audio signal to a first sound reproduction device;</div>
<div class="claim-text">transmit the second audio signal to a second sound reproduction device;</div>
<div class="claim-text">receive, from a microphone, a detected signal including a representation of a first portion of the first audio signal and a representation of a second portion of the second audio signal;</div>
<div class="claim-text">determine a sum of the first estimated signal output and the second estimated signal output;</div>
<div class="claim-text">subtract the sum from the detected signal to determine an output signal; and</div>
<div class="claim-text">adapt first filter coefficients of the first adaptive filter and second filter coefficients of the second adaptive filter to converge.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00008" num="00008">
<div class="claim-text">8. The computing device of <claim-ref idref="CLM-00007">claim 7</claim-ref>, wherein the instructions further configure the device to:
<div class="claim-text">determine a stability of a function of the output signal; and</div>
<div class="claim-text">determine that the first adaptive filter and the second adaptive filter have converged based on the stability of the function of the output signal.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00009" num="00009">
<div class="claim-text">9. The computing device of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the instructions further configure the device to:
<div class="claim-text">determine a quality metric characterizing the audio output signal;</div>
<div class="claim-text">determine that the quality metric does not satisfy a quality threshold value;</div>
<div class="claim-text">configure the first adaptive filter to further adapt the first filter coefficients and the second filter coefficients to reconverge;</div>
<div class="claim-text">determine that the first adaptive filter and the second adaptive filter have reconverged; and</div>
<div class="claim-text">disable adapting of the first and second filter coefficients after the first and second adaptive filters are determined to have reconverged.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00010" num="00010">
<div class="claim-text">10. The computing device of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the quality metric is based on one or more of an echo return loss enhancement (ERLE) for the audio output signal or an amount of time it takes the third adaptive filter to reconverge the function of the audio output signal after convergence is lost.</div>
</div>
</div> <div class="claim"> <div class="claim" id="CLM-00011" num="00011">
<div class="claim-text">11. A method to be performed by a device, the method comprising:
<div class="claim-text">providing a first audio signal as input to a first adaptive filter;</div>
<div class="claim-text">determining that first filter coefficients of the first adaptive filter have converged to thereby produce a first estimated signal output;</div>
<div class="claim-text">providing a second audio signal as input to a second adaptive filter;</div>
<div class="claim-text">determining that second filter coefficients of the second adaptive filter have converged, given a second audio signal as input, to thereby produce a second estimated signal output;</div>
<div class="claim-text">disabling adapting of the first filter coefficients after the adaptive filters is determined to have converged;</div>
<div class="claim-text">disabling adapting of the second filter coefficients after the second adaptive filter is determined to have converged;</div>
<div class="claim-text">providing a sum of the first estimated signal output and the second estimated signal output as input to a third adaptive filter to generate a third estimated signal output;</div>
<div class="claim-text">causing the third adaptive filter to converge to third filter coefficients; and</div>
<div class="claim-text">subtracting the third estimated signal from a microphone signal to determine an audio output signal.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00012" num="00012">
<div class="claim-text">12. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:
<div class="claim-text">determining a first frequency distribution corresponding to the first audio signal;</div>
<div class="claim-text">determining a second frequency distribution corresponding to the second audio signal;</div>
<div class="claim-text">determining that the first audio signal and the second audio signal are correlated using the first frequency distribution and second frequency distribution;</div>
<div class="claim-text">decorrelating the first and second audio signals prior to transmitting the first and second audio signals to first and second sound reproduction devices prior to providing the first and second audio signals as input to the first and second adaptive filters; and</div>
<div class="claim-text">ending decorrelation of the first and second audio signals after the first and second adaptive filters are determined to have converged.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00013" num="00013">
<div class="claim-text">13. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:
<div class="claim-text">determining that the first adaptive filter and the second adaptive filter have converged when a preset duration of time has expired.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00014" num="00014">
<div class="claim-text">14. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:
<div class="claim-text">determining a first frequency distribution of the first audio signal;</div>
<div class="claim-text">determining a second frequency distribution of the second audio signal;</div>
<div class="claim-text">determining that the first frequency distribution exceeds a threshold distribution parameter;</div>
<div class="claim-text">determining that the second frequency distribution exceeds the threshold distribution parameter; and</div>
<div class="claim-text">cause the first filter coefficients and the second filter coefficients to reconverge.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00015" num="00015">
<div class="claim-text">15. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:
<div class="claim-text">determining a first frequency distribution of the first audio signal;</div>
<div class="claim-text">determining a second frequency distribution of the second audio signal;</div>
<div class="claim-text">determining that the first frequency distribution exceeds a threshold distribution parameter;</div>
<div class="claim-text">determining that the second frequency distribution exceeds the threshold distribution parameter;</div>
<div class="claim-text">determining that the first audio signal and the second audio signal are decorrelated with each other using the first frequency distribution and second frequency distribution;</div>
<div class="claim-text">configuring the first adaptive filter to further adapt the first filter coefficients to reconverge;</div>
<div class="claim-text">configuring the second adaptive filter to further adapt the second filter coefficients to reconverge;</div>
<div class="claim-text">determining that the first adaptive filter has reconverged;</div>
<div class="claim-text">determine that the second adaptive filter has reconverged; and</div>
<div class="claim-text">disabling the adapting of the first and second filter coefficients after the first and second adaptive filters are determined to have reconverged.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00016" num="00016">
<div class="claim-text">16. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, wherein the first, second, and third adaptive filters apply a least mean squares (LMS) or a stochastic gradient algorithm to adapt their respective filter coefficients.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00017" num="00017">
<div class="claim-text">17. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:
<div class="claim-text">receiving the first audio signal;</div>
<div class="claim-text">receiving the second audio signal;</div>
<div class="claim-text">transmitting the first audio signal to a first sound reproduction device;</div>
<div class="claim-text">transmitting the second audio signal to a second sound reproduction device;</div>
<div class="claim-text">receiving, from a microphone, a detected signal including representation of a first portion of the first audio signal and a representation of a second portion of the second audio signal;</div>
<div class="claim-text">determining a sum of the first estimated signal output and the second estimated signal output;</div>
<div class="claim-text">subtracting the sum from the detected signal to determine an output signal; and</div>
<div class="claim-text">adapting first filter coefficients of the first adaptive filter and second filter coefficients of the second adaptive filter to converge.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00018" num="00018">
<div class="claim-text">18. The method of <claim-ref idref="CLM-00017">claim 17</claim-ref>, further comprising:
<div class="claim-text">determining a stability of a function of the output signal; and</div>
<div class="claim-text">determining that the first adaptive filter and the second adaptive filter have converged based on the stability of the function of the first output signal.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00019" num="00019">
<div class="claim-text">19. The method of <claim-ref idref="CLM-00011">claim 11</claim-ref>, further comprising:
<div class="claim-text">determining a quality metric characterizing the audio output signal;</div>
<div class="claim-text">determining that the quality metric does not satisfy a quality threshold value;</div>
<div class="claim-text">configuring the first adaptive filter to further adapt the first filter coefficients and the second filter coefficients to reconverge;</div>
<div class="claim-text">determining that the first adaptive filter and the second adaptive filter have reconverged; and</div>
<div class="claim-text">disabling the adapting of the first and second filter coefficients after the first and second adaptive filters are determined to have reconverged.</div>
</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00020" num="00020">
<div class="claim-text">20. The method of <claim-ref idref="CLM-00019">claim 19</claim-ref>, wherein the quality metric is based on an echo return loss enhancement (ERLE) for the audio output signal or an amount of time it takes the third adaptive filter to reconverge the function of the audio output signal after convergence is lost.</div>
</div>
</div> </div>
</div>
</section>
                </article>
            </search-app>
        </body>
    </html>
    