
    <html>
        <body>
            <search-app>
                <article class="result" itemscope="" itemtype="http://schema.org/ScholarlyArticle">
    <h1 itemprop="pageTitle">US20210129340A1 - End effectors in robotic systems 
      - Google Patents</h1><section itemprop="abstract" itemscope="">
<h2>Abstract</h2>
<div html="" itemprop="content"><abstract lang="EN" load-source="patent-office" mxw-id="PA445447957">
<div class="abstract" id="p-0001" num="0000">Disclosed herein are embodiments related to end effectors in robotic systems. For example, an end effector for a robotic apparatus may be couplable to the robotic apparatus, and the end effector may include a communication port for coupling to the robotic apparatus, a camera, and a lighting device, wherein a lighting color of the lighting device is controllable via the communication port.</div>
</abstract>
</div>
</section><section itemprop="description" itemscope="">
<h2>Description</h2>
<div html="" itemprop="content"><ul class="description" lang="EN" load-source="patent-office" mxw-id="PDES291888214">
<heading id="h-0001">BACKGROUND</heading>
<li> <para-num num="[0001]"> </para-num> <div class="description-line" id="p-0002" num="0001">Conventional robotic systems employed in commercial settings are typically custom-built for a particular task. The development of such systems requires significant cost and time, and retooling or otherwise changing such systems incurs further expense and delays. The time and cost of development and retooling may be increased yet further as the tasks performed become more complex, limiting the adoption of robotic solutions to commercial problems.</div>
</li> <description-of-drawings>
<heading id="h-0002">BRIEF DESCRIPTION OF THE DRAWINGS</heading>
<li> <para-num num="[0002]"> </para-num> <div class="description-line" id="p-0003" num="0002">Embodiments will be readily understood by the following detailed description in conjunction with the accompanying drawings. To facilitate this description, like reference numerals designate like structural elements. Embodiments are illustrated by way of example, not by way of limitation, in the figures of the accompanying drawings.</div>
</li> <li> <para-num num="[0003]"> </para-num> <div class="description-line" id="p-0004" num="0003"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a block diagram of a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0004]"> </para-num> <div class="description-line" id="p-0005" num="0004"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a block diagram of example hardware that may be included in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0005]"> </para-num> <div class="description-line" id="p-0006" num="0005"> <figref idrefs="DRAWINGS">FIGS. 3-5</figref> are perspective views of example robotic apparatuses that may be included in the robotic systems disclosed herein, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0006]"> </para-num> <div class="description-line" id="p-0007" num="0006"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a side, cross-sectional view of the robotic apparatus of <figref idrefs="DRAWINGS">FIG. 5</figref>, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0007]"> </para-num> <div class="description-line" id="p-0008" num="0007"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a block diagram of example control logic that may be included in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0008]"> </para-num> <div class="description-line" id="p-0009" num="0008"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a block diagram of example task logic that may be included in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0009]"> </para-num> <div class="description-line" id="p-0010" num="0009"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a block diagram of example joint elements that may be included in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0010]"> </para-num> <div class="description-line" id="p-0011" num="0010"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a side, cross-sectional view of an example instance of the robotic apparatus of <figref idrefs="DRAWINGS">FIG. 6</figref>, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0011]"> </para-num> <div class="description-line" id="p-0012" num="0011"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a block diagram of logic elements that may be part of joint-level compute hardware, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0012]"> </para-num> <div class="description-line" id="p-0013" num="0012"> <figref idrefs="DRAWINGS">FIG. 12</figref> depicts a stepper motor that may be included in a joint of a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0013]"> </para-num> <div class="description-line" id="p-0014" num="0013"> <figref idrefs="DRAWINGS">FIG. 13</figref> depicts an example motor drive arrangement that may be included in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0014]"> </para-num> <div class="description-line" id="p-0015" num="0014"> <figref idrefs="DRAWINGS">FIG. 14</figref> illustrates a diametric magnet that may be included in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0015]"> </para-num> <div class="description-line" id="p-0016" num="0015"> <figref idrefs="DRAWINGS">FIG. 15</figref> is a flow diagram of an example method of calibrating a motor in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0016]"> </para-num> <div class="description-line" id="p-0017" num="0016"> <figref idrefs="DRAWINGS">FIG. 16</figref> depicts an example data structure that may be used to calibrate a motor in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0017]"> </para-num> <div class="description-line" id="p-0018" num="0017"> <figref idrefs="DRAWINGS">FIG. 17</figref> is a flow diagram of an example open-loop method of driving a motor in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0018]"> </para-num> <div class="description-line" id="p-0019" num="0018"> <figref idrefs="DRAWINGS">FIG. 18</figref> is a flow diagram of an example closed-loop method of driving a motor in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0019]"> </para-num> <div class="description-line" id="p-0020" num="0019"> <figref idrefs="DRAWINGS">FIG. 19</figref> illustrates conventional and increased-torque drive currents over a step cycle for different phases of a stepper motor that may be used in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0020]"> </para-num> <div class="description-line" id="p-0021" num="0020"> <figref idrefs="DRAWINGS">FIG. 20</figref> depicts an example data structure that may be used to determine drive currents for different phases of a stepper motor in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0021]"> </para-num> <div class="description-line" id="p-0022" num="0021"> <figref idrefs="DRAWINGS">FIG. 21</figref> is a flow diagram of an example method of driving a motor in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0022]"> </para-num> <div class="description-line" id="p-0023" num="0022"> <figref idrefs="DRAWINGS">FIG. 22</figref> is an example of driver phase control circuitry that may be used in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0023]"> </para-num> <div class="description-line" id="p-0024" num="0023"> <figref idrefs="DRAWINGS">FIGS. 23-24</figref> illustrate example motor drive arrangements that may be included in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0024]"> </para-num> <div class="description-line" id="p-0025" num="0024"> <figref idrefs="DRAWINGS">FIG. 25</figref> illustrates H-bridge circuit elements that may be included in a motor drive arrangement in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0025]"> </para-num> <div class="description-line" id="p-0026" num="0025"> <figref idrefs="DRAWINGS">FIGS. 26 and 27</figref> illustrate example motor drive arrangements that may be included in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0026]"> </para-num> <div class="description-line" id="p-0027" num="0026"> <figref idrefs="DRAWINGS">FIG. 28</figref> is a flow diagram of a method of braking in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0027]"> </para-num> <div class="description-line" id="p-0028" num="0027"> <figref idrefs="DRAWINGS">FIG. 29</figref> is a flow diagram of an example method of enabling motor drive and braking in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0028]"> </para-num> <div class="description-line" id="p-0029" num="0028"> <figref idrefs="DRAWINGS">FIG. 30</figref> is a flow diagram of a method of detecting joint-level faults in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0029]"> </para-num> <div class="description-line" id="p-0030" num="0029"> <figref idrefs="DRAWINGS">FIG. 31</figref> is a flow diagram of a method of responding to faults in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0030]"> </para-num> <div class="description-line" id="p-0031" num="0030"> <figref idrefs="DRAWINGS">FIG. 32</figref> is a flow diagram of a method of utilizing visual indicators at a joint in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0031]"> </para-num> <div class="description-line" id="p-0032" num="0031"> <figref idrefs="DRAWINGS">FIG. 33</figref> is a flow diagram of a method of zeroing joints in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0032]"> </para-num> <div class="description-line" id="p-0033" num="0032"> <figref idrefs="DRAWINGS">FIG. 34</figref> is a flow diagram of a method of zeroing an individual joint in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0033]"> </para-num> <div class="description-line" id="p-0034" num="0033"> <figref idrefs="DRAWINGS">FIG. 35</figref> is a side view of an example robotic apparatus in a calibration setting, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0034]"> </para-num> <div class="description-line" id="p-0035" num="0034"> <figref idrefs="DRAWINGS">FIG. 36</figref> is a top view of an example reference structure for use in calibrating a robotic apparatus, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0035]"> </para-num> <div class="description-line" id="p-0036" num="0035"> <figref idrefs="DRAWINGS">FIG. 37</figref> is a side view of an example robotic apparatus during calibration, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0036]"> </para-num> <div class="description-line" id="p-0037" num="0036"> <figref idrefs="DRAWINGS">FIG. 38</figref> is a flow diagram of a method of calibrating a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0037]"> </para-num> <div class="description-line" id="p-0038" num="0037"> <figref idrefs="DRAWINGS">FIG. 39</figref> is a flow diagram of a method of error-correction in driving joints of a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0038]"> </para-num> <div class="description-line" id="p-0039" num="0038"> <figref idrefs="DRAWINGS">FIG. 40</figref> is a flow diagram of a method of establishing allowable operational conditions for a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0039]"> </para-num> <div class="description-line" id="p-0040" num="0039"> <figref idrefs="DRAWINGS">FIG. 41</figref> is a flow diagram of a method of detecting faults in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0040]"> </para-num> <div class="description-line" id="p-0041" num="0040"> <figref idrefs="DRAWINGS">FIG. 42</figref> is a flow diagram of a method of generating an inspection path for a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0041]"> </para-num> <div class="description-line" id="p-0042" num="0041"> <figref idrefs="DRAWINGS">FIG. 43</figref> is an example data structure that may be used to define an inspection path of a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0042]"> </para-num> <div class="description-line" id="p-0043" num="0042"> <figref idrefs="DRAWINGS">FIG. 44</figref> is an example data structure that may be used as part of defining an inspection path of the robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0043]"> </para-num> <div class="description-line" id="p-0044" num="0043"> <figref idrefs="DRAWINGS">FIG. 45</figref> is a flow diagram of a method of generating an inspection path for a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0044]"> </para-num> <div class="description-line" id="p-0045" num="0044"> <figref idrefs="DRAWINGS">FIGS. 46-53</figref> are examples of graphical user interfaces that may be used to generate an inspection path for a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0045]"> </para-num> <div class="description-line" id="p-0046" num="0045"> <figref idrefs="DRAWINGS">FIG. 54</figref> is a flow diagram of a method of performing an inspection, by a robotic system, in accordance with an inspection path, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0046]"> </para-num> <div class="description-line" id="p-0047" num="0046"> <figref idrefs="DRAWINGS">FIG. 55</figref> is an example data structure that may be used as part of an inspection performed by a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0047]"> </para-num> <div class="description-line" id="p-0048" num="0047"> <figref idrefs="DRAWINGS">FIG. 56</figref> is a flow diagram of a method of robot-aided inspection, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0048]"> </para-num> <div class="description-line" id="p-0049" num="0048"> <figref idrefs="DRAWINGS">FIGS. 57-60</figref> are examples of graphical user interfaces that may be used during robot-aided inspection, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0049]"> </para-num> <div class="description-line" id="p-0050" num="0049"> <figref idrefs="DRAWINGS">FIG. 61</figref> is a flow diagram of a method of training classifiers for use with a robot-aided inspection system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0050]"> </para-num> <div class="description-line" id="p-0051" num="0050"> <figref idrefs="DRAWINGS">FIG. 62</figref> is a perspective view of an example end effector that may be used in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0051]"> </para-num> <div class="description-line" id="p-0052" num="0051"> <figref idrefs="DRAWINGS">FIGS. 63-65</figref> are various views of an example end effector that may be used in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0052]"> </para-num> <div class="description-line" id="p-0053" num="0052"> <figref idrefs="DRAWINGS">FIGS. 66-69</figref> are side, cross-sectional views of example end effectors that may be used in a robotic system, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0053]"> </para-num> <div class="description-line" id="p-0054" num="0053"> <figref idrefs="DRAWINGS">FIGS. 70-72</figref> are block diagrams of example robotic systems in which any of the embodiments disclosed herein may be used.</div>
</li> </description-of-drawings>
<heading id="h-0003">DETAILED DESCRIPTION</heading>
<li> <para-num num="[0054]"> </para-num> <div class="description-line" id="p-0055" num="0054">Disclosed herein are embodiments related to end effectors in robotic systems. For example, an end effector for a robotic apparatus may be couplable to the robotic apparatus, and the end effector may include a communication port for coupling to the robotic apparatus, a camera, and a lighting device, wherein a lighting color of the lighting device is controllable via the communication port.</div>
</li> <li> <para-num num="[0055]"> </para-num> <div class="description-line" id="p-0056" num="0055">The robotic systems <b>100</b> disclosed herein may be used in a collaborative robotics environment. As used herein, “collaborative robotics” refers to settings in which human beings work alongside robots designed and operated to ensure human safety.</div>
</li> <li> <para-num num="[0056]"> </para-num> <div class="description-line" id="p-0057" num="0056">In the following detailed description, reference is made to the accompanying drawings that form a part hereof wherein like numerals designate like parts throughout, and in which is shown, by way of illustration, embodiments that may be practiced. It is to be understood that other embodiments may be utilized, and structural or logical changes may be made, without departing from the scope of the present disclosure. Therefore, the following detailed description is not to be taken in a limiting sense.</div>
</li> <li> <para-num num="[0057]"> </para-num> <div class="description-line" id="p-0058" num="0057">Various operations may be described as multiple discrete actions or operations in turn, in a manner that is most helpful in understanding the claimed subject matter. However, the order of description should not be construed as to imply that these operations are necessarily order dependent. In particular, these operations may not be performed in the order of presentation. Operations described may be performed in a different order from the described embodiment. Various additional operations may be performed, and/or described operations may be omitted in additional embodiments.</div>
</li> <li> <para-num num="[0058]"> </para-num> <div class="description-line" id="p-0059" num="0058">For the purposes of the present disclosure, the phrase “A and/or B” means (A), (B), or (A and B). For the purposes of the present disclosure, the phrase “A, B, and/or C” means (A), (B), (C), (A and B), (A and C), (B and C), or (A, B, and C). The drawings are not necessarily to scale. Although many of the drawings illustrate rectilinear structures with flat walls and right-angle corners, this is simply for ease of illustration, and actual devices made using these techniques will exhibit rounded corners, surface roughness, and other features.</div>
</li> <li> <para-num num="[0059]"> </para-num> <div class="description-line" id="p-0060" num="0059">The description uses the phrases “in an embodiment” or “in embodiments,” which may each refer to one or more of the same or different embodiments. Furthermore, the terms “comprising,” “including,” “having,” and the like, as used with respect to embodiments of the present disclosure, are synonymous. When used to describe a range of dimensions, the phrase “between X and Y” represents a range that includes X and Y.</div>
</li> <li> <para-num num="[0060]"> </para-num> <div class="description-line" id="p-0061" num="0060"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a block diagram of a robotic system <b>100</b>, in accordance with various embodiments. The robotic system <b>100</b> of <figref idrefs="DRAWINGS">FIG. 1</figref> may include hardware <b>102</b>, control logic <b>104</b>, and task logic <b>106</b>. The hardware <b>102</b> of a robotic system <b>100</b> may include one or more robotic apparatuses <b>101</b> (discussed further below with reference to <figref idrefs="DRAWINGS">FIG. 2</figref>) and hardware that supports the operation of the robotic apparatuses <b>101</b> and the performance of tasks by the robotic system <b>100</b>. The control logic <b>104</b> may include specialized circuitry and/or programmed instructions to be executed by one or more processing devices (e.g., included in the robotic apparatus <b>101</b> and/or the system-level compute hardware <b>124</b>, discussed further below) in order to control the operation of one or more robotic apparatuses <b>101</b> of the robotic system <b>100</b>. For example, the control logic <b>104</b> may include programmed instructions that, upon execution by one or more processing devices, control the motion and position of the joints <b>108</b> of a robotic apparatus <b>101</b>, as well as the operation of an end effector <b>118</b> of the robotic apparatus <b>101</b>; joints <b>108</b> and end effectors <b>118</b> of robotic apparatuses <b>101</b> are discussed further below. Particular examples of control logic <b>104</b> are discussed below with reference to <figref idrefs="DRAWINGS">FIG. 7</figref>. The task logic <b>106</b> may include specialized circuitry and/or programmed instructions to be executed by one or more processing devices (e.g., included in the robotic apparatus <b>101</b> and/or the system-level compute hardware <b>124</b>, discussed further below) in order to perform particular higher-level tasks that include operation of the robotic apparatus <b>101</b>. The task logic <b>106</b> may utilize the functionality of the control logic <b>104</b> in the execution of various tasks. For example, the task logic <b>106</b> may include programmed instructions that, upon execution by one or more processing devices, cause a robotic apparatus <b>101</b> to perform an inspection over a pre-defined inspection path. The task logic <b>106</b> may specify parameters of this inspection to the control logic <b>104</b>, which may “translate” these inspection parameters into specific commands to the components of the robotic apparatus <b>101</b> to cause the joints <b>108</b> and the end effector <b>118</b> of the robotic apparatus <b>101</b> to operate in a desired manner. Note that the division herein of various operations into “control logic <b>104</b>” and “task logic <b>106</b>” is largely illustrative, and any suitable specialized circuitry or programmed instructions may be used in the robotic systems <b>100</b> disclosed herein.</div>
</li> <li> <para-num num="[0061]"> </para-num> <div class="description-line" id="p-0062" num="0061"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a block diagram of example hardware <b>102</b> that may be included in a robotic system <b>100</b>, in accordance with various embodiments. The hardware <b>102</b> includes various hardware elements that are part of a robotic apparatus <b>101</b>. As used herein, a “robotic apparatus” may refer to a collection of movable components that may be controlled by computing logic to perform a particular physical task. Many examples of robotic apparatuses <b>101</b> are disclosed herein, including gantry-type robotic apparatuses <b>101</b> (e.g., as discussed below with reference to <figref idrefs="DRAWINGS">FIG. 3</figref>) and arm-type robotic apparatuses <b>101</b> (e.g., as discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 4-5</figref>). <figref idrefs="DRAWINGS">FIG. 2</figref> illustrates various elements of the hardware <b>102</b> (i.e., joints <b>108</b>, segments <b>110</b>, supports <b>112</b>, sensors <b>114</b>, mechanical brakes <b>116</b>, and end effectors <b>118</b>) as being part of a robotic apparatus <b>101</b>, but this indication of particular hardware as being included in or not included in a robotic apparatus <b>101</b> is simply exemplary, and a robotic apparatus <b>101</b> may not include all of the elements illustrated in <figref idrefs="DRAWINGS">FIG. 2</figref> and/or may include other hardware elements. For example, a robotic apparatus <b>101</b> may not include any mechanical brakes <b>116</b>. In another example, a robotic apparatus <b>101</b> may include one or more input/output (I/O) devices <b>120</b>, in addition to or instead of those included in the joints <b>108</b> (discussed below with reference to <figref idrefs="DRAWINGS">FIG. 9</figref>). In some embodiments, all of the hardware <b>102</b> of a robotic system <b>100</b> may be part of a robotic apparatus <b>101</b>, while in other embodiments, a robotic apparatus <b>101</b> may communicate with the other hardware <b>102</b> of a robotic system <b>100</b> by wired and/or wireless communication pathways.</div>
</li> <li> <para-num num="[0062]"> </para-num> <div class="description-line" id="p-0063" num="0062">As indicated in <figref idrefs="DRAWINGS">FIG. 2</figref>, a robotic apparatus <b>101</b> may include segments <b>110</b> and supports <b>112</b>. As used herein, a support <b>112</b> may represent a portion of a robotic apparatus <b>101</b> on which the robotic apparatus <b>101</b> rests or is used to couple the robotic apparatus <b>101</b> to a surface (e.g., to a wall). A segment <b>110</b> may represent a portion of the robotic apparatus <b>101</b> between joints <b>108</b>, or on around which a joint <b>108</b> moves; the number of joints <b>108</b> in a robotic apparatus <b>101</b> represents the degrees of freedom (DOF) of the robotic apparatus <b>101</b>. Sensors <b>114</b> included in a robotic apparatus <b>101</b> may include sensors at the joints <b>108</b> (examples of which are discussed further below with reference to <figref idrefs="DRAWINGS">FIG. 9</figref>, or sensors located in the segments <b>110</b> or supports <b>112</b> (e.g., an accelerometer located in the support <b>112</b> for use in zeroing, as discussed further below with reference to <figref idrefs="DRAWINGS">FIGS. 33-34</figref>). An end effector <b>118</b> may be a component that may couple to a segment <b>110</b> of a robotic apparatus <b>101</b>, and may include any desired number of devices (e.g., cameras, lasers, depth sensors, object manipulators, etc.). End effectors <b>118</b> may be removable so that different end effectors <b>118</b> may be coupled to the remainder of the robotic apparatus <b>101</b> to enable different tasks to be performed (e.g., calibration, inspection, and object manipulation, as discussed further herein).</div>
</li> <li> <para-num num="[0063]"> </para-num> <div class="description-line" id="p-0064" num="0063">The hardware <b>102</b> may include one or more I/O devices <b>120</b>. The I/O devices <b>120</b> may include input and/or output devices not included in the joints <b>108</b>. Examples of I/O devices <b>120</b> may include user-actuable power switches, a heads-up display, a computer monitor, a projector, a touchscreen display, a liquid crystal display (LCD), a light-emitting diode display, lasers, a flat panel display, speakers, headsets, earbuds, microphones, microphone arrays, or digital instruments (e.g., instruments having a musical instrument digital interface (MIDI) output), accelerometer, a gyroscope, a compass, an image capture device, a keyboard, a cursor control device such as a mouse, a stylus, a touchpad, a bar code reader, a Quick Response (QR) code reader, any sensor, and/or a radio frequency identification (RFID) reader.</div>
</li> <li> <para-num num="[0064]"> </para-num> <div class="description-line" id="p-0065" num="0064">The hardware <b>102</b> may include power circuitry <b>122</b>. The power circuitry <b>122</b> may include one or more energy storage devices (e.g., batteries or capacitors) and/or circuitry for coupling components of the robotic system <b>100</b> to an energy source separate from the robotic system <b>100</b> (e.g., AC line power). In some embodiments, the power demand of the robotic system <b>100</b> may be low enough to be supplied by a battery pack (e.g., a 36 volt scooter battery or a car battery), and thus the robotic systems <b>100</b> disclosed herein may be readily implemented on an untethered base, such as a cart, drone, or other vehicle. Such operation represents a significant contrast with conventional industrial robotic systems, which typically require a 240 volt power supply for operation. In some embodiments, the robotic system <b>100</b> may be run at 36 volts or more, but may be run from as low as 12 volts.</div>
</li> <li> <para-num num="[0065]"> </para-num> <div class="description-line" id="p-0066" num="0065">The hardware <b>102</b> may include system-level compute hardware <b>124</b>. The system-level compute hardware <b>124</b> may include one or more processing devices that enable the execution of system-level tasks (e.g., those controlled by the task logic <b>106</b>, discussed below). The joints <b>108</b> may be exposed to the system-level compute hardware <b>124</b> by an Application Programming Interface (API) that allows the system-level compute hardware <b>124</b> to read/write parameters in the joint-level data storage <b>229</b> (e.g., parameters stored in Flash memory such as joint name, gear ratio, control thresholds, control loop tuning parameters, etc., and/or control parameters such as control mode, goal points, etc.), as well as setting the state of the light-emitting diodes (LEDs) <b>220</b> at a joint <b>108</b> and setting general purpose input/output (GPIO) values (e.g., reading a pin, setting a pin, setting a frequency and duty cycle of pulse width modulation (PWM), etc.) for processing devices (e.g., a microcontroller) of the joint-level compute hardware <b>210</b>. The system-level compute hardware <b>124</b> may be local to the robotic apparatus <b>101</b>, remote from the robotic apparatus <b>101</b>, or may include both local and remote processing devices. Examples of the system-level compute hardware <b>124</b>, and arrangements thereof, are discussed further herein (e.g., with reference to <figref idrefs="DRAWINGS">FIGS. 70-72</figref>).</div>
</li> <li> <para-num num="[0066]"> </para-num> <div class="description-line" id="p-0067" num="0066">The hardware <b>102</b> may include communications hardware <b>128</b>. The communications hardware <b>128</b> may facilitate communications between the system-level compute hardware <b>124</b> and the joints <b>108</b>/end effectors <b>118</b> of one or more robotic apparatuses <b>101</b>, and/or between the robotic system <b>100</b> and the outside world. In some embodiments, the communications hardware <b>128</b> may manage the transfer of a packet of data from each of the joints <b>108</b> in a robotic apparatus <b>101</b> to the system-level compute hardware <b>124</b> at a rate that is greater than 1 kilohertz; this data may represent a current state of the joint <b>108</b>, and examples of this data are discussed further below. In some embodiments, the communications hardware <b>128</b> may include a Universal Serial Bus (USB) interface which may couple to a USB backbone of the robotic apparatus <b>101</b>, as discussed above. In other embodiments, the communications hardware <b>128</b> may support communication with a robotic apparatus <b>101</b> with a Controller Area Network (CAN) bus, an RS-485 bus, a Serial Peripheral Interface (SPI) bus, an Inter-Integrated Circuit (I2C) bus, or an RS-232 bus, for example.</div>
</li> <li> <para-num num="[0067]"> </para-num> <div class="description-line" id="p-0068" num="0067">The hardware <b>102</b> may include system-level data storage <b>150</b>. The system-level data storage <b>150</b> may include one or more memory devices used to store data and/or instructions executable by one or more processing devices to perform any suitable ones of the methods disclosed herein (e.g., with such stored instructions providing any suitable ones of the logic described herein). In some embodiments, the memory devices included in the system-level data storage <b>150</b> may include random access memory (RAM) devices, such as a static RAM (SRAM) devices, magnetic RAM (MRAM) devices, resistive RAM (RRAM) devices, or conductive-bridging RAM (CBRAM) devices, hard drive-based memory devices, solid state memory devices, or any combination of memory devices. The memory devices included in the system-level data storage <b>150</b> may not be local to each other, or the system-level compute hardware <b>124</b> (e.g., as discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 70-72</figref>).</div>
</li> <li> <para-num num="[0068]"> </para-num> <div class="description-line" id="p-0069" num="0068"> <figref idrefs="DRAWINGS">FIGS. 3-5</figref> are perspective views of example robotic apparatuses <b>101</b> that may be included in the robotic systems <b>100</b> disclosed herein, in accordance with various embodiments. As discussed further below with reference to <figref idrefs="DRAWINGS">FIGS. 70 and 71</figref>, a robotic system <b>100</b> may include more than one robotic apparatus <b>101</b>. Further, the particular robotic apparatuses <b>101</b> illustrated in the accompanying figures are simply examples, and any robotic apparatus <b>101</b> implementing any one or more of the embodiments disclosed herein may be part of a robotic system <b>100</b>.</div>
</li> <li> <para-num num="[0069]"> </para-num> <div class="description-line" id="p-0070" num="0069"> <figref idrefs="DRAWINGS">FIG. 3</figref> illustrates a gantry-type robotic apparatus <b>101</b>. The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 3</figref> includes a support <b>112</b> including tracks along which joints <b>108</b>-<b>1</b> of a segment <b>110</b>-<b>1</b> may move (in the x-direction, in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 3</figref>). The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 3</figref> also includes segments <b>110</b>-<b>2</b> acting as tracks along which joints <b>108</b>-<b>2</b> (coupled to a segment <b>110</b>-<b>3</b>) may move (in the z-direction, in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 3</figref>). The robotic apparatus of <figref idrefs="DRAWINGS">FIG. 3</figref> also includes a joint <b>108</b>-<b>3</b> (located on the underside of the segment <b>110</b>-<b>3</b>), which may be coupled to a segment <b>110</b>-<b>4</b> and may allow the segment <b>110</b>-<b>4</b> to move along the segment <b>110</b>-<b>3</b> (in the y-direction, in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 3</figref>). An end effector <b>118</b> may be coupled to the segment <b>110</b>-<b>4</b>. The end effector <b>118</b> may take any desired form (e.g., the form of any of the embodiments discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 62-69</figref>). Control of the joints <b>108</b> of the robotic apparatus <b>101</b> may allow the end effector <b>118</b> to be placed in a desired location relative to the segment <b>110</b>-<b>1</b>, and control of the end effector <b>118</b> may allow the robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 3</figref> to manipulate, inspect, or otherwise act with respect to an item disposed on the segment <b>110</b>-<b>1</b>. Because of its three controllable joints <b>108</b>, the gantry-type robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 3</figref> is an example of a three DOF robotic apparatus <b>101</b>.</div>
</li> <li> <para-num num="[0070]"> </para-num> <div class="description-line" id="p-0071" num="0070"> <figref idrefs="DRAWINGS">FIG. 4</figref> illustrates an arm-type robotic apparatus <b>101</b>. The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 4</figref> includes a support <b>112</b>, a segment <b>110</b>-<b>1</b>, and a joint <b>108</b>-<b>1</b> between the support <b>112</b> and the segment <b>110</b>-<b>1</b>. The joint <b>108</b>-<b>1</b> may be configured for rotation in the x-y plane (in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 4</figref>), allowing the segment <b>110</b>-<b>1</b> to rotate relative to the support <b>112</b>. The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 4</figref> further includes a segment <b>110</b>-<b>2</b> and a joint <b>108</b>-<b>2</b> between the segment <b>110</b>-<b>1</b> and the segment <b>110</b>-<b>2</b>. The joint <b>108</b>-<b>2</b> may be configured for rotation in the x-z plane (in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 4</figref>), allowing the segment <b>110</b>-<b>2</b> to move through the x-z plane. The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 4</figref> further includes a segment <b>110</b>-<b>3</b> and a joint <b>108</b>-<b>3</b> between the segment <b>110</b>-<b>2</b> and the segment <b>110</b>-<b>3</b>. The joint <b>108</b>-<b>3</b> may be configured for rotation in the x-z plane (in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 4</figref>), allowing the segment <b>110</b>-<b>3</b> to move through the x-z plane. The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 4</figref> further includes a segment <b>110</b>-<b>4</b> and a joint <b>108</b>-<b>4</b> between the segment <b>110</b>-<b>3</b> and the segment <b>110</b>-<b>4</b>. The joint <b>108</b>-<b>4</b> may be configured for rotation in the x-z plane (in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 4</figref>), allowing the segment <b>110</b>-<b>4</b> to move through the x-z plane. The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 4</figref> further includes a segment <b>110</b>-<b>5</b> and a joint <b>108</b>-<b>5</b> between the segment <b>110</b>-<b>4</b> and the segment <b>110</b>-<b>5</b>. The joint <b>108</b>-<b>5</b> may be configured for rotation in the x-z plane (in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 4</figref>), allowing the segment <b>110</b>-<b>5</b> to move through the x-z plane. The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 4</figref> further includes a segment <b>110</b>-<b>6</b> and a joint <b>108</b>-<b>6</b> between the segment <b>110</b>-<b>5</b> and the segment <b>110</b>-<b>6</b>. The joint <b>108</b>-<b>6</b> may be configured for rotation in the x-z plane (in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 4</figref>), allowing the segment <b>110</b>-<b>6</b> to move through the x-z plane. An end effector <b>118</b> may be coupled to the segment <b>110</b>-<b>6</b>. The end effector <b>118</b> may take any desired form (e.g., the form of any of the embodiments discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 62-69</figref>). Control of the joints <b>108</b> of the robotic apparatus <b>101</b> may allow the end effector <b>118</b> to be placed in a desired location relative to the support <b>112</b>, which may itself be resting on a surface, such as a table or cart. Control of the end effector <b>118</b> may allow the robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 4</figref> to manipulate, inspect, or otherwise act with respect to an item disposed on the surface. Because of its six controllable joints, the arm-type robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 4</figref> is an example of a six DOF robotic apparatus <b>101</b>.</div>
</li> <li> <para-num num="[0071]"> </para-num> <div class="description-line" id="p-0072" num="0071"> <figref idrefs="DRAWINGS">FIG. 5</figref> illustrates an arm-type robotic apparatus <b>101</b>. The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 5</figref> includes a support <b>112</b>, a segment <b>110</b>-<b>1</b>, and a joint <b>108</b>-<b>1</b> between the support <b>112</b> and the segment <b>110</b>-<b>1</b>. The joint <b>108</b>-<b>1</b> may be configured for rotation in the x-y plane (in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 4</figref>), allowing the segment <b>110</b>-<b>1</b> to rotate relative to the support <b>112</b>. The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 5</figref> further includes a segment <b>110</b>-<b>2</b> and a joint <b>108</b>-<b>2</b> (hidden by the segment <b>110</b>-<b>1</b>) between the segment <b>110</b>-<b>1</b> and the segment <b>110</b>-<b>2</b>. The joint <b>108</b>-<b>2</b> may be configured for rotation in the x-z plane (in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 5</figref>), allowing the segment <b>110</b>-<b>2</b> to rotate in the x-z plane. The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 5</figref> further includes a segment <b>110</b>-<b>3</b> and a joint <b>108</b>-<b>3</b> between the segment <b>110</b>-<b>2</b> and the segment <b>110</b>-<b>3</b>. The joint <b>108</b>-<b>3</b> may be configured for rotation in the x-z plane (in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 5</figref>), allowing the segment <b>110</b>-<b>3</b> to rotate in the x-z plane. The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 5</figref> further includes a segment <b>110</b>-<b>4</b> and a joint <b>108</b>-<b>4</b> between the segment <b>110</b>-<b>3</b> and the segment <b>110</b>-<b>4</b>. The joint <b>108</b>-<b>4</b> may be configured for rotation in the y-z plane (approximately, in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 5</figref>), allowing the segment <b>110</b>-<b>4</b> to rotate in the y-z plane (approximately). The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 5</figref> further includes a segment <b>110</b>-<b>5</b> and a joint <b>108</b>-<b>5</b> between the segment <b>110</b>-<b>4</b> and the segment <b>110</b>-<b>5</b>. The joint <b>108</b>-<b>5</b> may be configured for rotation in the x-z plane (in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 4</figref>), allowing the segment <b>110</b>-<b>5</b> to rotate in the x-z plane. The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 5</figref> further includes a segment <b>110</b>-<b>6</b> and a joint <b>108</b>-<b>6</b> between the segment <b>110</b>-<b>5</b> and the segment <b>110</b>-<b>6</b>. The joint <b>108</b>-<b>6</b> may be configured for rotation in the y-z plane (in accordance with the coordinate system illustrated in <figref idrefs="DRAWINGS">FIG. 5</figref>), allowing the segment <b>110</b>-<b>6</b> to rotate in the x-z plane. An end effector <b>118</b> may be coupled to the segment <b>110</b>-<b>6</b>. The end effector <b>118</b> may take any desired form (e.g., the form of any of the embodiments discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 62-69</figref>). Control of the joints <b>108</b> of the robotic apparatus <b>101</b> may allow the end effector <b>118</b> to be placed in a desired location relative to the support <b>112</b>, which may itself be resting on a surface, such as a table or cart. Control of the end effector <b>118</b> may allow the robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 5</figref> to manipulate, inspect, or otherwise act with respect to an item disposed on the surface. Because of its six controllable joints, the arm-type robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 5</figref> is an example of a six DOF robotic apparatus <b>101</b>. <figref idrefs="DRAWINGS">FIG. 6</figref> is a side, cross-sectional view of the robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 5</figref>, with the joints <b>108</b> indicated by asterisks. The axis of rotation <b>126</b> of each of the joints <b>108</b> is also indicated.</div>
</li> <li> <para-num num="[0072]"> </para-num> <div class="description-line" id="p-0073" num="0072"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a block diagram of example control logic <b>104</b> that may be included in a robotic system <b>100</b>, in accordance with various embodiments. The control logic <b>104</b> may include logic implemented at the joint level (e.g., by the joint-level compute hardware <b>210</b>) and logic implemented at the system level (e.g., by the system-level compute hardware <b>124</b>). The control logic <b>104</b> may provide for basic operational control of a robotic apparatus <b>101</b>, and functions of the control logic <b>104</b> may be used by the task logic <b>106</b> in the performance of specific tasks (e.g., inspection), as discussed further below.</div>
</li> <li> <para-num num="[0073]"> </para-num> <div class="description-line" id="p-0074" num="0073">The control logic <b>104</b> may include motion/position logic <b>132</b>. The motion/position logic <b>132</b> may control the motion and position of each of the joints <b>108</b> of a robotic apparatus <b>101</b>. For example, the motion/position logic <b>132</b> may include the motor drive logic <b>230</b> and the braking logic <b>234</b> implemented by the joint-level compute hardware <b>210</b>. The motion/position logic <b>132</b> may receive a command (e.g., from the task logic <b>106</b>) to move the robotic apparatus <b>101</b> to a particular position (e.g., a particular (x, y, z, roll (r), pitch (p), yaw (w)) position of an end effector <b>118</b> of the robotic apparatus) and may generate instructions for the motor drive logic <b>230</b> and/or the braking logic <b>234</b> of the joints <b>108</b> to implement the command. Examples of techniques that may be implemented by the motion/position logic <b>132</b> are discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 17-28</figref> and <figref idrefs="DRAWINGS">FIG. 39</figref>.</div>
</li> <li> <para-num num="[0074]"> </para-num> <div class="description-line" id="p-0075" num="0074">The control logic <b>104</b> may include calibration logic <b>134</b>. The calibration logic <b>134</b> may control joint-level and system-level calibration operations in the robotic system <b>100</b>. For example, the calibration logic <b>134</b> may include the joint calibration logic <b>232</b>, and examples of joint-level calibration techniques are discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 13-16</figref>. Further, the calibration logic <b>134</b> may perform system-level calibration techniques, such as those discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 35-38</figref>. The calibration techniques disclosed herein may be used to achieve high accuracy and controllability with relatively inexpensive and inaccurate hardware (e.g., inexpensive stepper motors <b>212</b>), enabling the robotic systems <b>100</b> disclosed herein to be utilized in settings in which robotic support was previously cost-prohibitive.</div>
</li> <li> <para-num num="[0075]"> </para-num> <div class="description-line" id="p-0076" num="0075">The control logic <b>104</b> may include safety logic <b>136</b>. The safety logic <b>136</b> may control joint-level and system-level safety operations in the robotic system <b>100</b>. For example, the safety logic <b>136</b> may include the joint safety logic <b>236</b>, and examples of joint-level safety techniques are discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 30-31</figref>. Further, the safety logic <b>136</b> may perform system-level safety techniques, such as those discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 40-41</figref>.</div>
</li> <li> <para-num num="[0076]"> </para-num> <div class="description-line" id="p-0077" num="0076">The control logic <b>104</b> may include end effector logic <b>142</b>. The end effector logic <b>142</b> may control operation of one or more devices of the end effector <b>118</b> of a robotic apparatus <b>101</b>. For example, the end effector logic <b>142</b> may control the operation of a camera, laser, depth sensor, object manipulator, electrical probe, display, and/or other device included in an end effector <b>118</b>. The operation of the device(s) of an end effector <b>118</b> may be controlled by the end effector logic <b>142</b> in accordance with commands from the task logic <b>106</b> (e.g., in accordance with an inspection process controlled by inspection logic <b>160</b>, discussed below).</div>
</li> <li> <para-num num="[0077]"> </para-num> <div class="description-line" id="p-0078" num="0077">The control logic <b>104</b> may include I/O device logic <b>144</b>. The I/O device logic <b>144</b> may control operation of one or more I/O devices <b>120</b> of the robotic system <b>100</b>. For example, the I/O device logic <b>144</b> may include drivers for any of the I/O devices <b>120</b> discussed above. The operation of the I/O devices <b>120</b> may be controlled by the I/O device logic <b>144</b> in accordance with commands from the task logic <b>106</b> (e.g., in accordance with an inspection process controlled by inspection logic <b>160</b>, discussed below).</div>
</li> <li> <para-num num="[0078]"> </para-num> <div class="description-line" id="p-0079" num="0078">The control logic <b>104</b> may include zeroing logic <b>148</b>. The zeroing logic <b>148</b> may work in conjunction with the motion/position logic <b>132</b> to bring the robotic apparatus <b>101</b> into a zeroed configuration, as discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 33 and 34</figref>. The robotic apparatus <b>101</b> may be brought into a zeroed configuration upon startup so that the movement of the robotic apparatus <b>101</b> may be controlled and monitored from a known start position, and/or brought into a zeroed configuration during operation (e.g., between inspection sessions).</div>
</li> <li> <para-num num="[0079]"> </para-num> <div class="description-line" id="p-0080" num="0079"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a block diagram of example task logic <b>106</b> that may be included in a robotic system <b>100</b>, in accordance with various embodiments. The task logic <b>106</b> may include logic implemented at the joint level (e.g., by the joint-level compute hardware <b>210</b>) and logic implemented at the system level (e.g., by the system-level compute hardware <b>124</b>). The task logic <b>106</b> may control the performance of particular tasks by the robotic system <b>100</b>, and may utilize functions of the control logic <b>104</b> to perform these tasks.</div>
</li> <li> <para-num num="[0080]"> </para-num> <div class="description-line" id="p-0081" num="0080">The task logic <b>106</b> may include inspection logic <b>160</b>. The inspection logic <b>160</b> may enable the robotic system <b>100</b> to perform inspections of items in a manufacturing or other commercial setting. For example, the inspection logic <b>160</b> may enable the robotic system <b>100</b> to visually inspect multiple instances of items and utilize inspection functions (which may include, for example, computational classifiers) to facilitate a robotic or a robot-aided inspection process. Examples of inspection processes, and related devices and techniques, are discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 42-61</figref>. Further, although various ones of the inspection-related embodiments discussed below focus on visual inspection techniques, the systems and techniques disclosed herein may be utilized to perform other types of inspections or tests, such as electrical inspection (e.g., when the end effector <b>118</b> includes an electrical probe and other circuit testing equipment) or materials inspection (e.g., when the end effector <b>118</b> includes a tensile test apparatus).</div>
</li> <li> <para-num num="[0081]"> </para-num> <div class="description-line" id="p-0082" num="0081">The task logic <b>106</b> may include user interface logic <b>162</b>. The user interface logic <b>162</b> may facilitate the provision of user interfaces (e.g., graphical user interfaces (GUIs)) to a user of the robotic system <b>100</b> in order for the user to guide operation of the robotic system <b>100</b> and/or receive information about the robotic system <b>100</b> itself or the tasks performed by the robotic system <b>100</b>. The user interface logic <b>162</b> may provide a GUI to control and monitor an inspection process, for example; particular examples of such embodiments are discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 46-53 and 57-60</figref>. The user interface logic <b>162</b> may support other I/O devices <b>120</b> that may provide a user interface, such as alphanumeric displays, LEDs, microphones, speakers, etc.</div>
</li> <li> <para-num num="[0082]"> </para-num> <div class="description-line" id="p-0083" num="0082">The task logic <b>106</b> may include dimensional analysis logic <b>164</b>. The dimensional analysis logic <b>164</b> may utilize cameras in an end effector <b>118</b> of a robotic apparatus <b>101</b> to capture one or more images of an item, and analyze the images to determine the dimensions of the item (e.g., diameter, curvature, length, width, height of the overall item and/or features of the item, etc.). Information about those dimensions may be provided to a user (e.g., via a GUI of the user interface logic <b>162</b>). The dimensional analysis logic <b>164</b> may implement any suitable image processing techniques to perform this dimensional analysis, and examples of end effectors <b>118</b> including cameras that may be used to support such dimensional analysis are discussed below.</div>
</li> <li> <para-num num="[0083]"> </para-num> <div class="description-line" id="p-0084" num="0083">The task logic <b>106</b> may include object manipulation logic <b>166</b>. The object manipulation logic <b>166</b> may support the physical manipulation of objects in the environment of the robotic apparatus <b>101</b> by the robotic apparatus <b>101</b>. For example, the object manipulation logic <b>166</b> may control the use of an object manipulator <b>184</b> in the end effector <b>118</b> of a robotic apparatus to allow the object manipulator <b>184</b> to move an object (e.g., to rotate, translate, stack, or otherwise move an item during an inspection process, or for packaging an item before shipping). Examples of object manipulators <b>184</b> are discussed in detail below, and the object manipulation logic <b>166</b> may utilize the object manipulators <b>184</b> and other information (e.g., feedback from one or more cameras included in the end effector <b>118</b>) to effectively manipulate objects.</div>
</li> <li> <para-num num="[0084]"> </para-num> <div class="description-line" id="p-0085" num="0084">The task logic <b>106</b> may include voice command logic <b>170</b>. The voice command logic <b>170</b> may enable the robotic system <b>100</b> to recognize voice commands from users and utilize these voice commands to control the operation of the robotic system <b>100</b>. The voice command logic <b>170</b> may receive the output of one or more microphones included in the I/O devices <b>120</b> and may utilize any suitable voice recognition technique to identify whether the microphone output includes a predetermined voice command (whose signature may be stored in the system-level data storage <b>150</b>). The voice command logic <b>170</b> may then act on or route the command appropriately in order to execute operations associated with the command. Examples of a number of voice commands that may be recognized by the voice command logic <b>170</b> are discussed herein.</div>
</li> <li> <para-num num="[0085]"> </para-num> <div class="description-line" id="p-0086" num="0085"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a block diagram of example elements of a joint <b>108</b> that may be included in a robotic system <b>100</b>, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0086]"> </para-num> <div class="description-line" id="p-0087" num="0086">The joint <b>108</b> may include joint-level compute hardware <b>210</b>. The joint-level compute hardware <b>210</b> may include one or more processing devices local to a joint <b>108</b> (e.g., attached to one or more printed circuit boards (PCBs) proximate to the joint <b>108</b>) that help control operation of the joint <b>108</b>. In some embodiments, the joint-level compute hardware <b>210</b> may include a single microcontroller, or multiple microcontrollers. In some embodiments, the reference clocks (e.g., generated by the joint-level compute hardware <b>210</b>) controlling communication and operation within a single joint <b>108</b> may be independent from the reference clocks utilized at others of the joints <b>108</b>.</div>
</li> <li> <para-num num="[0087]"> </para-num> <div class="description-line" id="p-0088" num="0087">The joint <b>108</b> may include a motor <b>212</b>. In some embodiments, the motor <b>212</b> may be a stepper motor; particular embodiments of robotic apparatuses <b>101</b> that include stepper motors <b>212</b>, and methods of operating such robotic apparatuses <b>101</b>, are disclosed herein. Stepper motors have been conventionally considered to be too heavy and inaccurate for use in robotic systems; conventional robotic apparatuses typically utilize brushless motors driven by a strain-wave or cycloidal gearbox, which may achieve high accuracy, but at a high price. The expense of such conventional systems has limited the adoption of robotic systems in many settings in which it might be otherwise useful. Disclosed herein are arrangements and techniques for using stepper motors in robotic apparatuses <b>101</b> (e.g., for collaborative robotics); these arrangements and techniques overcome the hurdles conventionally associated with stepper motors, such as accuracy, to enable accurate, safe, and inexpensive stepper motor-based robots. As discussed below, various ones of the embodiments disclosed herein may utilize a closed-loop control scheme around the operation of the stepper motor <b>212</b>, a further step away from conventional robots.</div>
</li> <li> <para-num num="[0088]"> </para-num> <div class="description-line" id="p-0089" num="0088">The joint <b>108</b> may include a drivetrain <b>214</b>. The drivetrain <b>214</b> may be coupled to the motor <b>212</b> such that the output of a joint <b>108</b> is the output of the drivetrain <b>214</b>. The drivetrain <b>214</b> may have a gear ratio that is less than 30:1 (e.g., between 1:1 and 30:1, between 5:1 and 25:1, or between 10:1 and 25:1); a drivetrain <b>214</b> with such a gear ratio may be referred to herein as a “quasi-direct drivetrain.” Conventional drivetrains used in conventional robots typically utilize a gear ratio that is greater than 30:1 (e.g., 100:1 to 500:1) in conjunction with a brushless motor, as discussed above. Utilizing a quasi-direct drivetrain <b>214</b> may enable the motor <b>212</b> and the drivetrain <b>214</b> to be backdriven (e.g., an external force on the joint <b>108</b> will result in a measurable torque at the motor <b>212</b>, which can be recognized and controlled for), functionality not available in robots whose gear ratios are higher.</div>
</li> <li> <para-num num="[0089]"> </para-num> <div class="description-line" id="p-0090" num="0089">The joint <b>108</b> may include drive support circuitry <b>216</b>. The drive support circuitry <b>216</b> may include circuitry that supports the driving of the motor <b>212</b> of the joint <b>108</b>. Examples of drive support circuitry <b>216</b> are discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 23-27</figref>.</div>
</li> <li> <para-num num="[0090]"> </para-num> <div class="description-line" id="p-0091" num="0090">The joint <b>108</b> may include brake support circuitry <b>218</b>. The brake support circuitry <b>218</b> may include circuitry that supports the braking of the motor <b>212</b> of the joint <b>108</b>. In some embodiments in which a joint <b>108</b> includes mechanical brakes <b>116</b>, the brake support circuitry <b>218</b> may be coupled between the joint-level compute hardware <b>210</b> and the mechanical brakes <b>116</b>, and may selectively activate the mechanical brakes <b>116</b> to slow or stop the motion of the joint <b>108</b>. In embodiments in which a joint <b>108</b> does not include mechanical brakes <b>116</b> (or in embodiments in which other braking techniques may be used in addition to mechanical brakes <b>116</b>), the brake support circuitry <b>218</b> may selectively apply signals to the motor <b>212</b> to electrically brake the motor <b>212</b>; examples of such brake support circuitry <b>218</b> are discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 23-27</figref>.</div>
</li> <li> <para-num num="[0091]"> </para-num> <div class="description-line" id="p-0092" num="0091">The joint <b>108</b> may include LEDs <b>220</b>. The LEDs <b>220</b> may be mounted proximate to the joint <b>108</b> so that the light generated by an LED <b>220</b> when it is on is visible at an exterior surface of a housing of the robotic apparatus <b>101</b>. Further, although “the LEDs <b>220</b>” may be plural, a joint <b>108</b> may include a single LED. LEDs <b>220</b>, or other display devices, may be used to indicate various conditions of the associated joint <b>108</b> or the robotic apparatus <b>101</b> as a whole; examples of different states of the LEDs indicating different conditions are discussed below with reference to <figref idrefs="DRAWINGS">FIG. 32</figref>. In some embodiments, the LEDs <b>220</b> included in a joint <b>108</b> may be full spectrum LEDs. In some embodiments, the color of the LEDs <b>220</b> included in a joint <b>108</b> may be changed by voice command; in particular, the voice command logic <b>170</b> may recognize a “LED color” voice command and may cause the color of the LED to change in response to the command.</div>
</li> <li> <para-num num="[0092]"> </para-num> <div class="description-line" id="p-0093" num="0092">The joint <b>108</b> may include a shaft encoder <b>222</b>. The shaft encoder <b>222</b> may be used to measure the angle of rotation of a shaft <b>248</b> of a motor <b>212</b>, as discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 13-21</figref>. In some embodiments, the shaft encoder <b>222</b> may be contactless in that it does not make physical contact with the shaft <b>248</b> to measure the angle of rotation of the shaft <b>248</b>. In other embodiments, the shaft encoder <b>222</b> may make contact with the shaft <b>248</b> to measure the angle of rotation of the shaft <b>248</b>. In some embodiments, the shaft encoder <b>222</b> may have a resolution greater than 12 bits (e.g., 14 bits). <figref idrefs="DRAWINGS">FIG. 13</figref>, discussed further below, illustrates a particular embodiment in which the shaft encoder <b>222</b> is a contactless, magnetic angle encoder, but the arrangement of <figref idrefs="DRAWINGS">FIG. 13</figref> and the techniques discussed with reference to <figref idrefs="DRAWINGS">FIGS. 14-21</figref> may be performed by any other suitable type of angle encoder (e.g., a contact angle encoder, an optical angle encoder, etc.). In conventional robotic systems, shaft encoders are typically not used to monitor a joint due to the extremely high gear ratios of such systems (e.g., greater than 30:1); if a shaft encoder were used in such settings, the error on the output of the drivetrain based on the angle of the motor shaft would be far too large for accurate operation. Instead, conventional robotic systems typically include a joint encoder to monitor the angle of the joint itself (rather than the angle of a shaft of a motor driving the joint). In some embodiments of the joints <b>108</b> disclosed herein, no joint encoder may be included at the joint <b>108</b>; instead, the position of the joint <b>108</b> may be determined by in the robotic system <b>100</b> by taking the position of the motor shaft <b>248</b> and dividing it down by the gear ratio of the drivetrain <b>214</b>. The gear ratio may be burned into the joint-level data storage <b>229</b>, for example. Thus, instructions to move a joint <b>108</b> may be communicated to the joint <b>108</b> in terms of joint degrees.</div>
</li> <li> <para-num num="[0093]"> </para-num> <div class="description-line" id="p-0094" num="0093">The joint <b>108</b> may include an accelerometer <b>224</b>. In some embodiments, the accelerometer <b>224</b> may be part of an inertial measurement unit (IMU), which may also include a gyroscope. For example, the accelerometer <b>224</b> may be provided by a six-axis IMU (including a three-axis accelerometer and a three-axis gyroscope). In other embodiments, the accelerometer <b>224</b> may be a standalone device.</div>
</li> <li> <para-num num="[0094]"> </para-num> <div class="description-line" id="p-0095" num="0094">The joint <b>108</b> may include communications hardware <b>226</b>. The communications hardware <b>226</b> included in a joint <b>108</b> may facilitate communication between the elements of the joint <b>108</b> and/or between different ones of the joints <b>108</b> and/or between a joint <b>108</b> and the system-level compute hardware <b>124</b>. In some embodiments, the communications hardware <b>226</b> at different ones of the joints <b>108</b> may support a non-deterministic serial bus communication link between the joints <b>108</b>, and between the joints <b>108</b> and the system-level compute hardware <b>124</b>. In some embodiments, the communications hardware <b>226</b> of a joint <b>108</b> may include a USB hub (e.g., a four-port hub) to which the joint-level compute hardware <b>210</b> may be communicatively coupled via a USB cable. Further, different ones of the USB hubs in the different joints <b>108</b> of a robotic apparatus may be communicatively coupled to each other, and further communicatively coupled to the system-level compute hardware <b>124</b>, in a daisy-chain fashion via USB cables. Such a USB backbone may permit communication of data between joints <b>108</b> and between any joint <b>108</b> and the system-level compute hardware <b>124</b>. Any suitable ones of the other elements of a joint <b>108</b> may be coupled to the USB hub included in the communications hardware <b>128</b>, and thus may be visible and addressable by any other USB device coupled to the backbone. Further, a set of USB ports may be exposed to the end effector <b>118</b> so that devices of the end effector <b>118</b> (e.g., cameras, lasers, depth sensors, lighting devices, etc.) may connect to the USB backbone, and thus may be readily recognized by the system-level compute hardware <b>124</b>. When the joint-level compute hardware <b>210</b> includes a microcontroller with its own communications ports (e.g., GPIO ports), the communications hardware <b>226</b> may support the operation of these communications ports. In some embodiments, the communications hardware <b>226</b> may support communication with the system-level compute hardware <b>124</b> via a CAN bus, an RS-485 bus, a SPI bus, an I2C bus, or an RS-232 bus, for example.</div>
</li> <li> <para-num num="[0095]"> </para-num> <div class="description-line" id="p-0096" num="0095">As noted above, in some embodiments, the communications hardware <b>226</b> (in conjunction with the communications hardware <b>128</b>) may manage the transfer of a packet of data from the joint <b>108</b> to the system-level compute hardware <b>124</b> at a rate that is greater than 1 kilohertz (e.g., between 1 kilohertz and 100 kilohertz). This packet of data may include the position of the joint <b>108</b> (as output from the shaft encoder <b>222</b>), the velocity of the joint <b>108</b> (represented by a time derivative of the output of the shaft encoder <b>222</b>), the acceleration of the joint <b>108</b> (represented by the second time derivative of the output of the shaft encoder <b>222</b>), a counter (representative of a timestamp, incremented at a clock frequency of the joint-level compute hardware <b>210</b>, used to align timestamps through the robotic system <b>100</b> with a timestamp of the system-level compute hardware <b>124</b>), status flags, the error in a control loop (as discussed below with reference to <figref idrefs="DRAWINGS">FIG. 21</figref>), the current to the motor <b>212</b>, acceleration and velocity data output from a multi-axis IMU (which may provide the accelerometer <b>224</b>, as discussed above), the output of one or more temperature sensors included in the other hardware <b>227</b> of the joint (discussed below), and other data, as desired. The data in this packet may be assembled by the joint-level compute hardware <b>210</b> (e.g., a microcontroller) and provided to the communications hardware <b>226</b> (e.g., to a USB hub via a Universal Asynchronous Receiver/Transmitter (UART) interface of the joint-level compute hardware <b>210</b> through a UART to USB module included in the communications hardware <b>226</b>). The system-level compute hardware <b>124</b> may use this data to control the operation of the robotic apparatus <b>101</b>, as suitable and as discussed herein.</div>
</li> <li> <para-num num="[0096]"> </para-num> <div class="description-line" id="p-0097" num="0096">The joint <b>108</b> may include a limit switch <b>228</b>. A limit switch <b>228</b> may be located in the joint <b>108</b> such that the limit switch <b>228</b> is triggered when the joint <b>108</b> (e.g., the joint output <b>258</b>, as discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 23-27</figref>) reaches a particular, predetermined position. A limit switch <b>228</b> may, in some embodiments, be used as part of a joint zeroing method, as discussed below with reference to <figref idrefs="DRAWINGS">FIG. 33</figref>. In some embodiments, some but not all of the joints <b>108</b> in a robotic apparatus <b>101</b> may include a limit switch <b>228</b>. In some embodiments, a joint <b>108</b> of a robotic apparatus <b>101</b> may include a limit switch <b>228</b>, but that limit switch <b>228</b> may not be used to zero the joint <b>108</b> (e.g., the method <b>610</b> of <figref idrefs="DRAWINGS">FIG. 34</figref> may be used to zero the joint <b>108</b>).</div>
</li> <li> <para-num num="[0097]"> </para-num> <div class="description-line" id="p-0098" num="0097">The joint <b>108</b> may include other hardware <b>227</b>. The other hardware <b>227</b> may include additional sensors (e.g., one or more temperature sensors, one or more moisture detection sensors, one or more current sensors, etc.) and/or peripheral devices (e.g., one or more fans, one or more lasers, one or more displays, etc.). In some embodiments, one or more elements of the other hardware <b>227</b> may be readily attached to and detached from the rest of the hardware of the joint <b>108</b> (e.g., via a USB port of a USB hub of the communications hardware <b>226</b>).</div>
</li> <li> <para-num num="[0098]"> </para-num> <div class="description-line" id="p-0099" num="0098">The joint <b>108</b> may include data storage <b>229</b>. The data storage <b>229</b> may include data storage included in the joint-level compute hardware <b>210</b> or data storage separate from, but accessible to, the joint-level compute hardware <b>210</b>. The contents of the data storage <b>229</b> may, in some embodiments, be read from and/or written to by remote devices via the communications hardware <b>226</b>. Although the data storage <b>229</b> may be referred to herein in the singular, this is simply for ease of illustration, and the data storage <b>229</b> may include multiple data storage devices (e.g., read-only memory (ROM), Flash memory, RAM, etc.). The data storage <b>229</b> may include one or more memory devices used to store data and/or instructions executable by one or more processing devices to perform any suitable ones of the methods disclosed herein (e.g., with such stored instructions providing any suitable ones of the logic described herein).</div>
</li> <li> <para-num num="[0099]"> </para-num> <div class="description-line" id="p-0100" num="0099"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a side, cross-sectional view of an example instance of the robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 6</figref>, in accordance with various embodiments. In particular, <figref idrefs="DRAWINGS">FIG. 10</figref> illustrates an example arrangement of a motor <b>212</b> and a drivetrain <b>214</b> in each of the joints <b>108</b> of the robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 6</figref>. The motors <b>212</b> associated with each of the joints <b>108</b> include an arrow indicating the direction of the longitudinal axis of the shaft <b>248</b> of the motor <b>212</b>. Note that, in <figref idrefs="DRAWINGS">FIG. 10</figref>, some of the joints <b>108</b> include a motor <b>212</b> whose shaft <b>248</b> is parallel to the axis of rotation <b>126</b> of the joint <b>108</b> (i.e., the joints <b>108</b>-<b>1</b>, <b>108</b>-<b>3</b>, <b>108</b>-<b>4</b>, <b>108</b>-<b>5</b>, and <b>108</b>-<b>6</b>) while others of the joints include a motor <b>212</b> whose shaft <b>248</b> is not parallel to the axis of rotation <b>126</b> of the joint <b>108</b> (i.e., the joint <b>108</b>-<b>2</b>). For the joint <b>108</b>-<b>2</b>, the shaft <b>248</b>-<b>2</b> of the motor <b>212</b>-<b>2</b> is rotated 90 degrees with respect to the axis of rotation <b>126</b>-<b>2</b> of the joint <b>108</b>-<b>2</b>, and thus the drivetrain <b>214</b>-<b>2</b> may convert rotation by the shaft <b>248</b>-<b>2</b> into rotation of the joint <b>108</b>-<b>2</b> (e.g., by a belt arrangement). More generally, however, a robotic apparatus <b>101</b> may include one or more joints <b>108</b> whose motors <b>212</b> have shafts <b>248</b> that are parallel with the axis of rotation <b>126</b> of the joint <b>108</b>, and/or one or more joints <b>108</b> whose motors <b>212</b> do not have shafts <b>248</b> that are parallel with the axis of rotation <b>126</b> of the joint <b>108</b>.</div>
</li> <li> <para-num num="[0100]"> </para-num> <div class="description-line" id="p-0101" num="0100">Further, in <figref idrefs="DRAWINGS">FIG. 10</figref>, some of the joints <b>108</b> having motors <b>212</b> with shafts <b>248</b> that are parallel with the axis of rotation <b>126</b> of the joint <b>108</b> may include an offset between the shaft <b>248</b> and the axis of rotation <b>126</b>. For example, for the joint <b>108</b>-<b>3</b>, the motor <b>212</b>-<b>3</b> may be located toward a “bottom” of the segment <b>110</b>-<b>2</b>, while the axis of rotation <b>126</b>-<b>3</b> of the joint <b>108</b>-<b>3</b> may be located toward a “top” of the segment <b>110</b>-<b>2</b>. The drivetrain <b>214</b>-<b>3</b> may bridge the offset between the shafts <b>248</b>-<b>3</b> of the motor <b>212</b>-<b>3</b> and the axis of rotation <b>126</b>-<b>3</b> of the joint <b>108</b>-<b>3</b>. More generally, the robotic apparatus <b>101</b> may include one or more joints <b>108</b> whose motors <b>212</b> have shafts <b>248</b> that are offset from the axis of rotation <b>126</b> of the joint <b>108</b>, and/or one or more joints <b>108</b> whose motors <b>212</b> do not have shafts <b>248</b> that are offset from the axis of rotation <b>126</b> of the joint <b>108</b>.</div>
</li> <li> <para-num num="[0101]"> </para-num> <div class="description-line" id="p-0102" num="0101"> <figref idrefs="DRAWINGS">FIG. 11</figref> is a block diagram of logic elements that may be part of a joint-level compute hardware <b>210</b>, in accordance with various embodiments. In particular, the logic elements illustrated in <figref idrefs="DRAWINGS">FIG. 11</figref> may be implemented by programmed instructions stored in the data storage <b>229</b> such that, upon execution by one or more processing devices of the joint-level compute hardware <b>210</b>, cause the joint-level compute hardware <b>210</b> to perform the operations disclosed herein. The logic elements illustrated in <figref idrefs="DRAWINGS">FIG. 11</figref> may be part of the control logic <b>104</b> of a robotic system <b>100</b>. In particular, the motor drive logic <b>230</b> may be part of the motion/position logic <b>132</b>, the joint calibration logic <b>232</b> may be part of the calibration logic <b>134</b>, the braking logic <b>234</b> may be part of the motion/position logic <b>132</b>, the joint safety logic <b>236</b> may be part of the safety logic <b>136</b>, the LED control logic <b>238</b> may be part of the I/O device logic <b>144</b>, etc.</div>
</li> <li> <para-num num="[0102]"> </para-num> <div class="description-line" id="p-0103" num="0102">As noted above, the joint-level compute hardware <b>210</b> may include motor drive logic <b>230</b>.</div>
</li> <li> <para-num num="[0103]"> </para-num> <div class="description-line" id="p-0104" num="0103">The joint-level compute hardware <b>210</b> may include joint calibration logic <b>232</b>. The joint calibration logic <b>232</b> may cause the robotic apparatus <b>101</b> to perform a joint calibration technique that maps the output of the shaft encoder <b>222</b> to the true position of the stepper motor <b>212</b> for the joint <b>108</b>. Examples of joint calibration techniques are discussed in further detail below with reference to <figref idrefs="DRAWINGS">FIGS. 15-16</figref>.</div>
</li> <li> <para-num num="[0104]"> </para-num> <div class="description-line" id="p-0105" num="0104">The joint-level compute hardware <b>210</b> may include braking logic <b>234</b>. The braking logic <b>234</b> may control the braking of the motor <b>212</b> of the joint <b>108</b>. In some embodiments in which a joint <b>108</b> includes mechanical brakes <b>116</b>, the braking logic <b>234</b> may selectively activate the mechanical brakes <b>116</b> to slow or stop the motion of the joint <b>108</b>. In embodiments in which a joint <b>108</b> does not include mechanical brakes <b>116</b> (or in embodiments in which other braking techniques may be used in addition to mechanical brakes <b>116</b>), the braking logic <b>234</b> may generate signals to the motor <b>212</b> to electrically brake the motor <b>212</b>, as discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 23-27</figref>.</div>
</li> <li> <para-num num="[0105]"> </para-num> <div class="description-line" id="p-0106" num="0105">The joint-level compute hardware <b>210</b> may include joint safety logic <b>236</b>. Examples of joint-level safety techniques that may be performed by the joint safety logic <b>236</b> are discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 30-31</figref>.</div>
</li> <li> <para-num num="[0106]"> </para-num> <div class="description-line" id="p-0107" num="0106">The joint-level compute hardware <b>210</b> may include LED control logic <b>238</b>. The LED control logic <b>238</b> may control the state (e.g., brightness, flashing frequency, color, etc.) of one or more LEDs <b>220</b> included in a joint <b>108</b>. Examples of methods of controlling LEDs <b>220</b> in a joint <b>108</b> that may be performed by the LED control logic <b>238</b> are discussed below with reference to <figref idrefs="DRAWINGS">FIG. 32</figref>.</div>
</li> <li> <para-num num="[0107]"> </para-num> <div class="description-line" id="p-0108" num="0107"> <figref idrefs="DRAWINGS">FIG. 12</figref> depicts a stepper motor <b>212</b> that may be included in a joint <b>108</b> of a robotic system <b>100</b>, in accordance with various embodiments. In particular, <figref idrefs="DRAWINGS">FIG. 12</figref> is a cross-sectional view perpendicular to the shaft <b>248</b> of the motor <b>212</b>. The stepper motor <b>212</b> may include a rotor <b>242</b> coupled to the shaft <b>248</b>. The rotor <b>242</b> may include teeth <b>250</b>, which face complementary teeth <b>247</b> of electromagnets <b>246</b> of a surrounding stator <b>244</b>. The electromagnets <b>246</b> of the stepper motor <b>212</b> illustrated in <figref idrefs="DRAWINGS">FIG. 12</figref> are arranged in two phases, labeled “A” and “B,” but a stepper motor <b>212</b> included in a joint <b>108</b> may have more than three phases, if desired. By selectively providing current to the phases of the stepper motor <b>212</b>, different ones of the electromagnets <b>246</b> may be energized so as to cause rotation of the rotor <b>242</b> with respect to the stator <b>244</b>. Four “steps” of the rotor <b>242</b> may equal rotation by one full tooth <b>250</b>; when the rotor <b>242</b> rotates by a full tooth <b>250</b>, the motor <b>212</b> may be said to have completed a full “step cycle,” as indicated in <figref idrefs="DRAWINGS">FIG. 12</figref>. Different stepper motors <b>212</b> may include different numbers of steps per one full revolution of the shaft <b>248</b> (e.g., 200 steps per revolution) and different embodiments of the motor drive logic <b>230</b> may support different microstepping capabilities (e.g., the ability to drive the stepper motor <b>212</b> at a half-step, a quarter-step, etc.).</div>
</li> <li> <para-num num="[0108]"> </para-num> <div class="description-line" id="p-0109" num="0108"> <figref idrefs="DRAWINGS">FIG. 13</figref> depicts an example motor drive arrangement that may be included in a joint <b>108</b> of a robotic system <b>100</b>, in accordance with various embodiments. In <figref idrefs="DRAWINGS">FIG. 13</figref>, a stepper motor <b>212</b>, including a motor body <b>254</b> and a shaft <b>248</b> that rotates within the motor body <b>254</b>, is mechanically coupled to a shaft encoder <b>222</b> by a shaft encoder support <b>252</b>. In a particular embodiment illustrated in <figref idrefs="DRAWINGS">FIG. 13</figref>, the shaft encoder <b>222</b> is a magnetic, contactless angle encoder, which senses the orientation of a diametric magnet <b>256</b> coupled to an end of the shaft <b>248</b>. <figref idrefs="DRAWINGS">FIG. 14</figref> illustrates a diametric magnet <b>256</b> (including north and south poles at opposite ends of a diameter of the magnet <b>256</b>) that may be included in a robotic system <b>100</b>, in accordance with various embodiments; the perspective of <figref idrefs="DRAWINGS">FIG. 14</figref> is rotated 90 degrees sideways relative to the perspective of <figref idrefs="DRAWINGS">FIG. 13</figref>, such that the shaft <b>248</b> would extend into the page of the drawing from the perspective of <figref idrefs="DRAWINGS">FIG. 14</figref>.</div>
</li> <li> <para-num num="[0109]"> </para-num> <div class="description-line" id="p-0110" num="0109">Returning to <figref idrefs="DRAWINGS">FIG. 13</figref>, the shaft encoder support <b>252</b> may be any suitable mechanical structure (e.g., a plastic frame) that allows the shaft encoder <b>222</b> and the diametric magnet <b>256</b> to maintain a desired spacing and relative orientation. As noted above with reference to <figref idrefs="DRAWINGS">FIG. 9</figref>, shaft encoders <b>222</b> that are not contactless and/or that are not magnetic may be used to detect the angular position of the shaft <b>248</b> of the stepper motor <b>212</b>. The output of the shaft encoder <b>222</b> (indicating the angular position of the shaft <b>248</b>) may be transmitted to the joint-level compute hardware <b>210</b>, where it may be used by the motor drive logic <b>230</b> during motor drive operations (as discussed further below) and used by the joint calibration logic <b>232</b> during joint calibration operations (as discussed further below). The motor drive logic <b>230</b> and/or the joint calibration logic <b>232</b> may cause the joint-level compute hardware <b>210</b> to generate drive current control signals that may be transmitted to drive support circuitry <b>216</b> and used by the drive support circuitry <b>216</b> to generate motor drive currents. Particular examples of drive support circuitry <b>216</b> are discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 23-27</figref>. The motor drive currents are then provided to the stepper motor <b>212</b> (i.e., to the phases of the stepper motor <b>212</b>, as discussed above with reference to <figref idrefs="DRAWINGS">FIG. 12</figref>) to cause the stepper motor <b>212</b> to move in a desired manner.</div>
</li> <li> <para-num num="[0110]"> </para-num> <div class="description-line" id="p-0111" num="0110">As noted above, the joint calibration logic <b>232</b> may cause the robotic apparatus <b>101</b> to perform a joint calibration technique that maps the output of the shaft encoder <b>222</b> to the true position of the stepper motor <b>212</b> for the joint <b>108</b>. <figref idrefs="DRAWINGS">FIG. 15</figref> is a flow diagram of an example method <b>300</b> of calibrating a motor <b>212</b> in a robotic system <b>100</b>, in accordance with various embodiments. The method <b>300</b> may be carried out by the joint calibration logic <b>232</b> of a joint-level compute hardware <b>210</b> (which may be located in the robotic apparatus <b>101</b>, and physically proximate to the joint <b>108</b>), and in some embodiments, may be performed in response to an instruction from the control logic <b>104</b> (e.g., the calibration logic <b>134</b>) to calibrate the joint <b>108</b>. In some embodiments, each of the different joints <b>108</b> in a robotic apparatus <b>101</b> may include a joint-level compute hardware <b>210</b> having joint calibration logic <b>232</b> that performs the method <b>300</b> for that particular joint <b>108</b>. Although the operations of the method <b>300</b> may be illustrated with reference to particular embodiments of the motors <b>212</b> and shaft encoders <b>222</b> disclosed herein, the method <b>300</b> may be performed using any suitable components; the same is true for any of the other methods disclosed herein. Various operations are illustrated once each and in a particular order in <figref idrefs="DRAWINGS">FIG. 15</figref>, but the operations may be reordered and/or repeated as desired (e.g., with different operations performed in parallel, as suitable); the same is true for any of the other methods disclosed herein.</div>
</li> <li> <para-num num="[0111]"> </para-num> <div class="description-line" id="p-0112" num="0111">At <b>302</b>, a motor may be caused to move by a known increment from a known starting point. For example, the joint calibration logic <b>232</b> may generate drive current control signals for drive support circuitry <b>216</b> such that the drive support circuitry <b>216</b> provides motor drive currents to the motor <b>212</b> to cause the shaft <b>248</b> of the motor <b>212</b> to rotate through a known angle (corresponding to, e.g., a full step, a half-step, any other suitable microstep, etc.). Zeroing techniques for causing a joint <b>108</b> to move to a known “zeroed” position (e.g., the known starting point at which joint calibration may begin) are discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 33-34</figref>.</div>
</li> <li> <para-num num="[0112]"> </para-num> <div class="description-line" id="p-0113" num="0112">At <b>304</b>, the cumulative incremental motor position may be stored. For example, the joint calibration logic <b>232</b> may store, in the data storage <b>229</b>, the cumulative incremental position of the shaft <b>248</b> of the stepper motor <b>212</b> (referred to herein as simply “the position of the motor”).</div>
</li> <li> <para-num num="[0113]"> </para-num> <div class="description-line" id="p-0114" num="0113">At <b>306</b>, the output of the shaft encoder may be read and stored. For example, the joint calibration logic <b>232</b> may receive an output indicative of the angle of the shaft <b>248</b> from the shaft encoder <b>222</b>, and may store that output in association with the cumulative incremental position stored at <b>304</b>.</div>
</li> <li> <para-num num="[0114]"> </para-num> <div class="description-line" id="p-0115" num="0114">At <b>308</b>, the stored motor position and shaft encoder data may be interpolated. This interpolation may be performed in accordance with any known technique (e.g., linear interpolation, quadratic interpolation, etc.) and with any desired resolution. For example, the joint calibration logic <b>232</b> may interpolate the previously stored motor position and shaft encoder data to achieve a lookup table of a desired size at the completion of the method <b>300</b>.</div>
</li> <li> <para-num num="[0115]"> </para-num> <div class="description-line" id="p-0116" num="0115">At <b>310</b>, the interpolated data may be stored in a lookup table. For example, the joint calibration logic <b>232</b> may store the interpolated data as a lookup table in the data storage <b>229</b>. For example, <figref idrefs="DRAWINGS">FIG. 16</figref> depicts an example data structure <b>400</b> that may be used to calibrate a stepper motor <b>212</b> in a robotic system <b>100</b>, in accordance with various embodiments. The data structure <b>400</b> may be a lookup table that associates shaft encoder values with motor positions.</div>
</li> <li> <para-num num="[0116]"> </para-num> <div class="description-line" id="p-0117" num="0116">Returning to <figref idrefs="DRAWINGS">FIG. 15</figref>, at <b>312</b>, it may be determined whether one full rotation of the motor has been completed. For example, the joint calibration logic <b>232</b> may monitor the cumulative incremental position of the stepper motor <b>212</b> to determine whether the shaft <b>248</b> has completed a full rotation since the start of the method <b>300</b>. If one full rotation of the motor has not been completed, the method <b>300</b> may proceed to <b>302</b>, and the motor may be caused to move by a known increment again. If one full rotation has been completed, the method <b>300</b> may end.</div>
</li> <li> <para-num num="[0117]"> </para-num> <div class="description-line" id="p-0118" num="0117">The results of the joint calibration technique of <figref idrefs="DRAWINGS">FIG. 16</figref> is a lookup table of a desired resolution mapping the output of the shaft encoder <b>222</b> to the “true” position of the stepper motor <b>212</b>. This lookup table may be used to accurately drive the motor <b>212</b> to a desired position (e.g., in a closed-loop fashion, as discussed below with reference to <figref idrefs="DRAWINGS">FIG. 18</figref>) while compensating for errors in the output of the shaft encoder <b>222</b> (due to, for example, variations in the mounting of the shaft encoder <b>222</b>, errors in the shaft encoder <b>222</b> itself, etc.). In some embodiments, the lookup table may have one entry per encoder reading, but the size of the lookup table may be scaled based on available Flash memory in the joint-level data storage <b>229</b>. For example, a 14-bit shaft encoder <b>22</b> may generate 2{circumflex over ( )}14 16-bit values, requiring 32 kilobytes of memory; if the position of the motor <b>212</b> is encoded with 16-bit values, this will allow the motor position to be specified with approximately 0.005 degrees of resolution.</div>
</li> <li> <para-num num="[0118]"> </para-num> <div class="description-line" id="p-0119" num="0118">As noted above, the motor drive logic <b>230</b> may generate drive current control signals for drive support circuitry <b>216</b>, which may use those drive current control signals to generate motor drive currents for the stepper motor <b>212</b>. The motor drive logic <b>230</b> may generate drive current control signals in an open-loop fashion or in a closed-loop fashion. In some embodiments, a joint <b>108</b> may be switched (e.g., by task logic <b>106</b>) between open-loop control and close-loop control depending upon the task to be performed.</div>
</li> <li> <para-num num="[0119]"> </para-num> <div class="description-line" id="p-0120" num="0119"> <figref idrefs="DRAWINGS">FIG. 17</figref> is a flow diagram of an example open-loop method <b>320</b> of driving a motor <b>212</b> in a robotic system <b>100</b>, in accordance with various embodiments. The method <b>320</b> may be carried out by the motor drive logic <b>230</b> of a joint-level compute hardware <b>210</b> (which may be located in the robotic apparatus <b>101</b>, and physically proximate to the joint <b>108</b>), and in some embodiments, may be performed in response to an instruction from the control logic <b>104</b> (e.g., the motion/position logic <b>132</b>) to move the joint <b>108</b>. In some embodiments, each of the different joints <b>108</b> in a robotic apparatus <b>101</b> may include a joint-level compute hardware <b>210</b> having motor drive logic <b>230</b> that performs the method <b>320</b> for that particular joint <b>108</b>.</div>
</li> <li> <para-num num="[0120]"> </para-num> <div class="description-line" id="p-0121" num="0120">At <b>322</b>, the current motor position may be determined. For example, the motor drive logic <b>230</b> may receive an output of a shaft encoder <b>222</b> indicating a current angular position of the shaft <b>248</b> of a stepper motor <b>212</b> (e.g., as discussed above with reference to <figref idrefs="DRAWINGS">FIG. 13</figref>), and the motor drive logic <b>230</b> may utilize a lookup table stored in the data storage <b>229</b> (e.g., the data structure <b>400</b> of <figref idrefs="DRAWINGS">FIG. 16</figref>) to determine the motor position corresponding to the current angular position.</div>
</li> <li> <para-num num="[0121]"> </para-num> <div class="description-line" id="p-0122" num="0121">At <b>324</b>, the target motor position may be determined. For example, the motor drive logic <b>230</b> may receive an instruction from the control logic <b>104</b> (e.g., the motion/position logic <b>132</b>) to move the joint <b>108</b> by causing the stepper motor <b>212</b> to rotate through a desired angle.</div>
</li> <li> <para-num num="[0122]"> </para-num> <div class="description-line" id="p-0123" num="0122">At <b>326</b>, provision of currents to the motor may be caused to drive the motor to the target motor position from the current motor position. For example, the motor drive logic <b>230</b> may provide currents to the phases of the stepper motor <b>212</b> (e.g., as discussed above with reference to <figref idrefs="DRAWINGS">FIG. 12</figref>) to cause the stepper motor <b>212</b> <b>2</b> move through the desired angle. The magnitude and timing of the currents provided to the phases of the stepper motor <b>212</b> may be based on a predetermined relationship between currents and motor position (e.g., using conventional open-loop stepper motor drive schemes). Note that, in an open-loop motor drive method like the method <b>320</b>, the position of the stepper motor <b>212</b> may not be monitored during driving of the stepper motor <b>212</b>.</div>
</li> <li> <para-num num="[0123]"> </para-num> <div class="description-line" id="p-0124" num="0123"> <figref idrefs="DRAWINGS">FIG. 18</figref> is a flow diagram of an example closed-loop method <b>330</b> of driving a motor <b>212</b> in a robotic system <b>100</b>, in accordance with various embodiments. The method <b>330</b> may be carried out by the motor drive logic <b>230</b> of a joint-level compute hardware <b>210</b> (which may be located in the robotic apparatus <b>101</b>, and physically proximate to the joint <b>108</b>), and in some embodiments, may be performed in response to an instruction from the control logic <b>104</b> (e.g., the motion/position logic <b>132</b>) to move the joint <b>108</b>. In some embodiments, each of the different joints <b>108</b> in a robotic apparatus <b>101</b> may include a joint-level compute hardware <b>210</b> having motor drive logic <b>230</b> that performs the method <b>330</b> for that particular joint <b>108</b>. Although motor position may be referred to herein as the variable around which closed-loop motor control is performed, this need not be the case, and in other embodiments, a closed-loop motor control method may be performed around other motor performance variables, such as velocity, current, or torque.</div>
</li> <li> <para-num num="[0124]"> </para-num> <div class="description-line" id="p-0125" num="0124">At <b>332</b>, a value of a motor performance variable may be measured. The motor performance variable may be motor position, motor velocity, motor current, etc. For example, the motor drive logic <b>230</b> may measure the position of a stepper motor <b>212</b> by receiving an output of a shaft encoder <b>222</b> indicating a current angular position of the shaft <b>248</b> of a stepper motor <b>212</b> (e.g., as discussed above with reference to <figref idrefs="DRAWINGS">FIG. 13</figref>), and the motor drive logic <b>230</b> may utilize a lookup table stored in the data storage <b>229</b> (e.g., the data structure <b>400</b> of <figref idrefs="DRAWINGS">FIG. 16</figref>) to determine the motor position corresponding to the current angular position.</div>
</li> <li> <para-num num="[0125]"> </para-num> <div class="description-line" id="p-0126" num="0125">At <b>334</b>, the measured value may be compared to a target value. For example, the motor drive logic <b>230</b> may compare the current position of a stepper motor <b>212</b> to a target position of the stepper motor <b>212</b> (e.g., as specified by an instruction from the control logic <b>104</b>).</div>
</li> <li> <para-num num="[0126]"> </para-num> <div class="description-line" id="p-0127" num="0126">At <b>336</b>, it may be determined whether motor drive should be turned off. For example, the motor drive logic <b>230</b> may determine that the motor drive should be turned off in accordance with the method <b>360</b> of <figref idrefs="DRAWINGS">FIG. 29</figref>, discussed below.</div>
</li> <li> <para-num num="[0127]"> </para-num> <div class="description-line" id="p-0128" num="0127">If it is determined at <b>336</b> that the motor drive should not be turned off, the method <b>330</b> may proceed to <b>338</b>, and provision of currents to the motor may be caused in order to bring the measured value closer to the target value. For example, the motor drive logic <b>230</b> may generate drive current control signals for the drive support circuitry <b>216</b> to cause the drive support circuitry <b>216</b> to provide motor drive currents to the stepper motor <b>212</b> (as discussed above with reference to <figref idrefs="DRAWINGS">FIG. 13</figref>) to bring the position of the stepper motor <b>212</b> closer to the target position. A control loop may generate appropriate currents to provide to the motor to bring it closer to the target value. Such a control loop may determine the error between the measured value and the target value (at <b>334</b>), and may provide, as an output, drive current control signals for the motor. This control loop may take any suitable form known in the art, such as a proportional (P) control loop, an integral (I) control loop, a derivative (D) control loop, any combination thereof (e.g., a proportional-integral-derivative (PID) control loop), or any other suitable control loop. A particular example of a method that may be performed at <b>332</b>/<b>334</b>/<b>338</b> is the method <b>340</b> of <figref idrefs="DRAWINGS">FIG. 21</figref> (discussed below). The method <b>330</b> may then proceed to <b>332</b>, and the value of the motor performance variable may be measured again.</div>
</li> <li> <para-num num="[0128]"> </para-num> <div class="description-line" id="p-0129" num="0128">If it is determined at <b>336</b> that the motor drive should be turned off, the method <b>330</b> may end.</div>
</li> <li> <para-num num="[0129]"> </para-num> <div class="description-line" id="p-0130" num="0129">As discussed above, causing a stepper motor <b>212</b> to move to a desired position involves the provision of motor drive currents to the stepper motor <b>212</b>. <figref idrefs="DRAWINGS">FIG. 19</figref> includes two plots; a plot <b>600</b>A of conventional drive currents for each phase (“A” and “B”) of a two-phase stepper motor <b>212</b>, and a plot <b>600</b>B of increased-torque drive currents for each phase of a two-phase stepper motor <b>212</b>. The drive currents of <figref idrefs="DRAWINGS">FIG. 19</figref> may be provided to a stepper motor <b>212</b> under the control of the motor drive logic <b>230</b>, in accordance with various embodiments. The drive currents of <figref idrefs="DRAWINGS">FIG. 19</figref> are illustrated as being delivered over four steps of a step cycle of a stepper motor <b>212</b>. The “A” and “B” curves in the plot <b>600</b>A are sinusoids separated by a 90 degree lag, as shown, as are the “A” and “B” curves in the plot <b>600</b>B. The plots <b>600</b>A and <b>600</b>B indicate the relative magnitudes of the currents that may be provided to the phases of the stepper motor <b>212</b> as a function of the current position of the stepper motor <b>212</b> in a step cycle. The plots <b>600</b>A and <b>600</b>B may be normalized so that the drive currents provided to a stepper motor <b>212</b> are based on the relative values indicated by the plot <b>600</b>A or <b>600</b>B, multiplied by a drive current scale factor, as discussed below with reference to <figref idrefs="DRAWINGS">FIG. 21</figref>. The relative magnitudes of the “A” and “B” currents at a position along a step cycle may be referred to as the “commutation” of the stepper motor <b>212</b> at that position.</div>
</li> <li> <para-num num="[0130]"> </para-num> <div class="description-line" id="p-0131" num="0130">When a conventional drive scheme like that of the plot <b>600</b>A is used to drive a stepper motor <b>212</b> (e.g., in an open-loop manner, as discussed above with reference to <figref idrefs="DRAWINGS">FIG. 17</figref>), the torque of the stepper motor <b>212</b> may vary in an undesirable manner over the step cycle. In particular, when the current is first changed at the beginning of a new step cycle, the torque is largest, and decreases to zero as the shaft <b>248</b> of the stepper motor <b>212</b> aligns with the magnetic field. When a drive scheme like that of the plot <b>600</b>B is used to drive a stepper motor <b>212</b>, the current provided (e.g., in a closed-loop manner, as discussed above with reference to <figref idrefs="DRAWINGS">FIG. 18</figref>) may always be set at a full step ahead of the current motor position across the entire step cycle, increasing the instantaneous torque provided by the stepper motor <b>212</b> of a joint <b>108</b> across the drive operation relative to conventional drive schemes. Further, in conventional motor drive schemes, the current level provided to the motor must be set high enough to generate enough torque to overcome the worst-case loading of the motor (e.g., by a safety factor of 2). Such a drive scheme often results in unnecessary torque (which requires additional power that is dissipated as heat), and also limits the ability to run the motor near its performance limits. The increased-torque drive schemes disclosed herein allow the motor <b>212</b> to be run at a greater torque than conventionally achieved, and also with only enough current (and therefore, power) to move the motor <b>212</b> as needed, eliminating the need for a conventional current safety factor and reducing the amount of wasted power.</div>
</li> <li> <para-num num="[0131]"> </para-num> <div class="description-line" id="p-0132" num="0131">Implementing the drive scheme of the plot <b>600</b>B may take any of a number of forms. For example, in some embodiments, the drive current scheme illustrated in the plot <b>600</b>B of <figref idrefs="DRAWINGS">FIG. 19</figref> may be stored in a lookup table to allow the motor drive logic <b>230</b> to determine the appropriate drive current for each of the phases of a stepper motor <b>212</b> based on the current location of the stepper motor <b>212</b> in a step cycle. For example, <figref idrefs="DRAWINGS">FIG. 20</figref> depicts an example data structure <b>402</b> that the motor drive logic <b>230</b> may use to determine drive currents for different phases of a stepper motor <b>212</b> in a robotic system <b>100</b>, in accordance with various embodiments. The data structure <b>402</b>, which may be a lookup table, may relate locations of the stepper motor <b>212</b> in the step cycle to the drive currents for the phases “A” and “B” of a two-phase stepper motor <b>212</b> in accordance with the plot <b>600</b>B. The number of entries in the lookup table (corresponding to the resolution of the “sampling” of the plot <b>600</b>B) may have any desired value. For example, when the motor drive logic <b>230</b> supports microstepping at 32 microsteps per step, the lookup table may have 128 entries (corresponding to 32 microsteps for each of the four steps in a step cycle); when the motor drive logic <b>230</b> supports microstepping at other intervals, the number of entries in the lookup table may vary accordingly, or in any other desired manner.</div>
</li> <li> <para-num num="[0132]"> </para-num> <div class="description-line" id="p-0133" num="0132">In some other embodiments, the drive current scheme illustrated in the plot <b>600</b>A of <figref idrefs="DRAWINGS">FIG. 19</figref> may be stored in a lookup table and used by the motor drive logic <b>230</b> to determine the appropriate drive current for each of the phases of a stepper motor <b>212</b> based on the current location of the stepper motor <b>212</b> in a step cycle by looking ahead in the lookup table by a full step. For example, the example data structure <b>402</b> of <figref idrefs="DRAWINGS">FIG. 20</figref> may relate locations in the step cycle to the drive currents for the phases “A” and “B” of a two-phase stepper motor <b>212</b> in accordance with the plot <b>600</b>A; in use, the motor drive logic <b>230</b> may determine the normalized drive currents to apply by identifying the entry in the data structure <b>402</b> corresponding to the location that is one full step ahead of the current location in the step cycle. The number of entries in the lookup table (corresponding to the resolution of the “sampling” of the plot <b>600</b>A) may have any desired value. Storing the drive currents of the plot <b>600</b>A in the data structure <b>402</b> of <figref idrefs="DRAWINGS">FIG. 20</figref> may advantageously allow the data structure <b>402</b> to be used in two different ways; in a conventional manner (e.g., when the motor <b>212</b> is being controlled in an open-loop fashion, with drive currents identified by looking at the entry in the lookup table associated with the current motor position) and in an increased-torque manner (e.g., when the motor <b>212</b> is being controlled in a closed-loop fashion, with drive currents identified by “looking ahead” to the entry in the lookup table corresponding to one step ahead of the current motor position).</div>
</li> <li> <para-num num="[0133]"> </para-num> <div class="description-line" id="p-0134" num="0133">The data structure <b>402</b> of <figref idrefs="DRAWINGS">FIG. 20</figref> also includes a “decay mode” column, which may be used to specify a decay mode for an H-bridge <b>260</b> included in the drive support circuitry <b>216</b>, as discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 24-28</figref>. As known in the art, H-bridges <b>260</b> may be used to pulse width modulate an on/off circuit to approximate a desired value; some H-bridges <b>260</b> may enable a “decay mode” to be set to control how current is managed during the “off” times of the pulse width modulated signal. In some embodiments, different decay modes (e.g., slow, fast, mixed, etc.) may be utilized at different points in the step cycle; for example, when the current to a phase is increasing, a “slow decay” mode may be used, and when the current to a phase is increasing, the “fast decay” mode may be used.</div>
</li> <li> <para-num num="[0134]"> </para-num> <div class="description-line" id="p-0135" num="0134"> <figref idrefs="DRAWINGS">FIG. 21</figref> is a flow diagram of an example method <b>340</b> of driving a motor <b>212</b> in a robotic system <b>100</b>, in accordance with various embodiments. The method <b>340</b> may be carried out by the motor drive logic <b>230</b> of a joint-level compute hardware <b>210</b> (which may be located in the robotic apparatus <b>101</b>, and physically proximate to the joint <b>108</b>), and in some embodiments, may be performed in response to an instruction from the control logic <b>104</b> (e.g., the motion/position logic <b>132</b>) to move the joint <b>108</b>. In some embodiments, each of the different joints <b>108</b> in a robotic apparatus <b>101</b> may include a joint-level compute hardware <b>210</b> having motor drive logic <b>230</b> that performs the method <b>340</b> for that particular joint <b>108</b>. In some embodiments, the method <b>340</b> is a particular example of a method that may be performed at <b>338</b> of the closed-loop control method <b>330</b> of <figref idrefs="DRAWINGS">FIG. 18</figref>.</div>
</li> <li> <para-num num="[0135]"> </para-num> <div class="description-line" id="p-0136" num="0135">At <b>342</b>, a current value of a shaft encoder may be read. As discussed above, the shaft encoder may monitor the angular position of the shaft of a motor (e.g., the shaft <b>248</b> of the stepper motor <b>212</b>). For example, the motor drive logic <b>230</b> may receive output data from the shaft encoder <b>222</b>.</div>
</li> <li> <para-num num="[0136]"> </para-num> <div class="description-line" id="p-0137" num="0136">At <b>344</b>, a calibration table may be used to determine a current motor position corresponding to the current shaft encoder value. For example, the motor drive logic <b>230</b> may use a lookup table like the data structure <b>400</b> of <figref idrefs="DRAWINGS">FIG. 16</figref> to determine a current position of a stepper motor <b>212</b> based on the shaft encoder value of 342.</div>
</li> <li> <para-num num="[0137]"> </para-num> <div class="description-line" id="p-0138" num="0137">At <b>346</b>, the current motor position may be compared to a target motor position to generate an error value. For example, the motor drive logic <b>230</b> may compare the current position of the stepper motor <b>212</b> (determined at <b>344</b>) to a target position of the stepper motor <b>212</b> (e.g., as specified by an instruction from the control logic <b>104</b>). At <b>348</b>, the error value may be provided to a control loop to generate a drive current scale factor. For example, the motor drive logic <b>230</b> may implement any of the control loops discussed above with reference to <figref idrefs="DRAWINGS">FIG. 18</figref> (e.g., a PID control loop) such that inputting an error value to the control loop results in the output of a drive current scale factor.</div>
</li> <li> <para-num num="[0138]"> </para-num> <div class="description-line" id="p-0139" num="0138">At <b>350</b>, the current location of the motor in the step cycle may be determined. For example, the motor drive logic <b>230</b> may determine a current location in the step cycle based on the motor position determined at <b>344</b>. The determination of the step cycle location may utilize a lookup table relating locations in the step cycle to motor position, or may use a calculation relating locations in the step cycle to motor position (e.g., dividing the current motor position by the number of degrees per step cycle, and then dividing the remainder by the number of degrees per step cycle).</div>
</li> <li> <para-num num="[0139]"> </para-num> <div class="description-line" id="p-0140" num="0139">At <b>352</b>, the motor location one full step ahead of the current motor location in the step cycle may be identified. For example, the motor drive logic <b>230</b> may determine that the stepper motor <b>212</b> is currently at a location of X steps in the step cycle, and thus the motor drive logic <b>230</b> may identify X+1 steps in the step cycle.</div>
</li> <li> <para-num num="[0140]"> </para-num> <div class="description-line" id="p-0141" num="0140">At <b>354</b>, nominal drive currents for each motor phase at the identified motor location in a conventional step cycle may be looked up. For example, the motor drive logic <b>230</b> may utilize a lookup table like the data structure <b>402</b> of <figref idrefs="DRAWINGS">FIG. 20</figref> to determine a nominal A drive current and a nominal B drive current in the conventional drive scheme of the plot <b>600</b>A of <figref idrefs="DRAWINGS">FIG. 19</figref> corresponding to the step cycle location identified at <b>352</b> (i.e., X+1 steps). When the data structure <b>402</b> stores the A drive current and the B drive current of the conventional drive scheme plot <b>600</b>A of <figref idrefs="DRAWINGS">FIG. 19</figref>, this use of the data structure <b>402</b> of <figref idrefs="DRAWINGS">FIG. 20</figref> at <b>354</b> is not to identify the A drive current and the B drive current corresponding to the current step cycle location, but to the step cycle location that is one step advanced from the current step cycle location. When the data structure <b>402</b> stores the A drive current and the B drive current of the increased-torque drive scheme plot <b>600</b>B of <figref idrefs="DRAWINGS">FIG. 19</figref>, this use of the data structure <b>402</b> of <figref idrefs="DRAWINGS">FIG. 20</figref> at <b>354</b> is to identify the A drive current and the B drive current corresponding to the current step cycle location.</div>
</li> <li> <para-num num="[0141]"> </para-num> <div class="description-line" id="p-0142" num="0141">At <b>356</b>, the nominal drive currents (looked up at <b>354</b>) may be scaled by the drive current scale factor (generated at <b>348</b>) to generate scaled drive currents. For example, the motor drive logic <b>230</b> may multiply the nominal A and B drive currents (looked up in the data structure <b>402</b> of <figref idrefs="DRAWINGS">FIG. 20</figref> at <b>354</b>) by the drive current scale factor (generated by the control loop at <b>348</b>) to generate scaled drive currents for the A and B phases of the stepper motor <b>212</b>.</div>
</li> <li> <para-num num="[0142]"> </para-num> <div class="description-line" id="p-0143" num="0142">At <b>358</b>, drive currents may be caused to be applied to the associated motor phases based on the scaled drive currents (generated at <b>356</b>). For example, the motor drive logic <b>230</b> may generate a drive current control signals for drive support circuitry <b>216</b> to cause the drive support circuitry <b>216</b> to generate motor drive currents based on the scaled drive currents generated at <b>356</b>. In some embodiments, the motor drive currents may be equal to the scaled drive currents generated at <b>356</b>, while in other embodiments, further operations may be performed on the scaled drive currents in order to generate the motor drive currents.</div>
</li> <li> <para-num num="[0143]"> </para-num> <div class="description-line" id="p-0144" num="0143">In some embodiments, determining A and B drive currents in accordance with the increased-torque drive schemes disclosed herein may also include adjusting the A and B drive currents from their nominal increased-torque values to account for back electromotive forces and other non-idealities encountered during the operation of the motor <b>212</b>. For example, determining A and B drive currents in accordance with the increased-torque drive schemes disclosed herein may include increasing or decreasing the nominal increased-torque A and B drive currents to account for back electromotive forces (which may vary as a function of the A and B drive currents). Such “adjusted” currents may further increase the torque provided by a motor <b>212</b>. In some embodiments, adjusting the A and B drive currents to account for back electromotive forces may be performed by identifying the motor location that is more or less than one full step away from the current motor location in a step cycle by some amount, and then nominal drive currents for each motor phase at the identified motor location in a conventional step cycle may be looked up and utilized as discussed above.</div>
</li> <li> <para-num num="[0144]"> </para-num> <div class="description-line" id="p-0145" num="0144"> <figref idrefs="DRAWINGS">FIG. 22</figref> is an example of driver phase control circuitry <b>265</b> that may be used in a robotic system <b>100</b>, in accordance with various embodiments. In particular, the driver phase control circuitry <b>265</b> may be used to generate the “B” drive signal for the “B” phase of a stepper motor <b>212</b> from the “A” drive signal for the “A” phase of the stepper motor <b>212</b> (or vice versa, as will be understood from the diagram and the accompanying description). Using driver phase control circuitry <b>265</b> to generate the “B” drive signal from the “A” drive signal may reduce the number of output pins required from the joint-level compute hardware <b>210</b> to generate drive signals for the stepper motor <b>212</b>, thereby allowing those pins to be used for other functions and/or allowing a joint-level compute hardware <b>210</b> with a reduced number of output pins (e.g., GPIO pins) to be used in a joint <b>108</b>. The driver phase control circuitry <b>265</b> of <figref idrefs="DRAWINGS">FIG. 22</figref> may be part of the drive support circuitry <b>216</b> of a joint <b>108</b> (e.g., as discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 24-27</figref>). The driver phase control circuitry <b>265</b> may receive, as an input (e.g., from the joint-level compute hardware <b>210</b> of a joint <b>108</b>), an “A” drive signal (representative of an A phase drive current), which may be passed through to the output (e.g., to other portions of the drive support circuitry <b>216</b>, such as the H-bridges <b>260</b> discussed below). The driver phase control circuitry <b>265</b> may include discrete logic <b>261</b>, which may be coupled to the “A” input and may invert this input by subtracting their value from one; the output of the discrete logic <b>261</b> may be a “B” drive signal (representative of a B phase drive current, and which may be provided, e.g., to other portions of the drive support circuitry <b>216</b>, such as the H-bridges <b>260</b> discussed below). The use of the discrete logic <b>261</b> to generate the “B” drive signal from the “A” drive signal enforces the one-step offset between the “A” and “B” drive signals illustrated in the plots <b>600</b>A and <b>600</b>B, without requiring dedicated output pins for the “B” drive signal from the joint-level compute hardware <b>210</b>, as discussed above.</div>
</li> <li> <para-num num="[0145]"> </para-num> <div class="description-line" id="p-0146" num="0145"> <figref idrefs="DRAWINGS">FIGS. 23-24</figref> illustrate example motor drive arrangements that may be included in joint <b>108</b> of a robotic system <b>100</b>, in accordance with various embodiments. <figref idrefs="DRAWINGS">FIG. 23</figref> depicts a motor <b>212</b> having a shaft <b>248</b> coupled to a drivetrain <b>214</b>; the output of the drivetrain <b>214</b> serves as the joint output <b>258</b>. The motor <b>212</b> may receive inputs from drive support circuitry <b>216</b> and brake support circuitry <b>218</b> (as discussed above with reference to <figref idrefs="DRAWINGS">FIG. 9</figref>). The drive support circuitry <b>216</b> and the brake support circuitry <b>218</b> may receive inputs from the joint-level compute hardware <b>210</b> (generated by the motor drive logic <b>230</b> and/or the braking logic <b>234</b>, as discussed herein). The drive support circuitry <b>216</b> and the brake support circuitry <b>218</b> may also receive “on” signals from a “motor drive on” and a “brakes on” output, respectively, of the joint-level compute hardware <b>210</b>. The “motor drive on” and the “brakes on” outputs of the joint-level compute hardware <b>210</b> (which may be logical outputs) may serve to enable motor drive and braking, respectively (e.g., as discussed below with reference to <figref idrefs="DRAWINGS">FIG. 32</figref>); although the joint-level compute hardware <b>210</b> may be configured to only enable one of motor drive and braking at any particular time, discrete logic (e.g., a NAND gate, as shown) may be coupled between the joint-level compute hardware <b>210</b> and the brake support circuitry <b>218</b> to provide a further, hardware-based control to prevent the simultaneous enabling of motor drive and braking. In some embodiments, the brake support circuitry <b>218</b> may further be coupled to a set of mechanical brakes <b>116</b> (not shown in <figref idrefs="DRAWINGS">FIG. 23</figref>, but discussed above with reference to <figref idrefs="DRAWINGS">FIG. 2</figref>), while in other embodiments, the braking logic <b>234</b> and brake support circuitry <b>218</b> (when utilized), may be used in accordance with the embodiments discussed below instead of the use of mechanical brakes <b>116</b>. The braking techniques disclosed herein may remove or reduce the need for heavy, expensive mechanical brakes <b>116</b>, further enabling the use of the robotic systems <b>100</b> disclosed herein in new settings.</div>
</li> <li> <para-num num="[0146]"> </para-num> <div class="description-line" id="p-0147" num="0146"> <figref idrefs="DRAWINGS">FIG. 24</figref> illustrates a particular embodiment of the arrangement of <figref idrefs="DRAWINGS">FIG. 23</figref>. In <figref idrefs="DRAWINGS">FIG. 24</figref>, the motor <b>212</b> may include “A+”, “A−”, “B+”, and “B−” inputs to drive the associated phases of the motor <b>212</b>; the arrangement of <figref idrefs="DRAWINGS">FIG. 24</figref> (and the other arrangements disclosed herein) may be generalized to motors <b>212</b> with any desired number of phases (e.g., four phases). The drive support circuitry <b>216</b> may include a set of H-bridges <b>260</b> and the driver phase control circuitry <b>265</b> of <figref idrefs="DRAWINGS">FIG. 22</figref>; in some embodiments, the driver phase control circuitry <b>265</b> may not be included, the joint-level compute hardware <b>210</b> itself may generate the “B” drive signals, as discussed above. In particular, motor drive signals (e.g., drive signals for the “A” phase of the stepper motor <b>212</b>) may be output from the joint-level compute hardware <b>210</b> to the driver phase control circuitry <b>265</b>, the driver phase control circuitry <b>265</b> may output drive signals for both the “A” and “B” phases of the motor <b>212</b> to the H-bridges <b>260</b>, and the H-bridges <b>260</b> may generate M<b>1</b>, M<b>2</b>, M<b>3</b>, and M<b>4</b> outputs for the “A+”, “A−”, “B+”, and “B−” inputs of the motor <b>212</b>. The “motor drive on” output of the joint-level compute hardware <b>210</b> may be provided to an enable input of the H-bridges <b>260</b>. <figref idrefs="DRAWINGS">FIG. 25</figref> illustrates H-bridges <b>260</b> that may be included in a motor drive arrangement in a robotic system <b>100</b>, in accordance with various embodiments.</div>
</li> <li> <para-num num="[0147]"> </para-num> <div class="description-line" id="p-0148" num="0147">Returning to <figref idrefs="DRAWINGS">FIG. 24</figref>, the brake support circuitry <b>218</b> may include switch circuitry <b>262</b>, which may include a switch “S<b>1</b>” and a switch “S<b>2</b>.” The switch “S<b>1</b>” may be coupled between the “A+” and “A-” inputs of the stepper motor <b>212</b>, and the switch “S<b>2</b>” may be coupled between the “B+” and “B−” inputs of the stepper motor <b>212</b>. Although the switches S<b>1</b> and S<b>2</b> are illustrated as open in <figref idrefs="DRAWINGS">FIG. 24</figref>, the switches S<b>1</b> and S<b>2</b> may be normally closed, and only opened when the switch circuitry <b>262</b> does not receive a “brakes on” signal from the joint-level compute hardware <b>210</b> (also referred to herein as receiving a “brakes off” signal). Shorting the leads of each phase of the stepper motor <b>212</b> (also referred to herein as “shorting each phase”) may, in conjunction with a quasi-direct drivetrain <b>214</b> (e.g., having a gear ratio between 1:1 and 20:1), produce enough braking force to serve as a brake on a joint <b>108</b> (e.g., enough force to overcome gravity when the robotic system <b>100</b> is powered off, and thus maintain the joint <b>108</b> in a particular position). However, the braking force provided by such braking techniques may be overcome by typical human force, and thus may be particularly suitable for use in collaborative robotics settings.</div>
</li> <li> <para-num num="[0148]"> </para-num> <div class="description-line" id="p-0149" num="0148"> <figref idrefs="DRAWINGS">FIG. 26</figref> illustrates a particular embodiment of the arrangement of <figref idrefs="DRAWINGS">FIG. 24</figref>. In <figref idrefs="DRAWINGS">FIG. 26</figref>, the switch circuitry <b>262</b> may include solid state or mechanical relays as the switches S<b>1</b> and S<b>2</b>. These relays may be normally closed (e.g., closed in a zero-power situation) so that the braking force applies when the robotic system <b>100</b> is powered down.</div>
</li> <li> <para-num num="[0149]"> </para-num> <div class="description-line" id="p-0150" num="0149"> <figref idrefs="DRAWINGS">FIG. 27</figref> illustrates another embodiment of the arrangement of <figref idrefs="DRAWINGS">FIG. 26</figref>, one in which the drive support circuitry <b>216</b> takes the form of the drive support circuitry <b>216</b> of <figref idrefs="DRAWINGS">FIG. 24</figref>. Further, in the embodiment of <figref idrefs="DRAWINGS">FIG. 27</figref>, no brake support circuitry <b>218</b> is included. Instead, the braking logic <b>234</b> of the joint-level compute hardware <b>210</b> may cause switches (e.g., metal oxide semiconductor field effect transistors (MOSFETs)) in the H-bridges <b>260</b> to short the phases of the stepper motor <b>212</b> to provide a braking force. Such MOSFETs may desirably have a low Rds(on). In such an embodiment, the H-bridges <b>260</b> may be configured to short the phases of the stepper motor <b>212</b> to provide a braking force in a zero-power situation.</div>
</li> <li> <para-num num="[0150]"> </para-num> <div class="description-line" id="p-0151" num="0150"> <figref idrefs="DRAWINGS">FIG. 28</figref> is a flow diagram of a method <b>500</b> of braking in a robotic system <b>100</b>, in accordance with various embodiments. The method <b>500</b> may be carried out by the braking logic <b>234</b> of a joint-level compute hardware <b>210</b> (which may be located in the robotic apparatus <b>101</b>, and physically proximate to the joint <b>108</b>), and in some embodiments, may be carried out continuously (e.g., as part of a state machine flow). In some embodiments, each of the different joints <b>108</b> in a robotic apparatus <b>101</b> may include a joint-level compute hardware <b>210</b> having braking logic <b>234</b> that performs the method <b>500</b> for that particular joint <b>108</b>.</div>
</li> <li> <para-num num="[0151]"> </para-num> <div class="description-line" id="p-0152" num="0151">At <b>502</b>, it may be determined whether brakes should be on. For example, the braking logic <b>234</b> of a joint-level compute hardware <b>210</b> may receive an instruction to turn brakes on or off from system-level compute hardware <b>124</b> (which may be performing the method <b>360</b> of <figref idrefs="DRAWINGS">FIG. 32</figref>, discussed further below). Alternately or additionally, the braking logic <b>234</b> of a joint-level compute hardware <b>210</b> may receive an instruction to turn brakes on in response to detection of a fault by the joint safety logic <b>236</b> of the joint-level compute hardware <b>210</b> (e.g., as discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 31 and 32</figref>).</div>
</li> <li> <para-num num="[0152]"> </para-num> <div class="description-line" id="p-0153" num="0152">If it is determined at <b>502</b> that brakes should not be on, the method <b>500</b> may proceed to <b>504</b> and control of the “A+”, “A−”, “B+”, and “B−” phases of a stepper motor may be released. For example, the braking logic <b>234</b> of a joint-level compute hardware <b>210</b> may generate a “brakes off” signal and provide that “brakes off” signal to brake support circuitry <b>218</b> (which may cause, for example, switches “S<b>1</b>” and “S<b>2</b>” of the brake support circuitry <b>218</b> to open). The method <b>500</b> may then return to <b>502</b>.</div>
</li> <li> <para-num num="[0153]"> </para-num> <div class="description-line" id="p-0154" num="0153">If it is determined at <b>502</b> that brakes should be on, the method <b>500</b> may proceed to <b>506</b> and shorting of the “A+” and “A−” phases of the stepper motor may be caused. The method <b>500</b> may then proceed to <b>508</b> and shorting of the “B+” and “B−” phases of the stepper motor may be caused. For example, the braking logic <b>234</b> of a joint-level compute hardware <b>210</b> may generate a “brakes on” signal and provide that “brakes on” signal to brake support circuitry <b>218</b> (which may cause, for example, switches “S<b>1</b>” and “S<b>2</b>” of the brake support circuitry <b>218</b> to close). As noted above, the particular ordering of the steps in the method <b>500</b> is simply illustrative, and in some embodiments, the operations of <b>506</b> and <b>508</b> may be performed simultaneously. The method <b>500</b> may then return to <b>502</b>.</div>
</li> <li> <para-num num="[0154]"> </para-num> <div class="description-line" id="p-0155" num="0154">As noted above, in a joint <b>108</b>, motor drive and braking may not be turned on at the same time. <figref idrefs="DRAWINGS">FIG. 29</figref> is a flow diagram of an example method <b>360</b> of enabling motor drive and braking in a robotic system <b>100</b>, in accordance with various embodiments. The method <b>360</b> may be carried out by the motor drive logic <b>230</b> in conjunction with the braking logic <b>234</b> of a joint-level compute hardware <b>210</b> (which may be located in the robotic apparatus <b>101</b>, and physically proximate to the joint <b>108</b>), and in some embodiments, may be performed upon startup of a robotic system <b>100</b>. In some embodiments, each of the different joints <b>108</b> in a robotic apparatus <b>101</b> may include a joint-level compute hardware <b>210</b> having motor drive logic <b>230</b>/braking logic <b>234</b> that performs the method <b>360</b> for that particular joint <b>108</b>.</div>
</li> <li> <para-num num="[0155]"> </para-num> <div class="description-line" id="p-0156" num="0155">At <b>362</b>, brakes may be on and motor drive may be off. For example, the braking logic <b>234</b> may generate a “brakes on” signal for communication to the brake support circuitry <b>218</b> and the motor drive logic <b>230</b> may generate a “motor drive off” signal for communication to the drive support circuitry <b>216</b>. The state at <b>362</b> may be the initial state of a robotic system <b>100</b> upon power-up.</div>
</li> <li> <para-num num="[0156]"> </para-num> <div class="description-line" id="p-0157" num="0156">At <b>364</b>, it is determined whether the brakes should be turned off. For example, the braking logic <b>234</b> may determine whether a “brakes off” command has been issued by the system-level compute hardware <b>124</b> (e.g., in response to a “brakes off” voice command by a user received at a microphone of the I/O devices <b>120</b> and recognized by the voice command logic <b>170</b> of the system-level compute hardware <b>124</b>).</div>
</li> <li> <para-num num="[0157]"> </para-num> <div class="description-line" id="p-0158" num="0157">If it is determined at <b>364</b> that the brakes should be turned off, the method <b>360</b> proceeds to <b>366</b>, at which the brakes are off and the motor drive is off. For example, at <b>366</b>, the braking logic <b>234</b> may generate a “brakes on” signal for communication to the brake support circuitry <b>218</b> and the motor drive logic <b>230</b> may generate a “motor drive off” signal for communication to the drive support circuitry <b>216</b>. In such a state, the joint <b>108</b> may be physically adjusted by a human user using typical human force. From <b>366</b>, the method <b>360</b> may proceed to <b>368</b>, at which it may be determined whether the brakes should be turned on. For example, the braking logic <b>234</b> may determine whether a “brakes on” command has been issued by the system-level compute hardware <b>124</b> (e.g., in response to a “brakes on” voice command by a user received at a microphone of the I/O devices <b>120</b> and recognized by the voice command logic <b>170</b> of the system-level compute hardware <b>124</b>). In some embodiments, a robotic apparatus <b>101</b> may include a designated I/O device <b>120</b>, such as a button, that, upon actuation, causes the braking logic <b>234</b> of each of the joints <b>108</b> of a robotic apparatus <b>101</b> to generate a “brakes on” signal for communication to the brake support circuitry <b>218</b> of that joint <b>108</b> without requiring receipt of a command from the system-level compute hardware <b>124</b>; such an embodiment may allow a user to quickly brake all of the joints <b>108</b> in a robotic apparatus <b>101</b> independent of the operation of the system-level compute hardware <b>124</b>. If it is determined at <b>368</b> that the brakes should be turned on, the method <b>360</b> returns to <b>362</b>.</div>
</li> <li> <para-num num="[0158]"> </para-num> <div class="description-line" id="p-0159" num="0158">If it is determined at <b>364</b> that the brakes should not be turned off, or if it is determined at <b>368</b> that the brakes should be turned on, the method <b>360</b> may proceed to <b>370</b>, at which it may be determined whether the motor drive should be turned on. For example, the braking logic <b>234</b> may determine whether a “motor drive on” command has been issued by the system-level compute hardware <b>124</b> (e.g., in response to a “control on” voice command by a user received at a microphone of the I/O devices <b>120</b> and recognized by the voice command logic <b>170</b> of the system-level compute hardware <b>124</b>).</div>
</li> <li> <para-num num="[0159]"> </para-num> <div class="description-line" id="p-0160" num="0159">If it is determined at <b>370</b> that the motor drive should not be turned on, the method <b>360</b> returns to <b>362</b>. If it is determined at <b>370</b> that the motor drive should be turned on, the method <b>360</b> proceeds to <b>372</b>, at which the brakes are off and the motor drive is on. For example, at <b>372</b>, the braking logic <b>234</b> may generate a “brakes off” signal for communication to the brake support circuitry <b>218</b> and the motor drive logic <b>230</b> may generate a “motor drive on” signal for communication to the drive support circuitry <b>216</b>. In this state, the joint <b>108</b> may be moved by sending appropriate drive signals to the motor <b>212</b> of the joint <b>108</b>.</div>
</li> <li> <para-num num="[0160]"> </para-num> <div class="description-line" id="p-0161" num="0160">From <b>372</b>, the method <b>360</b> may proceed to <b>374</b>, at which it may be determined whether a fault has been detected. For example, a fault may be detected by a joint-level safety method (e.g., as discussed below with reference to <figref idrefs="DRAWINGS">FIG. 30</figref>) or by system-level safety method (e.g., as discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 40-41</figref>). The joint safety logic <b>236</b> of the joint-level compute hardware <b>210</b> may itself detect the fault (e.g., in accordance with the method of <figref idrefs="DRAWINGS">FIG. 30</figref>) or may receive an indication of the fault (e.g., a joint-level fault from another joint <b>108</b>, or a system-level fault) from system-level compute hardware <b>124</b> via the communications hardware <b>226</b>.</div>
</li> <li> <para-num num="[0161]"> </para-num> <div class="description-line" id="p-0162" num="0161">If it is determined at <b>374</b> that a fault has been detected, the method <b>360</b> returns to <b>362</b>. If it is determined at <b>374</b> that a fault has not been detected, the method <b>360</b> proceeds to <b>376</b>, at which it may be determined whether the motor drive should be turned off. For example, the braking logic <b>234</b> may determine whether a “motor drive off” command has been issued by the system-level compute hardware <b>124</b> (e.g., in response to a “control off” voice command by a user received at a microphone of the I/O devices <b>120</b> and recognized by the voice command logic <b>170</b> of the system-level compute hardware <b>124</b>). If it is determined at <b>376</b> that the motor drive should not be turned off, the method <b>360</b> may return to <b>374</b>. If it is determined at <b>376</b> that the motor drive should be turned off, the method <b>360</b> may return to <b>362</b>.</div>
</li> <li> <para-num num="[0162]"> </para-num> <div class="description-line" id="p-0163" num="0162">Safety and faults in a robotic system <b>100</b> may be monitored and controlled at both the joint-level and the system-level. For example, <figref idrefs="DRAWINGS">FIG. 31</figref> is a flow diagram of a method <b>510</b> of detecting joint-level faults in a robotic system <b>100</b>, in accordance with various embodiments. The method <b>510</b> may be carried out by the joint safety logic <b>236</b> of a joint-level compute hardware <b>210</b> (which may be located in the robotic apparatus <b>101</b>, and physically proximate to the joint <b>108</b>), and in some embodiments, may be performed upon startup of a robotic system <b>100</b>. In some embodiments, each of the different joints <b>108</b> in a robotic apparatus <b>101</b> may include a joint-level compute hardware <b>210</b> having joint safety logic <b>236</b> that performs the method <b>510</b> for that particular joint <b>108</b>. Further, although the method <b>510</b> refers to monitoring of a single joint performance variable, this is simply for ease of illustration, and multiple joint performance variables (with multiple associated safety ranges) may be monitored as part of the method <b>510</b>.</div>
</li> <li> <para-num num="[0163]"> </para-num> <div class="description-line" id="p-0164" num="0163">At <b>512</b>, a value of a joint performance variable may be measured. The joint performance variable may be any variable indicative of operation of the associated joint. For example, in some embodiments, the joint safety logic <b>236</b> of a joint-level compute hardware <b>210</b> of a joint <b>108</b> may measure joint position (e.g., the position of the joint output <b>258</b>), joint velocity (e.g., the velocity of the joint output <b>258</b>), current drawn by the motor <b>212</b>, temperature at the joint <b>108</b>, error in the control loop of <b>348</b> of the method <b>340</b> of <figref idrefs="DRAWINGS">FIG. 21</figref>, data from the accelerometer <b>224</b> (which may be part of data provided by an IMU, all of which may be measured at <b>236</b>), velocity and/or acceleration data from the shaft encoder <b>222</b>, and/or any other variable indicative of operation of the joint <b>108</b>. The measurement of the joint performance variable may result from communication between the joint-level compute hardware <b>210</b> and a sensor (e.g., the shaft encoder <b>222</b>, the accelerometer <b>224</b>, temperature or current sensors included in the other hardware <b>227</b>, etc.).</div>
</li> <li> <para-num num="[0164]"> </para-num> <div class="description-line" id="p-0165" num="0164">At <b>514</b>, it may be determined whether the measured value is outside of a safety range or not. As used herein, a “safety range” may refer to one or more sets of values of a joint performance variable that represent acceptable operational conditions. For example, the data storage <b>229</b> of the joint <b>108</b> may store ranges of safe values of the joint performance variable and/or ranges of unsafe values of the joint performance variable; at <b>514</b>, the joint safety logic <b>236</b> may compare the measured value of the joint performance variable to these range(s) to determine whether the value is within a safety range or outside of a safety range (e.g., whether the velocity of the joint <b>108</b> is less than a maximum allowable velocity, whether the temperature of the joint <b>108</b> is within a range over which the joint-level compute hardware <b>210</b> may perform reliably, etc.). Generally, thresholds, minimums, maximums, averages, derivatives, or any other suitable range for any measured variable or combination of variables may be set as a safety range. The safety range(s) used at <b>514</b> may be programmable, as desired.</div>
</li> <li> <para-num num="[0165]"> </para-num> <div class="description-line" id="p-0166" num="0165">If it is determined at <b>514</b> that the measured value is within a safety range, the method <b>510</b> may return to <b>512</b>. If it is determined at <b>514</b> that the measured value is outside a safety range, a fault (corresponding to the measured value being outside the safety range) may be identified at <b>516</b>. For example, the joint safety logic <b>236</b> may generate a fault signal upon detection of a measured value of a joint performance variable being outside a safety range. This fault signal may be utilized by other elements of the robotic system <b>100</b> in any of a number of ways, several of which are discussed in detail herein.</div>
</li> <li> <para-num num="[0166]"> </para-num> <div class="description-line" id="p-0167" num="0166"> <figref idrefs="DRAWINGS">FIG. 31</figref> is a flow diagram of a method <b>520</b> of responding to faults in a robotic system <b>100</b>, in accordance with various embodiments. The method <b>520</b> may be carried out by the joint safety logic <b>236</b> of a joint-level compute hardware <b>210</b> (which may be located in the robotic apparatus <b>101</b>, and physically proximate to the joint <b>108</b>), and in some embodiments, may be performed in response to detection of a fault (e.g., a joint-level fault, as discussed above with reference to <figref idrefs="DRAWINGS">FIG. 30</figref>, or a system-level fault, as discussed above with reference to <figref idrefs="DRAWINGS">FIGS. 40-41</figref>). The fault may be identified to the joint safety logic <b>236</b> by the joint safety logic <b>236</b> itself (e.g., when the fault is detected in the joint <b>108</b> associated with the joint safety logic <b>236</b>) or identified upon receipt of a fault signal from the system-level compute hardware <b>124</b> (e.g., when the fault is detected in another joint <b>108</b>, and/or the fault is a system-level fault). In some embodiments, each of the different joints <b>108</b> in a robotic apparatus <b>101</b> may include a joint-level compute hardware <b>210</b> having joint safety logic <b>236</b> that performs the method <b>520</b> for that particular joint <b>108</b>; in response to detection of a joint-level or system-level fault, all of the joints <b>108</b> of a robotic apparatus <b>101</b> may perform the method <b>520</b>.</div>
</li> <li> <para-num num="[0167]"> </para-num> <div class="description-line" id="p-0168" num="0167">At <b>522</b>, power down of the motor may be caused. For example, the joint safety logic <b>236</b> may communicate with the motor drive logic <b>230</b> to cause the motor drive logic <b>230</b> to slow down and stop the motor <b>212</b> (e.g., by reducing the drive current scale factor of the method <b>340</b> of <figref idrefs="DRAWINGS">FIG. 21</figref> to zero).</div>
</li> <li> <para-num num="[0168]"> </para-num> <div class="description-line" id="p-0169" num="0168">At <b>524</b>, application of the brakes to the motor may be caused. For example, the joint safety logic <b>236</b> may communicate with the braking logic <b>234</b> to cause the braking logic <b>234</b> to turn the brakes on (e.g., in accordance with any of the embodiments discussed above with reference to <figref idrefs="DRAWINGS">FIGS. 24-28</figref>).</div>
</li> <li> <para-num num="[0169]"> </para-num> <div class="description-line" id="p-0170" num="0169">As noted above, in some embodiments, joints <b>108</b> of a robotic apparatus <b>101</b> may include LEDs <b>220</b>. The LEDs <b>220</b> of a joint <b>108</b> may be used to indicate a status of the joint <b>108</b> and/or a status of the robotic apparatus <b>101</b>. <figref idrefs="DRAWINGS">FIG. 32</figref> is a flow diagram of a method <b>530</b> of utilizing visual indicators at a joint <b>108</b> in a robotic system <b>100</b>, in accordance with various embodiments. The method <b>530</b> is discussed with reference to setting LEDs <b>220</b> to various states, but any suitable visual indicator (e.g., an alphanumeric display) may be used. The method <b>530</b> may be carried out by the LED control logic <b>238</b> of a joint-level compute hardware <b>210</b> (which may be located in the robotic apparatus <b>101</b>, and physically proximate to the joint <b>108</b>), and in some embodiments, may be performed upon power-on of the robotic apparatus <b>101</b>. Further, although the discussion of the method <b>530</b> refers to a single “LED,” this is simply for ease of illustration, and the method <b>530</b> may involve changing the state of multiple LEDs <b>220</b> of a joint <b>108</b>.</div>
</li> <li> <para-num num="[0170]"> </para-num> <div class="description-line" id="p-0171" num="0170">At <b>532</b>, the LED may be set to a booting state. For example, the LED control logic <b>238</b> may cause the LED to output a particular color and/or pattern (e.g., a turquoise color with a slow fade) to indicate booting. In some embodiments, the booting process may include performing a self-check; if the self-check fails, the LED control logic <b>328</b> may cause the LED to output a different color and/or pattern than that of the booting state (e.g., a purple color that is flashing).</div>
</li> <li> <para-num num="[0171]"> </para-num> <div class="description-line" id="p-0172" num="0171">At <b>534</b>, it may be determined whether calibration of the joint is needed. For example, the LED control logic <b>238</b> may determine whether the joint <b>108</b> has been calibrated (e.g., by determining whether a “joint calibrated” indicator has been set in the data storage <b>229</b> by the joint calibration logic <b>232</b>) or not. If it is determined at <b>534</b> that joint calibration is needed, the method <b>530</b> may proceed to <b>536</b>, at which it may be determined whether the joint is calibrating. For example, the LED control logic <b>238</b> may determine whether the joint <b>108</b> is calibrating (e.g., by determining whether a “joint calibrating” indicator has been set in the data storage <b>229</b> by the joint calibration logic <b>232</b>) or not. Calibration of a joint <b>108</b> may be performed in accordance with the embodiments discussed above with reference to <figref idrefs="DRAWINGS">FIGS. 15 and 16</figref>, for example. If it is determined at <b>536</b> that the joint is calibrating, the method <b>530</b> may proceed to <b>538</b> and an LED may be set to a calibration state. For example, the LED control logic <b>238</b> may cause the LED to output a particular color and/or pattern (e.g., a solid yellow color) to indicate calibration. After <b>538</b>, the method <b>530</b> may return to <b>536</b>, and the LED may be set to the calibration state until it is determined at <b>536</b> that the joint is no longer calibrating, at which point the method <b>530</b> may proceed to <b>542</b> and an LED may be set to a calibration complete state. For example, the LED control logic <b>238</b> may cause the LED to output a particular color and/or pattern (e.g., a fast fading green color) to indicate that calibration is complete.</div>
</li> <li> <para-num num="[0172]"> </para-num> <div class="description-line" id="p-0173" num="0172">If it is determined at <b>534</b> that joint calibration is not needed, or if the LED has been set to the calibration complete state at <b>542</b>, the method <b>530</b> may proceed to <b>544</b> to determine if system-level compute hardware is detected. For example, the LED control logic <b>238</b> may determine whether system-level compute hardware <b>124</b> is detected (e.g., by detecting receipt of an expected command from the system-level compute hardware <b>124</b>) or not. If it is determined at <b>544</b> that system-level compute hardware is not detected, the method <b>530</b> may proceed to <b>546</b> and an LED may be set to a no system-level compute hardware state. For example, the LED control logic <b>238</b> may cause the LED to output a particular color and/or pattern (e.g., a purple color with a slow fade) to indicate that no system-level compute hardware has been detected.</div>
</li> <li> <para-num num="[0173]"> </para-num> <div class="description-line" id="p-0174" num="0173">If it is determined at <b>544</b> that system-level compute hardware has been detected, or after the LED has been set to a no system-level compute hardware state, the method <b>530</b> may proceed to <b>548</b> at which it may be determined whether the brakes are on. For example, the LED control logic <b>238</b> may determine whether the braking logic <b>234</b> is outputting a “brakes on” signal. The brake and motor drive states may be controlled in accordance with the method <b>360</b> of <figref idrefs="DRAWINGS">FIG. 29</figref>. If it is determined at <b>548</b> that the brakes are on, the method <b>530</b> may proceed to <b>550</b> and an LED may be set to a brakes on state. For example, the LED control logic <b>238</b> may cause the LED to output a particular color and/or pattern (e.g., a solid white color) to indicate that the brakes are on. If it is determined at <b>548</b> that the brakes are off, the method <b>530</b> may proceed to <b>552</b> and an LED may be set to a brakes off state. For example, the LED control logic <b>238</b> may cause the LED to output a particular color and/or pattern (e.g., a white color with a slow fade) to indicate that the brakes are off.</div>
</li> <li> <para-num num="[0174]"> </para-num> <div class="description-line" id="p-0175" num="0174">After <b>552</b>, the method <b>530</b> may proceed to <b>554</b> at which it may be determined whether the motor drive is on. For example, the LED control logic <b>238</b> may determine whether the motor drive logic <b>230</b> is outputting a “motor drive on” signal. As noted above, the brake and motor drive states may be controlled in accordance with the method <b>360</b> of <figref idrefs="DRAWINGS">FIG. 29</figref>. If it is determined at <b>554</b> that the motor drive is on, the method <b>530</b> may proceed to <b>556</b> and an LED may be set to a motor drive on state. For example, the LED control logic <b>238</b> may cause the LED to output a particular color and/or pattern (e.g., a solid green color) to indicate that the motor drive is on.</div>
</li> <li> <para-num num="[0175]"> </para-num> <div class="description-line" id="p-0176" num="0175">If it is determined at <b>554</b> that the motor drive is off, the method <b>530</b> may proceed to <b>558</b> at which it may be determined whether a fault has been detected. For example, the fault may be identified to the LED control logic <b>238</b> by the joint safety logic <b>236</b> (e.g., when the fault is detected in the joint <b>108</b> associated with the joint safety logic <b>236</b>) or identified upon receipt of a fault signal from the system-level compute hardware <b>124</b> (e.g., when the fault is detected in another joint <b>108</b>, and/or the fault is a system-level fault). If it is determined at <b>558</b> that a fault has been detected, the method <b>530</b> may proceed to <b>560</b> and an LED may be set to a fault state <b>560</b>. For example, the LED control logic <b>238</b> may cause the LED to output a particular color and/or pattern to indicate the fault (e.g., a fast blinking yellow color for a control fault, a fast blinking orange color for a driver fault, a slow blinking orange color for a bad command, a fast blinking red color for a severe error, or a slow blinking red color when a self-test fails on boot). If it is determined at <b>558</b> that no fault has been detected, the method <b>530</b> may return to <b>548</b>.</div>
</li> <li> <para-num num="[0176]"> </para-num> <div class="description-line" id="p-0177" num="0176">The selection of colors and patterns for the various states of the LEDs <b>220</b> may be selected to quickly communicate a state of the robotic apparatus <b>101</b> to a user. For example, in some embodiments, having an LED <b>220</b> take on a green color may indicate normal operating conditions. Having an LED <b>220</b> take on a red color may indicate severe and/or unanticipated errors. Having an LED <b>220</b> take on a solid color may indicate a stable condition, while a soft fading color may indicate that a transition is taking place or that action is required from a user, while a blinking color may indicate an error.</div>
</li> <li> <para-num num="[0177]"> </para-num> <div class="description-line" id="p-0178" num="0177">When the robotic system <b>100</b> is powered on, it may be desirable for the robotic apparatus <b>101</b> to move into a known, “zeroed” configuration before further movement. In such a configuration, each joint <b>108</b> of a robotic apparatus <b>101</b> may be oriented in a zeroed position from which further movement of the joints <b>108</b> (and thus the robotic apparatus <b>101</b>) may be tracked and referenced. The zeroed position for each joint <b>108</b> in a robotic apparatus <b>101</b> may be set to any desired value (e.g., by storage of a desired position in the data storage <b>229</b>). In addition to assuming the zeroed configuration upon power-on, a robotic apparatus <b>101</b> may move into a zeroed configuration on command (e.g., in response to a “home” or “go home” voice command by a user received at a microphone of the I/O devices <b>120</b> and recognized by the voice command logic <b>170</b> of the system-level compute hardware <b>124</b>, and transmitted from the system-level compute hardware <b>124</b> to the joints <b>108</b> of the robotic apparatus <b>101</b> via the communications hardware <b>128</b>). In a robotic system <b>100</b> in which the joints <b>108</b> include shaft encoders <b>222</b> and not joint encoders, the robotic system <b>100</b> can not uniquely determine the configuration of the robotic apparatus <b>101</b> upon startup; the output of a shaft encoder <b>222</b> for a particular joint <b>108</b> corresponds to up to G different joint positions, where G is the gear ratio of the drivetrain <b>214</b>. Bringing the robotic apparatus <b>101</b> to a known zero position before attempting to move the robotic apparatus <b>101</b> to a controlled position allows the angle of each joint <b>108</b> to be properly tracked by monitoring the output of the associated shaft encoder <b>222</b>.</div>
</li> <li> <para-num num="[0178]"> </para-num> <div class="description-line" id="p-0179" num="0178"> <figref idrefs="DRAWINGS">FIG. 33</figref> is a flow diagram of a gravity-based method <b>570</b> of zeroing joints <b>108</b> in a robotic system <b>100</b>, in accordance with various embodiments. The method <b>570</b> may be carried out by the zeroing logic <b>148</b> of the system-level compute hardware <b>124</b> (which may or may not be located in the robotic apparatus <b>101</b>), and in some embodiments, may be performed upon power-on of the robotic apparatus <b>101</b> or in response to a command (e.g., as discussed above). In the method <b>570</b>, the joints <b>108</b> may be indexed using a counter variable N, and the indexing may represent the order in which the joints <b>108</b> are arranged relative to a support <b>112</b> or other “starting point”. Thus, the Nth joint <b>108</b> may be mechanically between the N−1th joint <b>108</b> and the N+1th joint <b>108</b>.</div>
</li> <li> <para-num num="[0179]"> </para-num> <div class="description-line" id="p-0180" num="0179">At <b>572</b>, a counter variable N may be set equal to an initial value (e.g., 1). For example, the zeroing logic <b>148</b> may initialize a counter variable N to count through the joints <b>108</b> in a robotic apparatus <b>101</b>, as discussed further below. At <b>574</b>, the joint N may be queried to determine the zeroing method to be applied to the joint N. For example, the zeroing logic <b>148</b> may query the data storage <b>229</b> of the Nth joint <b>108</b> via the communications hardware <b>128</b> to retrieve the value of a “zeroing method” parameter stored in the data storage <b>229</b>. Alternately, the zeroing logic <b>148</b> may query the system-level data storage <b>150</b>, which may store such “zeroing method” parameters for the joints <b>108</b> of a robotic apparatus <b>101</b>.</div>
</li> <li> <para-num num="[0180]"> </para-num> <div class="description-line" id="p-0181" num="0180">At <b>576</b>, it may be determined whether the zeroing method of joint N is a limit switch. As discussed above with reference to <figref idrefs="DRAWINGS">FIG. 9</figref>, in some embodiments, a joint <b>108</b> may include a limit switch <b>228</b> that may be triggered when the joint <b>108</b> (e.g., the joint output <b>258</b>, as discussed above) reaches a particular, predetermined position. If it is determined at <b>576</b> that the zeroing method of joint N is a limit switch, the method <b>570</b> may proceed to <b>578</b>, and the joint N may be brought into alignment with the limit switch. For example, the zeroing logic <b>148</b> may communicate with the joint <b>108</b> via the communications hardware <b>128</b> to cause the motor drive logic <b>230</b> to drive the motor <b>212</b> until the limit switch <b>228</b> of the joint <b>108</b> is triggered (indicating that alignment has been reached). The motor drive logic <b>230</b> may be communicatively coupled to the limit switch <b>228</b> so that driving of the motor <b>212</b> may stop once the limit switch <b>228</b> is triggered. If it is determined at <b>576</b> that the zeroing method of joint N is not a limit switch, the method <b>570</b> may proceed to <b>580</b>, and another zeroing method (determined at <b>574</b>) may be performed for joint N. An example of such another zeroing method is the method <b>610</b> of <figref idrefs="DRAWINGS">FIG. 34</figref>, discussed below). Note that, in some embodiments, a joint <b>108</b> may include a limit switch <b>228</b>, and that limit switch <b>228</b> may be used as part of the zeroing of the joint <b>108</b>, but the actual zeroed position of the joint <b>108</b> may be a position that is a predetermined number of degrees away from the position of the limit switch <b>228</b>; in such an embodiment, the joint <b>108</b> may be brought into alignment with the limit switch <b>228</b>, and then the zeroing logic <b>148</b> may cause the motor drive logic <b>230</b> to drive the joint <b>108</b> (i.e., the joint output <b>258</b>) to the predetermined number of degrees away from the position of the limit switch <b>228</b>. The particular number of degrees may be stored in the data storage <b>229</b>, or in the system-level data storage <b>150</b>.</div>
</li> <li> <para-num num="[0181]"> </para-num> <div class="description-line" id="p-0182" num="0181">After <b>578</b> or <b>580</b>, the method <b>570</b> may proceed to <b>582</b>, and it may be determined whether the counter variable N is equal to the total number of joints (and thus that all joints have been zeroed). If it is determined that the counter variable N is not equal to the total number of joints (and thus that all joints have not yet been zeroed), the method <b>570</b> may proceed to <b>584</b>, at which the counter variable N may be incremented. The method <b>570</b> may then return to <b>574</b>. If it is determined at <b>582</b> that the counter variable N is equal to the total number of joints (and thus that all joints have been zeroed), the method <b>570</b> may end.</div>
</li> <li> <para-num num="[0182]"> </para-num> <div class="description-line" id="p-0183" num="0182">In some embodiments, a joint <b>108</b> may be zeroed using a method that does not involve a limit switch <b>228</b> at the joint <b>108</b>. <figref idrefs="DRAWINGS">FIG. 34</figref> is a flow diagram of a method <b>610</b> of zeroing the Nth joint <b>108</b> in a robotic system <b>100</b>, in accordance with various embodiments. The method <b>610</b> may be carried out by the zeroing logic <b>148</b> of the system-level compute hardware <b>124</b> (which may or may not be located in the robotic apparatus <b>101</b>), and in some embodiments, may be performed as part of a process of zeroing a robotic apparatus <b>101</b> (e.g., at <b>580</b> of the method <b>570</b> discussed above with reference to <figref idrefs="DRAWINGS">FIG. 33</figref>). In the discussion of the method <b>610</b> below, the terms “previous joint” and “N−1th joint” may be used; these terms may refer to the joint <b>108</b> that is immediately mechanically previous to the Nth joint <b>108</b> or other joint <b>108</b> that has already been zeroed, as appropriate. Similarly, the term “N+1th joint” may be used; this term may refer to the joint <b>108</b> that immediately mechanically follows the Nth joint <b>108</b>, or another joint <b>108</b> that has not yet been zeroed, as appropriate.</div>
</li> <li> <para-num num="[0183]"> </para-num> <div class="description-line" id="p-0184" num="0183">At <b>612</b>, it may be determined whether a previous joint (the N−1th joint) should be moved before zeroing the Nth joint. For example, the zeroing logic <b>148</b> may query the data storage <b>229</b> of the Nth joint <b>108</b> via the communications hardware <b>128</b> to retrieve the value of a “zeroing method” parameter stored in the data storage <b>229</b>, and the “zeroing method” parameter may be used to determine whether the N−1th joint <b>108</b> should be moved to a predetermined position before proceeding with zeroing the Nth joint <b>108</b>. Alternately, the zeroing logic <b>148</b> may query the system-level data storage <b>150</b>, which may store such “zeroing method” parameters for the joints <b>108</b> of a robotic apparatus <b>101</b>. Moving the N−1th joint before zeroing the Nth joint may be helpful in the gravity-based method <b>610</b> when the rotation of the Nth joint may be perpendicular to the force of gravity, and thus a rotation of the Nth joint may not produce a change in the acceleration of the N+1th joint due to gravity (as required for further zeroing operations, as discussed below).</div>
</li> <li> <para-num num="[0184]"> </para-num> <div class="description-line" id="p-0185" num="0184">If it is determined at <b>612</b> that the N−1th joint should be moved before zeroing the Nth joint, the method <b>610</b> may proceed to <b>610</b>, at which the N−1th joint may be moved by a predetermined amount. The N−1th joint may have been previously zeroed (e.g., in accordance with the method <b>570</b> of <figref idrefs="DRAWINGS">FIG. 33</figref>), and thus moving the N−1th joint by a predetermined amount may start from a known, zeroed position. For example, the zeroing logic <b>148</b> may communicate with the motion/position logic <b>132</b> to cause the N−1th joint to rotate by 90 degrees (e.g., when the Nth joint <b>108</b> would otherwise rotate in a plane normal to the force of gravity).</div>
</li> <li> <para-num num="[0185]"> </para-num> <div class="description-line" id="p-0186" num="0185">If it is determined at <b>612</b> that the N−1th joint should not be moved before zeroing the Nth joint, or if the N−1th joint has been moved by a predetermined amount at <b>614</b>, the method <b>610</b> may proceed to <b>616</b>, at which a reference vector for zeroing the Nth joint may be determined. For example, the zeroing logic <b>148</b> may query the data storage <b>229</b> of the Nth joint <b>108</b> via the communications hardware <b>128</b> to retrieve the value of a “reference vector” parameter stored in the data storage <b>229</b>, and the “reference vector” parameter may be used to determine the reference vector for the Nth joint <b>108</b>. Alternately, the zeroing logic <b>148</b> may query the system-level data storage <b>150</b>, which may store such “reference vector” parameters for the joints <b>108</b> of a robotic apparatus <b>101</b>. In some embodiments, the reference vector for a joint <b>108</b> that is to be “vertically” oriented in its zeroed position may be generated from an accelerometer <b>224</b> in a support <b>112</b> (e.g., a base) of the robotic apparatus <b>101</b>; the output of this accelerometer may reflect the orientation of the support <b>112</b> with respect to gravity (e.g., whether a table on which the robotic apparatus <b>101</b> sits is tilted), and may be used as a reference for the zeroing of some or all of the joints <b>108</b>.</div>
</li> <li> <para-num num="[0186]"> </para-num> <div class="description-line" id="p-0187" num="0186">At <b>618</b>, an acceleration vector may be received from the N+1th joint. For example, the zeroing logic <b>148</b> may receive, via the communication hardware <b>128</b>, an output of the accelerometer <b>224</b> of the N+1th joint <b>108</b>. When the N+1th joint <b>108</b> is stationary, the output of the accelerometer <b>224</b> of the N+1th joint <b>108</b> may align with the gravity vector, indicating the orientation of the N+1th joint <b>108</b> relative to the force of gravity. The acceleration vector of the N+1th joint <b>108</b> may be indicative of the current position of the Nth joint; for example, in the robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIGS. 5 and 6</figref>, the acceleration vector of the joint <b>108</b>-<b>6</b> may indicate the current position of the joint <b>108</b>-<b>5</b>.</div>
</li> <li> <para-num num="[0187]"> </para-num> <div class="description-line" id="p-0188" num="0187">At <b>620</b>, offset corrections may be applied to the acceleration vector <b>620</b>. For example, if it is desired that the zeroed position of the Nth joint <b>108</b> is offset from the gravity vector by a particular amount (e.g., when the robotic apparatus <b>101</b> is mounted at an angle or imperfectly manufactured), the zeroing logic <b>148</b> may apply offset corrections to the acceleration vector <b>620</b> to “correct” the acceleration vector appropriately. In some embodiments, no offset corrections may be applied.</div>
</li> <li> <para-num num="[0188]"> </para-num> <div class="description-line" id="p-0189" num="0188">At <b>622</b>, it may be determined whether the acceleration vector (received and, optionally, offset-corrected at <b>618</b>-<b>620</b>) is aligned with the reference vector (determined at <b>616</b>). “Alignment” here may refer to the acceleration vector and the reference vector being within a specified threshold of each other (e.g., 0.1 degrees or 0.01 degrees). For example, the zeroing logic <b>148</b> may determine whether the acceleration vector of the N+1th joint <b>108</b> is aligned with the reference vector of the Nth joint. If it is determined at <b>622</b> that the acceleration vector is not aligned with the reference vector, the method <b>610</b> may proceed to <b>624</b> and cause the movement of the Nth joint. For example, the zeroing logic <b>148</b> may communicate with the motion/position logic <b>132</b> to cause the Nth joint <b>108</b> to move in a direction to improve the alignment between the acceleration vector of the N+1th joint <b>108</b> and the reference vector of the Nth joint <b>108</b>. The method may then return to <b>618</b>.</div>
</li> <li> <para-num num="[0189]"> </para-num> <div class="description-line" id="p-0190" num="0189">If it is determined at <b>622</b> that the acceleration vector is aligned with the reference vector (e.g., the acceleration vector and the reference vector are within a predetermined tolerance of each other), the method <b>610</b> may proceed to <b>626</b>, at which it may be determined whether the N−1th joint was moved before zeroing the Nth joint (e.g., at <b>614</b>). If it is determined at <b>626</b> that the N−1th joint was moved before zeroing the Nth joint (e.g., at <b>614</b>), the method <b>610</b> may proceed to <b>628</b>, at which the N−1th joint may be moved back to its zero position (e.g., the position of the N−1th joint prior to <b>614</b>). If it is determined at <b>626</b> that the N−1th joint was not moved before zeroing the Nth joint, the method <b>610</b> may end.</div>
</li> <li> <para-num num="[0190]"> </para-num> <div class="description-line" id="p-0191" num="0190">The zeroing methods <b>570</b> and <b>610</b> of <figref idrefs="DRAWINGS">FIGS. 33 and 34</figref>, respectively, may be illustrated with respect to a particular embodiment of the robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIGS. 5 and 6</figref>. In this particular embodiment, the joint <b>108</b>-<b>1</b> may include a limit switch <b>228</b>. To zero this robotic apparatus <b>101</b>, the joint <b>108</b>-<b>1</b> may first be zeroed, using the limit switch <b>228</b> of the joint <b>108</b>-<b>1</b> to bring the joint <b>108</b>-<b>1</b> into alignment with a desired position. Next, the joint <b>108</b>-<b>2</b> may be zeroed in accordance with the method <b>610</b> of <figref idrefs="DRAWINGS">FIG. 34</figref>. In particular, the joint <b>108</b>-<b>2</b> may be moved until the acceleration vector at the joint <b>108</b>-<b>3</b> is aligned with a reference vector associated with the joint <b>108</b>-<b>2</b>; in some embodiments, the reference vector of the joint <b>108</b>-<b>2</b> may be the vector that is aligned with the axis of rotation <b>126</b>-<b>1</b> of the joint <b>108</b>-<b>1</b>. Next, the joint <b>108</b>-<b>3</b> may be zeroed in accordance with the method <b>610</b> of <figref idrefs="DRAWINGS">FIG. 34</figref>. In particular, the joint <b>108</b>-<b>3</b> may be moved until the acceleration vector at the joint <b>108</b>-<b>4</b> is aligned with a reference vector associated with the joint <b>108</b>-<b>3</b>; in some embodiments, the reference vector of the joint <b>108</b>-<b>3</b> may be the vector that is aligned with the axis of rotation <b>126</b>-<b>1</b> of the joint <b>108</b>-<b>1</b>.</div>
</li> <li> <para-num num="[0191]"> </para-num> <div class="description-line" id="p-0192" num="0191">Next, the joint <b>108</b>-<b>4</b> may be zeroed in accordance with the method <b>610</b> of <figref idrefs="DRAWINGS">FIG. 34</figref>. In this particular example, the joint <b>108</b>-<b>3</b> may first be moved by 90 degrees (e.g., at <b>614</b> of the method <b>610</b>) from its zeroed position, and then the joint <b>108</b>-<b>4</b> may be moved until the acceleration vector at the joint <b>108</b>-<b>5</b> is aligned with a reference vector associated with the joint <b>108</b>-<b>4</b>; in some embodiments, the reference vector of the joint <b>108</b>-<b>4</b> may be the vector that is aligned with the axis of rotation <b>126</b>-<b>1</b> of the joint <b>108</b>-<b>1</b>. The joint <b>108</b>-<b>3</b> may then be moved by 90 degrees (e.g., at <b>628</b> of the method <b>610</b>) back to its zeroed position.</div>
</li> <li> <para-num num="[0192]"> </para-num> <div class="description-line" id="p-0193" num="0192">Next, the joint <b>108</b>-<b>5</b> may be zeroed in accordance with the method <b>610</b> of <figref idrefs="DRAWINGS">FIG. 34</figref>. In particular, the joint <b>108</b>-<b>5</b> may be moved until the acceleration vector at the joint <b>108</b>-<b>6</b> is aligned with a reference vector associated with the joint <b>108</b>-<b>5</b>; in some embodiments, the reference vector of the joint <b>108</b>-<b>5</b> may be the vector that is aligned with the axis of rotation <b>126</b>-<b>1</b> of the joint <b>108</b>-<b>1</b>.</div>
</li> <li> <para-num num="[0193]"> </para-num> <div class="description-line" id="p-0194" num="0193">Finally, the joint <b>108</b>-<b>6</b> may be zeroed in accordance with the method <b>610</b> of <figref idrefs="DRAWINGS">FIG. 34</figref>. In particular, the joint <b>108</b>-<b>5</b> may first be moved by 90 degrees (e.g., at <b>614</b> of the method <b>610</b>) from its zeroed position, and then the joint <b>108</b>-<b>6</b> may be moved until the acceleration vector at the end effector <b>118</b> (e.g., an acceleration vector generated by an accelerometer or other appropriate device included in the end effector <b>118</b>) is aligned with a reference vector associated with the joint <b>108</b>-<b>6</b>; in some embodiments, the reference vector of the joint <b>108</b>-<b>6</b> may be the vector that is aligned with the axis of rotation <b>126</b>-<b>1</b> of the joint <b>108</b>-<b>1</b>. The joint <b>108</b>-<b>5</b> may then be moved by 90 degrees (e.g., at <b>628</b> of the method <b>610</b>) back to its zeroed position. The robotic apparatus <b>101</b> may then be oriented in the zeroed configuration illustrated in <figref idrefs="DRAWINGS">FIG. 6</figref>.</div>
</li> <li> <para-num num="[0194]"> </para-num> <div class="description-line" id="p-0195" num="0194">Calibration of a particular joint <b>108</b> by the associated joint calibration logic <b>232</b> was discussed above with reference to <figref idrefs="DRAWINGS">FIGS. 15 and 16</figref>, but the calibration logic <b>134</b> of the robotic system <b>100</b> may also perform system-level calibration operations. These system-level calibration operations may associate the positions of the joints <b>108</b> of a robotic apparatus <b>101</b> with a position of the end effector <b>118</b> of the robotic apparatus <b>101</b>, thus ensuring the ability of the robotic apparatus <b>101</b> to achieve a desired position of the end effector <b>118</b> in space. Such system-level calibration may calibrate out errors and variations in the robotic apparatus <b>101</b>, including modeling errors (e.g., discrepancies between the actual robotic apparatus <b>101</b> and computer models intended to simulate the robotic apparatus <b>101</b>), manufacturing errors or tolerances (e.g., discrepancies between the positions/dimensions of various components and their intended positions/dimensions), and/or backlash or compliance in the motor drive (e.g., backlash or compliance introduced by lower cost drivetrains <b>214</b>).</div>
</li> <li> <para-num num="[0195]"> </para-num> <div class="description-line" id="p-0196" num="0195"> <figref idrefs="DRAWINGS">FIG. 35</figref> is a side view of an example robotic apparatus <b>101</b> in a calibration setting, in accordance with various embodiments. The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 35</figref> has the form of the robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIGS. 5 and 6</figref>, but this is simply illustrative, and the system-level calibration devices and techniques disclosed herein may be utilized with any suitable robotic apparatus <b>101</b>. The robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 35</figref> has an end effector <b>118</b> that includes a depth sensor <b>264</b>, a laser <b>266</b>, and a camera <b>268</b>. The depth sensor <b>264</b> may be any suitable device that measures the distance from the depth sensor <b>264</b> to a target surface (here, a surface of the reference structure <b>270</b>, as discussed below). For example, the depth sensor <b>264</b> may include a camera that can generate an array of depth data, a scanner that can generate a line of depth data, or a laser that can generate a single point of depth data. In some embodiments, the depth sensor <b>264</b> may be an ultrasonic rangefinder. The laser <b>266</b> may be any suitable device that can generate a beam of light whose point of impingement on the surface of the reference structure <b>270</b> may be imaged by the camera <b>268</b>. The camera <b>268</b> may be any suitable camera (e.g., a red-green-blue (RGB) camera). In some embodiments, one or more of the depth sensor <b>264</b>, the laser <b>266</b>, and the camera <b>268</b> may be integrated into a single device. For example, the depth sensor <b>264</b> and the camera <b>268</b> may be part of an integrated depth-sensing camera array. In another example, the depth sensor <b>264</b> and the laser <b>266</b> may be part of an integrated laser rangefinder. The end effector <b>118</b> may be specifically designed for calibration operations (and may be “swapped out” for a different end effector <b>118</b> during subsequent operations), or may be part of an end effector <b>118</b> that is used for other operations (e.g., inspection operations, as discussed further below). An example of an end effector <b>118</b> that may be used in the calibration arrangement of <figref idrefs="DRAWINGS">FIG. 35</figref> is illustrated in <figref idrefs="DRAWINGS">FIG. 69</figref> and discussed below.</div>
</li> <li> <para-num num="[0196]"> </para-num> <div class="description-line" id="p-0197" num="0196">In the calibration arrangement of <figref idrefs="DRAWINGS">FIG. 35</figref>, the robotic apparatus <b>101</b> and a reference structure <b>270</b> are positioned on a surface <b>276</b>, such as a table. The reference structure <b>270</b> of <figref idrefs="DRAWINGS">FIG. 35</figref> may take the form of a mat (a “two-dimensional” reference structure <b>270</b>), but the calibration operations and arrangements disclosed herein may be utilized with “three-dimensional” reference structures <b>270</b>, as desired. A top view of the reference structure <b>270</b> of <figref idrefs="DRAWINGS">FIG. 35</figref> is illustrated in <figref idrefs="DRAWINGS">FIG. 36</figref>; as shown, the reference structure <b>270</b> may include a plurality of calibration markers <b>272</b>, each with an accompanying marker label <b>274</b>. The calibration markers <b>272</b> may be visual markers identifying a location on the reference structure <b>270</b>, and may have any suitable shape (e.g., a circle, a star, a rectangle, etc.). The marker labels <b>274</b> may include information indicative of the location of the associated calibration marker <b>272</b> (e.g., x-, y-, and z-locations, as appropriate). In some embodiments, the marker labels <b>274</b> may be alphanumeric, but this need not be the case; for example, in other embodiments, the marker labels <b>274</b> may be QR codes. In still other embodiments, the information in the marker labels <b>274</b> may be encoded in the calibration markers <b>272</b> themselves (e.g., by a color of the calibration marker <b>272</b>), and thus no separate marker labels <b>274</b> may be included. In some embodiments, the calibration markers <b>272</b> may be placed a few centimeters apart. A support <b>112</b> of the robotic apparatus <b>101</b> may be positioned at a designated location relative to the reference structure <b>270</b>.</div>
</li> <li> <para-num num="[0197]"> </para-num> <div class="description-line" id="p-0198" num="0197">During calibration, the sensors of the end effector <b>118</b> of the robotic apparatus <b>101</b> may be used to determine the position of the end effector <b>118</b> in space relative to the calibration markers <b>272</b>, and thus to calibrate the positions of the joints <b>108</b> of the robotic apparatus with respect to space. <figref idrefs="DRAWINGS">FIG. 37</figref> is a side view of the example robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 35</figref> during calibration, in accordance with various embodiments. As shown, during calibration, the depth sensor <b>264</b> may measure a distance <b>282</b> between the end effector <b>118</b> and the reference structure <b>270</b>, the laser <b>266</b> may shine a laser beam onto a surface of the reference structure <b>270</b>, and the camera <b>268</b> may capture an image of the reference structure that includes the point of impingement <b>278</b> of the laser beam (generated by the laser <b>266</b>) on the reference structure <b>270</b>, as well as the proximate calibration markers <b>272</b> and marker labels <b>274</b>. This image may be analyzed by the calibration logic <b>134</b> (e.g., of the system-level compute hardware <b>124</b>) to determine the x-y distance <b>280</b> between the point of impingement <b>278</b> and the calibration marker <b>272</b> to which the laser beam is intended to point, as discussed further below.</div>
</li> <li> <para-num num="[0198]"> </para-num> <div class="description-line" id="p-0199" num="0198">In some embodiments, the laser <b>266</b> and/or the depth sensor <b>264</b> may be omitted from the end effector <b>118</b>, and instead, the calibration-related functionality of these elements may be performed by the camera <b>268</b> in conjunction with image processing techniques. For example, the laser <b>266</b> and/or the depth sensor <b>264</b> may be omitted from the end effector <b>118</b> and, during calibration, images captured by the camera <b>268</b> may be analyzed using known image processing techniques (e.g., machine vision techniques) to determine a spatial position of the end effector <b>118</b> relative to the calibration markers <b>272</b> of the reference structure <b>270</b>. Examples of such embodiments are discussed below with reference to <figref idrefs="DRAWINGS">FIG. 38</figref>.</div>
</li> <li> <para-num num="[0199]"> </para-num> <div class="description-line" id="p-0200" num="0199"> <figref idrefs="DRAWINGS">FIG. 38</figref> is a flow diagram of a method <b>630</b> of calibrating a robotic system <b>100</b>, in accordance with various embodiments. In particular, the method <b>630</b> may utilize a calibration arrangement like that of <figref idrefs="DRAWINGS">FIG. 37</figref>, and may be discussed with reference to the calibration arrangement of <figref idrefs="DRAWINGS">FIG. 37</figref> for ease of illustration, but any calibration arrangement including a camera may implement the method <b>630</b>. The method <b>630</b> may be carried out by the calibration logic <b>134</b> of the system-level compute hardware <b>124</b> (which may or may not be located in the robotic apparatus <b>101</b>), and may be performed after joint-level calibration and zeroing, as discussed above.</div>
</li> <li> <para-num num="[0200]"> </para-num> <div class="description-line" id="p-0201" num="0200">At <b>632</b>, a counter variable N may set to an initial value (e.g., 1). For example, the calibration logic <b>134</b> may initialize a counter variable N to count through all of the calibration markers <b>272</b> of a reference structure <b>270</b>, as discussed further below.</div>
</li> <li> <para-num num="[0201]"> </para-num> <div class="description-line" id="p-0202" num="0201">At <b>634</b>, a nominal position for an end effector of a robotic apparatus may be identified. The nominal position may be one at which the end effector may point to a calibration marker N on a reference structure from a specified—distance. For example, the calibration logic <b>134</b> may determine a nominal x-, y-, and z-position, as well as a nominal r-, p-, and w-position, for the end effector <b>118</b> in space that should cause the laser <b>266</b> to shine on the reference structure <b>270</b> such that the point of impingement <b>278</b> of the laser beam is aligned with the Nth calibration marker <b>272</b>. In embodiments in which the end effector <b>118</b> does not include or utilize a laser, the calibration logic <b>134</b> may determine a nominal (x, y, z, r, p, w) position for the end effector <b>118</b> in space that should cause a camera <b>268</b> of the end effector <b>118</b> to point to the Nth calibration marker <b>272</b> from a specified distance.</div>
</li> <li> <para-num num="[0202]"> </para-num> <div class="description-line" id="p-0203" num="0202">At <b>636</b>, a command may be sent to the robotic apparatus to go to the nominal position. For example, the calibration logic <b>134</b> may communicate with the motion/position logic <b>132</b> to cause the end effector <b>118</b> of a robotic apparatus <b>101</b> to move to the nominal position identified at <b>634</b>.</div>
</li> <li> <para-num num="[0203]"> </para-num> <div class="description-line" id="p-0204" num="0203">At <b>638</b>, an image of the reference structure may be captured. For example, the camera <b>268</b> (under the control of the calibration logic <b>134</b>) may capture an image of the reference structure <b>270</b>, including the point of impingement <b>278</b> of the laser beam, the Nth calibration marker <b>272</b>, and the marker label <b>274</b> associated with the Nth calibration marker <b>272</b>. In embodiments in which the end effector <b>118</b> does not include or utilize a laser, the camera <b>268</b> (under the control of the calibration logic <b>134</b>) may capture an image of the reference structure <b>270</b>, including the Nth calibration marker <b>272</b> and the marker label <b>274</b> associated with the Nth calibration marker <b>272</b>.</div>
</li> <li> <para-num num="[0204]"> </para-num> <div class="description-line" id="p-0205" num="0204">At <b>640</b>, the error between the actual location of the end effector and the nominal location of the end effector may be determined based at least in part on the image of the reference structure. For example, when the calibration arrangement of <figref idrefs="DRAWINGS">FIG. 37</figref> is used, the calibration logic <b>134</b> may analyze the image captured at <b>638</b> to determine the x-y distance <b>280</b> between the point of impingement <b>278</b> and the Nth calibration marker <b>272</b> (corresponding to the desired point of impingement <b>278</b>), the depth sensor <b>264</b> (under the control of the calibration logic <b>134</b>) may determine a z-distance <b>282</b> between the end effector <b>118</b> and the reference structure <b>270</b>, and the measured x-, y-, and z-distances may be compared to their nominal values to determine an error (which may be single- or vector-valued). In embodiments in which the end effector <b>118</b> does not include or utilize a laser, the calibration logic <b>134</b> may use the image of the reference structure (captured at <b>638</b>) to generate the x-, y-, and z-errors (e.g., using known image processing and computer vision techniques). The calibration logic <b>134</b> may confirm that the Nth calibration marker is indeed the Nth calibration marker by analysis of the associated marker label <b>274</b>.</div>
</li> <li> <para-num num="[0205]"> </para-num> <div class="description-line" id="p-0206" num="0205">At <b>646</b>, it may be determined whether the error (determined at <b>640</b>) is below a specified threshold. As noted above, the error and/or the threshold may be single-valued or vector-valued, as desired. For example, the calibration logic <b>134</b> may determine whether the x-, y-, and z-errors are within a desired tolerance (which may be the same for the x-, y-, and z-dimensions, or different, as desired). If it is determined at <b>646</b> that the error is not below the specified threshold, the method <b>630</b> may proceed to <b>648</b> and move the end effector to a new position to decrease the error. For example, the calibration logic <b>134</b> may communicate with the motion/position logic <b>132</b> to cause the joints <b>108</b> to move to cause the end effector <b>118</b> to move to a new (x, y, z, r, p, w) position that may decrease the x-, y-, and/or z-error. After <b>648</b>, the method <b>630</b> may return to <b>638</b>.</div>
</li> <li> <para-num num="[0206]"> </para-num> <div class="description-line" id="p-0207" num="0206">If it is determined at <b>646</b> that the error is below the specified threshold, the method <b>630</b> may proceed to <b>650</b>, at which the final position of the end effector (e.g., the (x, y, z, r, p, w) position), and the positions of the individual joints, is recorded, along with the nominal position of the end effector. For example, the calibration logic <b>134</b> may store, in the system-level data storage <b>150</b>, the (x, y, z, r, p, w) position of the end effector <b>118</b>, the positions of the individual joints <b>108</b> and the nominal position identified at <b>634</b>.</div>
</li> <li> <para-num num="[0207]"> </para-num> <div class="description-line" id="p-0208" num="0207">At <b>652</b>, it is determined whether the counter variable N is equal to the total number of calibration markers (and thus that all calibration markers have been evaluated during the calibration method). If it is determined that the counter variable N is not equal to the total number of calibration markers (and thus that all calibration markers have not yet been considered), the method <b>630</b> may proceed to <b>654</b>, at which the counter variable N may be incremented. The method <b>630</b> may then return to <b>634</b>.</div>
</li> <li> <para-num num="[0208]"> </para-num> <div class="description-line" id="p-0209" num="0208">If it is determined at <b>652</b> that the counter variable N is equal to the total number of calibration markers (and thus that all calibration markers have been evaluated), the method <b>630</b> may proceed to <b>656</b>, at which a calibration model mapping nominal positions (identified at <b>634</b>) to the final position (recorded at <b>650</b>) is generated. For example, the calibration logic <b>134</b> may generate a linear regression model, a polynomial regression model, or a deep learning model, using any suitable known techniques, to map the nominal positions to the final positions. This model may be saved in the system-level data storage <b>150</b>. The method <b>630</b> may then end.</div>
</li> <li> <para-num num="[0209]"> </para-num> <div class="description-line" id="p-0210" num="0209">The calibration model generated by the method <b>630</b> of <figref idrefs="DRAWINGS">FIG. 38</figref> may be used by the motion/position logic <b>132</b> to drive the end effector <b>118</b> of a robotic apparatus <b>101</b> accurately to a desired (x, y, z, r, p, w) position. <figref idrefs="DRAWINGS">FIG. 39</figref> is a flow diagram of a method <b>660</b> of error-correction in driving joints <b>108</b> of a robotic system <b>100</b>, in accordance with various embodiments. The method <b>660</b> may be carried out by the motion/position logic <b>132</b> of the system-level compute hardware <b>124</b> (which may or may not be located in the robotic apparatus <b>101</b>), and may utilize the calibration model generated by the calibration logic <b>134</b> in accordance with the method <b>630</b> of <figref idrefs="DRAWINGS">FIG. 38</figref>, as discussed above. At <b>662</b>, a target position for the end effector of a robotic apparatus may be identified. For example, the motion/position logic may identify a target (x, y, z, r, p, w) position for the end effector <b>118</b> of a robotic apparatus <b>101</b> (e.g., a position that is part of an inspection path, as discussed further below).</div>
</li> <li> <para-num num="[0210]"> </para-num> <div class="description-line" id="p-0211" num="0210">At <b>664</b>, a calibration model mapping input positions to error-corrected positions may be used to determine the error-corrected position corresponding to the target position. For example, the motion/position logic <b>132</b> may input the target (x, y, z, r, p, w) position to the calibration model generated at <b>656</b> of the method <b>630</b>, and the calibration model may generate an error-corrected position such that, if the motion/position logic <b>132</b> commands the joints <b>108</b> of a robotic apparatus <b>101</b> to go to the error-corrected position, the end effector <b>118</b> of the robotic apparatus <b>101</b> will actually be positioned at the target position.</div>
</li> <li> <para-num num="[0211]"> </para-num> <div class="description-line" id="p-0212" num="0211">At <b>666</b>, the joints may be commanded to go to the error-corrected position. For example, the motion/position logic <b>132</b> may communicate with the joints <b>108</b> via the communication hardware <b>128</b> to cause the individual joints <b>108</b> to go to the error-corrected positions, resulting in the end effector <b>118</b> being positioned at the target position.</div>
</li> <li> <para-num num="[0212]"> </para-num> <div class="description-line" id="p-0213" num="0212">As noted above, a robotic system <b>100</b> may include joint-level safety features and system-level safety features. In some embodiments, a system-level safety procedure for the robotic system <b>100</b> may be the result of a learning process in which the robotic apparatus <b>101</b> is moved through a trajectory while data from the robotic apparatus <b>101</b> (e.g., the data packets discussed above with reference to the joints <b>108</b>) is monitored by the system-level compute hardware <b>124</b>. The safety logic <b>136</b> may generate a model identifying expected values of this data as a function of the time index after the start of the trajectory, and may then be able to flag any future data that falls outside a range around the model as a potential fault. <figref idrefs="DRAWINGS">FIG. 40</figref> is a flow diagram of a method <b>670</b> of establishing system-level allowable operational conditions for a robotic system <b>100</b>, in accordance with various embodiments. The method <b>670</b> may be carried out by the safety logic <b>136</b> of the system-level compute hardware <b>124</b> (which may or may not be located in the robotic apparatus <b>101</b>), and may be performed after joint-level and system-level calibration, as discussed above. The method <b>670</b> may establish a safety model corresponding to a particular trajectory through which the robotic apparatus <b>101</b> may move; different safety models may be generated and stored for different trajectories, as desired.</div>
</li> <li> <para-num num="[0213]"> </para-num> <div class="description-line" id="p-0214" num="0213">At <b>672</b>, a trajectory may be identified through which to move a robotic apparatus. For example, the safety logic <b>136</b> may specify a time series of positions of the joints <b>108</b> of a robotic apparatus <b>101</b>. In some embodiments, the trajectory may be specified by a user through a GUI provided by an I/O device <b>120</b> (e.g., the trajectory may be part of an inspection path, as discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 42-53</figref>), or by “recording” a trajectory as a user physically manipulates a robotic apparatus <b>101</b> when the joints <b>108</b> are in the “motor drive off” and “brakes off” state, as discussed above with reference to <figref idrefs="DRAWINGS">FIG. 29</figref>. For example, the safety logic <b>136</b> may determine whether a “start recording” voice command by a user has been received at a microphone of the I/O devices <b>120</b> and recognized by the voice command logic <b>170</b> of the system-level compute hardware <b>124</b>; upon receipt of such a voice command, the positions of the joints <b>108</b> may be monitored and stored by the safety logic <b>136</b> (in conjunction with the motion/position logic <b>132</b>) until a “stop recording” voice command by a user has been received at a microphone of the I/O devices <b>120</b> and recognized by the voice command logic <b>170</b> of the system-level compute hardware <b>124</b>. A recorded trajectory may be “played back” (e.g., in response to a “play recording” voice command received at a microphone of the I/O devices <b>120</b> and recognized by the voice command logic <b>170</b>). Further, a trajectory may be recorded and referred to by a particular name in these voice commands (e.g., “start recording X,” “stop recording X,” and “play recording X”) in order to distinguish between multiple recorded trajectories. A speed of playback may be adjusted using a “speed X” voice command. Any other suitable technique for specifying a trajectory of a robotic apparatus <b>101</b> may be used in addition to or instead of these techniques.</div>
</li> <li> <para-num num="[0214]"> </para-num> <div class="description-line" id="p-0215" num="0214">At <b>674</b>, the robotic apparatus may be caused to move through the trajectory. For example, the safety logic <b>136</b> may communicate with the motion/position logic <b>132</b>, which may in turn communicate with the joints <b>108</b> via the communication hardware <b>128</b> to cause the joints <b>108</b> of the robotic apparatus <b>101</b> to move through the positions specified in the trajectory.</div>
</li> <li> <para-num num="[0215]"> </para-num> <div class="description-line" id="p-0216" num="0215">At <b>676</b>, per-joint metrics may be measured during the trajectory. For example, the safety logic <b>136</b> may receive data from sensors included in the joints <b>108</b> (e.g., the accelerometer <b>224</b> or sensors included in the other hardware <b>227</b>, such as temperature sensors, current sensors, etc., as discussed above with reference to the joint <b>108</b>), and/or from internal variables tracked by the joint-level compute hardware <b>210</b>, via the communication hardware <b>128</b> while the robotic apparatus <b>101</b> is moving through the trajectory, and may store that data in the system-level data storage <b>150</b>.</div>
</li> <li> <para-num num="[0216]"> </para-num> <div class="description-line" id="p-0217" num="0216">At <b>678</b>, a safety model may be generated, mapping the time index in the trajectory to per-joint metrics based on the measured per-joint metrics. For example, the safety logic <b>136</b> may generate a principal component model, a linear regression model, a polynomial regression model, or a deep learning model, using any suitable known techniques, to map the time index in the trajectory to the per-joint metrics (e.g., the model may determine that, at time T from the start of the trajectory, the expected x-position of the end effector <b>118</b> is X). This model may be saved in the system-level data storage <b>150</b>. In some embodiments, generation of the safety model may include performing a Principal Components Analysis (PCA) in which the high-dimensional metric space is mapped into a lower-dimensional space (where thresholds may be applied, as discussed below).</div>
</li> <li> <para-num num="[0217]"> </para-num> <div class="description-line" id="p-0218" num="0217">At <b>680</b>, one or more thresholds may be identified at which deviation from the safety model is not acceptable. For example, a user may specify a percentage or absolute deviation from the safety model that represents an unacceptable deviation, and the safety logic <b>136</b> may store the associated fault conditions.</div>
</li> <li> <para-num num="[0218]"> </para-num> <div class="description-line" id="p-0219" num="0218">The system-level safety model generated by the method <b>670</b> of <figref idrefs="DRAWINGS">FIG. 40</figref> may be utilized by the robotic system <b>100</b> to identify faults during operation of the robotic system <b>100</b>. <figref idrefs="DRAWINGS">FIG. 41</figref> is a flow diagram of a method <b>690</b> of detecting faults in a robotic system <b>100</b>, in accordance with various embodiments. The method <b>690</b> may be carried out by the safety logic <b>136</b> of the system-level compute hardware <b>124</b> (which may or may not be located in the robotic apparatus <b>101</b>), and may be performed when the robotic apparatus <b>101</b> moves through a trajectory after generation of a safety model for that trajectory in accordance with the method <b>670</b> of <figref idrefs="DRAWINGS">FIG. 40</figref>, as discussed above.</div>
</li> <li> <para-num num="[0219]"> </para-num> <div class="description-line" id="p-0220" num="0219">At <b>694</b>, per-joint metrics of the robotic apparatus may be monitored during operation of the robotic apparatus. For example, the safety logic <b>136</b> may receive data from sensors included in the joints <b>108</b> (e.g., the accelerometer <b>224</b> or sensors included in the other hardware <b>227</b>, such as temperature sensors, current sensors, etc.) via the communication hardware <b>128</b> while the robotic apparatus <b>101</b> is in operation (e.g., moving), and may store that data in the system-level data storage <b>150</b>.</div>
</li> <li> <para-num num="[0220]"> </para-num> <div class="description-line" id="p-0221" num="0220">At <b>696</b>, the time index in the trajectory of the robotic apparatus may be provided to the safety model to identify associated acceptable ranges of deviation around the safety model. For example, the safety logic <b>136</b> may input a time index in the trajectory (e.g., the trajectory started three seconds ago) to the safety model generated by the method <b>670</b> of <figref idrefs="DRAWINGS">FIG. 40</figref>, and the safety model may output expected values of the per-joint metrics for the trajectory at that time index(as discussed above with reference to <b>678</b> of <figref idrefs="DRAWINGS">FIG. 40</figref>), accompanied by acceptable ranges of deviation from these expected values (as discussed above with reference to <b>680</b> of <figref idrefs="DRAWINGS">FIG. 40</figref>).</div>
</li> <li> <para-num num="[0221]"> </para-num> <div class="description-line" id="p-0222" num="0221">At <b>698</b>, it may be determined whether any per-joint metrics (measured at <b>694</b>) fall outside the acceptable ranges of deviation from the safety model for the current time index in the trajectory. For example, the safety logic <b>136</b> may compare each of the per-joint metrics measured at <b>694</b> (or combinations of the per-joint metrics, as appropriate) to the acceptable ranges of deviation from the values of these per-joint metrics generated by the safety model as a function of the time index in the trajectory, and will determine whether any per-joint metrics or combinations thereof fall outside of the acceptable ranges.</div>
</li> <li> <para-num num="[0222]"> </para-num> <div class="description-line" id="p-0223" num="0222">If it is determined at <b>698</b> that there a per-joint metric, or combination of per-joint metrics, that falls outside the acceptable range, the method <b>690</b> may proceed to <b>700</b>, at which a fault is identified. The robotic system <b>100</b> may then respond to the identification of this fault appropriately (e.g., as discussed above with reference to <figref idrefs="DRAWINGS">FIGS. 29, 31, and 32</figref>). If it is determined at <b>698</b> that no per-joint metric, or combination of per-joint metrics, that falls outside the acceptable range, the method <b>690</b> may return to <b>694</b>.</div>
</li> <li> <para-num num="[0223]"> </para-num> <div class="description-line" id="p-0224" num="0223">As discussed above with reference to the task logic <b>106</b>, a robotic system <b>100</b> in accordance with the present disclosure may perform any of a number of tasks, including inspection of one or more items (e.g., for quality, grading, the identification of defects, etc.). A number of inspection systems and techniques are discussed below. Any of these inspection systems and techniques may be used as suitable in a commercial setting. For example, some or all of the inspection systems and techniques disclosed herein may be utilized for incoming inspections (i.e., inspections performed on incoming raw materials or parts), in-line inspections (i.e., inspections performed during an assembly or other manufacturing process), or outgoing inspections (i.e., for completed items before shipping out).</div>
</li> <li> <para-num num="[0224]"> </para-num> <div class="description-line" id="p-0225" num="0224">In some embodiments, a robotic system <b>100</b> may inspect an item by following a programmed inspection path for that item to capture images of that item using an image capture device included in the end effector <b>118</b>; the images may then be analyzed to assess the item. An inspection path may include one or more locations for the end effector <b>118</b> of a robotic apparatus <b>101</b> (i.e., (x, y, z) location), and for each location, the inspection path may include one or more angles (i.e., (r, p, w)) at which the end effector <b>118</b> of the robotic apparatus may be positioned to capture an image of the item. Thus, an inspection path for a robotic system <b>100</b> may include a series of locations of the end effector <b>118</b>, with an image captured by the end effector <b>118</b> at each of one or more angles at each location. In some embodiments, the inspection logic <b>160</b> may utilize the safety logic <b>136</b> to generate and use a safety model for each inspection path, in accordance with the methods discussed above with reference to <figref idrefs="DRAWINGS">FIGS. 40-41</figref>.</div>
</li> <li> <para-num num="[0225]"> </para-num> <div class="description-line" id="p-0226" num="0225">Each angle in an inspection path may also be associated with a particular inspection function that may be run on the image of the item captured at that angle. As used herein, an “inspection function” may refer to a set of operations that takes data, captured by a robotic apparatus <b>101</b>, about an item as an input, and generates, as an output, information about that item. For example, an inspection function may include a bar code reader; such an inspection function may take an image or other optical data of a bar code on an item as an input, and may output the data encoded in the bar code. Another example of an inspection function may be a dimensional analysis tool; such an inspection function may take an image of an item as an input, and may output one or more physical dimensions of that item (e.g., radius, area, length, etc.). Another example of an inspection function may be a resistance measurement tool; such an inspection function may take voltage and current measurements between two points in a device as an input, and may output the electrical resistance between those points. In some embodiments, an inspection function may include a computational classifier. As used herein, a “computational classifier,” or simply a “classifier,” may refer to a machine learning model that receives data representative of a particular item (e.g., an image of the item) as an input and returns a classification result (e.g., “pass,” “fail,” “unknown,” or some other result). In some embodiments, a classifier may return “needs data” when its amount of training has not yet reached a predetermined, adequate level. In some embodiments, a classifier may return “error” when an error has occurred during execution of the classifier. Computational classifiers may include anomaly detection classifiers, which may detect whether a particular image is significantly different from the average image, or defect-specific classifiers. Examples of specific defects for which classifiers may be trained include missing components, solder bridges, bent pins, scratched lenses, etc.</div>
</li> <li> <para-num num="[0226]"> </para-num> <div class="description-line" id="p-0227" num="0226"> <figref idrefs="DRAWINGS">FIG. 42</figref> is a flow diagram of a method <b>710</b> of generating an inspection path for a robotic system <b>100</b>, in accordance with various embodiments. The method <b>670</b> may be carried out by the inspection logic <b>160</b> of the system-level compute hardware <b>124</b> (which may or may not be located in the robotic apparatus <b>101</b>), which may rely on the control logic <b>104</b> to reliably operate a robotic apparatus <b>101</b>.</div>
</li> <li> <para-num num="[0227]"> </para-num> <div class="description-line" id="p-0228" num="0227">At <b>714</b>, at least one location and angle at which to capture an image of an item may be identified. For example, the inspection logic <b>160</b> may receive an identification, from a user via an I/O device <b>120</b>, of one or more locations and one or more associated angles at which the end effector <b>118</b> of a robotic apparatus <b>101</b> may capture an image of an item to be inspected. In some embodiments, the inspection path may be specified by a user through a GUI provided by an I/O device <b>120</b> (e.g., as discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 46-53</figref>), by manually inputting and storing the locations and angles, or by “recording” an inspection path as a user physically manipulates a robotic apparatus <b>101</b> when the joints <b>108</b> are in the “motor drive off” and “brakes off” state, as discussed above with reference to <figref idrefs="DRAWINGS">FIG. 29</figref>. For example, the safety logic <b>136</b> may determine whether a “start task” voice command by a user has been received at a microphone of the I/O devices <b>120</b> and recognized by the voice command logic <b>170</b> of the system-level compute hardware <b>124</b>; upon receipt of such a voice command, the positions of the joints <b>108</b> may be monitored and stored by the safety logic <b>136</b> (in conjunction with the motion/position logic <b>132</b>) whenever an “waypoint” voice command has been received at a microphone of the I/O devices <b>120</b> and recognized by the voice command logic <b>170</b> of the system-level compute hardware <b>124</b>. A recorded inspection path may be “played back” (e.g., in response to a “play task” voice command received at a microphone of the I/O devices <b>120</b> and recognized by the voice command logic <b>170</b>). Further, an inspection path may be recorded and referred to by a particular name in these voice commands (e.g., “start task X” and “play task X”) in order to distinguish between multiple recorded inspection paths. A speed of playback may be adjusted using a “speed X” voice command. Any other suitable technique for specifying an inspection path of a robotic apparatus <b>101</b> may be used in addition to or instead of these techniques.</div>
</li> <li> <para-num num="[0228]"> </para-num> <div class="description-line" id="p-0229" num="0228">At <b>716</b>, at least one inspection function associated with each captured image may be identified. For example, the inspection logic <b>160</b> may receive an identification, from a user via an I/O device <b>120</b>, of one or more inspection functions to apply to an image captured at each angle of the inspection path when the robotic apparatus <b>101</b> performs an inspection along the inspection path. In some embodiments, the inspection function(s) for each angle may be specified by a user through a GUI provided by an I/O device <b>120</b> (e.g., as discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 46-53</figref>).</div>
</li> <li> <para-num num="[0229]"> </para-num> <div class="description-line" id="p-0230" num="0229"> <figref idrefs="DRAWINGS">FIG. 43</figref> is an example data structure <b>404</b> that may be used to define an inspection path of a robotic system <b>100</b> for inspecting an item, in accordance with various embodiments. The data structure <b>404</b> includes a location and angle at which an overview image of the item is to be captured (discussed further below with reference to <figref idrefs="DRAWINGS">FIGS. 46-53</figref>), one or more locations, and for each location, one or more angles at which an image is to be captured by an image capture device included in an end effector <b>118</b>. Further, the data structure <b>404</b> includes, for each angle, an identification of at least one inspection function to be applied to the image captured at that angle. A data structure like the data structure <b>404</b> may be stored in the system-level data storage <b>150</b>, to be accessed by the inspection logic <b>160</b> when the inspection path is to be run. <figref idrefs="DRAWINGS">FIG. 44</figref> is an example data structure <b>406</b> that may be used as part of defining an inspection path of the robotic system <b>100</b>, in accordance with various embodiments. In particular, the data structure <b>406</b> may store the locations, associated angles, and associated inspection functions for an inspection path. A data structure like the data structure <b>406</b> may be stored in the system-level data storage <b>150</b>, to be accessed by the inspection logic <b>160</b> when the inspection path is to be run.</div>
</li> <li> <para-num num="[0230]"> </para-num> <div class="description-line" id="p-0231" num="0230">As noted above, an inspection path for a robotic system <b>100</b> may be generated in a number of ways. For example, in some embodiments, an inspection path may be at least partially (e.g., fully) generated by the inspection logic <b>160</b> based on an initial surface scan of the item. <figref idrefs="DRAWINGS">FIG. 45</figref> is a flow diagram of a method <b>720</b> of generating an inspection path for a robotic system <b>100</b>, in accordance with various embodiments. The method <b>720</b> may be a particular embodiment of the method <b>710</b> discussed above with reference to <figref idrefs="DRAWINGS">FIG. 42</figref>. Like the method <b>710</b> of <figref idrefs="DRAWINGS">FIG. 42</figref>, the method <b>720</b> of <figref idrefs="DRAWINGS">FIG. 45</figref> may be carried out by the inspection logic <b>160</b> of the system-level compute hardware <b>124</b> (which may or may not be located in the robotic apparatus <b>101</b>), which may rely on the control logic <b>104</b> to reliably operate a robotic apparatus <b>101</b>. The robotic apparatus <b>101</b> that is operated during the execution of the method <b>720</b> may include an end effector <b>118</b> with a depth sensor <b>264</b> and a camera <b>268</b>. Further, the method <b>720</b> may involve the end effector <b>118</b> positioned above the item to be inspected. For example, the robotic apparatus <b>101</b> (e.g., a gantry- or arm-type robotic apparatus <b>101</b>) may be positioned on a table, floor, wall, or cart, and the item may be positioned so that the end effector <b>118</b> of the robotic apparatus <b>101</b> can move above and around at least a portion of the item in order to image desired surfaces of the item. In some embodiments, an arm-type robotic apparatus <b>101</b> may be positioned on a table, and the item to be inspected may also be positioned on the table.</div>
</li> <li> <para-num num="[0231]"> </para-num> <div class="description-line" id="p-0232" num="0231">At <b>722</b>, an indicator of an item may be received. For example, the inspection logic <b>160</b> may receive a name of an item to be inspected from a user via a GUI provided by an I/O device <b>120</b>. The indicator may be stored in the system-level data storage <b>150</b> (e.g., as part of a file name or an item field of a data structure that includes the inspection path).</div>
</li> <li> <para-num num="[0232]"> </para-num> <div class="description-line" id="p-0233" num="0232">At <b>724</b>, an indicator of a level of detail at which to perform a surface scan of the item may be received. For example, the inspection logic <b>160</b> may receive an input, from a user via a GUI, indicating whether an initial surface scan of an item is to be performed at a high level of detail or at a low level of detail (e.g., via a slider element in the GUI).</div>
</li> <li> <para-num num="[0233]"> </para-num> <div class="description-line" id="p-0234" num="0233">At <b>726</b>, an indicator of whether multiple surface scans are to be performed may be received. Multiple surface scans may be useful when an item has multiple surfaces (e.g., a front face and a back face, a top surface and one or more side surfaces, etc.) to be inspected. For example, the inspection logic <b>160</b> may receive an input, from a user via a GUI, indicating whether multiple surface scans of an item should be performed (e.g., using a GUI element that allows the user to specify how many surface scans should be performed).</div>
</li> <li> <para-num num="[0234]"> </para-num> <div class="description-line" id="p-0235" num="0234">At <b>728</b>, a user may be instructed to position the item at an approximate center of the field-of-view (FOV) of a depth sensor for a new surface scan. For example, the inspection logic <b>160</b> may provide a visual or audio instruction, to a user via a GUI and/or one or more speakers included in the I/O devices <b>120</b>, instructing the user to position the item to be inspected in the FOV of a depth sensor <b>264</b> (and in the FOV of a camera <b>268</b>) of the end effector <b>118</b>. In some embodiments, the GUI may display a current image from the camera <b>268</b> of the approximate FOV of the depth sensor <b>264</b> so that the user can see and position the item accordingly; note that, in some embodiments, the camera <b>268</b> and the depth sensor <b>264</b> may be part of an integrated depth-sensing camera array.</div>
</li> <li> <para-num num="[0235]"> </para-num> <div class="description-line" id="p-0236" num="0235">At <b>730</b>, a z-height of the surface scan may be set based on the level of detail (specified at <b>724</b>). For example, the inspection logic <b>160</b> may select a z-height above the surface of the item for the surface scan (corresponding to a particular z-distance between the item and the end effector <b>118</b>) based on the desired level of detail received from the user; a smaller z-height (closer to the item) may be selected when a higher level of detail is desired, and a larger z-height (farther away from the item) may be selected when a lower level of detail is desired. In some embodiments, the operations of <b>724</b> may not be included in the method <b>720</b>, and instead, a z-height of the surface scan may be automatically selected by the inspection logic <b>160</b> as the z-height that allows the item to maximally fill the FOV of the depth sensor <b>264</b> (with the item identified by segmentation, as discussed below with reference to <b>732</b>).</div>
</li> <li> <para-num num="[0236]"> </para-num> <div class="description-line" id="p-0237" num="0236">At <b>732</b>, the item may be segmented from the background in an overview image of the item. For example, the inspection logic <b>160</b> may cause a camera <b>268</b> of the end effector <b>118</b> to capture an overview image of the item (e.g., as specified in the data structure <b>404</b> of <figref idrefs="DRAWINGS">FIG. 43</figref>), and the inspection logic <b>160</b> may perform any suitable segmentation technique on the captured image to segment the item itself from the background of the image (e.g., the table or other surface on which the item rests).</div>
</li> <li> <para-num num="[0237]"> </para-num> <div class="description-line" id="p-0238" num="0237">At <b>734</b>, a set of image capture locations may be generated based on the camera FOV and a specified overlap (e.g., 25% to 50%) between the images captured at the image capture locations. For example, the inspection logic <b>160</b> may use the results of the segmentation of <b>732</b> to identify where the item is in the depth sensor FOV, and then determine how many images of the item should be captured, with the camera <b>268</b>, in order to fully cover the visible surface of the item with a specified overlap between images, and the (x, y) locations of the end effector <b>118</b> (at the specified z-height) in order to capture these items. The number and spacing of these images may depend on the size of the camera FOV. In some embodiments, the angle of the end effector <b>118</b> (e.g., (r, p, w)) for the capture of these images may be oriented directly downward (in the negative z-direction). The set of locations generated at <b>734</b> may be a set of locations at which images may be captured by the camera <b>268</b> to overlappingly image the desired surface of the item.</div>
</li> <li> <para-num num="[0238]"> </para-num> <div class="description-line" id="p-0239" num="0238">At <b>736</b>, an inspection path may be stored including the locations generated at <b>734</b>, with a single angle associated with each location. This angle may be normal to the surface of the item to be inspected. For example, the inspection logic <b>160</b> may use a data structure like the data structure <b>404</b> (<figref idrefs="DRAWINGS">FIG. 43</figref>) and/or the data structure <b>406</b> (<figref idrefs="DRAWINGS">FIG. 44</figref>) to store an inspection path that includes the locations generated at <b>734</b>, and for each location, a single angle (e.g., so that the camera <b>268</b> faces the negative z-direction when the surface of the item is in the x-y plane). Inspection functions (not discussed in <figref idrefs="DRAWINGS">FIG. 45</figref>) may be separately assigned to the angles by a user (e.g., as discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 46-53</figref>), or automatically (e.g., an “anomaly detection” inspection function may be automatically assigned to each angle). In this manner, an inspection path for a surface of an item may be automatically generated by the robotic system <b>100</b>.</div>
</li> <li> <para-num num="[0239]"> </para-num> <div class="description-line" id="p-0240" num="0239">At <b>738</b>, it may be determined whether all surface scans are complete (based on the number of surface scans indicated at <b>726</b>). If it is determined at <b>738</b> that all surface scans are complete, the method <b>720</b> may end. If it is determined at <b>738</b> that additional surface scans are to be performed (e.g., to scan surfaces of the item other than the “top” surface), the method <b>720</b> may return to <b>728</b> and separate inspection paths may be generated for each of the other surfaces. In some embodiments, the operations of <b>726</b> may be omitted, and the robotic system <b>100</b> may perform a single surface scan by default; if additional surface scans are desired, the method <b>720</b> may be performed again.</div>
</li> <li> <para-num num="[0240]"> </para-num> <div class="description-line" id="p-0241" num="0240">As noted above, in some embodiments, the I/O devices <b>120</b> may be used to provide a GUI that allows a user to specify an inspection path. <figref idrefs="DRAWINGS">FIGS. 46-53</figref> are examples of GUIs that may be used to generate an inspection path for a robotic system, in accordance with various embodiments. In some embodiments, a tablet or laptop computing device, or a desktop computing device with an associated touchscreen display, may provide an I/O device <b>120</b> through which the GUIs of <figref idrefs="DRAWINGS">FIGS. 46-53</figref> may be run; in some embodiments, the tablet, laptop, or desktop computing device may provide some or all of the system-level compute hardware <b>124</b> and some or all of the system-level data storage <b>150</b>. The GUIs may be provided by the user interface logic <b>162</b> in conjunction with the inspection logic <b>160</b>. In some embodiments, the GUIs may be provided on a touchscreen display communicatively coupled, and proximate to, the robotic apparatus <b>101</b>.</div>
</li> <li> <para-num num="[0241]"> </para-num> <div class="description-line" id="p-0242" num="0241"> <figref idrefs="DRAWINGS">FIG. 46</figref> depicts a GUI <b>1000</b> that allows a user to define an inspection path for an item. An identifier of the item, “PCB1 Item” may have been previously provided to the user interface logic <b>162</b> (e.g., via another GUI, not shown). In use, a user may select the “+ Inspection Routine” element to begin to generate an inspection routine for the item.</div>
</li> <li> <para-num num="[0242]"> </para-num> <div class="description-line" id="p-0243" num="0242">Upon selection of the “+ Inspection Routine” element of the GUI <b>1000</b> of <figref idrefs="DRAWINGS">FIG. 46</figref>, the user may be presented with the GUI <b>1002</b> of <figref idrefs="DRAWINGS">FIG. 47</figref>. The GUI <b>1002</b> may include a “Live Feed” showing the current view of a camera of the end effector <b>118</b> of the robotic apparatus <b>101</b> (showing the item, a PCB). The GUI <b>1002</b> may also include the results of the performance of the method <b>720</b> of <figref idrefs="DRAWINGS">FIG. 45</figref> in a “Routine Overview” region. The “Routine Overview” region may show the overview image of the item with approximate coverage areas for each of the images to be captured by the inspection path (i.e., at the different locations of the inspection path generated by the method <b>720</b> of <figref idrefs="DRAWINGS">FIG. 45</figref>) shown as overlays over the overview image. In this manner, a user may see the images that will be captured upon execution of the automatically generated inspection path. The GUI <b>1002</b> also includes a “Robot Control” region that includes elements that a user may select in order to change the location of the end effector <b>118</b> (e.g., the (x, y) location), zoom in or out (e.g., by changing the distance to the surface of the item), and change the angle of the end effector <b>118</b> (e.g., the (r, p, w)); manipulation of these elements may cause the motion/position logic <b>132</b> to move the robotic apparatus <b>101</b> accordingly. The GUI <b>1002</b> may further include save (“SAVE”) and delete (“DEL”) elements to allow a user to save the current view in the “Live Feed” region as a new location in the inspection path, or to delete a location in the inspection path (e.g., by selecting a particular overlay in the “Routine Overview” region and then selecting the delete element).</div>
</li> <li> <para-num num="[0243]"> </para-num> <div class="description-line" id="p-0244" num="0243">Upon using the controls in the “Robot Control” region to zoom and move the robotic apparatus <b>101</b> to zoom in on a particular portion of the item of the GUI <b>1002</b> of <figref idrefs="DRAWINGS">FIG. 47</figref>, the user may be presented with the GUI <b>1004</b> of <figref idrefs="DRAWINGS">FIG. 48</figref>.</div>
</li> <li> <para-num num="[0244]"> </para-num> <div class="description-line" id="p-0245" num="0244">Upon selecting the save element of the GUI <b>1004</b> of <figref idrefs="DRAWINGS">FIG. 48</figref>, the user may be presented with the GUI <b>1006</b> of <figref idrefs="DRAWINGS">FIG. 49</figref>. In the GUI <b>1006</b>, a new overlay has been added to the “Routine Overview” region, corresponding to the area currently highlighted in the “Live Feed” region and indicating that the location and angle of the end effector <b>118</b> at the time that the save element was selected has now been added to the inspection path. Further, the overlay associated with the new inspection path location may be highlighted, and the user may be presented with one or more inspection functions that may be applied to images captured at the new inspection path location. The GUI <b>1006</b> depicts “Anomaly” and “Solder Bridge” inspection functions, and also presents a selectable option “+Add” for a user to select from additional inspection functions. In some embodiments, a user may select multiple inspection functions for a particular angle of the inspection path.</div>
</li> <li> <para-num num="[0245]"> </para-num> <div class="description-line" id="p-0246" num="0245">Upon selecting the “Anomaly” inspection function of the GUI <b>1006</b> of <figref idrefs="DRAWINGS">FIG. 49</figref>, the user may be presented with the GUI <b>1008</b> of <figref idrefs="DRAWINGS">FIG. 50</figref>.</div>
</li> <li> <para-num num="[0246]"> </para-num> <div class="description-line" id="p-0247" num="0246">Upon selecting the bottom right hand overlay in the GUI <b>1008</b> of <figref idrefs="DRAWINGS">FIG. 50</figref>, the user may be presented with the GUI <b>1010</b> of <figref idrefs="DRAWINGS">FIG. 51</figref>. The bottom right hand overlay may be highlighted, and the user may be presented with one or more inspection functions that may be applied to images captured at this inspection path location.</div>
</li> <li> <para-num num="[0247]"> </para-num> <div class="description-line" id="p-0248" num="0247">Upon selecting the delete element of the GUI <b>1010</b> of <figref idrefs="DRAWINGS">FIG. 51</figref>, the user may be presented with the GUI <b>1012</b> of <figref idrefs="DRAWINGS">FIG. 52</figref>, and then with the GUI <b>1014</b> of <figref idrefs="DRAWINGS">FIG. 53</figref>. In the GUI <b>1014</b> of <figref idrefs="DRAWINGS">FIG. 53</figref>, the overlay formerly at the bottom right hand corner of the “Routine Overview” region is gone, indicating that the location and angle associated with that overlay has been deleted from the inspection path. Using the GUIs of <figref idrefs="DRAWINGS">FIGS. 46-53</figref>, a user may add locations/angles to an inspection path, delete locations/angles from an inspection path, and select classifiers associated with each location/angle.</div>
</li> <li> <para-num num="[0248]"> </para-num> <div class="description-line" id="p-0249" num="0248">Once an inspection path is defined, the robotic system <b>100</b> may inspect items in accordance with the inspection path. Further, in some embodiments, the robotic system <b>100</b> may apply a set of specified logic to the classification results of an inspection in order to generate a particular inspection outcome for the inspected item (e.g., “pass,” “fail,” “Grade A,” “Grade B,” etc.). <figref idrefs="DRAWINGS">FIG. 54</figref> is a flow diagram of a method <b>740</b> of performing an inspection, by a robotic system <b>100</b>, in accordance with an inspection path, in accordance with various embodiments. The method <b>740</b> may be carried out by the inspection logic <b>160</b> of the system-level compute hardware <b>124</b> (which may or may not be located in the robotic apparatus <b>101</b>), which may rely on the control logic <b>104</b> to reliably operate a robotic apparatus <b>101</b>. Further, although various operations of the method <b>740</b> may be discussed with reference to “images” captured at “locations” and “angles,” this is not intended to limit the use of this method to discrete, static images captured at disparate locations and angles, and any of the inspection methods disclosed herein (including the method <b>740</b>) may be performed using video image capture.</div>
</li> <li> <para-num num="[0249]"> </para-num> <div class="description-line" id="p-0250" num="0249">At <b>742</b>, an overview image of an item may be captured. For example, the inspection logic <b>160</b> may cause a camera of the end effector <b>118</b> to capture an image of the entire item to be inspected; this image may help users associate the outcome of the inspection with the particular item itself. The overview image may be stored in the system-level data storage <b>150</b>.</div>
</li> <li> <para-num num="[0250]"> </para-num> <div class="description-line" id="p-0251" num="0250">At <b>744</b>, for each location and angle of an inspection path, an image may be captured. For example, the inspection logic <b>160</b> may cause the robotic apparatus <b>101</b> to move through an inspection path, with a camera of the end effector <b>118</b> capturing an image of the item at each angle of the inspection path, as discussed above. The images captured may be stored in the system-level data storage.</div>
</li> <li> <para-num num="[0251]"> </para-num> <div class="description-line" id="p-0252" num="0251">At <b>746</b>, for each image, one or more associated inspection functions may be run. For example, the inspection logic <b>160</b> may run one or more inspection functions on each image captured during the inspection path run (at <b>744</b>). As discussed above, an inspection function may include a computational classifier; such a classifier may receive an image as an input, and may output a classification result (e.g., “pass,” “fail,” “anomaly detected,” “grade A”, “grade B,” “unknown,” etc.) in accordance with its training.</div>
</li> <li> <para-num num="[0252]"> </para-num> <div class="description-line" id="p-0253" num="0252">At <b>748</b>, the classification results may be stored in conjunction with the associated images, locations, and angles. For example, <figref idrefs="DRAWINGS">FIG. 55</figref> is an example data structure <b>408</b> that may be used as part of an inspection performed by a robotic system <b>100</b>, in accordance with various embodiments. In particular, the data structure <b>408</b> may store the locations, associated angles, associated inspection functions, associated images, and associated results of running the inspection functions on the images. Data structures like the data structure <b>408</b> may be used by the inspection logic <b>160</b> to store inspection results in the system-level data storage <b>150</b>.</div>
</li> <li> <para-num num="[0253]"> </para-num> <div class="description-line" id="p-0254" num="0253">Returning to <figref idrefs="DRAWINGS">FIG. 54</figref>, at <b>750</b>, specified logic may be applied to the classification results to generate an inspection outcome for the item. The logic may be specified by a user (e.g., via a GUI) or automatically generated by the robotic system <b>100</b>, applied by the inspection logic <b>160</b>, and indicated to the user (e.g., via a GUI or report). For example, the logic may specify that if any one of the classification results for an item indicates that an anomaly has been detected, the inspection outcome for that item is “fail.” In another example, the logic may specify that if any of the classification results for an item indicates that a solder bridge has been detected, and that none of the classification results indicate that another anomaly has been detected, the inspection outcome for that item is “send item for repair.” In another example, the logic may specify that if the number of anomalies detected for an item is under a threshold number, the inspection outcome for that item is “first class,” while if the number of anomalies detected for the item is greater than the threshold number, the inspection outcome for that item is “second class.” These are simply examples, and any suitable logic may be used to generate any type of inspection outcome based on the classification results for that item. The inspection logic <b>160</b> may store the inspection outcome for an item in the system-level data storage <b>150</b>.</div>
</li> <li> <para-num num="[0254]"> </para-num> <div class="description-line" id="p-0255" num="0254">The inspection process of the method <b>740</b> of <figref idrefs="DRAWINGS">FIG. 54</figref> may be used to inspect multiple instances of an item (e.g., multiple PCBs manufactured to nominally have the same structure) as part of a human-in-the-loop inspection process that allows trained human inspectors to utilize their inspection expertise while accelerating the inspection process. <figref idrefs="DRAWINGS">FIG. 56</figref> is a flow diagram of a method <b>760</b> of robot-aided inspection, in accordance with various embodiments. The method <b>760</b> may be carried out by the inspection logic <b>160</b> of the system-level compute hardware <b>124</b> (which may or may not be located in the robotic apparatus <b>101</b>), which may rely on the control logic <b>104</b> to reliably operate a robotic apparatus <b>101</b>.</div>
</li> <li> <para-num num="[0255]"> </para-num> <div class="description-line" id="p-0256" num="0255">At <b>762</b>, a counter variable N may be set equal to an initial value (e.g., 1). For example, the inspection logic <b>160</b> may initialize a counter variable N to count through the instances of an item to be inspected by a robotic system <b>100</b>, as discussed further below.</div>
</li> <li> <para-num num="[0256]"> </para-num> <div class="description-line" id="p-0257" num="0256">At <b>764</b>, an inspection routine may be run on item N to generate an inspection outcome. For example, the inspection logic <b>160</b> may perform an inspection routine like the method <b>740</b> of <figref idrefs="DRAWINGS">FIG. 54</figref> on an item N to generate an inspection outcome for the item N.</div>
</li> <li> <para-num num="[0257]"> </para-num> <div class="description-line" id="p-0258" num="0257">At <b>766</b>, the inspection outcome may be presented to a user. For example, the inspection logic <b>160</b> may provide a GUI that includes one or more images of the item N and the inspection outcome for the item N. In some embodiments, a user may be allowed to select, via a GUI, to display images whose proposed classifications are “fail,” images whose proposed classifications are “pass,” images whose proposed classifications are “unknown,” or any other subset of the images based on their classification result.</div>
</li> <li> <para-num num="[0258]"> </para-num> <div class="description-line" id="p-0259" num="0258">At <b>768</b>, the user is allowed to confirm or change the inspection outcome. For example, the inspection logic <b>160</b> may provide a GUI that allows a user to confirm or change the inspection outcome for the item N (e.g., based on the user's knowledge of an appropriate outcome for the item N).</div>
</li> <li> <para-num num="[0259]"> </para-num> <div class="description-line" id="p-0260" num="0259">At <b>770</b>, the confirmed or changed inspection outcome may be stored in association with an identifier of the item N. For example, the inspection logic <b>160</b> may store an identifier of the item N (e.g., a serial number) in association with the inspection outcome decided at <b>768</b>. Note that, in some embodiments, confirming or changing an inspection outcome at <b>768</b> and <b>770</b> may include confirming or changing the classification results themselves, instead of or in addition to confirming or changing the inspection outcome itself. Examples of such embodiments are discussed below with reference to <figref idrefs="DRAWINGS">FIGS. 58-59</figref>.</div>
</li> <li> <para-num num="[0260]"> </para-num> <div class="description-line" id="p-0261" num="0260">At <b>772</b>, it may be determined whether the counter variable N is equal to the total number of items (and thus that all items have been inspected). If it is determined that the counter variable N is not equal to the total number of items (and thus that all items have not yet been inspected), the method <b>760</b> may proceed to <b>774</b>, at which the counter variable N may be incremented. In some embodiments, the voice command logic <b>170</b> may recognize a “next item” voice command that may restart the inspection process for another instance of the item. The method <b>760</b> may then return to <b>764</b>. If it is determined at <b>772</b> that the counter variable N is equal to the total number of items (and thus that all items have been inspected), the method <b>760</b> may end.</div>
</li> <li> <para-num num="[0261]"> </para-num> <div class="description-line" id="p-0262" num="0261"> <figref idrefs="DRAWINGS">FIGS. 57-60</figref> are examples of GUIs that may be used during robot-aided inspection (e.g., as discussed above with reference to the method <b>760</b> of <figref idrefs="DRAWINGS">FIG. 56</figref>), in accordance with various embodiments. In some embodiments, a tablet or laptop computing device, or a desktop computing device with an associated touchscreen display, may provide an I/O device <b>120</b> through which the GUIs of <figref idrefs="DRAWINGS">FIGS. 57-60</figref> may be run; in some embodiments, the tablet, laptop, or desktop computing device may provide some or all of the system-level compute hardware <b>124</b> and some or all of the system-level data storage <b>150</b>. The GUIs may be provided by the user interface logic <b>162</b> in conjunction with the inspection logic <b>160</b>. In some embodiments, the GUIs may be provided on a touchscreen display communicatively coupled, and proximate to, the robotic apparatus <b>101</b>.</div>
</li> <li> <para-num num="[0262]"> </para-num> <div class="description-line" id="p-0263" num="0262"> <figref idrefs="DRAWINGS">FIG. 57</figref> depicts a GUI <b>1016</b> that may be used to facilitate robot-aided inspection, as discussed above. The GUI <b>1016</b> may include a “Live Feed” showing the current view of a camera of the end effector <b>118</b> of the robotic apparatus <b>101</b> (showing the item, a PCB). A timer in the upper righthand corner may be used to track the total inspection time, as desired. On the left side of the GUI <b>1016</b>, inspection statistics are provided, including the number of items inspected in a current session, the percentage of the total number of items whose inspection has been completed, the cumulative percentage of items whose inspection outcome has been “pass,” the cumulative percentage of items whose inspection outcome has been “reject,” and the cumulative percentage of items whose inspection outcome has been “unknown.” Control buttons (“Pause” and “Stop Inspection”) may allow the user to control the flow of the inspection session; in some embodiments, “pause” and “stop” voice commands may be recognized by the voice command logic <b>170</b>, in addition to the GUI. The GUI <b>1016</b> also includes an “Image Results” region that includes the most recently captured image of the item (“Current Image,” associated with a particular location/angle of the inspection path, as discussed above) displayed next to a corresponding image of a known-good item (“Golden Image”) so that a user may readily visually compare the two. An indicator between the two images indicates the classification result of the “Current Image”; in the case of the GUI <b>1016</b> of <figref idrefs="DRAWINGS">FIG. 57</figref>, the “X” indicates that the “Current Image” has been classified as “fail” (e.g., “anomaly detected”). A statistic below the “Current Image” indicates the percentage of images taken from this same location/angle for different items that are classified as “fail.” The array of images below the statistic in the “Image Results” region are previously captured images of the item currently under inspection (i.e., images captured at earlier locations/angles in the inspection path).</div>
</li> <li> <para-num num="[0263]"> </para-num> <div class="description-line" id="p-0264" num="0263"> <figref idrefs="DRAWINGS">FIG. 58</figref> depicts a GUI <b>1018</b> that may be used to facilitate robot-aided inspection; the GUI <b>1018</b> may be used after the inspection path has been run (e.g., in accordance with the method <b>740</b> of <figref idrefs="DRAWINGS">FIG. 54</figref> and using the GUI <b>1016</b> of <figref idrefs="DRAWINGS">FIG. 57</figref>) and as part of a human user review process, as discussed above with reference to the method <b>760</b> of <figref idrefs="DRAWINGS">FIG. 56</figref>. The GUI <b>1018</b> may include the most recently captured image of the item (“Current Image,” associated with a particular location/angle of the inspection path, as discussed above) displayed next to a corresponding image of a known-good item (“Golden Image”) so that a user may readily visually compare the two. An indicator between the two images indicates the classification result of the “Current Image”; in the case of the GUI <b>1018</b> of <figref idrefs="DRAWINGS">FIG. 58</figref>, the “X” indicates that the “Current Image” has been classified as “fail” (e.g., “anomaly detected”). A statistic below the “Current Image” indicates the percentage of images taken from this same location/angle for different items that are classified as “fail.” <figref idrefs="DRAWINGS">FIG. 58</figref> also depicts a highlight box on a particular portion of the “Current Image,” indicating the portion of the image that cased the “fail”; such a highlight box may be the result of a component detection process performed as part of the classification, as discussed below with reference to <b>786</b> of the method <b>780</b> of <figref idrefs="DRAWINGS">FIG. 61</figref>. The user may be given selectable options (“Pass” and “Fail”) that they may use to confirm or change the classification result. The GUI <b>1018</b> also includes an option to return to classification results of previously considered images (“&lt;4/15”) if the user wishes to revisit her previous confirmations/changes. In some embodiments, in order for a user to evaluate the next classification result associated with the inspection path, the user must confirm or change the classification result currently presented in the GUI <b>1018</b>.</div>
</li> <li> <para-num num="[0264]"> </para-num> <div class="description-line" id="p-0265" num="0264"> <figref idrefs="DRAWINGS">FIG. 59</figref> depicts a GUI <b>1020</b> that may be used to facilitate robot-aided inspection; the GUI <b>1020</b> may be used after the inspection path has been run (e.g., in accordance with the method <b>740</b> of <figref idrefs="DRAWINGS">FIG. 54</figref> and using the GUI <b>1016</b> of <figref idrefs="DRAWINGS">FIG. 57</figref>), and after the classification results have been confirmed or changed by a user (e.g., in accordance with the method <b>760</b> of <figref idrefs="DRAWINGS">FIG. 56</figref> and using the GUI <b>1018</b> of <figref idrefs="DRAWINGS">FIG. 58</figref>), to perform a final review of the inspection of the item. The GUI <b>1020</b> may include a scrollable list of captured images of the item (“Current Image,” associated with a particular location/angle of the inspection path, as discussed above) displayed next to a corresponding image of a known-good item (“Golden Image”) so that a user may readily visually compare the two. An indicator beside each pair of two images indicates the confirmed/changed classification result of the “Current Image,” as confirmed or changed by the user as discussed above with reference to the method <b>760</b> of <figref idrefs="DRAWINGS">FIG. 56</figref> and the GUI <b>1018</b> of <figref idrefs="DRAWINGS">FIG. 58</figref>. In the case of the GUI <b>1020</b> of <figref idrefs="DRAWINGS">FIG. 59</figref>, an “X” indicates that the “Current Image” has been classified as “fail” (e.g., “anomaly detected”) and a checkmark indicates that the “Current Image” has been classified as “pass” (e.g., “no anomaly detected”). The user may have an opportunity to review all of the classification results (and edit them, if needed) before she selects “Confirm Results.”</div>
</li> <li> <para-num num="[0265]"> </para-num> <div class="description-line" id="p-0266" num="0265">Upon selection of “Confirm Results” in the GUI <b>1020</b> of <figref idrefs="DRAWINGS">FIG. 59</figref>, the GUI <b>1022</b> of <figref idrefs="DRAWINGS">FIG. 60</figref> may be presented. The GUI <b>1022</b> may include the overview image of the inspected item, along with the inspection outcome (i.e., “FAILED”). The GUI <b>1022</b> may also include a selectable option for the user to inspect another item. The process discussed with reference to the GUIs of <figref idrefs="DRAWINGS">FIGS. 56-60</figref> may be repeated for any number of instances of a particular item. Further, the inspection outcome/classification results of a particular item may be reviewed as or immediately after the item is inspected, or multiple items may be inspected and then the inspection outcome/classification results for the multiple items may be reviewed.</div>
</li> <li> <para-num num="[0266]"> </para-num> <div class="description-line" id="p-0267" num="0266">In embodiments in which an inspection function includes computational classifier, such a classifier may be trained by running through test inspections and receiving input from experienced human users as to the proper classifications; this corpus of data may then be used to train the classifiers for use in a production inspection process. <figref idrefs="DRAWINGS">FIG. 61</figref> is a flow diagram of a method <b>780</b> of training classifiers for use with a robot-aided inspection system (e.g., the robotic system <b>100</b>), in accordance with various embodiments. The method <b>780</b> may be carried out by the inspection logic <b>160</b> of the system-level compute hardware <b>124</b> (which may or may not be located in the robotic apparatus <b>101</b>), which may rely on the control logic <b>104</b> to reliably operate a robotic apparatus <b>101</b>.</div>
</li> <li> <para-num num="[0267]"> </para-num> <div class="description-line" id="p-0268" num="0267">At <b>782</b>, an inspection routine may be performed for a set of items with known classifications. In some embodiments, the inspection routine may be performed without the classification operations; for example, the method <b>740</b> of <figref idrefs="DRAWINGS">FIG. 54</figref>, minus the operations of <b>746</b>-<b>750</b>, may be performed on a set of items with known classifications (e.g., “known-good” items, items with specific known defects, etc.). In other embodiments, the inspection routine may be performed with the classification operations (e.g., in accordance with the method <b>740</b> of <figref idrefs="DRAWINGS">FIG. 54</figref>); when the untrained classifiers attempt to classify an image, the result will likely be a classification of “unknown” until a training corpus is developed (as discussed below). When an anomaly detection classifier is being trained, for example, 10 to 100 “known-good” items may be inspected, with the classification results provided in advance or by a user in response to “unknown” classification results from the untrained classifier, as discussed below.</div>
</li> <li> <para-num num="[0268]"> </para-num> <div class="description-line" id="p-0269" num="0268">At <b>786</b>, the images from the inspection routine, and the known classifications, may be used to train classifier(s). For example, the inspection logic <b>160</b> may provide the images and the known classifications as inputs to a classifier training routine; the classifiers to be trained may be specified as part of the inspection path, as discussed above with reference to the method <b>710</b> of <figref idrefs="DRAWINGS">FIG. 42</figref> and various ones of the accompanying GUIs. In embodiments in which the classification operations were not performed at <b>784</b>, the classification results may be manually provided to the inspection logic <b>160</b> (e.g., all “pass” results). In embodiments in which the classification operations were performed at <b>784</b>, and the classifiers returned “unknown,” a human user may be prompted (e.g., via a GUI) to select a classification result for each image based on their inspection expertise (e.g., using GUIs like those of <figref idrefs="DRAWINGS">FIGS. 57-59</figref>, where the classifiers return “unknown” and the user is able to select an appropriate classification result). This entered result will then be used to train the classifiers used in one or more inspection functions. Alternately, in some embodiments, when items are being scanned for training, all of the images of these items may be automatically marked “pass” in a GUI; a user may manually mark some of the images as “fail” based on their expertise, and the user may then mark the results as a training run or otherwise certify the results.</div>
</li> <li> <para-num num="[0269]"> </para-num> <div class="description-line" id="p-0270" num="0269">In some embodiments, an inspection function may include performing a component detection technique on the images before providing them to a computational classifier or otherwise performing further analysis. For example, when the item being inspected is a PCB, an inspection function may include performing a component detection technique such as R-CNN to identify components of the PCB, and then execution of different anomaly detection classifiers on images of the different individual components. In other embodiments, an inspection function may utilize additional information about the PCB (such as a Gerber file, a drill file, or a pick-and-place file) to identify particular components of the item, and then images of the individual components may be further analyzed (e.g., provided to an anomaly detection classifier for that particular component). In other embodiments, bounding boxes around different components may be manually entered into the robotic system <b>100</b> and stored for use during the execution of various inspection functions.</div>
</li> <li> <para-num num="[0270]"> </para-num> <div class="description-line" id="p-0271" num="0270">The classifiers that may be trained at <b>786</b> (and thereafter used during inspection) may include any suitable classifiers. For example, an anomaly detection neural network may be trained to detect anomalies in a set of images of an item. Further, as noted above, examples of specific defects for which classifiers may be trained include solder bridges, bent pins, scratched lenses, etc. In some embodiments, Generative Adversarial Networks (GAN) or other data generation techniques may be used to augment the training data set to reduce the number of items that need to be inspected before a classifier is trained adequately enough for use in production. In some embodiments, a classifier trained at <b>786</b> may be a “single-shot” classifier in which a single “known-good” image is provided to the classifier, against which other images may be compared in an embedded space; such an approach may have particularly low training data requirements.</div>
</li> <li> <para-num num="[0271]"> </para-num> <div class="description-line" id="p-0272" num="0271">At <b>788</b>, the trained classifiers may be stored for use in production inspection routines. For example, the inspection logic <b>160</b> may store the trained classifiers in the system-level data storage <b>150</b> for use in future inspection routines (e.g., when an inspection function that utilizes that classifier is called).</div>
</li> <li> <para-num num="[0272]"> </para-num> <div class="description-line" id="p-0273" num="0272">At <b>790</b>, the training of the classifiers may be updated based on the results of production inspections. For example, the inspection logic <b>160</b> may store the confirmed or changed classification results in conjunction with the associated images, as discussed above with reference to the method <b>760</b> of <figref idrefs="DRAWINGS">FIG. 56</figref> and the GUIs of <figref idrefs="DRAWINGS">FIGS. 57-60</figref>, and these confirmed/changed classification results and images may be input to a classifier training routine (e.g., at the end of each business day or inspection shift) to update the training of the classifier with the input from the trained human inspectors. The updated trained classifiers may then be used in the next set of production inspections, and this process may continue during production, with the performance of the classifiers continuing to improve as inspection routines are repeated.</div>
</li> <li> <para-num num="[0273]"> </para-num> <div class="description-line" id="p-0274" num="0273">As noted above, any suitable end effector <b>118</b> may be used with a robotic apparatus <b>101</b> to enable the robotic apparatus <b>101</b> to perform a desired task. For example, various examples of end effectors <b>118</b> including depth sensors <b>264</b>, lasers <b>266</b>, and/or cameras <b>268</b> (used, e.g., for calibration and item inspection purposes) have been discussed. <figref idrefs="DRAWINGS">FIGS. 62-69</figref> illustrate various end effectors <b>118</b> that may be part of a robotic apparatus <b>101</b> and controlled by the end effector logic <b>142</b> during operation of a robotic system <b>100</b>. Any of the end effectors <b>118</b> disclosed herein may include, or may be modified to include, additional degrees of freedom; for example, any of the end effectors <b>118</b> disclosed herein may include one or more controllable gimbals to enable the rotation of some or all of the remaining elements of the end effector <b>118</b>. Thus, the degrees of freedom of the robotic apparatus <b>101</b> may be extended by including an end effector <b>118</b> that brings additional degrees of freedom.</div>
</li> <li> <para-num num="[0274]"> </para-num> <div class="description-line" id="p-0275" num="0274"> <figref idrefs="DRAWINGS">FIG. 62</figref> is a perspective view of an example end effector <b>118</b> that may be used in a robotic system <b>100</b>, in accordance with various embodiments. The end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 63</figref> is shown as mounted on a segment <b>110</b> of a robotic apparatus <b>101</b> (e.g., the segment <b>110</b>-<b>4</b> of the gantry-type robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 3</figref>, or the segment <b>110</b>-<b>6</b> of the arm-type robotic apparatuses <b>101</b> of <figref idrefs="DRAWINGS">FIGS. 4-6</figref>). The end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 63</figref> may include an object manipulator <b>184</b>, a lighting device <b>186</b>, and a depth sensor <b>188</b>. The object manipulator <b>184</b> may be any suitable device for picking up or otherwise moving an object (e.g., moving an item during an inspection process). An object manipulator <b>184</b> may be controlled by the object manipulation logic <b>166</b> and/or by the inspection logic <b>160</b>, for example. In some embodiments, an object manipulator <b>184</b> may be a magnetic manipulator whose magnetic strength may be adjusted by electrical signals provided to the object manipulator <b>184</b>; for example, the magnetic strength of the object manipulator <b>184</b> may be increased to allow the object manipulator <b>184</b> to pick up a magnetic object by magnetic force, and the magnetic strength of the object manipulator <b>184</b> may be decreased to allow the object manipulator <b>184</b> to release the magnetic object. In some embodiments, an object manipulator <b>184</b> may use adjustable vacuum suction to move an object; for example, the amount of suction generated at the end of a suction arm of the object manipulator <b>184</b> may be increased by a vacuum system (e.g., a pump) to pick up an object by suction force, and the amount of suction generated at the end of the suction arm of the object manipulator <b>184</b> may be decreased by the vacuum system to allow the object manipulator <b>184</b> to release the object. Other types of object manipulators <b>184</b> (e.g., grippers, pincers, etc.) may be used in the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 63</figref>; more generally, any of the end effectors <b>118</b> discussed herein may include, or may be modified to include, an object manipulator <b>184</b>, as desired.</div>
</li> <li> <para-num num="[0275]"> </para-num> <div class="description-line" id="p-0276" num="0275">The lighting device <b>186</b> of the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 63</figref> may be a bar-shaped array of LEDs or another lighting device. The depth sensor <b>188</b> of the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 63</figref> may be a camera array, as discussed above with reference to the depth sensor <b>264</b> of <figref idrefs="DRAWINGS">FIG. 35</figref>, and more generally, may take any of the forms discussed above with reference to the depth sensor <b>264</b> of <figref idrefs="DRAWINGS">FIG. 35</figref>. In some embodiments, the depth sensor <b>188</b> may include an integrated RGB camera, as noted above. The lighting device <b>186</b> may be used to illuminate an object (e.g., an item under inspection) that is being manipulated by the object manipulator <b>184</b> and/or being measured/imaged by the depth sensor <b>188</b>. In some embodiments, the end effector logic <b>142</b> may determine whether a “light on” voice command by a user has been received at a microphone of the I/O devices <b>120</b> and recognized by the voice command logic <b>170</b> of the system-level compute hardware <b>124</b>; upon receipt of such a voice command, the end effector logic <b>142</b> may cause the lighting device <b>186</b> to illuminate. In some embodiments, the lighting device <b>186</b> of the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 63</figref> (and of any of the other end effectors <b>118</b> disclosed herein) may generate light whose color is controllable (e.g., by commands issued by the system-level compute hardware <b>124</b> or other hardware, as appropriate). The ability to dynamically change the color of the light generated by a lighting device <b>186</b> may allow the robotic system <b>100</b> to more readily detect various defects in an item under inspection. For example, scratches in certain plastic materials may not be readily apparent when the material is illuminated by white light, but may be readily apparent when the material is illuminated by blue or pink light.</div>
</li> <li> <para-num num="[0276]"> </para-num> <div class="description-line" id="p-0277" num="0276"> <figref idrefs="DRAWINGS">FIGS. 63-65</figref> are various views of an example end effector <b>118</b> that may be used in a robotic system <b>100</b>, in accordance with various embodiments. In particular, <figref idrefs="DRAWINGS">FIG. 64</figref> is a side, cross-sectional view of the end effector <b>118</b>, <figref idrefs="DRAWINGS">FIG. 65</figref> is a top view of the first portion <b>118</b>A of the end effector <b>118</b>, and <figref idrefs="DRAWINGS">FIG. 66</figref> is a top view of the second portion <b>118</b>B of the end effector <b>118</b>. <figref idrefs="DRAWINGS">FIG. 65</figref> illustrates the end effector <b>118</b> positioned on a segment <b>110</b> of a robotic apparatus <b>101</b> (e.g., the segment <b>110</b>-<b>4</b> of the gantry-type robotic apparatus <b>101</b> of <figref idrefs="DRAWINGS">FIG. 3</figref>, or the segment <b>110</b>-<b>6</b> of the arm-type robotic apparatuses <b>101</b> of <figref idrefs="DRAWINGS">FIGS. 4-6</figref>) that itself has two portions: a first portion <b>110</b>A and a second portion <b>110</b>B, with the second portion <b>110</b>B between the first portion <b>110</b>A and the rest of the robotic apparatus <b>101</b> (not shown). The first portion <b>118</b>A of the end effector <b>118</b> may be mounted to the first portion <b>110</b>A of the segment <b>110</b>, and the second portion <b>118</b>B of the end effector <b>118</b> may be mounted to the second portion <b>110</b>B of the segment <b>110</b>.</div>
</li> <li> <para-num num="[0277]"> </para-num> <div class="description-line" id="p-0278" num="0277">The first portion <b>118</b>A of the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIGS. 63-65</figref> may include a lighting device <b>186</b> mounted on a lighting device support <b>194</b>. In some embodiments, the lighting device support <b>194</b> may be a funnel-shaped structure formed of plastic and/or metal, with the lighting device <b>186</b> mounted at a top portion of the lighting device support <b>194</b>. The lighting device <b>186</b> of <figref idrefs="DRAWINGS">FIGS. 63-65</figref> may be a ring-shaped lighting device, with LEDs <b>202</b> positioned in a ring configuration, as shown. The top portion of the lighting device support <b>194</b> may have a diameter that is greater than a diameter of the bottom portion of the lighting device support, and the bottom portion of the lighting device support <b>194</b> may couple to a first camera <b>196</b> of the end effector <b>118</b>. In particular, the bottom portion of the lighting device support <b>194</b> may act as a sleeve into which the first camera <b>196</b> extends so that the first camera <b>196</b> may capture images “through” the lighting device support <b>194</b>, with the lighting device <b>186</b> providing illumination for these images. In a visual inspection process, providing a lighting device <b>186</b> close to the item to be inspected may ensure sufficient illumination in captured images to permit accurate computational classification; inadequate lighting may reduce the efficacy of such classification. In some embodiments, the end effector logic <b>142</b> may control operation of the lighting device <b>186</b> and the first camera <b>196</b> of the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIGS. 63-65</figref> so that the lighting device <b>186</b> is activated when the first camera <b>196</b> captures an image, and is otherwise inactivated (“dark”). The first camera <b>196</b> may be mounted to the first portion <b>110</b>A of the segment <b>110</b> by a first support <b>198</b>, which may bolt or otherwise attach to the first portion <b>110</b>A of the segment <b>110</b>.</div>
</li> <li> <para-num num="[0278]"> </para-num> <div class="description-line" id="p-0279" num="0278">The second portion <b>118</b>B of the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIGS. 63-65</figref> may include a second support <b>192</b> on which a second camera <b>189</b> and a depth sensor <b>190</b> is mounted. The second support <b>192</b> may have a ring shape, and in use, may be disposed around the first portion <b>118</b>A and may be mounted to the second portion <b>118</b>B of the segment <b>110</b> (e.g., by one or more bolts or other attachment mechanisms). The second camera <b>189</b> and the depth sensor <b>190</b> may be mounted to the second support <b>192</b>, as shown. The depth sensor <b>190</b> may take the form of any of the depth sensors discussed herein. In particular, in some embodiments, the second camera <b>189</b> and the depth sensor <b>190</b> be integrated into a single device (as discussed above with reference to <figref idrefs="DRAWINGS">FIG. 35</figref>). The relative spacing between the lighting device <b>186</b> and the depth sensor <b>190</b> may ensure that, when the end effector <b>118</b> is being used to inspect an object, the depth sensor <b>190</b> is farther away from the object than the lighting device <b>186</b> and the depth sensor <b>190</b>. As some commercially available depth sensors <b>190</b> (e.g., those including a camera array and an integrated RGB camera) require a specified minimum distance between the depth sensor <b>190</b> and the surface to which depth is to be measured for reliable operation (e.g., a spacing of at least 10 centimeters), setting the depth sensor <b>190</b> “back” from the lighting device <b>186</b> and the first camera <b>196</b> may help achieve this minimum distance.</div>
</li> <li> <para-num num="[0279]"> </para-num> <div class="description-line" id="p-0280" num="0279">The end effector <b>118</b> of <figref idrefs="DRAWINGS">FIGS. 63-65</figref> may be used when an inspection process like those discussed above with reference to <figref idrefs="DRAWINGS">FIGS. 42-61</figref> is being performed by a robotic system <b>100</b>. In some embodiments of the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIGS. 63-65</figref>, the second camera <b>189</b> may have lower resolution than the first camera <b>196</b>. For example, when the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIGS. 63-65</figref> is used to perform an inspection process as discussed above with reference to <figref idrefs="DRAWINGS">FIG. 54</figref>, the second camera <b>189</b> may be used to capture an overview image of an item (e.g., as discussed above with reference to <b>742</b> of the method <b>740</b> of <figref idrefs="DRAWINGS">FIG. 54</figref>) and the first camera <b>196</b> may be used to capture the images of the item to which inspection function(s) will be applied (e.g., as discussed above with reference to <b>744</b> of the method <b>740</b> of <figref idrefs="DRAWINGS">FIG. 54</figref>). In some embodiments, no second camera <b>189</b> may be included in the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIGS. 63-65</figref>, and/or the first camera <b>196</b> may be used to capture the overview image of an item during an inspection process (e.g., as discussed above with reference to <b>742</b> of the method <b>740</b> of <figref idrefs="DRAWINGS">FIG. 54</figref>).</div>
</li> <li> <para-num num="[0280]"> </para-num> <div class="description-line" id="p-0281" num="0280"> <figref idrefs="DRAWINGS">FIG. 66</figref> is a side, cross-sectional view of another end effector <b>118</b> that may be used in a robotic system <b>100</b>, in accordance with various embodiments. The end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 66</figref> shares a number of elements in common with the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIGS. 63-65</figref>; a discussion of these common elements is not repeated here, and these common elements may take the form of any of the embodiments discussed above with reference to <figref idrefs="DRAWINGS">FIGS. 63-65</figref>. Compared to the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIGS. 63-65</figref>, the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 66</figref> does not include a second camera <b>189</b>, a depth sensor <b>190</b>, or a second support <b>192</b>. The end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 66</figref> may be used when an inspection process like those discussed above with reference to <figref idrefs="DRAWINGS">FIGS. 42-61</figref> is being performed by a robotic system <b>100</b>; such a process may be configured so that depth information is not needed, or so that depth information may be obtained in another way.</div>
</li> <li> <para-num num="[0281]"> </para-num> <div class="description-line" id="p-0282" num="0281"> <figref idrefs="DRAWINGS">FIG. 67</figref> is a side, cross-sectional view of another end effector <b>118</b> that may be used in a robotic system <b>100</b>, in accordance with various embodiments. The end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 67</figref> shares a number of elements in common with the end effectors <b>118</b> of <figref idrefs="DRAWINGS">FIGS. 63-65</figref> and <figref idrefs="DRAWINGS">FIG. 66</figref>; a discussion of these common elements is not repeated here, and these common elements may take the form of any of the embodiments discussed above. Compared to the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIGS. 63-65</figref>, the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 67</figref> does not include a first camera <b>196</b>, a lighting device support <b>194</b>, or a lighting device <b>186</b>, but the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 67</figref> includes an object manipulator <b>184</b>. In particular, the object manipulator <b>184</b> of <figref idrefs="DRAWINGS">FIG. 67</figref> includes a suction arm <b>206</b> (e.g., having a suction cup at an end of a tube) and a vacuum system <b>204</b> (including, e.g., a pump). As discussed above with reference to <figref idrefs="DRAWINGS">FIG. 62</figref>, the object manipulator <b>18</b> of <figref idrefs="DRAWINGS">FIG. 67</figref> may use adjustable vacuum suction to move an object; for example, the amount of suction generated at the end of the suction arm <b>206</b> may be increased by the vacuum system <b>204</b> to allow the suction arm <b>206</b> to pick up an object by suction force, and the amount of suction generated at the end of the suction arm <b>206</b> may be decreased by the vacuum system <b>204</b> to allow the suction arm <b>206</b> to release the object. The end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 66</figref> may be used when an inspection process like those discussed above with reference to <figref idrefs="DRAWINGS">FIGS. 42-61</figref> is being performed by a robotic system <b>100</b>, and manipulation of the items under inspection is desired. Such a process may be configured so that the images captured by the second camera <b>189</b> have adequate resolution for performing inspection functions during inspection.</div>
</li> <li> <para-num num="[0282]"> </para-num> <div class="description-line" id="p-0283" num="0282"> <figref idrefs="DRAWINGS">FIG. 68</figref> is a side, cross-sectional view of another end effector <b>118</b> that may be used in a robotic system <b>100</b>, in accordance with various embodiments. The end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 68</figref> shares a number of elements in common with the end effectors <b>118</b> of <figref idrefs="DRAWINGS">FIGS. 63-67</figref>; a discussion of these common elements is not repeated here, and these common elements may take the form of any of the embodiments discussed above. In particular, the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 68</figref> includes all of the elements of the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIGS. 63-65</figref> and the object manipulator <b>184</b> of <figref idrefs="DRAWINGS">FIG. 67</figref>; both the object manipulator <b>184</b> and the camera <b>196</b> may be mounted to the first portion <b>110</b>A of the segment <b>110</b> by a first support <b>208</b> (which may itself be bolted or otherwise attached to the first portion <b>110</b>A). The end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 66</figref> may be used when an inspection process like those discussed above with reference to <figref idrefs="DRAWINGS">FIGS. 42-61</figref> is being performed by a robotic system <b>100</b>, and manipulation of the items under inspection is desired.</div>
</li> <li> <para-num num="[0283]"> </para-num> <div class="description-line" id="p-0284" num="0283"> <figref idrefs="DRAWINGS">FIG. 69</figref> is a side, cross-sectional view of another end effector <b>118</b> that may be used in a robotic system <b>100</b>, in accordance with various embodiments. The end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 69</figref> shares a number of elements in common with the end effectors <b>118</b> of <figref idrefs="DRAWINGS">FIGS. 63-68</figref>; a discussion of these common elements is not repeated here, and these common elements may take the form of any of the embodiments discussed above. Compared to the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 67</figref>, the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 69</figref> does not include an object manipulator <b>184</b>, but the end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 69</figref> includes a laser <b>266</b> (e.g., as discussed above with reference to <figref idrefs="DRAWINGS">FIG. 35</figref>). The end effector <b>118</b> of <figref idrefs="DRAWINGS">FIG. 69</figref> may be particularly useful as a “calibration” end effector <b>118</b>, and may be used during system-level calibration of the robotic apparatus <b>101</b> (e.g., as discussed above with reference to <figref idrefs="DRAWINGS">FIGS. 35-38</figref>) and then replace with another end effector <b>118</b> (e.g., the end effectors <b>118</b> of any of <figref idrefs="DRAWINGS">FIGS. 63-68</figref>) when further tasks are performed (e.g., inspection tasks).</div>
</li> <li> <para-num num="[0284]"> </para-num> <div class="description-line" id="p-0285" num="0284">Various elements of the hardware <b>102</b> of a robotic system <b>100</b> may be distributed in any of a number of ways, including sharing a housing with the robotic apparatus <b>101</b>, being local to the robotic apparatus <b>101</b> (e.g., coupled to the robotic apparatus <b>101</b> in a same room via a cable or wireless communication connection), or being remote from the robotic apparatus <b>101</b> (e.g., with memory or processing devices located in the cloud). Further, a robotic system <b>100</b> may include more than one robotic apparatus <b>101</b>, and different robotic apparatus <b>101</b> may be local to each other (e.g., in the same room) or remote from one another (e.g., on different floors of a building, in different buildings, in different cities, etc.). In some embodiments, a robotic apparatus <b>101</b> may be connected to an Internet of Things (IoT) stack that allows for command and control of the robotic apparatus <b>101</b> through a web-based application, a virtual or augmented reality application, a mobile application, and/or a desktop application. The IoT stack may further allow for the logging and aggregation of data on a per-robotic apparatus <b>101</b> basis or based on multiple (e.g., a fleet) of robotic apparatuses <b>101</b>; such data may include logs of critical events and/or failures, movements per unit time, and inspections per unit time. Further, the IoT stack may enable the redeployment of inspection functions (e.g., including updated classifiers) for use in inspection, as desired. <figref idrefs="DRAWINGS">FIGS. 70-72</figref> are block diagrams of example arrangements of the hardware <b>102</b> of example robotic systems <b>100</b>; any of the embodiments disclosed herein may implemented in any of these arrangements.</div>
</li> <li> <para-num num="[0285]"> </para-num> <div class="description-line" id="p-0286" num="0285"> <figref idrefs="DRAWINGS">FIG. 70</figref> illustrates an embodiment of a robotic system <b>100</b> in which the system-level compute hardware <b>124</b> is part of a local computing system <b>180</b>, and the robotic system <b>100</b> includes one or more robotic apparatuses <b>101</b> that are also local to the local computing system <b>180</b>. The I/O devices <b>120</b> and other elements of the hardware <b>102</b> (e.g., some or all of the system-level data storage <b>150</b>) may be part of the local computing system <b>180</b>. In some embodiments, the local computing system <b>180</b> may include a laptop computing device, a tablet computing device, a desktop computing device, and/or a server computing device (or multiple ones of any of these devices, coupled together using any suitable communication protocol), and the local computing system <b>180</b> may be coupled via local communication connections to the robotic apparatuses <b>101</b>.</div>
</li> <li> <para-num num="[0286]"> </para-num> <div class="description-line" id="p-0287" num="0286"> <figref idrefs="DRAWINGS">FIG. 71</figref> illustrates an embodiment of a robotic system <b>100</b> in which some or all of the system-level compute hardware <b>124</b> is part of a remote computing system <b>182</b>, with one or more robotic apparatuses <b>101</b> that are each coupled to a local computing system <b>180</b> that is in remote communication with the remote computing system <b>182</b>. The I/O devices <b>120</b> and other elements of the hardware <b>102</b> (e.g., some or all of the system-level data storage <b>150</b>, and/or some or all of the system-level compute hardware <b>124</b>) may be part of the local computing systems <b>180</b>. The local computing systems <b>180</b> may take the form of any of the embodiments discussed above with reference to <figref idrefs="DRAWINGS">FIG. 70</figref>. In some embodiments, the remote computing system <b>182</b> may be a cloud computing system, implementing some or all of the system-level compute hardware <b>124</b> (and/or some or all of the system-level data storage <b>150</b>, not shown). The local computing systems <b>180</b> may communicate with the remote computing system <b>182</b> via any suitable communication protocol, such as wired or wireless Internet communication protocols.</div>
</li> <li> <para-num num="[0287]"> </para-num> <div class="description-line" id="p-0288" num="0287"> <figref idrefs="DRAWINGS">FIG. 72</figref> illustrates an embodiment of a robotic system <b>100</b> in which some of the system-level compute hardware <b>124</b> is part of a remote computing system <b>182</b>, one or more robotic apparatuses <b>101</b> are each coupled to a local computing system <b>180</b> that is in remote communication with the remote computing system <b>182</b>, and some of the system-level compute hardware <b>124</b> is part of the local computing systems <b>180</b>. The embodiment of <figref idrefs="DRAWINGS">FIG. 72</figref> may thus represent a hybrid arrangement of the robotic systems <b>100</b> of <figref idrefs="DRAWINGS">FIGS. 70 and 71</figref>. Similarly, some of the system-level data storage <b>150</b>, not shown, may be included in the local computing systems <b>180</b>, and some of the system-level data storage <b>150</b> may be included in the remote computing system <b>182</b>.</div>
</li> <li> <para-num num="[0288]"> </para-num> <div class="description-line" id="p-0289" num="0288">The system-level compute hardware <b>124</b> and the joint-level compute hardware <b>210</b> may include any suitable processing device(s). As used herein, the term “processing device” or “processor” may refer to any device or portion of a device that processes electronic data from registers and/or memory to transform that electronic data into other electronic data that may be stored in registers and/or memory. The processing device(s) included in the system-level compute hardware <b>124</b> and/or the joint-level compute hardware <b>210</b> may include one or more digital signal processors (DSPs), application-specific integrated circuits (ASICs), central processing units (CPUs), graphics processing units (GPUs), tensor processing units (TPUs), cryptoprocessors (specialized processors that execute cryptographic algorithms within hardware), server processors, or any other suitable processing devices.</div>
</li> <li> <para-num num="[0289]"> </para-num> <div class="description-line" id="p-0290" num="0289">As noted above, the system-level data storage <b>150</b> and/or the joint-level data storage <b>229</b> may include any suitable storage devices, such as volatile memory (e.g., dynamic RAM (DRAM)), nonvolatile memory (e.g., ROM), Flash memory, solid state memory, networked drives, cloud drives, and/or local hard drives.</div>
</li> <li> <para-num num="[0290]"> </para-num> <div class="description-line" id="p-0291" num="0290">In some embodiments, the communications hardware <b>128</b> of a robotic system <b>100</b> may include one or more communication chips. For example, a communication chip may be configured for managing wireless communications for the transfer of data to/from or within the robotic system <b>100</b>. The term “wireless” and its derivatives may be used to describe circuits, devices, systems, methods, techniques, communications channels, etc., that may communicate data through the use of modulated electromagnetic radiation through a nonsolid medium. The term does not imply that the associated devices do not contain any wires, although in some embodiments they might not. A communication chip may implement any of a number of wireless standards or protocols, including but not limited to Institute for Electrical and Electronic Engineers (IEEE) standards including Wi-Fi (IEEE 802.11 family), IEEE 802.16 standards (e.g., IEEE 802.16-2005 Amendment), Long-Term Evolution (LTE) project along with any amendments, updates, and/or revisions (e.g., advanced LTE project, ultra mobile broadband (UMB) project (also referred to as “3GPP2”), etc.). IEEE 802.16 compatible Broadband Wireless Access (BWA) networks are generally referred to as WiMAX networks, an acronym that stands for Worldwide Interoperability for Microwave Access, which is a certification mark for products that pass conformity and interoperability tests for the IEEE 802.16 standards. A communication chip may operate in accordance with a Global System for Mobile Communication (GSM), General Packet Radio Service (GPRS), Universal Mobile Telecommunications System (UMTS), High Speed Packet Access (HSPA), Evolved HSPA (E-HSPA), or LTE network. A communication chip may operate in accordance with Enhanced Data for GSM Evolution (EDGE), GSM EDGE Radio Access Network (GERAN), Universal Terrestrial Radio Access Network (UTRAN), or Evolved UTRAN (E-UTRAN). A communication chip may operate in accordance with Code Division Multiple Access (CDMA), Time Division Multiple Access (TDMA), Digital Enhanced Cordless Telecommunications (DECT), Evolution-Data Optimized (EV-DO), and derivatives thereof, as well as any other wireless protocols that are designated as 3G, 4G, 5G, and beyond. A communication chip may operate in accordance with other wireless protocols in other embodiments. The robotic system <b>100</b> may include an antenna (not shown) to facilitate wireless communications and/or to receive other wireless communications (such as AM or FM radio transmissions).</div>
</li> <li> <para-num num="[0291]"> </para-num> <div class="description-line" id="p-0292" num="0291">In some embodiments, a communication chip may manage wired communications, such as electrical, optical, or any other suitable communication protocols (e.g., Ethernet). As noted above, a communication chip may include multiple communication chips. For instance, a first communication chip may be dedicated to shorter-range wireless communications such as Wi-Fi or Bluetooth, and a second communication chip may be dedicated to longer-range wireless communications such as global positioning system (GPS), EDGE, GPRS, CDMA, WiMAX, LTE, EV-DO, or others. In some embodiments, a first communication chip may be dedicated to wireless communications, and a second communication chip may be dedicated to wired communications.</div>
</li> <li> <para-num num="[0292]"> </para-num> <div class="description-line" id="p-0293" num="0292">The following paragraphs provide various examples of the embodiments disclosed herein.</div>
</li> <li> <para-num num="[0293]"> </para-num> <div class="description-line" id="p-0294" num="0293">Example A1 is an apparatus for collaborative robotics, including: a first segment; a second segment; and a joint assembly, wherein the joint assembly includes a stepper motor and a drivetrain to control a relative position of the first and second segments, and the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0294]"> </para-num> <div class="description-line" id="p-0295" num="0294">Example A2 includes the subject matter of Example A1, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0295]"> </para-num> <div class="description-line" id="p-0296" num="0295">Example A3 includes the subject matter of any of Examples A1-2, and further specifies that the joint assembly further includes an angle encoder to detect an angular position of a shaft of the stepper motor.</div>
</li> <li> <para-num num="[0296]"> </para-num> <div class="description-line" id="p-0297" num="0296">Example A4 includes the subject matter of Example A3, and further specifies that the angle encoder is contactless.</div>
</li> <li> <para-num num="[0297]"> </para-num> <div class="description-line" id="p-0298" num="0297">Example A5 includes the subject matter of any of Examples A3-4, and further specifies that the angle encoder is magnetic.</div>
</li> <li> <para-num num="[0298]"> </para-num> <div class="description-line" id="p-0299" num="0298">Example A6 includes the subject matter of any of Examples A3-5, and further specifies that a diametric magnet is at an end of the shaft of the stepper motor, proximate to the angle encoder.</div>
</li> <li> <para-num num="[0299]"> </para-num> <div class="description-line" id="p-0300" num="0299">Example A7 includes the subject matter of any of Examples A3-6, and further specifies that the angle encoder is spaced away from the shaft of the stepper motor.</div>
</li> <li> <para-num num="[0300]"> </para-num> <div class="description-line" id="p-0301" num="0300">Example A8 includes the subject matter of any of Examples A1-7, and further specifies that the apparatus does not include a joint encoder for the joint assembly.</div>
</li> <li> <para-num num="[0301]"> </para-num> <div class="description-line" id="p-0302" num="0301">Example A9 includes the subject matter of any of Examples A1-8, and further specifies that the joint assembly is one of a plurality of joint assemblies of the apparatus, and individual ones of the joint assemblies include a stepper motor and a drivetrain with a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0302]"> </para-num> <div class="description-line" id="p-0303" num="0302">Example A10 includes the subject matter of Example A9, and further specifies that individual ones of the joint assemblies further include an angle encoder to detect an angular position of a shaft of the stepper motor of that joint assembly.</div>
</li> <li> <para-num num="[0303]"> </para-num> <div class="description-line" id="p-0304" num="0303">Example A11 includes the subject matter of any of Examples A9-10, and further specifies that different ones of the joint assemblies are communicatively coupled by a Universal Serial Bus (USB) link, a Controller Area Network (CAN) link, or an RS-485 link.</div>
</li> <li> <para-num num="[0304]"> </para-num> <div class="description-line" id="p-0305" num="0304">Example A12 includes the subject matter of any of Examples A9-11, and further specifies that the apparatus includes at least three joint assemblies.</div>
</li> <li> <para-num num="[0305]"> </para-num> <div class="description-line" id="p-0306" num="0305">Example A13 includes the subject matter of Example A12, and further specifies that the apparatus includes at least six joint assemblies.</div>
</li> <li> <para-num num="[0306]"> </para-num> <div class="description-line" id="p-0307" num="0306">Example A14 includes the subject matter of any of Examples A1-13, and further specifies that the first segment includes a substantially cylindrical housing.</div>
</li> <li> <para-num num="[0307]"> </para-num> <div class="description-line" id="p-0308" num="0307">Example A15 includes the subject matter of any of Examples A14, and further specifies that the second segment includes a substantially cylindrical housing.</div>
</li> <li> <para-num num="[0308]"> </para-num> <div class="description-line" id="p-0309" num="0308">Example A16 includes the subject matter of any of Examples A1-15, and further specifies that the apparatus includes an end effector.</div>
</li> <li> <para-num num="[0309]"> </para-num> <div class="description-line" id="p-0310" num="0309">Example A17 includes the subject matter of Example A16, and further specifies that the end effector includes at least one camera.</div>
</li> <li> <para-num num="[0310]"> </para-num> <div class="description-line" id="p-0311" num="0310">Example A18 includes the subject matter of any of Examples A16-17, and further specifies that the end effector includes at least one object manipulator.</div>
</li> <li> <para-num num="[0311]"> </para-num> <div class="description-line" id="p-0312" num="0311">Example A19 includes the subject matter of any of Examples A1-18, and further specifies that the joint assembly includes an accelerometer.</div>
</li> <li> <para-num num="[0312]"> </para-num> <div class="description-line" id="p-0313" num="0312">Example A20 includes the subject matter of any of Examples A1-19, and further specifies that the joint assembly includes one or more H-bridges electrically coupled to the stepper motor.</div>
</li> <li> <para-num num="[0313]"> </para-num> <div class="description-line" id="p-0314" num="0313">Example A21 includes the subject matter of any of Examples A1-20, and further specifies that the joint assembly includes a Universal Serial Bus (USB) hub or a Controller Area Network (CAN) port.</div>
</li> <li> <para-num num="[0314]"> </para-num> <div class="description-line" id="p-0315" num="0314">Example A22 includes the subject matter of any of Examples A1-21, and further specifies that the joint assembly includes one or more light-emitting diodes (LEDs).</div>
</li> <li> <para-num num="[0315]"> </para-num> <div class="description-line" id="p-0316" num="0315">Example A23 includes the subject matter of any of Examples A1-22, and further specifies that the joint assembly includes a processing device.</div>
</li> <li> <para-num num="[0316]"> </para-num> <div class="description-line" id="p-0317" num="0316">Example A24 includes the subject matter of any of Examples A1-23, and further specifies that the joint assembly is part of a robotic arm.</div>
</li> <li> <para-num num="[0317]"> </para-num> <div class="description-line" id="p-0318" num="0317">Example A25 includes the subject matter of any of Examples A1-23, and further specifies that the joint assembly is part of a robotic gantry.</div>
</li> <li> <para-num num="[0318]"> </para-num> <div class="description-line" id="p-0319" num="0318">Example A26 includes the subject matter of any of Examples A1-25, and further specifies that the apparatus is part of a product inspection system.</div>
</li> <li> <para-num num="[0319]"> </para-num> <div class="description-line" id="p-0320" num="0319">Example A27 is an apparatus for use in a robotic system, including: a processing device to perform a position-encoder output association operation, wherein the position-encoder output association operation includes: causing a stepper motor in a joint assembly of the robotic system to move by a known increment, causing storage of a cumulative incremental motor position in a memory, receiving an output of an angle encoder in the joint assembly, wherein the output of the angle encoder is indicative of an angular position of a shaft of the stepper motor, and causing storage of an indicator of the output of the angle encoder in the memory in association with the cumulative incremental motor position.</div>
</li> <li> <para-num num="[0320]"> </para-num> <div class="description-line" id="p-0321" num="0320">Example A28 includes the subject matter of Example A27, and further specifies that the processing device is to: repeat the position-encoder output association operation for a full rotation of the shaft of the stepper motor.</div>
</li> <li> <para-num num="[0321]"> </para-num> <div class="description-line" id="p-0322" num="0321">Example A29 includes the subject matter of Example A28, and further specifies that the processing device is to: interpolate between the cumulative incremental motor positions and the associated indicators of angle encoder output stored in the memory to generate an interpolated set of position-encoder output associations.</div>
</li> <li> <para-num num="[0322]"> </para-num> <div class="description-line" id="p-0323" num="0322">Example A30 includes the subject matter of Example A29, and further specifies that the processing device is to: cause the interpolated set of position-encoder output associations to be stored in a memory device in the joint assembly.</div>
</li> <li> <para-num num="[0323]"> </para-num> <div class="description-line" id="p-0324" num="0323">Example A31 includes the subject matter of any of Examples A27-30, and further specifies that the processing device is a first processing device, and the first processing device is to: before performing the position-encoder output association operation, query a second processing device of the joint assembly to determine whether the joint assembly has been previously calibrated; wherein the first processing device is to perform the position-encoder output association operation in response to a determination that the joint assembly has not been previously calibrated.</div>
</li> <li> <para-num num="[0324]"> </para-num> <div class="description-line" id="p-0325" num="0324">Example A32 includes the subject matter of any of Examples A27-31, and further specifies that the angle encoder is a magnetic angle encoder.</div>
</li> <li> <para-num num="[0325]"> </para-num> <div class="description-line" id="p-0326" num="0325">Example A33 includes the subject matter of any of Examples A27-32, and further specifies that the angle encoder is contactless.</div>
</li> <li> <para-num num="[0326]"> </para-num> <div class="description-line" id="p-0327" num="0326">Example A34 includes the subject matter of any of Examples A27-33, and further specifies that the angle encoder is spaced away from the shaft of the stepper motor.</div>
</li> <li> <para-num num="[0327]"> </para-num> <div class="description-line" id="p-0328" num="0327">Example A35 includes the subject matter of any of Examples A27-34, and further specifies that a diametric magnetic is at an end of the shaft of the stepper motor.</div>
</li> <li> <para-num num="[0328]"> </para-num> <div class="description-line" id="p-0329" num="0328">Example A36 includes the subject matter of any of Examples A27-35, and further specifies that the joint assembly includes a drivetrain with a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0329]"> </para-num> <div class="description-line" id="p-0330" num="0329">Example A37 includes the subject matter of any of Examples A27-36, and further specifies that the joint assembly is part of a robotic arm.</div>
</li> <li> <para-num num="[0330]"> </para-num> <div class="description-line" id="p-0331" num="0330">Example A38 includes the subject matter of any of Examples A27-36, and further specifies that the joint assembly is part of a robotic gantry.</div>
</li> <li> <para-num num="[0331]"> </para-num> <div class="description-line" id="p-0332" num="0331">Example A39 includes the subject matter of any of Examples A27-38, and further specifies that the robotic system is a product inspection system.</div>
</li> <li> <para-num num="[0332]"> </para-num> <div class="description-line" id="p-0333" num="0332">Example A40 is an apparatus for use in a robotic system, including: a processing device to receive an indication of a value of a performance variable of a stepper motor of a joint assembly of a robotic apparatus, compare the value to a target value, and cause drive currents to be provided to the stepper motor to bring the value closer to the target value.</div>
</li> <li> <para-num num="[0333]"> </para-num> <div class="description-line" id="p-0334" num="0333">Example A41 includes the subject matter of Example A40, and further specifies that causing drive currents to be provided to the stepper motor includes identifying a current position of the stepper motor in a step cycle.</div>
</li> <li> <para-num num="[0334]"> </para-num> <div class="description-line" id="p-0335" num="0334">Example A42 includes the subject matter of Example A41, and further specifies that causing drive currents to be provided to the stepper motor further includes: determining a position of the stepper motor a predetermined number of steps away from the current position of the stepper motor in the step cycle; identifying nominal drive currents for each phase of the stepper motor at the determined position; and causing drive currents to be provided to the phases of the stepper motor based on the nominal drive currents.</div>
</li> <li> <para-num num="[0335]"> </para-num> <div class="description-line" id="p-0336" num="0335">Example A43 includes the subject matter of Example A42, and further specifies that the predetermined number of steps is one step.</div>
</li> <li> <para-num num="[0336]"> </para-num> <div class="description-line" id="p-0337" num="0336">Example A44 includes the subject matter of any of Examples A42-43, and further specifies that comparing the value to a target value includes determining an error, and causing drive currents to be provided to the stepper motor includes: providing the error to a control loop to generate a drive current magnitude; scaling the nominal drive currents by the drive current magnitude; and causing drive currents to be provided to phases of the stepper motor based on the scaled nominal drive currents.</div>
</li> <li> <para-num num="[0337]"> </para-num> <div class="description-line" id="p-0338" num="0337">Example A45 includes the subject matter of Example A44, and further specifies that the control loop includes a proportional control element, an integral control element, or a derivative control element.</div>
</li> <li> <para-num num="[0338]"> </para-num> <div class="description-line" id="p-0339" num="0338">Example A46 includes the subject matter of any of Examples A40-45, and further specifies that the processing device is a first processing device, the first processing device is in the joint assembly, and the first processing device is to: receiving the target value from a second processing device in communication with the first processing device via a communications bus.</div>
</li> <li> <para-num num="[0339]"> </para-num> <div class="description-line" id="p-0340" num="0339">Example A47 includes the subject matter of any of Examples A40-46, and further specifies that the performance variable includes position, velocity, current, or torque.</div>
</li> <li> <para-num num="[0340]"> </para-num> <div class="description-line" id="p-0341" num="0340">Example A48 includes the subject matter of any of Examples A40-47, and further specifies that the processing device us to receive the indication of the value of the performance variable, compare the value to the target value, and cause drive currents to be provided to the stepper motor at a frequency between 1 kilohertz and 100 kilohertz.</div>
</li> <li> <para-num num="[0341]"> </para-num> <div class="description-line" id="p-0342" num="0341">Example A49 includes the subject matter of any of Examples A40-48, and further specifies that the stepper motor is powered by a battery.</div>
</li> <li> <para-num num="[0342]"> </para-num> <div class="description-line" id="p-0343" num="0342">Example A50 includes the subject matter of any of Examples A40-49, and further specifies that causing drive currents to be provided to the stepper motor includes causing drive currents for one phase of the stepper motor to be provided to a discrete logic circuit to generate drive currents for another phase of the stepper motor.</div>
</li> <li> <para-num num="[0343]"> </para-num> <div class="description-line" id="p-0344" num="0343">Example A51 includes the subject matter of any of Examples A40-49, and further specifies that the joint assembly is part of a robotic arm or a robotic gantry.</div>
</li> <li> <para-num num="[0344]"> </para-num> <div class="description-line" id="p-0345" num="0344">Example A52 includes the subject matter of any of Examples A40-51, and further specifies that the robotic system is a product inspection system.</div>
</li> <li> <para-num num="[0345]"> </para-num> <div class="description-line" id="p-0346" num="0345">Example A53 is a method of calibrating a joint assembly of a robotic apparatus, including: performing a position-encoder output association operation, including: causing a stepper motor in the joint assembly to move by a known increment, causing storage of a cumulative incremental motor position in a memory, receiving an output of an angle encoder in the joint assembly, wherein the output of the angle encoder is indicative of an angular position of a shaft of the stepper motor, and causing storage of an indicator of the output of the angle encoder in the memory in association with the cumulative incremental motor position.</div>
</li> <li> <para-num num="[0346]"> </para-num> <div class="description-line" id="p-0347" num="0346">Example A54 includes the subject matter of Example A53, and further includes: repeating the position-encoder output association operation for a full rotation of the shaft of the stepper motor.</div>
</li> <li> <para-num num="[0347]"> </para-num> <div class="description-line" id="p-0348" num="0347">Example A55 includes the subject matter of Example A54, and further includes: interpolating between the cumulative incremental motor positions and the associated indicators of angle encoder output stored in the memory to generate an interpolated set of position-encoder output associations.</div>
</li> <li> <para-num num="[0348]"> </para-num> <div class="description-line" id="p-0349" num="0348">Example A56 includes the subject matter of Example A55, and further includes: causing the interpolated set of position-encoder output associations to be stored in a memory device in the joint assembly.</div>
</li> <li> <para-num num="[0349]"> </para-num> <div class="description-line" id="p-0350" num="0349">Example A57 includes the subject matter of any of Examples A53-56, and further includes: before performing the position-encoder output association operation, querying a processing device of the joint assembly to determine whether the joint assembly has been previously calibrated; wherein the position-encoder output association operation is performed in response to a determination that the joint assembly has not been previously calibrated.</div>
</li> <li> <para-num num="[0350]"> </para-num> <div class="description-line" id="p-0351" num="0350">Example A58 includes the subject matter of any of Examples A53-57, and further specifies that the angle encoder is a magnetic angle encoder.</div>
</li> <li> <para-num num="[0351]"> </para-num> <div class="description-line" id="p-0352" num="0351">Example A59 includes the subject matter of any of Examples A53-58, and further specifies that the angle encoder is contactless.</div>
</li> <li> <para-num num="[0352]"> </para-num> <div class="description-line" id="p-0353" num="0352">Example A60 includes the subject matter of any of Examples A53-59, and further specifies that the angle encoder is spaced away from the shaft of the stepper motor.</div>
</li> <li> <para-num num="[0353]"> </para-num> <div class="description-line" id="p-0354" num="0353">Example A61 includes the subject matter of any of Examples A53-60, and further specifies that a diametric magnetic is at an end of the shaft of the stepper motor.</div>
</li> <li> <para-num num="[0354]"> </para-num> <div class="description-line" id="p-0355" num="0354">Example A62 includes the subject matter of any of Examples A53-61, and further specifies that the joint assembly includes a drivetrain with a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0355]"> </para-num> <div class="description-line" id="p-0356" num="0355">Example A63 includes the subject matter of any of Examples A53-62, and further specifies that the joint assembly is part of a robotic arm.</div>
</li> <li> <para-num num="[0356]"> </para-num> <div class="description-line" id="p-0357" num="0356">Example A64 includes the subject matter of any of Examples A53-62, and further specifies that the joint assembly is part of a robotic gantry.</div>
</li> <li> <para-num num="[0357]"> </para-num> <div class="description-line" id="p-0358" num="0357">Example A65 includes the subject matter of any of Examples A53-64, and further specifies that the robotic apparatus is part of a product inspection system.</div>
</li> <li> <para-num num="[0358]"> </para-num> <div class="description-line" id="p-0359" num="0358">Example A66 is a method of moving a stepper motor in a joint assembly of a robotic apparatus, including: receiving an indication of a value of a performance variable of the stepper motor; comparing the value to a target value; and causing drive currents to be provided to the stepper motor to bring the value closer to the target value.</div>
</li> <li> <para-num num="[0359]"> </para-num> <div class="description-line" id="p-0360" num="0359">Example A67 includes the subject matter of Example A66, and further specifies that causing drive currents to be provided to the stepper motor includes identifying a current position of the stepper motor in a step cycle.</div>
</li> <li> <para-num num="[0360]"> </para-num> <div class="description-line" id="p-0361" num="0360">Example A68 includes the subject matter of Example A67, and further specifies that causing drive currents to be provided to the stepper motor further includes: determining a position of the stepper motor a predetermined number of steps away from the current position of the stepper motor in the step cycle; identifying nominal drive currents for each phase of the stepper motor at the determined position; and causing drive currents to be provided to the phases of the stepper motor based on the nominal drive currents.</div>
</li> <li> <para-num num="[0361]"> </para-num> <div class="description-line" id="p-0362" num="0361">Example A69 includes the subject matter of Example A68, and further specifies that the predetermined number of steps is one step.</div>
</li> <li> <para-num num="[0362]"> </para-num> <div class="description-line" id="p-0363" num="0362">Example A70 includes the subject matter of any of Examples A68-69, and further specifies that comparing the value to a target value includes determining an error, and causing drive currents to be provided to the stepper motor includes: providing the error to a control loop to generate a drive current magnitude; scaling the nominal drive currents by the drive current magnitude; and causing drive currents to be provided to phases of the stepper motor based on the scaled nominal drive currents.</div>
</li> <li> <para-num num="[0363]"> </para-num> <div class="description-line" id="p-0364" num="0363">Example A71 includes the subject matter of Example A70, and further specifies that the control loop includes a proportional control element, an integral control element, or a derivative control element.</div>
</li> <li> <para-num num="[0364]"> </para-num> <div class="description-line" id="p-0365" num="0364">Example A72 includes the subject matter of any of Examples A66-71, and further specifies that the method is performed by a first processing device in the joint assembly, and the method further includes: receiving the target value from a second processing device in communication with the first processing device via a communications bus.</div>
</li> <li> <para-num num="[0365]"> </para-num> <div class="description-line" id="p-0366" num="0365">Example A73 includes the subject matter of any of Examples A66-72, and further specifies that the performance variable includes position, velocity, current, or torque.</div>
</li> <li> <para-num num="[0366]"> </para-num> <div class="description-line" id="p-0367" num="0366">Example A74 includes the subject matter of any of Examples A66-73, and further specifies that the method is repeated at a frequency between 1 kilohertz and 100 kilohertz.</div>
</li> <li> <para-num num="[0367]"> </para-num> <div class="description-line" id="p-0368" num="0367">Example A75 includes the subject matter of any of Examples A66-74, and further specifies that the stepper motor is powered by a battery.</div>
</li> <li> <para-num num="[0368]"> </para-num> <div class="description-line" id="p-0369" num="0368">Example A76 includes the subject matter of any of Examples A66-75, and further specifies that the joint assembly is part of a robotic arm.</div>
</li> <li> <para-num num="[0369]"> </para-num> <div class="description-line" id="p-0370" num="0369">Example A77 includes the subject matter of any of Examples A66-75, and further specifies that the joint assembly is part of a robotic gantry.</div>
</li> <li> <para-num num="[0370]"> </para-num> <div class="description-line" id="p-0371" num="0370">Example A78 includes the subject matter of any of Examples A66-77, and further specifies that the robotic apparatus is part of a product inspection system.</div>
</li> <li> <para-num num="[0371]"> </para-num> <div class="description-line" id="p-0372" num="0371">Example A79 is one or more computer readable media having instructions thereon that, when executed by one or more processing devices of a computing system, cause the computing system to perform any of the methods of Examples A53-78.</div>
</li> <li> <para-num num="[0372]"> </para-num> <div class="description-line" id="p-0373" num="0372">Example A80 is an apparatus for collaborative robotics, including means for performing any of the methods of Examples A53-78.</div>
</li> <li> <para-num num="[0373]"> </para-num> <div class="description-line" id="p-0374" num="0373">Example B1 is an apparatus for collaborative robotics, including: a first segment; a second segment; and a joint assembly, wherein the joint assembly includes a stepper motor to control a relative position of the first and second segments, and a phase of the stepper motor is shorted when the apparatus is unpowered.</div>
</li> <li> <para-num num="[0374]"> </para-num> <div class="description-line" id="p-0375" num="0374">Example B2 includes the subject matter of Example B1, and further specifies that the joint assembly further includes a drivetrain, and the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0375]"> </para-num> <div class="description-line" id="p-0376" num="0375">Example B3 includes the subject matter of Example B2, and further specifies that the gear ratio is less than 25:1.</div>
</li> <li> <para-num num="[0376]"> </para-num> <div class="description-line" id="p-0377" num="0376">Example B4 includes the subject matter of Example B3, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0377]"> </para-num> <div class="description-line" id="p-0378" num="0377">Example B5 includes the subject matter of any of Examples B1-4, and further specifies that the joint assembly includes a mechanical relay to short the phase.</div>
</li> <li> <para-num num="[0378]"> </para-num> <div class="description-line" id="p-0379" num="0378">Example B6 includes the subject matter of any of Examples B1-4, and further specifies that the joint assembly includes a solid state relay to short the phase.</div>
</li> <li> <para-num num="[0379]"> </para-num> <div class="description-line" id="p-0380" num="0379">Example B7 includes the subject matter of any of Examples B1-4, and further specifies that the joint assembly includes an H-bridge to short the phase.</div>
</li> <li> <para-num num="[0380]"> </para-num> <div class="description-line" id="p-0381" num="0380">Example B8 includes the subject matter of any of Examples B1-7, and further specifies that the apparatus does not include a mechanical brake to brake the joint assembly.</div>
</li> <li> <para-num num="[0381]"> </para-num> <div class="description-line" id="p-0382" num="0381">Example B9 includes the subject matter of any of Examples B1-8, and further specifies that, when the apparatus is unpowered, a braking force of the joint assembly may be overcome by typical human force.</div>
</li> <li> <para-num num="[0382]"> </para-num> <div class="description-line" id="p-0383" num="0382">Example B10 includes the subject matter of any of Examples B1-9, and further specifies that the joint assembly further includes an angle encoder to detect an angular position of a shaft of the stepper motor.</div>
</li> <li> <para-num num="[0383]"> </para-num> <div class="description-line" id="p-0384" num="0383">Example B11 includes the subject matter of any of Examples B1-10, and further specifies that the apparatus does not include a joint encoder for the joint assembly.</div>
</li> <li> <para-num num="[0384]"> </para-num> <div class="description-line" id="p-0385" num="0384">Example B12 includes the subject matter of any of Examples B1-8, and further specifies that the joint assembly is one of a plurality of joint assemblies of the apparatus, and individual ones of the joint assemblies include a stepper motor, and a phase for an individual stepper motor is shorted when the apparatus is unpowered.</div>
</li> <li> <para-num num="[0385]"> </para-num> <div class="description-line" id="p-0386" num="0385">Example B13 includes the subject matter of Example B12, and further specifies that individual joint assemblies include a drivetrain with a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0386]"> </para-num> <div class="description-line" id="p-0387" num="0386">Example B14 includes the subject matter of any of Examples B12-13, and further specifies that different ones of the joint assemblies are communicatively coupled by a Universal Serial Bus (USB) link, a Controller Area Network (CAN) link, or an RS-485 link.</div>
</li> <li> <para-num num="[0387]"> </para-num> <div class="description-line" id="p-0388" num="0387">Example B15 includes the subject matter of any of Examples B12-14, and further specifies that the apparatus includes at least three joint assemblies.</div>
</li> <li> <para-num num="[0388]"> </para-num> <div class="description-line" id="p-0389" num="0388">Example B16 includes the subject matter of Example B15, and further specifies that the apparatus includes at least six joint assemblies.</div>
</li> <li> <para-num num="[0389]"> </para-num> <div class="description-line" id="p-0390" num="0389">Example B17 includes the subject matter of any of Examples B1-16, and further specifies that the first segment includes a substantially cylindrical housing.</div>
</li> <li> <para-num num="[0390]"> </para-num> <div class="description-line" id="p-0391" num="0390">Example B18 includes the subject matter of Example B17, and further specifies that the second segment includes a substantially cylindrical housing.</div>
</li> <li> <para-num num="[0391]"> </para-num> <div class="description-line" id="p-0392" num="0391">Example B19 includes the subject matter of any of Examples B1-18, and further specifies that the apparatus includes an end effector.</div>
</li> <li> <para-num num="[0392]"> </para-num> <div class="description-line" id="p-0393" num="0392">Example B20 includes the subject matter of Example B19, and further specifies that the end effector includes at least one camera.</div>
</li> <li> <para-num num="[0393]"> </para-num> <div class="description-line" id="p-0394" num="0393">Example B21 includes the subject matter of any of Examples B19-20, and further specifies that the end effector includes at least one object manipulator.</div>
</li> <li> <para-num num="[0394]"> </para-num> <div class="description-line" id="p-0395" num="0394">Example B22 includes the subject matter of any of Examples B1-21, and further specifies that the joint assembly includes an accelerometer.</div>
</li> <li> <para-num num="[0395]"> </para-num> <div class="description-line" id="p-0396" num="0395">Example B23 includes the subject matter of any of Examples B1-22, and further specifies that the joint assembly includes one or more H-bridges electrically coupled to the stepper motor.</div>
</li> <li> <para-num num="[0396]"> </para-num> <div class="description-line" id="p-0397" num="0396">Example B24 includes the subject matter of any of Examples B1-23, and further specifies that the joint assembly includes a Universal Serial Bus (USB) hub or a Controller Area Network (CAN) port.</div>
</li> <li> <para-num num="[0397]"> </para-num> <div class="description-line" id="p-0398" num="0397">Example B25 includes the subject matter of any of Examples B1-24, and further specifies that the joint assembly includes one or more light-emitting diodes (LEDs).</div>
</li> <li> <para-num num="[0398]"> </para-num> <div class="description-line" id="p-0399" num="0398">Example B26 includes the subject matter of any of Examples B1-25, and further specifies that the joint assembly includes a processing device.</div>
</li> <li> <para-num num="[0399]"> </para-num> <div class="description-line" id="p-0400" num="0399">Example B27 includes the subject matter of any of Examples B1-26, and further specifies that the joint assembly is part of a robotic arm.</div>
</li> <li> <para-num num="[0400]"> </para-num> <div class="description-line" id="p-0401" num="0400">Example B28 includes the subject matter of any of Examples B1-26, and further specifies that the joint assembly is part of a robotic gantry.</div>
</li> <li> <para-num num="[0401]"> </para-num> <div class="description-line" id="p-0402" num="0401">Example B29 includes the subject matter of any of Examples B1-28, and further specifies that the apparatus is part of a product inspection system.</div>
</li> <li> <para-num num="[0402]"> </para-num> <div class="description-line" id="p-0403" num="0402">Example B30 is an apparatus for use in a robotic system, including: a processing device to identify a signal to brake a joint assembly, wherein the joint assembly is driven by a stepper motor, and in response to identification of the signal, cause a phase of the stepper motor to be shorted.</div>
</li> <li> <para-num num="[0403]"> </para-num> <div class="description-line" id="p-0404" num="0403">Example B31 includes the subject matter of Example B30, and further specifies that the joint assembly further includes a drivetrain, and the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0404]"> </para-num> <div class="description-line" id="p-0405" num="0404">Example B32 includes the subject matter of Example B31, and further specifies that the gear ratio is less than 25:1.</div>
</li> <li> <para-num num="[0405]"> </para-num> <div class="description-line" id="p-0406" num="0405">Example B33 includes the subject matter of Example B32, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0406]"> </para-num> <div class="description-line" id="p-0407" num="0406">Example B34 includes the subject matter of any of Examples B30-33, and further specifies that causing the phase to be shorted includes causing a mechanical relay to short the phase.</div>
</li> <li> <para-num num="[0407]"> </para-num> <div class="description-line" id="p-0408" num="0407">Example B35 includes the subject matter of any of Examples B30-33, and further specifies that causing the phase to be shorted includes causing a solid state relay to short the phase.</div>
</li> <li> <para-num num="[0408]"> </para-num> <div class="description-line" id="p-0409" num="0408">Example B36 includes the subject matter of any of Examples B30-33, and further specifies that causing the phase to be shorted includes causing an H-bridge to short the phase.</div>
</li> <li> <para-num num="[0409]"> </para-num> <div class="description-line" id="p-0410" num="0409">Example B37 includes the subject matter of any of Examples B30-36, and further specifies that the signal is generated in response to a fault condition.</div>
</li> <li> <para-num num="[0410]"> </para-num> <div class="description-line" id="p-0411" num="0410">Example B38 includes the subject matter of any of Examples B30-36, and further specifies that the signal is generated in response to a command to turn brakes on.</div>
</li> <li> <para-num num="[0411]"> </para-num> <div class="description-line" id="p-0412" num="0411">Example B39 includes the subject matter of any of Examples B30-36, and further specifies that the signal is generated in response to a command to turn motor drive off.</div>
</li> <li> <para-num num="[0412]"> </para-num> <div class="description-line" id="p-0413" num="0412">Example B40 includes the subject matter of any of Examples B30-37, and further specifies that the processing device is part of the joint assembly.</div>
</li> <li> <para-num num="[0413]"> </para-num> <div class="description-line" id="p-0414" num="0413">Example B41 includes the subject matter of any of Examples B30-40, and further specifies that the signal is a first signal, and the processing device is to: identify a second signal to stop braking the joint assembly; and in response to identification of the second signal, cause the phase to no longer be shorted.</div>
</li> <li> <para-num num="[0414]"> </para-num> <div class="description-line" id="p-0415" num="0414">Example B42 includes the subject matter of Example B41, and further specifies that the second signal is generated in response to a command to turn brakes off.</div>
</li> <li> <para-num num="[0415]"> </para-num> <div class="description-line" id="p-0416" num="0415">Example B43 includes the subject matter of Example B41, and further specifies that the second signal is generated in response to a command to turn motor drive on.</div>
</li> <li> <para-num num="[0416]"> </para-num> <div class="description-line" id="p-0417" num="0416">Example B44 includes the subject matter of any of Examples B41-43, and further specifies that the processing device is part of the joint assembly.</div>
</li> <li> <para-num num="[0417]"> </para-num> <div class="description-line" id="p-0418" num="0417">Example B45 includes the subject matter of any of Examples B30-44, and further specifies that the processing device is a first processing device, and the first processing device is to: receive the signal from a second processing device in communication with the first processing device via a communications bus.</div>
</li> <li> <para-num num="[0418]"> </para-num> <div class="description-line" id="p-0419" num="0418">Example B46 includes the subject matter of any of Examples B30-45, and further specifies that the joint assembly is part of a robotic arm.</div>
</li> <li> <para-num num="[0419]"> </para-num> <div class="description-line" id="p-0420" num="0419">Example B47 includes the subject matter of any of Examples B30-45, and further specifies that the joint assembly is part of a robotic gantry.</div>
</li> <li> <para-num num="[0420]"> </para-num> <div class="description-line" id="p-0421" num="0420">Example B48 includes the subject matter of any of Examples B30-47, and further specifies that the robotic system is a product inspection system.</div>
</li> <li> <para-num num="[0421]"> </para-num> <div class="description-line" id="p-0422" num="0421">Example B49 is an apparatus for use in a robotic system, including: a processing device to cause a phase of a stepper motor to be shorted to brake the stepper motor, and cause the phase of the stepper motor to not be shorted together to allow the stepper motor to move.</div>
</li> <li> <para-num num="[0422]"> </para-num> <div class="description-line" id="p-0423" num="0422">Example B50 includes the subject matter of Example B49, and further specifies that the gear ratio is less than 30:1.</div>
</li> <li> <para-num num="[0423]"> </para-num> <div class="description-line" id="p-0424" num="0423">Example B51 includes the subject matter of Example B50, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0424]"> </para-num> <div class="description-line" id="p-0425" num="0424">Example B52 includes the subject matter of any of Examples B49-50, and further specifies that causing the phase to be shorted includes causing a mechanical relay to short the phase.</div>
</li> <li> <para-num num="[0425]"> </para-num> <div class="description-line" id="p-0426" num="0425">Example B53 includes the subject matter of any of Examples B49-50, and further specifies that causing the phase to be shorted includes causing a solid state relay to short the phase.</div>
</li> <li> <para-num num="[0426]"> </para-num> <div class="description-line" id="p-0427" num="0426">Example B54 includes the subject matter of any of Examples B49-50, and further specifies that causing the phase to be shorted includes causing an H-bridge to short the phase.</div>
</li> <li> <para-num num="[0427]"> </para-num> <div class="description-line" id="p-0428" num="0427">Example B55 includes the subject matter of any of Examples B49-54, and further specifies that shorting the phase of the stepper motor is caused in response to a fault condition.</div>
</li> <li> <para-num num="[0428]"> </para-num> <div class="description-line" id="p-0429" num="0428">Example B56 includes the subject matter of any of Examples B49-54, and further specifies that shorting the phase of the stepper motor is caused in response to a command to turn brakes on.</div>
</li> <li> <para-num num="[0429]"> </para-num> <div class="description-line" id="p-0430" num="0429">Example B57 includes the subject matter of any of Examples B49-54, and further specifies that shorting the phase of the stepper motor is caused in response to a command to turn motor drive off.</div>
</li> <li> <para-num num="[0430]"> </para-num> <div class="description-line" id="p-0431" num="0430">Example B58 includes the subject matter of any of Examples B49-57, and further specifies that causing the phase of the stepper motor to not be shorted is performed in response to a command to turn brakes off.</div>
</li> <li> <para-num num="[0431]"> </para-num> <div class="description-line" id="p-0432" num="0431">Example B59 includes the subject matter of any of Examples B49-57, and further specifies that causing the phase of the stepper motor to not be shorted is performed in response to a command to turn motor drive on.</div>
</li> <li> <para-num num="[0432]"> </para-num> <div class="description-line" id="p-0433" num="0432">Example B60 includes the subject matter of any of Examples B49-59, and further specifies that the stepper motor is part of a robotic arm.</div>
</li> <li> <para-num num="[0433]"> </para-num> <div class="description-line" id="p-0434" num="0433">Example B61 includes the subject matter of any of Examples B49-60, and further specifies that the stepper motor is part of a robotic gantry.</div>
</li> <li> <para-num num="[0434]"> </para-num> <div class="description-line" id="p-0435" num="0434">Example B62 includes the subject matter of any of Examples B49-61, and further specifies that the robotic system is a product inspection system.</div>
</li> <li> <para-num num="[0435]"> </para-num> <div class="description-line" id="p-0436" num="0435">Example B63 is a method of braking a joint assembly of a robotic apparatus, including: identifying a signal to brake the joint assembly, wherein the joint assembly is driven by a stepper motor; and in response to identification of the signal, causing a phase of the stepper motor to be shorted.</div>
</li> <li> <para-num num="[0436]"> </para-num> <div class="description-line" id="p-0437" num="0436">Example B64 includes the subject matter of Example B63, and further specifies that the joint assembly further includes a drivetrain, and the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0437]"> </para-num> <div class="description-line" id="p-0438" num="0437">Example B65 includes the subject matter of Example B64, and further specifies that the gear ratio is less than 50:1.</div>
</li> <li> <para-num num="[0438]"> </para-num> <div class="description-line" id="p-0439" num="0438">Example B66 includes the subject matter of Example B65, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0439]"> </para-num> <div class="description-line" id="p-0440" num="0439">Example B67 includes the subject matter of any of Examples B63-66, and further specifies that causing the phase to be shorted includes causing a mechanical relays to short the phase.</div>
</li> <li> <para-num num="[0440]"> </para-num> <div class="description-line" id="p-0441" num="0440">Example B68 includes the subject matter of any of Examples B63-66, and further specifies that causing the phase to be shorted includes causing a solid state relay to short the phase.</div>
</li> <li> <para-num num="[0441]"> </para-num> <div class="description-line" id="p-0442" num="0441">Example B69 includes the subject matter of any of Examples B63-66, and further specifies that causing the phase to be shorted includes causing an H-bridge to short the phase.</div>
</li> <li> <para-num num="[0442]"> </para-num> <div class="description-line" id="p-0443" num="0442">Example B70 includes the subject matter of any of Examples B63-69, and further specifies that the signal is generated in response to a fault condition.</div>
</li> <li> <para-num num="[0443]"> </para-num> <div class="description-line" id="p-0444" num="0443">Example B71 includes the subject matter of any of Examples B63-69, and further specifies that the signal is generated in response to a command to turn brakes on.</div>
</li> <li> <para-num num="[0444]"> </para-num> <div class="description-line" id="p-0445" num="0444">Example B72 includes the subject matter of any of Examples B63-69, and further specifies that the signal is generated in response to a command to turn motor drive off.</div>
</li> <li> <para-num num="[0445]"> </para-num> <div class="description-line" id="p-0446" num="0445">Example B73 includes the subject matter of any of Examples B63-72, and further specifies that a processing device in the joint assembly generates the signal and causes the phase to be shorted.</div>
</li> <li> <para-num num="[0446]"> </para-num> <div class="description-line" id="p-0447" num="0446">Example B74 includes the subject matter of any of Examples B63-73, and further specifies that the signal is a first signal, and the method further includes: identifying a second signal to stop braking the joint assembly of the robotic apparatus; and in response to identification of the second signal, causing the phase to no longer be shorted.</div>
</li> <li> <para-num num="[0447]"> </para-num> <div class="description-line" id="p-0448" num="0447">Example B75 includes the subject matter of Example B74, and further specifies that the second signal is generated in response to a command to turn brakes off.</div>
</li> <li> <para-num num="[0448]"> </para-num> <div class="description-line" id="p-0449" num="0448">Example B76 includes the subject matter of Example B74, and further specifies that the second signal is generated in response to a command to turn motor drive on.</div>
</li> <li> <para-num num="[0449]"> </para-num> <div class="description-line" id="p-0450" num="0449">Example B77 includes the subject matter of any of Examples B74-76, and further specifies that a processing device in the joint assembly generates the second signal and causes the phase to no longer be shorted.</div>
</li> <li> <para-num num="[0450]"> </para-num> <div class="description-line" id="p-0451" num="0450">Example B78 includes the subject matter of any of Examples B63-77, and further specifies that a first processing device in the joint assembly causes the phase to be shorted, and the method further includes: receiving the signal from a second processing device in communication with the first processing device via a communications bus.</div>
</li> <li> <para-num num="[0451]"> </para-num> <div class="description-line" id="p-0452" num="0451">Example B79 includes the subject matter of any of Examples B63-78, and further specifies that the robotic apparatus includes a robotic arm.</div>
</li> <li> <para-num num="[0452]"> </para-num> <div class="description-line" id="p-0453" num="0452">Example B80 includes the subject matter of any of Examples B63-78, and further specifies that the robotic apparatus includes a robotic gantry.</div>
</li> <li> <para-num num="[0453]"> </para-num> <div class="description-line" id="p-0454" num="0453">Example B81 includes the subject matter of any of Examples B63-80, and further specifies that the robotic apparatus is part of a product inspection system.</div>
</li> <li> <para-num num="[0454]"> </para-num> <div class="description-line" id="p-0455" num="0454">Example B82 is a method of controlling a stepper motor in a robotic system, including: causing a phase of a stepper motor to be shorted to brake the stepper motor; and causing the phase of the stepper motor to not be shorted to allow the stepper motor to move.</div>
</li> <li> <para-num num="[0455]"> </para-num> <div class="description-line" id="p-0456" num="0455">Example B83 includes the subject matter of Example B82, and further specifies that the gear ratio is less than 30:1.</div>
</li> <li> <para-num num="[0456]"> </para-num> <div class="description-line" id="p-0457" num="0456">Example B84 includes the subject matter of Example B83, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0457]"> </para-num> <div class="description-line" id="p-0458" num="0457">Example B85 includes the subject matter of any of Examples B82-84, and further specifies that causing the phase to be shorted includes causing a mechanical relay to short the phase.</div>
</li> <li> <para-num num="[0458]"> </para-num> <div class="description-line" id="p-0459" num="0458">Example B86 includes the subject matter of any of Examples B82-84, and further specifies that causing the phase to be shorted includes causing a solid state relay to short the phase.</div>
</li> <li> <para-num num="[0459]"> </para-num> <div class="description-line" id="p-0460" num="0459">Example B87 includes the subject matter of any of Examples B82-84, and further specifies that causing the two leads for each phase to be shorted includes causing an H-bridge to short the phase.</div>
</li> <li> <para-num num="[0460]"> </para-num> <div class="description-line" id="p-0461" num="0460">Example B88 includes the subject matter of any of Examples B82-87, and further specifies that the shorting of the phase of the stepper motor is caused in response to a fault condition.</div>
</li> <li> <para-num num="[0461]"> </para-num> <div class="description-line" id="p-0462" num="0461">Example B89 includes the subject matter of any of Examples B82-87, and further specifies that the shorting of the phase of the stepper motor is caused in response to a command to turn brakes on.</div>
</li> <li> <para-num num="[0462]"> </para-num> <div class="description-line" id="p-0463" num="0462">Example B90 includes the subject matter of any of Examples B82-87, and further specifies that the shorting of the phase of the stepper motor is caused in response to a command to turn motor drive off.</div>
</li> <li> <para-num num="[0463]"> </para-num> <div class="description-line" id="p-0464" num="0463">Example B91 includes the subject matter of any of Examples B82-90, and further specifies that causing the phase of the stepper motor to not be shorted is performed in response to a command to turn brakes off.</div>
</li> <li> <para-num num="[0464]"> </para-num> <div class="description-line" id="p-0465" num="0464">Example B92 includes the subject matter of any of Examples B82-90, and further specifies that causing the phase of the stepper motor to not be shorted is performed in response to a command to turn motor drive on.</div>
</li> <li> <para-num num="[0465]"> </para-num> <div class="description-line" id="p-0466" num="0465">Example B93 includes the subject matter of any of Examples B82-92, and further specifies that the stepper motor is part of a robotic arm.</div>
</li> <li> <para-num num="[0466]"> </para-num> <div class="description-line" id="p-0467" num="0466">Example B94 includes the subject matter of any of Examples B82-92, and further specifies that the stepper motor is part of a robotic gantry.</div>
</li> <li> <para-num num="[0467]"> </para-num> <div class="description-line" id="p-0468" num="0467">Example B95 includes the subject matter of any of Examples B82-94, and further specifies that the apparatus is part of a product inspection system.</div>
</li> <li> <para-num num="[0468]"> </para-num> <div class="description-line" id="p-0469" num="0468">Example B96 is one or more computer readable media having instructions thereon that, when executed by one or more processing devices of a computing system, cause the computing system to perform any of the methods of Examples B63-95.</div>
</li> <li> <para-num num="[0469]"> </para-num> <div class="description-line" id="p-0470" num="0469">Example B97 is an apparatus for collaborative robotics, including means for performing any of the methods of Examples B63-95.</div>
</li> <li> <para-num num="[0470]"> </para-num> <div class="description-line" id="p-0471" num="0470">Example C1 is an apparatus for collaborative robotics, including: a first segment; a second segment; and a joint assembly, wherein the joint assembly includes a processing device and a stepper motor, the stepper motor is to control a relative position of the first and second segments, the processing device is to perform closed-loop control of the stepper motor and monitor one or more performance metrics, and the processing device is to cause drive of the stepper motor to cease when a value of at least one of the performance metrics is outside an allowable range.</div>
</li> <li> <para-num num="[0471]"> </para-num> <div class="description-line" id="p-0472" num="0471">Example C2 includes the subject matter of Example C1, and further specifies that the joint assembly includes a drivetrain coupled to the stepper motor, and the drivetrain has a gear ratio that is less than 30:1. Example C3 includes the subject matter of Example C2, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0472]"> </para-num> <div class="description-line" id="p-0473" num="0472">Example C4 includes the subject matter of any of Examples C1-3, and further specifies that the one or more performance metrics include joint position, joint velocity, joint acceleration, motor current, joint temperature, an error in a control loop, joint accelerometer data, or joint gyroscope data.</div>
</li> <li> <para-num num="[0473]"> </para-num> <div class="description-line" id="p-0474" num="0473">Example C5 includes the subject matter of Example C4, and further specifies that the one or more performance metrics include a combination of joint position, joint velocity, motor current, joint temperature, an error in a control loop, joint accelerometer data, or joint gyroscope data.</div>
</li> <li> <para-num num="[0474]"> </para-num> <div class="description-line" id="p-0475" num="0474">Example C6 includes the subject matter of any of Examples C1-5, and further specifies that the allowable range is updateable during movement of the joint assembly.</div>
</li> <li> <para-num num="[0475]"> </para-num> <div class="description-line" id="p-0476" num="0475">Example C7 includes the subject matter of any of Examples C1-5, and further specifies that the allowable range is stored in a Flash memory of the joint assembly.</div>
</li> <li> <para-num num="[0476]"> </para-num> <div class="description-line" id="p-0477" num="0476">Example C8 includes the subject matter of any of Examples C1-7, and further specifies that the allowable range includes a minimum allowable value or a maximum allowable value.</div>
</li> <li> <para-num num="[0477]"> </para-num> <div class="description-line" id="p-0478" num="0477">Example C9 includes the subject matter of any of Examples C1-8, and further specifies that the value of the at least one of the performance metrics is compared to the allowable range at a frequency equal to a frequency of execution of a control loop.</div>
</li> <li> <para-num num="[0478]"> </para-num> <div class="description-line" id="p-0479" num="0478">Example 010 includes the subject matter of any of Examples C1-9, and further specifies that the joint assembly is one of a plurality of joint assemblies of the apparatus, and individual ones of the joint assemblies include a processing device and a stepper motor, the processing device of an individual joint assembly is to perform closed-loop control of the stepper motor of the individual joint assembly and monitor one or more performance metrics of the individual joint assembly, and the processing device of the individual joint assembly is to cause drive of the stepper motor of the individual joint assembly to cease when a value of at least one of the performance metrics is outside an allowable range.</div>
</li> <li> <para-num num="[0479]"> </para-num> <div class="description-line" id="p-0480" num="0479">Example C11 includes the subject matter of Example C10, and further specifies that different ones of the joint assemblies are to monitor one or more performance metrics of the associated joint assembly independently of other joint assemblies.</div>
</li> <li> <para-num num="[0480]"> </para-num> <div class="description-line" id="p-0481" num="0480">Example C12 includes the subject matter of any of Examples 010-11, and further specifies that individual ones of the joint assemblies include a drivetrain with a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0481]"> </para-num> <div class="description-line" id="p-0482" num="0481">Example C13 includes the subject matter of any of Examples 010-12, and further specifies that different ones of the joint assemblies are communicatively coupled by a Universal Serial Bus (USB) link, a Controller Area Network (CAN) link, or an RS-485 link.</div>
</li> <li> <para-num num="[0482]"> </para-num> <div class="description-line" id="p-0483" num="0482">Example C14 includes the subject matter of any of Examples 010-13, and further specifies that the apparatus includes at least three joint assemblies.</div>
</li> <li> <para-num num="[0483]"> </para-num> <div class="description-line" id="p-0484" num="0483">Example C15 includes the subject matter of Example C14, and further specifies that the apparatus includes at least six joint assemblies.</div>
</li> <li> <para-num num="[0484]"> </para-num> <div class="description-line" id="p-0485" num="0484">Example C16 includes the subject matter of any of Examples C1-15, and further specifies that the joint assembly further includes an angle encoder to detect an angular position of a shaft of the stepper motor.</div>
</li> <li> <para-num num="[0485]"> </para-num> <div class="description-line" id="p-0486" num="0485">Example C17 includes the subject matter of Example C16, and further specifies that the angle encoder is contactless.</div>
</li> <li> <para-num num="[0486]"> </para-num> <div class="description-line" id="p-0487" num="0486">Example C18 includes the subject matter of any of Examples C16-17, and further specifies that the angle encoder is magnetic.</div>
</li> <li> <para-num num="[0487]"> </para-num> <div class="description-line" id="p-0488" num="0487">Example C19 includes the subject matter of any of Examples C16-18, and further specifies that a diametric magnet is at an end of the shaft of the stepper motor, proximate to the angle encoder.</div>
</li> <li> <para-num num="[0488]"> </para-num> <div class="description-line" id="p-0489" num="0488">Example C20 includes the subject matter of any of Examples C16-19, and further specifies that the angle encoder is spaced away from the shaft of the stepper motor.</div>
</li> <li> <para-num num="[0489]"> </para-num> <div class="description-line" id="p-0490" num="0489">Example C21 includes the subject matter of any of Examples C1-20, and further specifies that the apparatus does not include a joint encoder for the joint assembly.</div>
</li> <li> <para-num num="[0490]"> </para-num> <div class="description-line" id="p-0491" num="0490">Example C22 includes the subject matter of any of Examples C1-21, and further specifies that the first segment includes a substantially cylindrical housing.</div>
</li> <li> <para-num num="[0491]"> </para-num> <div class="description-line" id="p-0492" num="0491">Example C23 includes the subject matter of Example C22, and further specifies that the second segment includes a substantially cylindrical housing.</div>
</li> <li> <para-num num="[0492]"> </para-num> <div class="description-line" id="p-0493" num="0492">Example C24 includes the subject matter of any of Examples C1-23, and further specifies that the apparatus includes an end effector.</div>
</li> <li> <para-num num="[0493]"> </para-num> <div class="description-line" id="p-0494" num="0493">Example C25 includes the subject matter of Example C24, and further specifies that the end effector includes at least one camera.</div>
</li> <li> <para-num num="[0494]"> </para-num> <div class="description-line" id="p-0495" num="0494">Example C26 includes the subject matter of any of Examples C24-25, and further specifies that the end effector includes at least one object manipulator.</div>
</li> <li> <para-num num="[0495]"> </para-num> <div class="description-line" id="p-0496" num="0495">Example C27 includes the subject matter of any of Examples C1-26, and further specifies that the joint assembly includes an accelerometer.</div>
</li> <li> <para-num num="[0496]"> </para-num> <div class="description-line" id="p-0497" num="0496">Example C28 includes the subject matter of any of Examples C1-27, and further specifies that the joint assembly includes one or more H-bridges electrically coupled to the stepper motor.</div>
</li> <li> <para-num num="[0497]"> </para-num> <div class="description-line" id="p-0498" num="0497">Example C29 includes the subject matter of any of Examples C1-27, and further specifies that the joint assembly includes a Universal Serial Bus (USB) hub or a Controller Area Network (CAN) port.</div>
</li> <li> <para-num num="[0498]"> </para-num> <div class="description-line" id="p-0499" num="0498">Example C30 includes the subject matter of any of Examples C1-29, and further specifies that the joint assembly includes one or more light-emitting diodes (LEDs).</div>
</li> <li> <para-num num="[0499]"> </para-num> <div class="description-line" id="p-0500" num="0499">Example C31 includes the subject matter of any of Examples C1-30, and further specifies that the joint assembly includes a processing device.</div>
</li> <li> <para-num num="[0500]"> </para-num> <div class="description-line" id="p-0501" num="0500">Example C32 includes the subject matter of any of Examples C1-31, and further specifies that the joint assembly is part of a robotic arm.</div>
</li> <li> <para-num num="[0501]"> </para-num> <div class="description-line" id="p-0502" num="0501">Example C33 includes the subject matter of any of Examples C1-31, and further specifies that the joint assembly is part of a robotic gantry.</div>
</li> <li> <para-num num="[0502]"> </para-num> <div class="description-line" id="p-0503" num="0502">Example C34 includes the subject matter of any of Examples C1-33, and further specifies that the apparatus is part of a product inspection system.</div>
</li> <li> <para-num num="[0503]"> </para-num> <div class="description-line" id="p-0504" num="0503">Example C35 includes the subject matter of any of Examples C1-34, and further specifies that the processing device is to cause braking of the stepper motor when the value of at least one of the performance metrics is outside the allowable range, and causing braking of the stepper motor includes shorting a phase of the stepper motor.</div>
</li> <li> <para-num num="[0504]"> </para-num> <div class="description-line" id="p-0505" num="0504">Example C36 is an apparatus for robotic control, including: a processing device to identify a trajectory through which to run a robotic apparatus, wherein the robotic apparatus includes one or more joints, cause the robotic apparatus to run through the trajectory, receive data indicative of performance metrics of the one or more joints while the robotic apparatus is running through the trajectory, generate a computational model mapping a time index of the trajectory to the received data, and identify one or more fault conditions for a difference between the computational model and performance of the robotic apparatus.</div>
</li> <li> <para-num num="[0505]"> </para-num> <div class="description-line" id="p-0506" num="0505">Example C37 includes the subject matter of Example C36, and further specifies that the one or more performance metrics include joint position, joint velocity, joint acceleration, motor current, joint temperature, an error in a control loop, joint accelerometer data, or joint gyroscope data.</div>
</li> <li> <para-num num="[0506]"> </para-num> <div class="description-line" id="p-0507" num="0506">Example C38 includes the subject matter of any of Examples C36-37, and further specifies that the processing device is a first processing device, the first processing device is to receive the data indicative of performance metrics from one or more second processing devices via a communications bus, and individual ones of the second processing devices are associated with individual ones of the one or more joints.</div>
</li> <li> <para-num num="[0507]"> </para-num> <div class="description-line" id="p-0508" num="0507">Example C39 includes the subject matter of Example C38, and further specifies that the communications bus is a Universal Serial Bus (USB) or a Controller Area Network (CAN).</div>
</li> <li> <para-num num="[0508]"> </para-num> <div class="description-line" id="p-0509" num="0508">Example C40 includes the subject matter of any of Examples C36-39, and further specifies that the trajectory is specified by a user via a Graphical User Interface (GUI) or by an Application Programming Interface (API).</div>
</li> <li> <para-num num="[0509]"> </para-num> <div class="description-line" id="p-0510" num="0509">Example C41 includes the subject matter of any of Examples C36-39, and further specifies that the trajectory is recorded during manual manipulation of the robotic apparatus by a user.</div>
</li> <li> <para-num num="[0510]"> </para-num> <div class="description-line" id="p-0511" num="0510">Example C42 includes the subject matter of any of Examples C36-41, and further specifies that the computational model is a principal component model, a linear regression model, a polynomial regression model, or a deep learning model.</div>
</li> <li> <para-num num="[0511]"> </para-num> <div class="description-line" id="p-0512" num="0511">Example C43 includes the subject matter of any of Examples C36-42, and further specifies that the one or more fault conditions are specified as a percentage deviation from the computational model.</div>
</li> <li> <para-num num="[0512]"> </para-num> <div class="description-line" id="p-0513" num="0512">Example C44 includes the subject matter of any of Examples C36-43, and further specifies that the processing device is to: in response to detection of a fault condition during operation of the robotic apparatus, cause movement of the robotic apparatus to cease.</div>
</li> <li> <para-num num="[0513]"> </para-num> <div class="description-line" id="p-0514" num="0513">Example C45 includes the subject matter of Example C44, and further specifies that causing movement of the robotic apparatus to cease includes causing shorting of a phase of a stepper motor associated with at least one of the joints.</div>
</li> <li> <para-num num="[0514]"> </para-num> <div class="description-line" id="p-0515" num="0514">Example C46 includes the subject matter of any of Examples C36-45, and further specifies that individual ones of the joints include a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0515]"> </para-num> <div class="description-line" id="p-0516" num="0515">Example C47 includes the subject matter of Example C46, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0516]"> </para-num> <div class="description-line" id="p-0517" num="0516">Example C48 includes the subject matter of Example C47, and further specifies that the drivetrain has a gear ratio that is less than 20:1.</div>
</li> <li> <para-num num="[0517]"> </para-num> <div class="description-line" id="p-0518" num="0517">Example C49 includes the subject matter of any of Examples C36-48, and further specifies that individual ones of the joints include an angle encoder to monitor angular position of a shaft of a stepper motor of the joint.</div>
</li> <li> <para-num num="[0518]"> </para-num> <div class="description-line" id="p-0519" num="0518">Example C50 includes the subject matter of any of Examples C36-49, and further specifies that the robotic apparatus includes a robotic arm.</div>
</li> <li> <para-num num="[0519]"> </para-num> <div class="description-line" id="p-0520" num="0519">Example C51 includes the subject matter of any of Examples C36-49, and further specifies that the robotic apparatus includes a robotic gantry.</div>
</li> <li> <para-num num="[0520]"> </para-num> <div class="description-line" id="p-0521" num="0520">Example C52 includes the subject matter of any of Examples C36-51, and further specifies that the robotic apparatus is part of a product inspection system.</div>
</li> <li> <para-num num="[0521]"> </para-num> <div class="description-line" id="p-0522" num="0521">Example C53 includes the subject matter of any of Examples C36-52, and further specifies that identify one or more fault conditions includes store one or more fault conditions in a memory.</div>
</li> <li> <para-num num="[0522]"> </para-num> <div class="description-line" id="p-0523" num="0522">Example C54 includes the subject matter of any of Examples C36-53, and further specifies that the processing device is in a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0523]"> </para-num> <div class="description-line" id="p-0524" num="0523">Example C55 includes the subject matter of any of Examples C36-53, and further specifies that the processing device has a housing separate from a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0524]"> </para-num> <div class="description-line" id="p-0525" num="0524">Example C56 includes the subject matter of any of Examples C36-55, and further specifies that the processing device is part of a desktop computing device, a laptop computing device, or a tablet computing device.</div>
</li> <li> <para-num num="[0525]"> </para-num> <div class="description-line" id="p-0526" num="0525">Example C57 includes the subject matter of any of Examples C36-56, and further includes: the robotic apparatus.</div>
</li> <li> <para-num num="[0526]"> </para-num> <div class="description-line" id="p-0527" num="0526">Example C58 includes the subject matter of any of Examples C36-57, and further specifies that the processing device is to communicate with the robotic apparatus via a Universal Serial Bus (USB) or a Controller Area Network (CAN).</div>
</li> <li> <para-num num="[0527]"> </para-num> <div class="description-line" id="p-0528" num="0527">Example C59 is a method of operating a stepper motor in a joint assembly of a robotic apparatus, including: performing closed-loop control of the stepper motor; monitoring one or more performance metrics of the joint assembly; and causing braking of the stepper motor when a value of at least one of the performance metrics is outside an allowable range.</div>
</li> <li> <para-num num="[0528]"> </para-num> <div class="description-line" id="p-0529" num="0528">Example C60 includes the subject matter of Example C59, and further specifies that the joint assembly includes a drivetrain coupled to the stepper motor, and the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0529]"> </para-num> <div class="description-line" id="p-0530" num="0529">Example C61 includes the subject matter of Example C60, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0530]"> </para-num> <div class="description-line" id="p-0531" num="0530">Example C62 includes the subject matter of any of Examples C59-61, and further specifies that the one or more performance metrics include joint position, joint velocity, joint acceleration, motor current, joint temperature, an error in a control loop, joint accelerometer data, or joint gyroscope data.</div>
</li> <li> <para-num num="[0531]"> </para-num> <div class="description-line" id="p-0532" num="0531">Example C63 includes the subject matter of Example C62, and further specifies that the one or more performance metrics include a combination of joint position, joint velocity, motor current, joint temperature, an error in a control loop, joint accelerometer data, or joint gyroscope data.</div>
</li> <li> <para-num num="[0532]"> </para-num> <div class="description-line" id="p-0533" num="0532">Example C64 includes the subject matter of any of Examples C59-63, and further specifies that the allowable range is updateable during movement of the joint assembly.</div>
</li> <li> <para-num num="[0533]"> </para-num> <div class="description-line" id="p-0534" num="0533">Example C65 includes the subject matter of any of Examples C59-63, and further specifies that the allowable range is stored in a Flash memory of the joint assembly.</div>
</li> <li> <para-num num="[0534]"> </para-num> <div class="description-line" id="p-0535" num="0534">Example C66 includes the subject matter of any of Examples C59-65, and further specifies that the allowable range includes a minimum allowable value or a maximum allowable value.</div>
</li> <li> <para-num num="[0535]"> </para-num> <div class="description-line" id="p-0536" num="0535">Example C67 includes the subject matter of any of Examples C59-66, and further specifies that the value of the at least one of the performance metrics is compared to the allowable range at a frequency equal to a frequency of execution of a control loop.</div>
</li> <li> <para-num num="[0536]"> </para-num> <div class="description-line" id="p-0537" num="0536">Example C68 includes the subject matter of any of Examples C59-67, and further specifies that the joint assembly is part of a robotic arm.</div>
</li> <li> <para-num num="[0537]"> </para-num> <div class="description-line" id="p-0538" num="0537">Example C69 includes the subject matter of any of Examples C59-67, and further specifies that the joint assembly is part of a robotic gantry.</div>
</li> <li> <para-num num="[0538]"> </para-num> <div class="description-line" id="p-0539" num="0538">Example C70 includes the subject matter of any of Examples C59-69, and further specifies that the apparatus is part of a product inspection system.</div>
</li> <li> <para-num num="[0539]"> </para-num> <div class="description-line" id="p-0540" num="0539">Example C71 includes the subject matter of any of Examples C59-70, and further specifies that causing braking of the stepper motor includes causing shorting of a phase of the stepper motor.</div>
</li> <li> <para-num num="[0540]"> </para-num> <div class="description-line" id="p-0541" num="0540">Example C72 is a method for generating fault conditions for a robotic apparatus, including: identifying a trajectory through which to run the robotic apparatus, wherein the robotic apparatus includes one or more joints, causing the robotic apparatus to run through the trajectory, receiving data indicative of performance metrics of the one or more joints while the robotic apparatus is running through the trajectory, generating a computational model mapping a time index of the trajectory to the received data, and identifying one or more fault conditions for a difference between the computational model and performance of the robotic apparatus.</div>
</li> <li> <para-num num="[0541]"> </para-num> <div class="description-line" id="p-0542" num="0541">Example C73 includes the subject matter of Example C72, and further specifies that the one or more performance metrics include joint position, joint velocity, joint acceleration, motor current, joint temperature, an error in a control loop, joint accelerometer data, or joint gyroscope data.</div>
</li> <li> <para-num num="[0542]"> </para-num> <div class="description-line" id="p-0543" num="0542">Example C74 includes the subject matter of any of Examples C72-73, and further specifies that the receiving the data indicative of performance metrics includes receiving the data indicative of performance metrics from one or more processing devices via a communications bus, and individual ones of the processing devices are associated with individual ones of the one or more joints.</div>
</li> <li> <para-num num="[0543]"> </para-num> <div class="description-line" id="p-0544" num="0543">Example C75 includes the subject matter of Example C74, and further specifies that the communications bus is a Universal Serial Bus (USB) or a Controller Area Network (CAN).</div>
</li> <li> <para-num num="[0544]"> </para-num> <div class="description-line" id="p-0545" num="0544">Example C76 includes the subject matter of any of Examples C72-75, and further specifies that the trajectory is specified by a user via a Graphical User Interface (GUI) or an Application Programming Interface (API).</div>
</li> <li> <para-num num="[0545]"> </para-num> <div class="description-line" id="p-0546" num="0545">Example C77 includes the subject matter of any of Examples C72-75, and further specifies that the trajectory is recorded during manual manipulation of the robotic apparatus by a user.</div>
</li> <li> <para-num num="[0546]"> </para-num> <div class="description-line" id="p-0547" num="0546">Example C78 includes the subject matter of any of Examples C72-77, and further specifies that the computational model is a principal component model, a linear regression model, a polynomial regression model, or a deep learning model.</div>
</li> <li> <para-num num="[0547]"> </para-num> <div class="description-line" id="p-0548" num="0547">Example C79 includes the subject matter of any of Examples C72-78, and further specifies that the one or more fault conditions are specified as a percentage deviation from the computational model.</div>
</li> <li> <para-num num="[0548]"> </para-num> <div class="description-line" id="p-0549" num="0548">Example C80 includes the subject matter of any of Examples C72-79, and further includes: in response to detection of a fault condition during operation of the robotic apparatus, causing movement of the robotic apparatus to cease.</div>
</li> <li> <para-num num="[0549]"> </para-num> <div class="description-line" id="p-0550" num="0549">Example C81 includes the subject matter of any of Examples C72-79, and further specifies that causing movement of the robotic apparatus to cease includes causing shorting of a phase of a stepper motor associated with least one of the joints.</div>
</li> <li> <para-num num="[0550]"> </para-num> <div class="description-line" id="p-0551" num="0550">Example C82 includes the subject matter of any of Examples C72-81, and further specifies that individual ones of the joints include a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0551]"> </para-num> <div class="description-line" id="p-0552" num="0551">Example C83 includes the subject matter of Example C82, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0552]"> </para-num> <div class="description-line" id="p-0553" num="0552">Example C84 includes the subject matter of Example C83, and further specifies that the drivetrain has a gear ratio that is less than 20:1.</div>
</li> <li> <para-num num="[0553]"> </para-num> <div class="description-line" id="p-0554" num="0553">Example C85 includes the subject matter of any of Examples C72-84, and further specifies that individual ones of the joints include an angle encoder to monitor angular position of a shaft of a stepper motor of the joint.</div>
</li> <li> <para-num num="[0554]"> </para-num> <div class="description-line" id="p-0555" num="0554">Example C86 includes the subject matter of any of Examples C72-85, and further specifies that the robotic apparatus includes a robotic arm.</div>
</li> <li> <para-num num="[0555]"> </para-num> <div class="description-line" id="p-0556" num="0555">Example C87 includes the subject matter of any of Examples C72-85, and further specifies that the robotic apparatus includes a robotic gantry.</div>
</li> <li> <para-num num="[0556]"> </para-num> <div class="description-line" id="p-0557" num="0556">Example C88 includes the subject matter of any of Examples C72-87, and further specifies that the robotic apparatus is part of a product inspection system.</div>
</li> <li> <para-num num="[0557]"> </para-num> <div class="description-line" id="p-0558" num="0557">Example C89 includes the subject matter of any of Examples C72-88, and further specifies that identifying one or more fault conditions includes storing one or more fault conditions in a memory.</div>
</li> <li> <para-num num="[0558]"> </para-num> <div class="description-line" id="p-0559" num="0558">Example C90 includes the subject matter of any of Examples C72-89, and further specifies that the method is performed by a processing device, and the processing device is part of a desktop computing device, a laptop computing device, or a tablet computing device.</div>
</li> <li> <para-num num="[0559]"> </para-num> <div class="description-line" id="p-0560" num="0559">Example C91 is one or more computer readable media having instructions thereon that, when executed by one or more processing devices of a computing system, cause the computing system to perform any of the methods of Examples C59-90.</div>
</li> <li> <para-num num="[0560]"> </para-num> <div class="description-line" id="p-0561" num="0560">Example C92 is an apparatus for collaborative robotics, including means for performing any of the methods of Examples C59-90.</div>
</li> <li> <para-num num="[0561]"> </para-num> <div class="description-line" id="p-0562" num="0561">Example D1 is an apparatus for robotic zeroing, including: a processing device to perform a joint zeroing operation on a first joint assembly of a robotic apparatus, wherein the joint zeroing operation includes determining a reference vector for zeroing the first joint assembly, wherein the first joint assembly is mechanically coupled to a support of the robotic apparatus, identifying an acceleration vector representative of an orientation of a second joint assembly of the robotic apparatus, wherein the first joint assembly is mechanically between the support and the second joint assembly determining whether the acceleration vector is aligned with the reference vector, and in response to a determination that the acceleration vector is not aligned with the reference vector, causing the first joint assembly to move.</div>
</li> <li> <para-num num="[0562]"> </para-num> <div class="description-line" id="p-0563" num="0562">Example D2 includes the subject matter of Example D1, and further specifies that the joint zeroing operation further includes: before determining whether the acceleration vector is aligned with the reference vector, determining whether a third joint assembly is to be moved away from its zeroed position prior to identification of the acceleration vector representative of the orientation of the second joint assembly, wherein the first joint assembly is mechanically between the third joint assembly and the second joint assembly; and in response to the determination that the third joint assembly is to be moved away from its zeroed position, causing the third joint assembly to move to a predetermined position prior to identification of the acceleration vector representative of the orientation of the second joint assembly.</div>
</li> <li> <para-num num="[0563]"> </para-num> <div class="description-line" id="p-0564" num="0563">Example D3 includes the subject matter of Example D2, and further specifies that the predetermined position is 90 degrees away from the zeroed position of the third joint assembly.</div>
</li> <li> <para-num num="[0564]"> </para-num> <div class="description-line" id="p-0565" num="0564">Example D4 includes the subject matter of any of Examples D2-3, and further specifies that the joint zeroing operation further includes: after causing a third joint assembly to move to the predetermined position, determining whether the acceleration vector is aligned with reference vector, and in response to determination that the acceleration vector is aligned with the reference vector, maintaining the first joint assembly in its current position and cause the third joint assembly to be moved to its zeroed position.</div>
</li> <li> <para-num num="[0565]"> </para-num> <div class="description-line" id="p-0566" num="0565">Example D5 includes the subject matter of any of Examples D1-4, and further specifies that the joint zeroing operation further includes: in response to a determination that the acceleration vector is aligned with the reference vector, maintaining the first joint assembly in its current position.</div>
</li> <li> <para-num num="[0566]"> </para-num> <div class="description-line" id="p-0567" num="0566">Example D6 includes the subject matter of Example D5, and further specifies that the processing device is to: after performing the joint zeroing operation on the first joint assembly of the robotic apparatus, perform the joint zeroing operation on an other joint assembly of the robotic apparatus, wherein the first joint assembly is mechanically between the support and the other joint assembly.</div>
</li> <li> <para-num num="[0567]"> </para-num> <div class="description-line" id="p-0568" num="0567">Example D7 includes the subject matter of any of Examples D1-6, and further specifies that identifying the acceleration vector representative of the orientation of the second joint assembly includes receiving data from an accelerometer of the second joint assembly.</div>
</li> <li> <para-num num="[0568]"> </para-num> <div class="description-line" id="p-0569" num="0568">Example D8 includes the subject matter of Example D7, and further specifies that identifying the acceleration vector representative of the orientation of the second joint assembly includes adjusting the receive data with a set of known offset corrections.</div>
</li> <li> <para-num num="[0569]"> </para-num> <div class="description-line" id="p-0570" num="0569">Example D9 includes the subject matter of any of Examples D1-8, and further specifies that the joint zeroing operation further includes: prior to identifying the acceleration vector, determine that the first joint assembly does not include a zeroing limit switch.</div>
</li> <li> <para-num num="[0570]"> </para-num> <div class="description-line" id="p-0571" num="0570">Example D10 includes the subject matter of Example D9, and further specifies that determining that the first joint assembly does not include a zeroing limit switch includes querying another processing device in the first joint assembly.</div>
</li> <li> <para-num num="[0571]"> </para-num> <div class="description-line" id="p-0572" num="0571">Example D11 includes the subject matter of any of Examples D1-10, and further specifies that the first joint assembly includes a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0572]"> </para-num> <div class="description-line" id="p-0573" num="0572">Example D12 includes the subject matter of Example D11, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0573]"> </para-num> <div class="description-line" id="p-0574" num="0573">Example D13 includes the subject matter of Example D12, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0574]"> </para-num> <div class="description-line" id="p-0575" num="0574">Example D14 includes the subject matter of any of Examples D1-13, and further specifies that the robotic apparatus includes at least three joint assemblies.</div>
</li> <li> <para-num num="[0575]"> </para-num> <div class="description-line" id="p-0576" num="0575">Example D15 includes the subject matter of Example D14, and further specifies that the apparatus includes at least six joint assemblies.</div>
</li> <li> <para-num num="[0576]"> </para-num> <div class="description-line" id="p-0577" num="0576">Example D16 includes the subject matter of any of Examples D1-15, and further specifies that the processing device is in a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0577]"> </para-num> <div class="description-line" id="p-0578" num="0577">Example D17 includes the subject matter of any of Examples D1-15, and further specifies that the processing device has a housing separate from a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0578]"> </para-num> <div class="description-line" id="p-0579" num="0578">Example D18 includes the subject matter of any of Examples D1-17, and further specifies that the processing device is included in a desktop computing device, a laptop computing device, or a tablet computing device.</div>
</li> <li> <para-num num="[0579]"> </para-num> <div class="description-line" id="p-0580" num="0579">Example D19 includes the subject matter of any of Examples D1-18, and further specifies that the robotic apparatus includes a robotic arm.</div>
</li> <li> <para-num num="[0580]"> </para-num> <div class="description-line" id="p-0581" num="0580">Example D20 includes the subject matter of any of Examples D1-18, and further specifies that the robotic apparatus includes a robotic gantry.</div>
</li> <li> <para-num num="[0581]"> </para-num> <div class="description-line" id="p-0582" num="0581">Example D21 includes the subject matter of any of Examples D1-20, and further specifies that the processing device is part of a product inspection system.</div>
</li> <li> <para-num num="[0582]"> </para-num> <div class="description-line" id="p-0583" num="0582">Example D22 includes the subject matter of any of Examples D1-21, and further includes: the robotic apparatus.</div>
</li> <li> <para-num num="[0583]"> </para-num> <div class="description-line" id="p-0584" num="0583">Example D23 includes the subject matter of any of Examples D1-22, and further specifies that the processing device is to communicate with the robotic apparatus via a Universal Serial Bus (USB) or a Controller Area Network (CAN).</div>
</li> <li> <para-num num="[0584]"> </para-num> <div class="description-line" id="p-0585" num="0584">Example D24 is an apparatus for robotic calibration, including: a processing device to perform a marker calibration operation, wherein the marker calibration operation includes: causing a robotic apparatus to move its end effector to a nominal position associated with a marker on a reference structure, determining an error between the nominal position and the actual position, adjusting the actual position of the end effector of the robotic apparatus to reduce the error between the nominal position and the actual position, and causing storage of the nominal position and the adjusted actual position; repeat the marker calibration operation for different markers of the reference structure; generate a computational model mapping nominal positions of the robotic apparatus and the adjusted actual positions; and use the computational model to determine, for a target position of the end effector, the position command to send to the robotic apparatus.</div>
</li> <li> <para-num num="[0585]"> </para-num> <div class="description-line" id="p-0586" num="0585">Example D25 includes the subject matter of Example D24, and further specifies that the robotic apparatus includes a plurality of joint assemblies, and causing storage of the adjusted actual position includes causing storage of the positions of individual ones of the joint assemblies.</div>
</li> <li> <para-num num="[0586]"> </para-num> <div class="description-line" id="p-0587" num="0586">Example D26 includes the subject matter of Example D25, and further specifies that individual ones of the joint assemblies include a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0587]"> </para-num> <div class="description-line" id="p-0588" num="0587">Example D27 includes the subject matter of Example D26, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0588]"> </para-num> <div class="description-line" id="p-0589" num="0588">Example D28 includes the subject matter of any of Examples D24-27, and further specifies that the end effector includes a camera and a laser.</div>
</li> <li> <para-num num="[0589]"> </para-num> <div class="description-line" id="p-0590" num="0589">Example D29 includes the subject matter of Example D28, and further specifies that determining an error between the nominal position and the actual position includes: causing the camera to capture an image that includes the laser location on the reference structure and the marker; and determining a distance between the laser location and the marker based on the image.</div>
</li> <li> <para-num num="[0590]"> </para-num> <div class="description-line" id="p-0591" num="0590">Example D30 includes the subject matter of Example D29, and further specifies that the image includes a marker label on the reference structure.</div>
</li> <li> <para-num num="[0591]"> </para-num> <div class="description-line" id="p-0592" num="0591">Example D31 includes the subject matter of Example D30, and further specifies that the marker label includes a Quick Response (QR) code.</div>
</li> <li> <para-num num="[0592]"> </para-num> <div class="description-line" id="p-0593" num="0592">Example D32 includes the subject matter of any of Examples D24-31, and further specifies that the end effector includes a depth sensor.</div>
</li> <li> <para-num num="[0593]"> </para-num> <div class="description-line" id="p-0594" num="0593">Example D33 includes the subject matter of Example D32, and further specifies that determining an error between the nominal position and the actual position includes: causing the depth sensor to measure a distance to the reference structure; and determining a difference between the measured distance to the reference structure and a distance to the reference structure from the nominal position.</div>
</li> <li> <para-num num="[0594]"> </para-num> <div class="description-line" id="p-0595" num="0594">Example D34 includes the subject matter of any of Examples D32-33, and further specifies that the depth sensor includes a camera array.</div>
</li> <li> <para-num num="[0595]"> </para-num> <div class="description-line" id="p-0596" num="0595">Example D35 includes the subject matter of any of Examples D24-34, and further specifies that the reference structure is a two-dimensional structure.</div>
</li> <li> <para-num num="[0596]"> </para-num> <div class="description-line" id="p-0597" num="0596">Example D36 includes the subject matter of Example D35, and further specifies that the reference structure is a mat.</div>
</li> <li> <para-num num="[0597]"> </para-num> <div class="description-line" id="p-0598" num="0597">Example D37 includes the subject matter of Example D36, and further specifies that the robotic apparatus is to sit on the mat.</div>
</li> <li> <para-num num="[0598]"> </para-num> <div class="description-line" id="p-0599" num="0598">Example D38 includes the subject matter of any of Examples D24-34, and further specifies that the reference structure is a three-dimensional structure.</div>
</li> <li> <para-num num="[0599]"> </para-num> <div class="description-line" id="p-0600" num="0599">Example D39 includes the subject matter of any of Examples D24-38, and further specifies that the marker is printed on a surface of the reference structure.</div>
</li> <li> <para-num num="[0600]"> </para-num> <div class="description-line" id="p-0601" num="0600">Example D40 includes the subject matter of any of Examples D24-39, and further specifies that the computational model is a principal component model, a linear regression model, a polynomial regression model, or a deep learning model.</div>
</li> <li> <para-num num="[0601]"> </para-num> <div class="description-line" id="p-0602" num="0601">Example D41 includes the subject matter of any of Examples D24-40, and further specifies that the processing device is a first processing device, the first processing device is to adjust the actual position of the end effector by sending commands to one or more second processing devices via a communications bus, and individual ones of the second processing devices are associated with individual joints of the robotic apparatus.</div>
</li> <li> <para-num num="[0602]"> </para-num> <div class="description-line" id="p-0603" num="0602">Example D42 includes the subject matter of Example D41, and further specifies that the communications bus is a Universal Serial Bus (USB) or a Controller Area Network (CAN).</div>
</li> <li> <para-num num="[0603]"> </para-num> <div class="description-line" id="p-0604" num="0603">Example D43 includes the subject matter of any of Examples D24-42, and further specifies that the processing device is in a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0604]"> </para-num> <div class="description-line" id="p-0605" num="0604">Example D44 includes the subject matter of any of Examples D24-42, and further specifies that the processing device has a housing separate from a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0605]"> </para-num> <div class="description-line" id="p-0606" num="0605">Example D45 includes the subject matter of any of Examples D24-44, and further specifies that the processing device is included in a desktop computing device, a laptop computing device, or a tablet computing device.</div>
</li> <li> <para-num num="[0606]"> </para-num> <div class="description-line" id="p-0607" num="0606">Example D46 includes the subject matter of any of Examples D24-45, and further includes: the robotic apparatus.</div>
</li> <li> <para-num num="[0607]"> </para-num> <div class="description-line" id="p-0608" num="0607">Example D47 includes the subject matter of any of Examples D24-46, and further specifies that the processing device is to communicate with the robotic apparatus via a Universal Serial Bus (USB) or a Controller Area Network (CAN).</div>
</li> <li> <para-num num="[0608]"> </para-num> <div class="description-line" id="p-0609" num="0608">Example D48 includes the subject matter of any of Examples D24-47, and further includes: the reference structure.</div>
</li> <li> <para-num num="[0609]"> </para-num> <div class="description-line" id="p-0610" num="0609">Example D49 is an apparatus for robotic zeroing, including: a processing device, wherein the processing device is to perform a zeroing operation on a robotic apparatus, the robotic apparatus includes a support, and the zeroing operation includes causing individual joints of the robotic apparatus to move to a zeroed position one at a time and sequentially, beginning with an individual joint mechanically closest to the support.</div>
</li> <li> <para-num num="[0610]"> </para-num> <div class="description-line" id="p-0611" num="0610">Example D50 includes the subject matter of Example D49, and further specifies that the zeroing operation further includes: for a particular joint, moving a prior joint away from its zeroed position, zeroing the particular joint, and then moving the prior joint back to its zeroed position.</div>
</li> <li> <para-num num="[0611]"> </para-num> <div class="description-line" id="p-0612" num="0611">Example D51 includes the subject matter of Example D50, and further specifies that moving the prior joint away from its zeroed position includes moving the prior joint 90 degrees away from its zeroed position.</div>
</li> <li> <para-num num="[0612]"> </para-num> <div class="description-line" id="p-0613" num="0612">Example D52 includes the subject matter of any of Examples D49-51, and further specifies that the zeroing operation further includes: zeroing a particular joint by utilizing a limit switch associated with that joint.</div>
</li> <li> <para-num num="[0613]"> </para-num> <div class="description-line" id="p-0614" num="0613">Example D53 includes the subject matter of any of Examples D49-52, and further specifies that individual joints include a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0614]"> </para-num> <div class="description-line" id="p-0615" num="0614">Example D54 includes the subject matter of Example D53, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0615]"> </para-num> <div class="description-line" id="p-0616" num="0615">Example D55 includes the subject matter of Example D54, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0616]"> </para-num> <div class="description-line" id="p-0617" num="0616">Example D56 includes the subject matter of any of Examples D49-55, and further specifies that the robotic apparatus includes at least three joint assemblies.</div>
</li> <li> <para-num num="[0617]"> </para-num> <div class="description-line" id="p-0618" num="0617">Example D57 includes the subject matter of Example D56, and further specifies that the apparatus includes at least six joint assemblies.</div>
</li> <li> <para-num num="[0618]"> </para-num> <div class="description-line" id="p-0619" num="0618">Example D58 includes the subject matter of any of Examples D49-57, and further specifies that the processing device is in a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0619]"> </para-num> <div class="description-line" id="p-0620" num="0619">Example D59 includes the subject matter of any of Examples D49-57, and further specifies that the processing device has a housing separate from a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0620]"> </para-num> <div class="description-line" id="p-0621" num="0620">Example D60 includes the subject matter of any of Examples D49-59, and further specifies that the processing device is included in a desktop computing device, a laptop computing device, or a tablet computing device.</div>
</li> <li> <para-num num="[0621]"> </para-num> <div class="description-line" id="p-0622" num="0621">Example D61 includes the subject matter of any of Examples D49-60, and further specifies that the robotic apparatus includes a robotic arm.</div>
</li> <li> <para-num num="[0622]"> </para-num> <div class="description-line" id="p-0623" num="0622">Example D62 includes the subject matter of any of Examples D49-60, and further specifies that the robotic apparatus includes a robotic gantry.</div>
</li> <li> <para-num num="[0623]"> </para-num> <div class="description-line" id="p-0624" num="0623">Example D63 includes the subject matter of any of Examples D49-62, and further specifies that the processing device is part of a product inspection system.</div>
</li> <li> <para-num num="[0624]"> </para-num> <div class="description-line" id="p-0625" num="0624">Example D64 includes the subject matter of any of Examples D49-63, and further includes: the robotic apparatus.</div>
</li> <li> <para-num num="[0625]"> </para-num> <div class="description-line" id="p-0626" num="0625">Example D65 includes the subject matter of any of Examples D49-64, and further specifies that the processing device is to communicate with the robotic apparatus via a Universal Serial Bus (USB) or a Controller Area Network (CAN).</div>
</li> <li> <para-num num="[0626]"> </para-num> <div class="description-line" id="p-0627" num="0626">Example D66 is an apparatus for robotic calibration, including: a processing device to perform a marker calibration operation, wherein the marker calibration operation includes causing a robotic apparatus to move to a nominal position to shine a laser on a marker on a reference structure, and causing the robotic apparatus to adjust its position to reduce the error between the laser location and the marker; wherein the processing device is to repeat the marker calibration operation for different markers on the reference structure.</div>
</li> <li> <para-num num="[0627]"> </para-num> <div class="description-line" id="p-0628" num="0627">Example D67 includes the subject matter of Example D66, and further specifies that the robotic apparatus includes a plurality of joint assemblies, and individual ones of the joint assemblies include a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0628]"> </para-num> <div class="description-line" id="p-0629" num="0628">Example D68 includes the subject matter of Example D67, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0629]"> </para-num> <div class="description-line" id="p-0630" num="0629">Example D69 includes the subject matter of any of Examples D66-68, and further specifies that the robotic apparatus further includes a camera.</div>
</li> <li> <para-num num="[0630]"> </para-num> <div class="description-line" id="p-0631" num="0630">Example D70 includes the subject matter of any of Examples D66-69, and further specifies that the robotic apparatus further includes a depth sensor.</div>
</li> <li> <para-num num="[0631]"> </para-num> <div class="description-line" id="p-0632" num="0631">Example D71 includes the subject matter of Example D70, and further specifies that the depth sensor includes a camera array.</div>
</li> <li> <para-num num="[0632]"> </para-num> <div class="description-line" id="p-0633" num="0632">Example D72 includes the subject matter of any of Examples D66-71, and further specifies that the reference structure is a two-dimensional structure.</div>
</li> <li> <para-num num="[0633]"> </para-num> <div class="description-line" id="p-0634" num="0633">Example D73 includes the subject matter of Example D72, and further specifies that the reference structure is a mat.</div>
</li> <li> <para-num num="[0634]"> </para-num> <div class="description-line" id="p-0635" num="0634">Example D74 includes the subject matter of Example D73, and further specifies that the robotic apparatus is to sit on the mat.</div>
</li> <li> <para-num num="[0635]"> </para-num> <div class="description-line" id="p-0636" num="0635">Example D75 includes the subject matter of any of Examples D66-71, and further specifies that the reference structure is a three-dimensional structure.</div>
</li> <li> <para-num num="[0636]"> </para-num> <div class="description-line" id="p-0637" num="0636">Example D76 includes the subject matter of any of Examples D66-75, and further specifies that the marker is printed on a surface of the reference structure.</div>
</li> <li> <para-num num="[0637]"> </para-num> <div class="description-line" id="p-0638" num="0637">Example D77 includes the subject matter of any of Examples D66-76, and further specifies that the reference structure includes a marker label for individual markers.</div>
</li> <li> <para-num num="[0638]"> </para-num> <div class="description-line" id="p-0639" num="0638">Example D78 includes the subject matter of Example D77, and further specifies that the marker label includes a Quick Response (QR) code.</div>
</li> <li> <para-num num="[0639]"> </para-num> <div class="description-line" id="p-0640" num="0639">Example D79 includes the subject matter of any of Examples D66-78, and further specifies that the processing device is a first processing device, the first processing device is to adjust the actual position of the end effector by sending commands to one or more second processing devices via a communications bus, and individual ones of the second processing devices are associated with individual joints of the robotic apparatus.</div>
</li> <li> <para-num num="[0640]"> </para-num> <div class="description-line" id="p-0641" num="0640">Example D80 includes the subject matter of Example D79, and further specifies that the communications bus is a Universal Serial Bus (USB) or a Controller Area Network (CAN).</div>
</li> <li> <para-num num="[0641]"> </para-num> <div class="description-line" id="p-0642" num="0641">Example D81 includes the subject matter of any of Examples D66-80, and further specifies that the processing device is in a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0642]"> </para-num> <div class="description-line" id="p-0643" num="0642">Example D82 includes the subject matter of any of Examples D66-80, and further specifies that the processing device has a housing separate from a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0643]"> </para-num> <div class="description-line" id="p-0644" num="0643">Example D83 includes the subject matter of any of Examples D66-82, and further specifies that the processing device is included in a desktop computing device, a laptop computing device, or a tablet computing device.</div>
</li> <li> <para-num num="[0644]"> </para-num> <div class="description-line" id="p-0645" num="0644">Example D84 includes the subject matter of any of Examples D66-83, and further includes: the robotic apparatus.</div>
</li> <li> <para-num num="[0645]"> </para-num> <div class="description-line" id="p-0646" num="0645">Example D85 includes the subject matter of any of Examples D66-84, and further specifies that the processing device is to communicate with the robotic apparatus via a Universal Serial Bus (USB) or a Controller Area Network (CAN).</div>
</li> <li> <para-num num="[0646]"> </para-num> <div class="description-line" id="p-0647" num="0646">Example D86 is a method performed by any of the processing devices of Examples D1-85.</div>
</li> <li> <para-num num="[0647]"> </para-num> <div class="description-line" id="p-0648" num="0647">Example D87 is one or more computer readable media having instructions thereon that, when executed by one or more processing devices of a computing system, cause the computing system to perform any of the methods of Example D86.</div>
</li> <li> <para-num num="[0648]"> </para-num> <div class="description-line" id="p-0649" num="0648">Example D88 is an apparatus for collaborative robotics, including means for performing any of the methods of Example D86.</div>
</li> <li> <para-num num="[0649]"> </para-num> <div class="description-line" id="p-0650" num="0649">Example E1 is an inspection apparatus, including: a processing device to communicatively couple to a robotic apparatus, wherein the processing device is to generate an inspection path for the robotic apparatus to follow to inspect an item, the inspection path includes a set of positions of an end effector of the robotic apparatus, and the processing device is to cause a camera of the end effector to capture an image of the item at each position.</div>
</li> <li> <para-num num="[0650]"> </para-num> <div class="description-line" id="p-0651" num="0650">Example E2 includes the subject matter of Example E1, and further specifies that a position of an end effector includes a spatial location and an angular position.</div>
</li> <li> <para-num num="[0651]"> </para-num> <div class="description-line" id="p-0652" num="0651">Example E3 includes the subject matter of any of Examples E1-2, and further specifies that at least some of the positions are indicated to the processing device via a user input device.</div>
</li> <li> <para-num num="[0652]"> </para-num> <div class="description-line" id="p-0653" num="0652">Example E4 includes the subject matter of Example E3, and further specifies that the processing device is to receive commands, via the user input device, to move the end effector of the robotic apparatus.</div>
</li> <li> <para-num num="[0653]"> </para-num> <div class="description-line" id="p-0654" num="0653">Example E5 includes the subject matter of any of Examples E3-4, and further specifies that the processing device is to receive a command, via the user input device, to store a current position of the end effector as a position in the inspection path.</div>
</li> <li> <para-num num="[0654]"> </para-num> <div class="description-line" id="p-0655" num="0654">Example E6 includes the subject matter of any of Examples E1-5, and further specifies that the processing device is to generate at least some of the positions.</div>
</li> <li> <para-num num="[0655]"> </para-num> <div class="description-line" id="p-0656" num="0655">Example E7 includes the subject matter of Example E6, and further specifies that the processing device is to receive an instruction, via a user input device, to generate at least some of the positions.</div>
</li> <li> <para-num num="[0656]"> </para-num> <div class="description-line" id="p-0657" num="0656">Example E8 includes the subject matter of any of Examples E6-7, and further specifies that the processing device is to cause the robotic apparatus to: capture an overview image of the item; segment the item from a background in the overview image; using the segmentation results, generate a set of positions for the end effector of the robotic apparatus at which images of the item may be captured so as to cover a surface of the item.</div>
</li> <li> <para-num num="[0657]"> </para-num> <div class="description-line" id="p-0658" num="0657">Example E9 includes the subject matter of Example E8, and further specifies that the end effector includes a first camera and a second camera, the second camera has a higher resolution than the first camera, and the processing device is to cause the robotic apparatus to capture the overview image of the item with the first camera.</div>
</li> <li> <para-num num="[0658]"> </para-num> <div class="description-line" id="p-0659" num="0658">Example E10 includes the subject matter of any of Examples E6-8, and further specifies that the processing device is to: receive an indication, via the user input device, of a level of detail with which the user would like to perform the inspection; and based on the indicated level of detail, control a distance between the item and the end effector in the set of positions.</div>
</li> <li> <para-num num="[0659]"> </para-num> <div class="description-line" id="p-0660" num="0659">Example E11 includes the subject matter of any of Examples E1-10, and further specifies that the processing device is to communicate with a display device, and is to: prompt a user to select positions for the inspection path from a set of candidate positions.</div>
</li> <li> <para-num num="[0660]"> </para-num> <div class="description-line" id="p-0661" num="0660">Example E12 includes the subject matter of Example E11, and further specifies that the processing device is to cause an overview image of the item to be displayed during prompting of the user.</div>
</li> <li> <para-num num="[0661]"> </para-num> <div class="description-line" id="p-0662" num="0661">Example E13 includes the subject matter of any of Examples E11-12, and further includes: the display device.</div>
</li> <li> <para-num num="[0662]"> </para-num> <div class="description-line" id="p-0663" num="0662">Example E14 includes the subject matter of any of Examples E1-13, and further specifies that the processing device is to store an inspection function identifier in association with each position, and the inspection function identifier identifies an inspection function that is to be applied to images captured by the camera when the end effector is at the associated position.</div>
</li> <li> <para-num num="[0663]"> </para-num> <div class="description-line" id="p-0664" num="0663">Example E15 includes the subject matter of Example E14, and further specifies that the processing device is to receive a selection of an inspection function, via a user input device, for a particular position.</div>
</li> <li> <para-num num="[0664]"> </para-num> <div class="description-line" id="p-0665" num="0664">Example E16 includes the subject matter of any of Examples E14-15, and further specifies that the processing device is to present a plurality of inspection functions from which a user may choose, via a user input device, for association with a particular position.</div>
</li> <li> <para-num num="[0665]"> </para-num> <div class="description-line" id="p-0666" num="0665">Example E17 includes the subject matter of any of Examples E14-16, and further specifies that the inspection function includes anomaly detection, recognition of a particular defect, or optical character recognition.</div>
</li> <li> <para-num num="[0666]"> </para-num> <div class="description-line" id="p-0667" num="0666">Example E18 includes the subject matter of any of Examples E1-17, and further specifies that the processing device is to communicatively couple to a display device and a user input device to provide a Graphical User Interface (GUI) through which a user may specify the inspection path.</div>
</li> <li> <para-num num="[0667]"> </para-num> <div class="description-line" id="p-0668" num="0667">Example E19 includes the subject matter of Example E18, and further includes: the display device.</div>
</li> <li> <para-num num="[0668]"> </para-num> <div class="description-line" id="p-0669" num="0668">Example E20 includes the subject matter of any of Examples E18-19, and further includes: the user input device.</div>
</li> <li> <para-num num="[0669]"> </para-num> <div class="description-line" id="p-0670" num="0669">Example E21 includes the subject matter of any of Examples E18-20, and further specifies that the display device and the user input device are provided by a touchscreen device.</div>
</li> <li> <para-num num="[0670]"> </para-num> <div class="description-line" id="p-0671" num="0670">Example E22 includes the subject matter of any of Examples E1-21, and further specifies that the robotic apparatus includes a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0671]"> </para-num> <div class="description-line" id="p-0672" num="0671">Example E23 includes the subject matter of Example E22, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0672]"> </para-num> <div class="description-line" id="p-0673" num="0672">Example E24 includes the subject matter of Example E23, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0673]"> </para-num> <div class="description-line" id="p-0674" num="0673">Example E25 includes the subject matter of any of Examples E1-24, and further specifies that the robotic apparatus includes at least three joints.</div>
</li> <li> <para-num num="[0674]"> </para-num> <div class="description-line" id="p-0675" num="0674">Example E26 includes the subject matter of Example E25, and further specifies that the apparatus includes at least six joints.</div>
</li> <li> <para-num num="[0675]"> </para-num> <div class="description-line" id="p-0676" num="0675">Example E27 includes the subject matter of any of Examples E1-26, and further specifies that the processing device is in a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0676]"> </para-num> <div class="description-line" id="p-0677" num="0676">Example E28 includes the subject matter of any of Examples E1-26, and further specifies that the processing device has a housing separate from a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0677]"> </para-num> <div class="description-line" id="p-0678" num="0677">Example E29 includes the subject matter of any of Examples E1-28, and further specifies that the processing device is included in a desktop computing device, a laptop computing device, or a tablet computing device.</div>
</li> <li> <para-num num="[0678]"> </para-num> <div class="description-line" id="p-0679" num="0678">Example E30 includes the subject matter of any of Examples E1-29, and further specifies that the robotic apparatus includes a robotic arm.</div>
</li> <li> <para-num num="[0679]"> </para-num> <div class="description-line" id="p-0680" num="0679">Example E31 includes the subject matter of any of Examples E1-29, and further specifies that the robotic apparatus includes a robotic gantry.</div>
</li> <li> <para-num num="[0680]"> </para-num> <div class="description-line" id="p-0681" num="0680">Example E32 includes the subject matter of any of Examples E1-31, and further includes: the robotic apparatus.</div>
</li> <li> <para-num num="[0681]"> </para-num> <div class="description-line" id="p-0682" num="0681">Example E33 is an inspection apparatus, including: a processing device to communicatively couple to a robotic apparatus, wherein the processing device is to cause the robotic apparatus to follow an inspection path to inspect an item, the inspection path includes a set of positions to which an end effector of the robotic apparatus is to move, and the processing device is to cause a camera of the end effector to capture an image of the item at each position.</div>
</li> <li> <para-num num="[0682]"> </para-num> <div class="description-line" id="p-0683" num="0682">Example E34 includes the subject matter of Example E33, and further specifies that a position of an end effector includes a spatial location and an angular position.</div>
</li> <li> <para-num num="[0683]"> </para-num> <div class="description-line" id="p-0684" num="0683">Example E35 includes the subject matter of any of Examples E33-34, and further specifies that the end effector includes a first camera and a second camera, the second camera has a higher resolution than the first camera, and the processing device is to use the second camera to capture the image of the item at each position.</div>
</li> <li> <para-num num="[0684]"> </para-num> <div class="description-line" id="p-0685" num="0684">Example E36 includes the subject matter of Example E35, and further specifies that the processing device is to use the first camera to capture the overview image of the item.</div>
</li> <li> <para-num num="[0685]"> </para-num> <div class="description-line" id="p-0686" num="0685">Example E37 includes the subject matter of any of Examples E33-36, and further specifies that the processing device is to communicatively couple to a display device, and the processing device is to cause the images to be presented on the display device.</div>
</li> <li> <para-num num="[0686]"> </para-num> <div class="description-line" id="p-0687" num="0686">Example E38 includes the subject matter of Example E37, and further includes: the display device.</div>
</li> <li> <para-num num="[0687]"> </para-num> <div class="description-line" id="p-0688" num="0687">Example E39 includes the subject matter of Example E38, and further specifies that the processing device is to cause the images to be presented on the display along with images captured from the same positions of a known-good item.</div>
</li> <li> <para-num num="[0688]"> </para-num> <div class="description-line" id="p-0689" num="0688">Example E40 includes the subject matter of any of Examples E33-39, and further specifies that the robotic apparatus includes a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0689]"> </para-num> <div class="description-line" id="p-0690" num="0689">Example E41 includes the subject matter of Example E40, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0690]"> </para-num> <div class="description-line" id="p-0691" num="0690">Example E42 includes the subject matter of Example E41, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0691]"> </para-num> <div class="description-line" id="p-0692" num="0691">Example E43 includes the subject matter of any of Examples E33-42, and further specifies that the robotic apparatus includes at least three joints.</div>
</li> <li> <para-num num="[0692]"> </para-num> <div class="description-line" id="p-0693" num="0692">Example E44 includes the subject matter of Example E43, and further specifies that the apparatus includes at least six joints.</div>
</li> <li> <para-num num="[0693]"> </para-num> <div class="description-line" id="p-0694" num="0693">Example E45 includes the subject matter of any of Examples E33-44, and further specifies that the processing device is in a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0694]"> </para-num> <div class="description-line" id="p-0695" num="0694">Example E46 includes the subject matter of any of Examples E33-44, and further specifies that the processing device has a housing separate from a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0695]"> </para-num> <div class="description-line" id="p-0696" num="0695">Example E47 includes the subject matter of any of Examples E33-46, and further specifies that the processing device is included in a desktop computing device, a laptop computing device, or a tablet computing device.</div>
</li> <li> <para-num num="[0696]"> </para-num> <div class="description-line" id="p-0697" num="0696">Example E48 includes the subject matter of any of Examples E33-47, and further specifies that the robotic apparatus includes a robotic arm.</div>
</li> <li> <para-num num="[0697]"> </para-num> <div class="description-line" id="p-0698" num="0697">Example E49 includes the subject matter of any of Examples E33-47, and further specifies that the robotic apparatus includes a robotic gantry.</div>
</li> <li> <para-num num="[0698]"> </para-num> <div class="description-line" id="p-0699" num="0698">Example E50 includes the subject matter of any of Examples E33-49, and further specifies that the inspection path is a first inspection path, and the processing device is to: after completion of the first inspection path, causing a user to be prompted to move the item; and receiving an indication, from a user input device, that a second inspection path is to be followed to inspect the moved item; and after receipt of the indication that the second inspection path is to be followed, cause the robotic apparatus to follow the second inspection path to inspect the moved item.</div>
</li> <li> <para-num num="[0699]"> </para-num> <div class="description-line" id="p-0700" num="0699">Example E51 includes the subject matter of any of Examples E33-50, and further specifies that the processing device is to communicatively couple to the robotic apparatus via a communications port, and the communications port is a Universal Serial Bus (USB) port or a Controller Area Network (CAN) port.</div>
</li> <li> <para-num num="[0700]"> </para-num> <div class="description-line" id="p-0701" num="0700">Example E52 includes the subject matter of any of Examples E33-51, and further includes: the robotic apparatus.</div>
</li> <li> <para-num num="[0701]"> </para-num> <div class="description-line" id="p-0702" num="0701">Example E53 is a method performed by any of the processing devices of Examples E1-52.</div>
</li> <li> <para-num num="[0702]"> </para-num> <div class="description-line" id="p-0703" num="0702">Example E54 is one or more computer readable media having instructions thereon that, when executed by one or more processing devices of a computing system, cause the computing system to perform any of the methods of Example E53.</div>
</li> <li> <para-num num="[0703]"> </para-num> <div class="description-line" id="p-0704" num="0703">Example E55 is an apparatus for collaborative robotics, including means for performing any of the methods of Example E53.</div>
</li> <li> <para-num num="[0704]"> </para-num> <div class="description-line" id="p-0705" num="0704">Example F1 is an inspection apparatus, including: a processing device to communicatively couple to a robotic apparatus, to a display device, and to a user input device, wherein the processing device is to receive an image of an item, wherein the image was captured by the robotic apparatus, generate a proposed classification for the image, wherein the classification indicates an attribute of the item based on the image, cause the image to be displayed on the display device along with the proposed classification, and receive an indication from the user input device of a final classification of the image.</div>
</li> <li> <para-num num="[0705]"> </para-num> <div class="description-line" id="p-0706" num="0705">Example F2 includes the subject matter of Example F1, and further specifies that receive the indication from the user input device of the final classification of the image includes receiving an indication from the user input device that the user accepts or rejects the proposed classification of the image.</div>
</li> <li> <para-num num="[0706]"> </para-num> <div class="description-line" id="p-0707" num="0706">Example F3 includes the subject matter of any of Examples F1-2, and further specifies that receive the indication from the user input device of the final classification of the image includes receiving an indication that the user has selected a final classification that is different than the proposed classification.</div>
</li> <li> <para-num num="[0707]"> </para-num> <div class="description-line" id="p-0708" num="0707">Example F4 includes the subject matter of Example F3, and further specifies that the proposed classification is an unknown classification.</div>
</li> <li> <para-num num="[0708]"> </para-num> <div class="description-line" id="p-0709" num="0708">Example F5 includes the subject matter of any of Examples F1-4, and further specifies that causing the image to be displayed on the display device includes causing a visual indicator to be displayed, and the visual indicator indicates a portion of the image on which the proposed classification is based.</div>
</li> <li> <para-num num="[0709]"> </para-num> <div class="description-line" id="p-0710" num="0709">Example F6 includes the subject matter of Example F5, and further specifies that the visual indicator includes a box.</div>
</li> <li> <para-num num="[0710]"> </para-num> <div class="description-line" id="p-0711" num="0710">Example F7 includes the subject matter of any of Examples F1-6, and further specifies that causing the image to be displayed on the display device along with the proposed classification includes causing the image to be displayed on the display device along with the proposed classification and along with a known-good image of the item.</div>
</li> <li> <para-num num="[0711]"> </para-num> <div class="description-line" id="p-0712" num="0711">Example F8 includes the subject matter of Example F7, and further specifies that the known-good image is captured from the same position as the image.</div>
</li> <li> <para-num num="[0712]"> </para-num> <div class="description-line" id="p-0713" num="0712">Example F9 includes the subject matter of any of Examples F1-8, and further specifies that the processing device is to: after receipt of the indication from the user input device of the final classification of the image, cause storage of the final classification in association with the image.</div>
</li> <li> <para-num num="[0713]"> </para-num> <div class="description-line" id="p-0714" num="0713">Example F10 includes the subject matter of Example F9, and further specifies that generating a proposed classification for the image includes executing an inspection function with the image as an input, the inspection function includes a computational classifier, and the processing device is to: after causing storage of the final classification in association with the image, retrain the computational classifier on a training set that includes the image and the final classification.</div>
</li> <li> <para-num num="[0714]"> </para-num> <div class="description-line" id="p-0715" num="0714">Example F11 includes the subject matter of Example F10, and further specifies that the training set includes images captured from the same position as the image.</div>
</li> <li> <para-num num="[0715]"> </para-num> <div class="description-line" id="p-0716" num="0715">Example F12 includes the subject matter of any of Examples F1-11, and further specifies that generate the proposed classification for the image includes executing an anomaly detection classifier based on stored images of the item.</div>
</li> <li> <para-num num="[0716]"> </para-num> <div class="description-line" id="p-0717" num="0716">Example F13 includes the subject matter of Example F12, and further specifies that the stored images are captured from the same position as the image.</div>
</li> <li> <para-num num="[0717]"> </para-num> <div class="description-line" id="p-0718" num="0717">Example F14 includes the subject matter of any of Examples F1-13, and further specifies that generate the classification for the image includes executing a missing component detection classifier or a solder bridge detection classifier.</div>
</li> <li> <para-num num="[0718]"> </para-num> <div class="description-line" id="p-0719" num="0718">Example F15 includes the subject matter of any of Examples F1-14, and further specifies that the image is one of a plurality of images of the item captured by the robotic apparatus from different positions, and the processing device is to: generate a proposed classification for each image; cause each image to be displayed on the display device along with the associated proposed classification; and receive an indication from the user input device of a final classification for each image.</div>
</li> <li> <para-num num="[0719]"> </para-num> <div class="description-line" id="p-0720" num="0719">Example F16 includes the subject matter of Example F15, and further specifies that the processing device is to: generate a classification for the item based at least in part on the final classifications of the plurality of images.</div>
</li> <li> <para-num num="[0720]"> </para-num> <div class="description-line" id="p-0721" num="0720">Example F17 includes the subject matter of Example F16, and further specifies that the item is classified as failed when at least one of the images is classified as failed.</div>
</li> <li> <para-num num="[0721]"> </para-num> <div class="description-line" id="p-0722" num="0721">Example F18 includes the subject matter of any of Examples F1-17, and further specifies that the processing device is to: before receipt of the image of the item, cause the robotic apparatus to follow an inspection path to inspect the item, wherein the inspection path includes a set of positions of an end effector of the robotic apparatus, and the processing device is to cause a camera of the end effector to capture an image of the item at each position.</div>
</li> <li> <para-num num="[0722]"> </para-num> <div class="description-line" id="p-0723" num="0722">Example F19 includes the subject matter of Example F18, and further specifies that a position of an end effector includes a spatial location and an angular position.</div>
</li> <li> <para-num num="[0723]"> </para-num> <div class="description-line" id="p-0724" num="0723">Example F20 includes the subject matter of any of Examples F18-19, and further specifies that the processing device is to store an inspection function identifier in association with each position, and the inspection function identifier identifies an inspection function that is to be applied to images captured by the camera when the end effector is at the associated position.</div>
</li> <li> <para-num num="[0724]"> </para-num> <div class="description-line" id="p-0725" num="0724">Example F21 includes the subject matter of any of Examples F1-20, and further includes: the robotic apparatus.</div>
</li> <li> <para-num num="[0725]"> </para-num> <div class="description-line" id="p-0726" num="0725">Example F22 includes the subject matter of any of Examples F1-21, and further includes: the display device. Example F23 includes the subject matter of any of Examples F1-22, and further specifies that the robotic apparatus includes a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0726]"> </para-num> <div class="description-line" id="p-0727" num="0726">Example F24 includes the subject matter of Example F23, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0727]"> </para-num> <div class="description-line" id="p-0728" num="0727">Example F25 includes the subject matter of Example F24, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0728]"> </para-num> <div class="description-line" id="p-0729" num="0728">Example F26 includes the subject matter of any of Examples F1-25, and further specifies that the robotic apparatus includes at least three joints.</div>
</li> <li> <para-num num="[0729]"> </para-num> <div class="description-line" id="p-0730" num="0729">Example F27 includes the subject matter of Example F26, and further specifies that the apparatus includes at least six joints.</div>
</li> <li> <para-num num="[0730]"> </para-num> <div class="description-line" id="p-0731" num="0730">Example F28 includes the subject matter of any of Examples F1-27, and further specifies that the processing device is in a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0731]"> </para-num> <div class="description-line" id="p-0732" num="0731">Example F29 includes the subject matter of any of Examples F1-27, and further specifies that the processing device has a housing separate from a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0732]"> </para-num> <div class="description-line" id="p-0733" num="0732">Example F30 includes the subject matter of any of Examples F1-29, and further specifies that the processing device is included in a desktop computing device, a laptop computing device, or a tablet computing device.</div>
</li> <li> <para-num num="[0733]"> </para-num> <div class="description-line" id="p-0734" num="0733">Example F31 includes the subject matter of any of Examples F1-30, and further specifies that the robotic apparatus includes a robotic arm.</div>
</li> <li> <para-num num="[0734]"> </para-num> <div class="description-line" id="p-0735" num="0734">Example F32 includes the subject matter of any of Examples F1-30, and further specifies that the robotic apparatus includes a robotic gantry.</div>
</li> <li> <para-num num="[0735]"> </para-num> <div class="description-line" id="p-0736" num="0735">Example F33 includes the subject matter of any of Examples F1-32, and further includes: the user input device.</div>
</li> <li> <para-num num="[0736]"> </para-num> <div class="description-line" id="p-0737" num="0736">Example F34 is an inspection apparatus, including: a processing device to communicatively couple to a robotic apparatus, to a display device, and to a user input device, wherein the processing device is to: receive a plurality of images of an item, wherein the plurality of images were captured by a camera of an end effector of the robotic apparatus, and different ones of the images were captured at different positions of the end effector, generate a proposed classification for individual ones of the images, wherein the classification indicates an attribute of the item based on the associated image, cause the proposed classifications to be displayed on the display device, and allow a user to indicate, via the user input device, which images to display on the display device based on their associated proposed classifications.</div>
</li> <li> <para-num num="[0737]"> </para-num> <div class="description-line" id="p-0738" num="0737">Example F35 includes the subject matter of Example F34, and further specifies that allow the user to indicate which images to display includes allowing a user to display images whose proposed classifications are failed.</div>
</li> <li> <para-num num="[0738]"> </para-num> <div class="description-line" id="p-0739" num="0738">Example F36 includes the subject matter of any of Examples F34-35, and further specifies that allow the user to indicate which images to display includes allowing a user to display images whose proposed classifications are unknown.</div>
</li> <li> <para-num num="[0739]"> </para-num> <div class="description-line" id="p-0740" num="0739">Example F37 includes the subject matter of any of Examples F34-36, and further specifies that allow the user to indicate which images to display includes allowing a user to display images whose proposed classifications are unknown or failed.</div>
</li> <li> <para-num num="[0740]"> </para-num> <div class="description-line" id="p-0741" num="0740">Example F38 includes the subject matter of any of Examples F34-37, and further specifies that the processing device is further to: allow a user to, via the user input device, specify a final classification for each image.</div>
</li> <li> <para-num num="[0741]"> </para-num> <div class="description-line" id="p-0742" num="0741">Example F39 includes the subject matter of Example F38, and further specifies that allowing a user to specify a final classification for each image includes allowing a user to confirm or change the proposed classifications.</div>
</li> <li> <para-num num="[0742]"> </para-num> <div class="description-line" id="p-0743" num="0742">Example F40 includes the subject matter of any of Examples F38-39, and further specifies that allowing a user to specify a final classification for each image includes allowing a user to select an option to set the final classifications of all images as passed.</div>
</li> <li> <para-num num="[0743]"> </para-num> <div class="description-line" id="p-0744" num="0743">Example F41 includes the subject matter of any of Examples F38-40, and further specifies that the processing device is to: after receipt of the specification of the final classification of each image, cause storage of the final classifications in association with the images.</div>
</li> <li> <para-num num="[0744]"> </para-num> <div class="description-line" id="p-0745" num="0744">Example F42 includes the subject matter of any of Examples F34-41, and further specifies that the processing device is to: before receipt of the images of the item, cause the robotic apparatus to follow an inspection path to inspect the item, wherein the inspection path includes a set of positions of an end effector of the robotic apparatus, and the processing device is to cause a camera of the end effector to capture an image of the item at each position.</div>
</li> <li> <para-num num="[0745]"> </para-num> <div class="description-line" id="p-0746" num="0745">Example F43 includes the subject matter of Example F42, and further specifies that a position of an end effector includes a spatial location and an angular position.</div>
</li> <li> <para-num num="[0746]"> </para-num> <div class="description-line" id="p-0747" num="0746">Example F44 includes the subject matter of any of Examples F42-43, and further specifies that the processing device is to store an inspection function identifier in association with each position, and the inspection function identifier identifies an inspection function that is to be applied to images captured by the camera when the end effector is at the associated position.</div>
</li> <li> <para-num num="[0747]"> </para-num> <div class="description-line" id="p-0748" num="0747">Example F45 includes the subject matter of any of Examples F34-44, and further includes: the robotic apparatus.</div>
</li> <li> <para-num num="[0748]"> </para-num> <div class="description-line" id="p-0749" num="0748">Example F46 includes the subject matter of any of Examples F34-45, and further includes: the display device.</div>
</li> <li> <para-num num="[0749]"> </para-num> <div class="description-line" id="p-0750" num="0749">Example F47 includes the subject matter of any of Examples F34-46, and further specifies that the robotic apparatus includes a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0750]"> </para-num> <div class="description-line" id="p-0751" num="0750">Example F48 includes the subject matter of Example F47, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0751]"> </para-num> <div class="description-line" id="p-0752" num="0751">Example F49 includes the subject matter of Example F48, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0752]"> </para-num> <div class="description-line" id="p-0753" num="0752">Example F50 includes the subject matter of any of Examples F34-49, and further specifies that the robotic apparatus includes at least three joints.</div>
</li> <li> <para-num num="[0753]"> </para-num> <div class="description-line" id="p-0754" num="0753">Example F51 includes the subject matter of Example F50, and further specifies that the apparatus includes at least six joints.</div>
</li> <li> <para-num num="[0754]"> </para-num> <div class="description-line" id="p-0755" num="0754">Example F52 includes the subject matter of any of Examples F34-51, and further specifies that the processing device is in a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0755]"> </para-num> <div class="description-line" id="p-0756" num="0755">Example F53 includes the subject matter of any of Examples F34-51, and further specifies that the processing device has a housing separate from a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0756]"> </para-num> <div class="description-line" id="p-0757" num="0756">Example F54 includes the subject matter of any of Examples F34-53, and further specifies that the processing device is included in a desktop computing device, a laptop computing device, or a tablet computing device.</div>
</li> <li> <para-num num="[0757]"> </para-num> <div class="description-line" id="p-0758" num="0757">Example F55 includes the subject matter of any of Examples F34-54, and further specifies that the robotic apparatus includes a robotic arm.</div>
</li> <li> <para-num num="[0758]"> </para-num> <div class="description-line" id="p-0759" num="0758">Example F56 includes the subject matter of any of Examples F34-54, and further specifies that the robotic apparatus includes a robotic gantry.</div>
</li> <li> <para-num num="[0759]"> </para-num> <div class="description-line" id="p-0760" num="0759">Example F57 includes the subject matter of any of Examples F34-56, and further includes: the user input device.</div>
</li> <li> <para-num num="[0760]"> </para-num> <div class="description-line" id="p-0761" num="0760">Example F58 is a method performed by any of the processing devices of Examples F1-57.</div>
</li> <li> <para-num num="[0761]"> </para-num> <div class="description-line" id="p-0762" num="0761">Example F59 is one or more computer readable media having instructions thereon that, when executed by one or more processing devices of a computing system, cause the computing system to perform any of the methods of Example F58.</div>
</li> <li> <para-num num="[0762]"> </para-num> <div class="description-line" id="p-0763" num="0762">Example F60 is an apparatus for collaborative robotics, including means for performing any of the methods of Example F58.</div>
</li> <li> <para-num num="[0763]"> </para-num> <div class="description-line" id="p-0764" num="0763">Example G1 is an apparatus for robotic calibration, including: an end effector for a robotic apparatus, wherein the end effector is couplable to the robotic apparatus, and the end effector includes a communication port for coupling to the robotic apparatus, a laser, a camera, and a depth sensor.</div>
</li> <li> <para-num num="[0764]"> </para-num> <div class="description-line" id="p-0765" num="0764">Example G2 includes the subject matter of Example G1, and further specifies that the depth sensor includes a camera array.</div>
</li> <li> <para-num num="[0765]"> </para-num> <div class="description-line" id="p-0766" num="0765">Example G3 includes the subject matter of any of Examples G1-2, and further specifies that the end effector has an axis normal to a lens of the camera, and the camera and the depth sensor are spaced apart in a direction parallel to the axis.</div>
</li> <li> <para-num num="[0766]"> </para-num> <div class="description-line" id="p-0767" num="0766">Example G4 includes the subject matter of Example G3, and further specifies that the camera and the depth sensor are spaced apart by a distance greater than 10 centimeters.</div>
</li> <li> <para-num num="[0767]"> </para-num> <div class="description-line" id="p-0768" num="0767">Example G5 includes the subject matter of any of Examples G1-4, and further specifies that the end effector has an axis normal to a lens of the camera, and the laser is oriented to direct a laser beam parallel to the axis.</div>
</li> <li> <para-num num="[0768]"> </para-num> <div class="description-line" id="p-0769" num="0768">Example G6 includes the subject matter of any of Examples G1-5, and further specifies that the laser is to be powered by an output of a microcontroller of the robotic apparatus.</div>
</li> <li> <para-num num="[0769]"> </para-num> <div class="description-line" id="p-0770" num="0769">Example G7 includes the subject matter of any of Examples G1-6, and further specifies that the camera and depth sensor are controllable via the communication port.</div>
</li> <li> <para-num num="[0770]"> </para-num> <div class="description-line" id="p-0771" num="0770">Example G8 includes the subject matter of any of Examples G1-7, and further specifies that data from the camera and depth sensor is communicable to the robotic apparatus via the communication port.</div>
</li> <li> <para-num num="[0771]"> </para-num> <div class="description-line" id="p-0772" num="0771">Example G9 includes the subject matter of any of Examples G1-8, and further specifies that the communication port is a Universal Serial Bus (USB) port or a Controller Area Network (CAN) port.</div>
</li> <li> <para-num num="[0772]"> </para-num> <div class="description-line" id="p-0773" num="0772">Example G10 includes the subject matter of any of Examples G1-9, and further includes: the robotic apparatus.</div>
</li> <li> <para-num num="[0773]"> </para-num> <div class="description-line" id="p-0774" num="0773">Example G11 includes the subject matter of any of Examples G1-10, and further specifies that the robotic apparatus includes a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0774]"> </para-num> <div class="description-line" id="p-0775" num="0774">Example G12 includes the subject matter of Example G11, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0775]"> </para-num> <div class="description-line" id="p-0776" num="0775">Example G13 includes the subject matter of Example G12, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0776]"> </para-num> <div class="description-line" id="p-0777" num="0776">Example G14 includes the subject matter of any of Examples G1-13, and further specifies that the robotic apparatus includes at least three joints.</div>
</li> <li> <para-num num="[0777]"> </para-num> <div class="description-line" id="p-0778" num="0777">Example G15 includes the subject matter of Example G14, and further specifies that the apparatus includes at least six joints.</div>
</li> <li> <para-num num="[0778]"> </para-num> <div class="description-line" id="p-0779" num="0778">Example G16 includes the subject matter of any of Examples G1-15, and further specifies that the robotic apparatus includes a robotic arm.</div>
</li> <li> <para-num num="[0779]"> </para-num> <div class="description-line" id="p-0780" num="0779">Example G17 includes the subject matter of any of Examples G1-15, and further specifies that the robotic apparatus includes a robotic gantry.</div>
</li> <li> <para-num num="[0780]"> </para-num> <div class="description-line" id="p-0781" num="0780">Example G18 includes the subject matter of any of Examples G1-17, and further specifies that the end effector includes: a mechanical fastener to secure the end effector to the robotic apparatus.</div>
</li> <li> <para-num num="[0781]"> </para-num> <div class="description-line" id="p-0782" num="0781">Example G19 includes the subject matter of any of Examples G1-18, and further includes: a processing device to control operation of the end effector via the robotic apparatus.</div>
</li> <li> <para-num num="[0782]"> </para-num> <div class="description-line" id="p-0783" num="0782">Example G20 includes the subject matter of Example G19, and further specifies that the processing device is in a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0783]"> </para-num> <div class="description-line" id="p-0784" num="0783">Example G21 includes the subject matter of Example G19, and further specifies that the processing device has a housing separate from a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0784]"> </para-num> <div class="description-line" id="p-0785" num="0784">Example G22 includes the subject matter of any of Examples G19, and further specifies that the processing device is included in a desktop computing device, a laptop computing device, or a tablet computing device.</div>
</li> <li> <para-num num="[0785]"> </para-num> <div class="description-line" id="p-0786" num="0785">Example G23 is a method of robotic calibration, including: performing a marker calibration operation, wherein the marker calibration operation includes causing a robotic apparatus to move its end effector to a nominal position associated with a marker on a reference structure, wherein the end effector includes a laser, a camera, and a depth sensor, causing the laser of the end effector to shine a laser beam on the reference structure; using the depth sensor to measure a distance to the reference structure in the direction of the laser beam; and using the camera to capture an image of the reference structure, wherein the image includes the marker and a point of impingement of the laser beam on the reference structure; and repeating the marker calibration operation for different markers on the reference structure.</div>
</li> <li> <para-num num="[0786]"> </para-num> <div class="description-line" id="p-0787" num="0786">Example G24 includes the subject matter of Example G23, and further specifies that the marker calibration operation further includes: causing the robotic apparatus to adjust its position to reduce an error between the marker and the point of impingement.</div>
</li> <li> <para-num num="[0787]"> </para-num> <div class="description-line" id="p-0788" num="0787">Example G25 includes the subject matter of any of Examples G23-24, and further specifies that the robotic apparatus includes a plurality of joint assemblies, and individual ones of the joint assemblies include a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0788]"> </para-num> <div class="description-line" id="p-0789" num="0788">Example G26 includes the subject matter of Example G25, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0789]"> </para-num> <div class="description-line" id="p-0790" num="0789">Example G27 includes the subject matter of any of Examples G23-26, and further specifies that the depth sensor includes a camera array.</div>
</li> <li> <para-num num="[0790]"> </para-num> <div class="description-line" id="p-0791" num="0790">Example G28 includes the subject matter of any of Examples G23-27, and further specifies that the reference structure is a two-dimensional structure.</div>
</li> <li> <para-num num="[0791]"> </para-num> <div class="description-line" id="p-0792" num="0791">Example G29 includes the subject matter of Example G28, and further specifies that the reference structure is a mat.</div>
</li> <li> <para-num num="[0792]"> </para-num> <div class="description-line" id="p-0793" num="0792">Example G30 includes the subject matter of Example G29, and further specifies that the robotic apparatus is to sit on the mat.</div>
</li> <li> <para-num num="[0793]"> </para-num> <div class="description-line" id="p-0794" num="0793">Example G31 includes the subject matter of any of Examples G23-27, and further specifies that the reference structure is a three-dimensional structure.</div>
</li> <li> <para-num num="[0794]"> </para-num> <div class="description-line" id="p-0795" num="0794">Example G32 includes the subject matter of any of Examples G23-31, and further specifies that the marker is printed on a surface of the reference structure.</div>
</li> <li> <para-num num="[0795]"> </para-num> <div class="description-line" id="p-0796" num="0795">Example G33 includes the subject matter of any of Examples G23-32, and further specifies that the reference structure includes a marker label for individual markers.</div>
</li> <li> <para-num num="[0796]"> </para-num> <div class="description-line" id="p-0797" num="0796">Example G34 includes the subject matter of Example G33, and further specifies that the marker label includes a</div>
</li> <li> <para-num num="[0797]"> </para-num> <div class="description-line" id="p-0798" num="0797">Quick Response (QR) code.</div>
</li> <li> <para-num num="[0798]"> </para-num> <div class="description-line" id="p-0799" num="0798">Example G35 is an apparatus for inspection, including: an end effector for a robotic apparatus, wherein the end effector is couplable to the robotic apparatus, and the end effector includes a communication port for coupling to the robotic apparatus, a camera, and a lighting device, wherein a lighting color of the lighting device is controllable via the communication port.</div>
</li> <li> <para-num num="[0799]"> </para-num> <div class="description-line" id="p-0800" num="0799">Example G36 includes the subject matter of Example G35, and further specifies that the lighting device includes one or more light-emitting diodes.</div>
</li> <li> <para-num num="[0800]"> </para-num> <div class="description-line" id="p-0801" num="0800">Example G37 includes the subject matter of Example G36, and further specifies that the lighting device includes a plurality of light-emitting diodes arranged in a ring formation.</div>
</li> <li> <para-num num="[0801]"> </para-num> <div class="description-line" id="p-0802" num="0801">Example G38 includes the subject matter of Example G37, and further specifies that an axis normal to a center of a lens of the camera extends through the ring.</div>
</li> <li> <para-num num="[0802]"> </para-num> <div class="description-line" id="p-0803" num="0802">Example G39 includes the subject matter of any of Examples G35-38, and further specifies that the end effector includes: a depth sensor.</div>
</li> <li> <para-num num="[0803]"> </para-num> <div class="description-line" id="p-0804" num="0803">Example G40 includes the subject matter of Example G39, and further specifies that the depth sensor includes a camera array.</div>
</li> <li> <para-num num="[0804]"> </para-num> <div class="description-line" id="p-0805" num="0804">Example G41 includes the subject matter of any of Examples G39-40, and further specifies that the end effector has an axis normal to a center of a lens of the camera, and the camera and the depth sensor are spaced apart in a direction parallel to the axis.</div>
</li> <li> <para-num num="[0805]"> </para-num> <div class="description-line" id="p-0806" num="0805">Example G42 includes the subject matter of Example G41, and further specifies that the camera and the depth sensor are spaced apart by a distance greater than 10 centimeters.</div>
</li> <li> <para-num num="[0806]"> </para-num> <div class="description-line" id="p-0807" num="0806">Example G43 includes the subject matter of any of Examples G35-42, and further specifies that the camera is a first camera, and the end effector further includes: a second camera, wherein the second camera has a lower resolution than the first camera.</div>
</li> <li> <para-num num="[0807]"> </para-num> <div class="description-line" id="p-0808" num="0807">Example G44 includes the subject matter of any of Examples G35-43, and further specifies that the end effector further includes: an object manipulator.</div>
</li> <li> <para-num num="[0808]"> </para-num> <div class="description-line" id="p-0809" num="0808">Example G45 includes the subject matter of Example G44, and further specifies that the object manipulator includes a suction device.</div>
</li> <li> <para-num num="[0809]"> </para-num> <div class="description-line" id="p-0810" num="0809">Example G46 includes the subject matter of any of Examples G44-45, and further specifies that the object manipulator includes a clamping device.</div>
</li> <li> <para-num num="[0810]"> </para-num> <div class="description-line" id="p-0811" num="0810">Example G47 includes the subject matter of any of Examples G35-47, and further specifies that data from the camera is communicable to the robotic apparatus via the communication port.</div>
</li> <li> <para-num num="[0811]"> </para-num> <div class="description-line" id="p-0812" num="0811">Example G49 includes the subject matter of any of Examples G35-48, and further specifies that the communication port is a Universal Serial Bus (USB) port or a Controller Area Network (CAN) port.</div>
</li> <li> <para-num num="[0812]"> </para-num> <div class="description-line" id="p-0813" num="0812">Example G50 includes the subject matter of any of Examples G35-49, and further includes: the robotic apparatus.</div>
</li> <li> <para-num num="[0813]"> </para-num> <div class="description-line" id="p-0814" num="0813">Example G51 includes the subject matter of any of Examples G35-50, and further specifies that the robotic apparatus includes a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0814]"> </para-num> <div class="description-line" id="p-0815" num="0814">Example G52 includes the subject matter of Example G51, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0815]"> </para-num> <div class="description-line" id="p-0816" num="0815">Example G53 includes the subject matter of Example G52, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0816]"> </para-num> <div class="description-line" id="p-0817" num="0816">Example G54 includes the subject matter of any of Examples G35-53, and further specifies that the robotic apparatus includes at least three joints.</div>
</li> <li> <para-num num="[0817]"> </para-num> <div class="description-line" id="p-0818" num="0817">Example G55 includes the subject matter of Example G54, and further specifies that the apparatus includes at least six joints.</div>
</li> <li> <para-num num="[0818]"> </para-num> <div class="description-line" id="p-0819" num="0818">Example G56 includes the subject matter of any of Examples G35-55, and further specifies that the robotic apparatus includes a robotic arm.</div>
</li> <li> <para-num num="[0819]"> </para-num> <div class="description-line" id="p-0820" num="0819">Example G57 includes the subject matter of any of Examples G35-55, and further specifies that the robotic apparatus includes a robotic gantry.</div>
</li> <li> <para-num num="[0820]"> </para-num> <div class="description-line" id="p-0821" num="0820">Example G58 includes the subject matter of any of Examples G35-57, and further specifies that the end effector includes: a mechanical fastener to secure the end effector to the robotic apparatus.</div>
</li> <li> <para-num num="[0821]"> </para-num> <div class="description-line" id="p-0822" num="0821">Example G59 includes the subject matter of any of Examples G35-58, and further includes: a processing device to control operation of the end effector via the robotic apparatus.</div>
</li> <li> <para-num num="[0822]"> </para-num> <div class="description-line" id="p-0823" num="0822">Example G60 includes the subject matter of Example G59, and further specifies that the processing device is in a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0823]"> </para-num> <div class="description-line" id="p-0824" num="0823">Example G61 includes the subject matter of Example G59, and further specifies that the processing device has a housing separate from a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0824]"> </para-num> <div class="description-line" id="p-0825" num="0824">Example G62 includes the subject matter of Example G59, and further specifies that the processing device is included in a desktop computing device, a laptop computing device, or a tablet computing device.</div>
</li> <li> <para-num num="[0825]"> </para-num> <div class="description-line" id="p-0826" num="0825">Example G63 is a method of inspecting an item, including: causing a robotic apparatus to follow an inspection path to inspect the item, wherein the inspection path includes a set of identified positions to which an end effector of the robotic apparatus is to move; and at each identified position, causing a lighting device of the end effector to illuminate with a controllable light color, and a camera of the end effector to capture an image.</div>
</li> <li> <para-num num="[0826]"> </para-num> <div class="description-line" id="p-0827" num="0826">Example G64 includes the subject matter of Example G63, and further includes: at each identified position, causing a depth sensor of the end effector to measure a depth to the item.</div>
</li> <li> <para-num num="[0827]"> </para-num> <div class="description-line" id="p-0828" num="0827">Example G65 includes the subject matter of Example G64, and further specifies that the depth sensor includes a camera array.</div>
</li> <li> <para-num num="[0828]"> </para-num> <div class="description-line" id="p-0829" num="0828">Example G66 includes the subject matter of any of Examples G64-65, and further specifies that the end effector has an axis normal to a center of a lens of the camera, and the camera and the depth sensor are spaced apart in a direction parallel to the axis.</div>
</li> <li> <para-num num="[0829]"> </para-num> <div class="description-line" id="p-0830" num="0829">Example G67 includes the subject matter of Example G66, and further specifies that the camera and the depth sensor are spaced apart by a distance greater than 10 centimeters.</div>
</li> <li> <para-num num="[0830]"> </para-num> <div class="description-line" id="p-0831" num="0830">Example G68 includes the subject matter of any of Examples G63-67, and further specifies that the lighting device includes one or more light-emitting diodes.</div>
</li> <li> <para-num num="[0831]"> </para-num> <div class="description-line" id="p-0832" num="0831">Example G69 includes the subject matter of Example G68, and further specifies that the lighting device includes a plurality of light-emitting diodes arranged in a ring formation.</div>
</li> <li> <para-num num="[0832]"> </para-num> <div class="description-line" id="p-0833" num="0832">Example G70 includes the subject matter of Example G69, and further specifies that an axis normal to a center of a lens of the second camera extends through the ring.</div>
</li> <li> <para-num num="[0833]"> </para-num> <div class="description-line" id="p-0834" num="0833">Example G71 includes the subject matter of any of Examples G63-70, and further specifies that the camera is a first camera, and the method further includes: causing a second camera of the end effector to capture an overview image of the item, wherein the second camera has a lower resolution than the first camera.</div>
</li> <li> <para-num num="[0834]"> </para-num> <div class="description-line" id="p-0835" num="0834">Example G72 includes the subject matter of any of Examples G63-71, and further includes: causing an object manipulator of the end effector to move the item.</div>
</li> <li> <para-num num="[0835]"> </para-num> <div class="description-line" id="p-0836" num="0835">Example G73 includes the subject matter of Example G72, and further specifies that the object manipulator includes a suction device.</div>
</li> <li> <para-num num="[0836]"> </para-num> <div class="description-line" id="p-0837" num="0836">Example G74 includes the subject matter of any of Examples G72-73, and further specifies that the object manipulator includes a clamping device.</div>
</li> <li> <para-num num="[0837]"> </para-num> <div class="description-line" id="p-0838" num="0837">Example G75 includes the subject matter of any of Examples G63-74, and further specifies that the robotic apparatus includes a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0838]"> </para-num> <div class="description-line" id="p-0839" num="0838">Example G76 includes the subject matter of Example G75, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0839]"> </para-num> <div class="description-line" id="p-0840" num="0839">Example G77 is an apparatus for inspection, including an end effector for a robotic apparatus, wherein the end effector is couplable to the robotic apparatus, and the end effector includes: a communication port for coupling to the robotic apparatus, a camera, and a gimbal, wherein the camera is mechanically coupled to the gimbal.</div>
</li> <li> <para-num num="[0840]"> </para-num> <div class="description-line" id="p-0841" num="0840">Example G78 includes the subject matter of Example G77, and further specifies that the end effector further includes a lighting device, and the lighting device includes one or more light-emitting diodes.</div>
</li> <li> <para-num num="[0841]"> </para-num> <div class="description-line" id="p-0842" num="0841">Example G79 includes the subject matter of Example G78, and further specifies that the lighting device includes a plurality of light-emitting diodes arranged in a ring formation.</div>
</li> <li> <para-num num="[0842]"> </para-num> <div class="description-line" id="p-0843" num="0842">Example G80 includes the subject matter of Example G79, and further specifies that an axis normal to a center of a lens of the camera extends through the ring.</div>
</li> <li> <para-num num="[0843]"> </para-num> <div class="description-line" id="p-0844" num="0843">Example G81 includes the subject matter of any of Examples G77-80, and further specifies that the end effector includes: a depth sensor.</div>
</li> <li> <para-num num="[0844]"> </para-num> <div class="description-line" id="p-0845" num="0844">Example G82 includes the subject matter of any of Examples G77-81, and further specifies that the end effector further includes: an object manipulator.</div>
</li> <li> <para-num num="[0845]"> </para-num> <div class="description-line" id="p-0846" num="0845">Example G83 includes the subject matter of any of Examples G77-84, and further specifies that data from the camera is communicable to the robotic apparatus via the communication port.</div>
</li> <li> <para-num num="[0846]"> </para-num> <div class="description-line" id="p-0847" num="0846">Example G86 includes the subject matter of any of Examples G77-85, and further specifies that the communication port is a Universal Serial Bus (USB) port or a Controller Area Network (CAN) port.</div>
</li> <li> <para-num num="[0847]"> </para-num> <div class="description-line" id="p-0848" num="0847">Example G87 includes the subject matter of any of Examples G77-86, and further includes: the robotic apparatus.</div>
</li> <li> <para-num num="[0848]"> </para-num> <div class="description-line" id="p-0849" num="0848">Example G88 includes the subject matter of any of Examples G77-87, and further specifies that the robotic apparatus includes a stepper motor and a drivetrain.</div>
</li> <li> <para-num num="[0849]"> </para-num> <div class="description-line" id="p-0850" num="0849">Example G89 includes the subject matter of Example G88, and further specifies that the drivetrain has a gear ratio that is less than 30:1.</div>
</li> <li> <para-num num="[0850]"> </para-num> <div class="description-line" id="p-0851" num="0850">Example G90 includes the subject matter of Example G89, and further specifies that the gear ratio is less than 20:1.</div>
</li> <li> <para-num num="[0851]"> </para-num> <div class="description-line" id="p-0852" num="0851">Example G91 includes the subject matter of any of Examples G77-90, and further specifies that the robotic apparatus includes at least three joints.</div>
</li> <li> <para-num num="[0852]"> </para-num> <div class="description-line" id="p-0853" num="0852">Example G92 includes the subject matter of Example G91, and further specifies that the robotic apparatus includes at least six joints.</div>
</li> <li> <para-num num="[0853]"> </para-num> <div class="description-line" id="p-0854" num="0853">Example G93 includes the subject matter of any of Examples G77-92, and further specifies that the robotic apparatus includes a robotic arm.</div>
</li> <li> <para-num num="[0854]"> </para-num> <div class="description-line" id="p-0855" num="0854">Example G94 includes the subject matter of any of Examples G77-92, and further specifies that the robotic apparatus includes a robotic gantry.</div>
</li> <li> <para-num num="[0855]"> </para-num> <div class="description-line" id="p-0856" num="0855">Example G95 includes the subject matter of any of Examples G77-94, and further specifies that the end effector includes: a mechanical fastener to secure the end effector to the robotic apparatus.</div>
</li> <li> <para-num num="[0856]"> </para-num> <div class="description-line" id="p-0857" num="0856">Example G96 includes the subject matter of any of Examples G77-95, and further includes: a processing device to control operation of the end effector via the robotic apparatus.</div>
</li> <li> <para-num num="[0857]"> </para-num> <div class="description-line" id="p-0858" num="0857">Example G97 includes the subject matter of Example G96, and further specifies that the processing device is in a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0858]"> </para-num> <div class="description-line" id="p-0859" num="0858">Example G98 includes the subject matter of Example G96, and further specifies that the processing device has a housing separate from a housing of the robotic apparatus.</div>
</li> <li> <para-num num="[0859]"> </para-num> <div class="description-line" id="p-0860" num="0859">Example G99 includes the subject matter of Example G96, and further specifies that the processing device is included in a desktop computing device, a laptop computing device, or a tablet computing device.</div>
</li> <li> <para-num num="[0860]"> </para-num> <div class="description-line" id="p-0861" num="0860">Example G100 is one or more computer readable media having instructions thereon that, when executed by one or more processing devices of a computing system, cause the computing system to perform any of the methods of Examples G23-34 or Examples G63-75.</div>
</li> <li> <para-num num="[0861]"> </para-num> <div class="description-line" id="p-0862" num="0861">Example G101 is an apparatus for collaborative robotics, including means for performing any of the methods of Examples G23-34 or Examples G63-75.</div>
</li> </ul>
</div>
</section><section itemprop="claims" itemscope="">
<h2>Claims (<span itemprop="count">20</span>)</h2>
<div html="" itemprop="content"><div class="claims" lang="EN" load-source="patent-office" mxw-id="PCLM288057231">
<div class="claim"> <div class="claim" id="CLM-00001" num="00001">
<div class="claim-text"> <b>1</b>. An apparatus for inspection, comprising:
<div class="claim-text">an end effector for a robotic apparatus, wherein the end effector is couplable to the robotic apparatus, and the end effector includes:
<div class="claim-text">a communication port for coupling to the robotic apparatus,</div>
<div class="claim-text">a camera, and</div>
<div class="claim-text">a lighting device, wherein a lighting color of the lighting device is controllable via the communication port.</div>
</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00002" num="00002">
<div class="claim-text"> <b>2</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the lighting device includes one or more light-emitting diodes.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00003" num="00003">
<div class="claim-text"> <b>3</b>. The apparatus of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the lighting device includes a plurality of light-emitting diodes arranged in a ring formation.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00004" num="00004">
<div class="claim-text"> <b>4</b>. The apparatus of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein an axis normal to a center of a lens of the camera extends through the ring.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00005" num="00005">
<div class="claim-text"> <b>5</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the end effector includes:
<div class="claim-text">a depth sensor.</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00006" num="00006">
<div class="claim-text"> <b>6</b>. The apparatus of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the depth sensor includes a camera array.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00007" num="00007">
<div class="claim-text"> <b>7</b>. The apparatus of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the end effector has an axis normal to a center of a lens of the camera, and the camera and the depth sensor are spaced apart in a direction parallel to the axis.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00008" num="00008">
<div class="claim-text"> <b>8</b>. The apparatus of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the camera and the depth sensor are spaced apart by a distance greater than 10 centimeters.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00009" num="00009">
<div class="claim-text"> <b>9</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the end effector further includes:
<div class="claim-text">an object manipulator.</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00010" num="00010">
<div class="claim-text"> <b>10</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">the robotic apparatus.</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00011" num="00011">
<div class="claim-text"> <b>11</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the robotic apparatus includes a stepper motor and a drivetrain.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00012" num="00012">
<div class="claim-text"> <b>12</b>. The apparatus of <claim-ref idref="CLM-00001">claim 1</claim-ref>, further comprising:
<div class="claim-text">a processing device to control operation of the end effector via the robotic apparatus.</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00013" num="00013">
<div class="claim-text"> <b>13</b>. The apparatus of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the processing device is included in a desktop computing device, a laptop computing device, or a tablet computing device.</div>
</div>
</div> <div class="claim"> <div class="claim" id="CLM-00014" num="00014">
<div class="claim-text"> <b>14</b>. An apparatus for inspection, comprising:
<div class="claim-text">an end effector for a robotic apparatus, wherein the end effector is couplable to the robotic apparatus, and the end effector includes:
<div class="claim-text">a communication port for coupling to the robotic apparatus,</div>
<div class="claim-text">a camera, and</div>
<div class="claim-text">a gimbal, wherein the camera is mechanically coupled to the gimbal.</div>
</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00015" num="00015">
<div class="claim-text"> <b>15</b>. The apparatus of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the end effector further includes a lighting device, and the lighting device includes one or more light-emitting diodes.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00016" num="00016">
<div class="claim-text"> <b>16</b>. The apparatus of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the end effector further includes:
<div class="claim-text">an object manipulator.</div> </div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00017" num="00017">
<div class="claim-text"> <b>17</b>. The apparatus of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the camera and the gimbal are controllable via the communication port.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00018" num="00018">
<div class="claim-text"> <b>18</b>. The apparatus of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein data from the camera is communicable to the robotic apparatus via the communication port.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00019" num="00019">
<div class="claim-text"> <b>19</b>. The apparatus of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the communication port is a Universal Serial Bus (USB) port, a Controller Area Network (CAN) port, or an RS-485 port.</div>
</div>
</div> <div class="claim-dependent"> <div class="claim" id="CLM-00020" num="00020">
<div class="claim-text"> <b>20</b>. The apparatus of <claim-ref idref="CLM-00014">claim 14</claim-ref>, further comprising:
<div class="claim-text">the robotic apparatus.</div> </div>
</div>
</div> </div>
</div>
</section>
                </article>
            </search-app>
        </body>
    </html>
    